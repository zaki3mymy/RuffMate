# airflow-variable-name-task-id-mismatch (AIR001)

Derived from the **Airflow** linter.

## What it does
Checks that the task variable name matches the `task_id` value for
Airflow Operators.

## Why is this bad?
When initializing an Airflow Operator, for consistency, the variable
name should match the `task_id` value. This makes it easier to
follow the flow of the DAG.

## Example
```python
from airflow.operators import PythonOperator


incorrect_name = PythonOperator(task_id="my_task")
```

Use instead:
```python
from airflow.operators import PythonOperator


my_task = PythonOperator(task_id="my_task")
```

# airflow-dag-no-schedule-argument (AIR002)

Derived from the **Airflow** linter.

## What it does
Checks for a `DAG()` class or `@dag()` decorator without an explicit
`schedule` (or `schedule_interval` for Airflow 1) parameter.

## Why is this bad?
The default value of the `schedule` parameter on Airflow 2 and
`schedule_interval` on Airflow 1 is `timedelta(days=1)`, which is almost
never what a user is looking for. Airflow 3 changed the default value to `None`,
and would break existing dags using the implicit default.

If your dag does not have an explicit `schedule` / `schedule_interval` argument,
Airflow 2 schedules a run for it every day (at the time determined by `start_date`).
Such a dag will no longer be scheduled on Airflow 3 at all, without any
exceptions or other messages visible to the user.

## Example
```python
from airflow import DAG


# Using the implicit default schedule.
dag = DAG(dag_id="my_dag")
```

Use instead:
```python
from datetime import timedelta

from airflow import DAG


dag = DAG(dag_id="my_dag", schedule=timedelta(days=1))
```

# airflow3-removal (AIR301)

Derived from the **Airflow** linter.

Fix is sometimes available.

## What it does
Checks for uses of deprecated Airflow functions and values.

## Why is this bad?
Airflow 3.0 removed various deprecated functions, members, and other
values. Some have more modern replacements. Others are considered too niche
and not worth continued maintenance in Airflow.

## Example
```python
from airflow.utils.dates import days_ago


yesterday = days_ago(today, 1)
```

Use instead:
```python
from datetime import timedelta


yesterday = today - timedelta(days=1)
```

# airflow3-moved-to-provider (AIR302)

Derived from the **Airflow** linter.

Fix is sometimes available.

## What it does
Checks for uses of Airflow functions and values that have been moved to its providers
(e.g., `apache-airflow-providers-fab`).

## Why is this bad?
Airflow 3.0 moved various deprecated functions, members, and other
values to its providers. The user needs to install the corresponding provider and replace
the original usage with the one in the provider.

## Example
```python
from airflow.auth.managers.fab.fab_auth_manager import FabAuthManager

fab_auth_manager_app = FabAuthManager().get_fastapi_app()
```

Use instead:
```python
from airflow.providers.fab.auth_manager.fab_auth_manager import FabAuthManager

fab_auth_manager_app = FabAuthManager().get_fastapi_app()
```

# airflow3-suggested-update (AIR311)

Derived from the **Airflow** linter.

Fix is sometimes available.

## What it does
Checks for uses of deprecated Airflow functions and values that still have
a compatibility layer.

## Why is this bad?
Airflow 3.0 removed various deprecated functions, members, and other
values. Some have more modern replacements. Others are considered too niche
and not worth continued maintenance in Airflow.
Even though these symbols still work fine on Airflow 3.0, they are expected to be removed in a future version.
Where available, users should replace the removed functionality with the new alternatives.

## Example
```python
from airflow import Dataset


Dataset(uri="test://test/")
```

Use instead:
```python
from airflow.sdk import Asset


Asset(uri="test://test/")
```

# airflow3-suggested-to-move-to-provider (AIR312)

Derived from the **Airflow** linter.

Fix is sometimes available.

## What it does
Checks for uses of Airflow functions and values that have been moved to its providers
but still have a compatibility layer (e.g., `apache-airflow-providers-standard`).

## Why is this bad?
Airflow 3.0 moved various deprecated functions, members, and other
values to its providers. Even though these symbols still work fine on Airflow 3.0,
they are expected to be removed in a future version. The user is suggested to install
the corresponding provider and replace the original usage with the one in the provider.

## Example
```python
from airflow.operators.python import PythonOperator


def print_context(ds=None, **kwargs):
    print(kwargs)
    print(ds)


print_the_context = PythonOperator(
    task_id="print_the_context", python_callable=print_context
)
```

Use instead:
```python
from airflow.providers.standard.operators.python import PythonOperator


def print_context(ds=None, **kwargs):
    print(kwargs)
    print(ds)


print_the_context = PythonOperator(
    task_id="print_the_context", python_callable=print_context
)
```

# commented-out-code (ERA001)

Derived from the **eradicate** linter.

## What it does
Checks for commented-out Python code.

## Why is this bad?
Commented-out code is dead code, and is often included inadvertently.
It should be removed.

## Known problems
Prone to false positives when checking comments that resemble Python code,
but are not actually Python code ([#4845]).

## Example
```python
# print("Hello, world!")
```

## Options
- `lint.task-tags`

[#4845]: https://github.com/astral-sh/ruff/issues/4845

# fast-api-redundant-response-model (FAST001)

Derived from the **FastAPI** linter.

Fix is always available.

## What it does
Checks for FastAPI routes that use the optional `response_model` parameter
with the same type as the return type.

## Why is this bad?
FastAPI routes automatically infer the response model type from the return
type, so specifying it explicitly is redundant.

The `response_model` parameter is used to override the default response
model type. For example, `response_model` can be used to specify that
a non-serializable response type should instead be serialized via an
alternative type.

For more information, see the [FastAPI documentation](https://fastapi.tiangolo.com/tutorial/response-model/).

## Example

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()


class Item(BaseModel):
    name: str


@app.post("/items/", response_model=Item)
async def create_item(item: Item) -> Item:
    return item
```

Use instead:

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()


class Item(BaseModel):
    name: str


@app.post("/items/")
async def create_item(item: Item) -> Item:
    return item
```

# fast-api-non-annotated-dependency (FAST002)

Derived from the **FastAPI** linter.

Fix is sometimes available.

## What it does
Identifies FastAPI routes with deprecated uses of `Depends` or similar.

## Why is this bad?
The [FastAPI documentation] recommends the use of [`typing.Annotated`][typing-annotated]
for defining route dependencies and parameters, rather than using `Depends`,
`Query` or similar as a default value for a parameter. Using this approach
everywhere helps ensure consistency and clarity in defining dependencies
and parameters.

`Annotated` was added to the `typing` module in Python 3.9; however,
the third-party [`typing_extensions`][typing-extensions] package
provides a backport that can be used on older versions of Python.

## Example

```python
from fastapi import Depends, FastAPI

app = FastAPI()


async def common_parameters(q: str | None = None, skip: int = 0, limit: int = 100):
    return {"q": q, "skip": skip, "limit": limit}


@app.get("/items/")
async def read_items(commons: dict = Depends(common_parameters)):
    return commons
```

Use instead:

```python
from typing import Annotated

from fastapi import Depends, FastAPI

app = FastAPI()


async def common_parameters(q: str | None = None, skip: int = 0, limit: int = 100):
    return {"q": q, "skip": skip, "limit": limit}


@app.get("/items/")
async def read_items(commons: Annotated[dict, Depends(common_parameters)]):
    return commons
```

## Fix safety
This fix is always unsafe, as adding/removing/changing a function parameter's
default value can change runtime behavior. Additionally, comments inside the
deprecated uses might be removed.

## Availability

Because this rule relies on the third-party `typing_extensions` module for Python versions
before 3.9, if the target version is < 3.9 and `typing_extensions` imports have been
disabled by the [`lint.typing-extensions`] linter option the diagnostic will not be emitted
and no fix will be offered.

## Options

- `lint.typing-extensions`

[FastAPI documentation]: https://fastapi.tiangolo.com/tutorial/query-params-str-validations/?h=annotated#advantages-of-annotated
[typing-annotated]: https://docs.python.org/3/library/typing.html#typing.Annotated
[typing-extensions]: https://typing-extensions.readthedocs.io/en/stable/

# fast-api-unused-path-parameter (FAST003)

Derived from the **FastAPI** linter.

Fix is sometimes available.

## What it does
Identifies FastAPI routes that declare path parameters in the route path
that are not included in the function signature.

## Why is this bad?
Path parameters are used to extract values from the URL path.

If a path parameter is declared in the route path but not in the function
signature, it will not be accessible in the function body, which is likely
a mistake.

If a path parameter is declared in the route path, but as a positional-only
argument in the function signature, it will also not be accessible in the
function body, as FastAPI will not inject the parameter.

## Known problems
If the path parameter is _not_ a valid Python identifier (e.g., `user-id`, as
opposed to `user_id`), FastAPI will normalize it. However, this rule simply
ignores such path parameters, as FastAPI's normalization behavior is undocumented.

## Example

```python
from fastapi import FastAPI

app = FastAPI()


@app.get("/things/{thing_id}")
async def read_thing(query: str): ...
```

Use instead:

```python
from fastapi import FastAPI

app = FastAPI()


@app.get("/things/{thing_id}")
async def read_thing(thing_id: int, query: str): ...
```

## Fix safety
This rule's fix is marked as unsafe, as modifying a function signature can
change the behavior of the code.

# sys-version-slice3 (YTT101)

Derived from the **flake8-2020** linter.

## What it does
Checks for uses of `sys.version[:3]`.

## Why is this bad?
If the current major or minor version consists of multiple digits,
`sys.version[:3]` will truncate the version number (e.g., `"3.10"` would
become `"3.1"`). This is likely unintended, and can lead to subtle bugs if
the version string is used to test against a specific Python version.

Instead, use `sys.version_info` to access the current major and minor
version numbers as a tuple, which can be compared to other tuples
without issue.

## Example
```python
import sys

sys.version[:3]  # Evaluates to "3.1" on Python 3.10.
```

Use instead:
```python
import sys

sys.version_info[:2]  # Evaluates to (3, 10) on Python 3.10.
```

## References
- [Python documentation: `sys.version`](https://docs.python.org/3/library/sys.html#sys.version)
- [Python documentation: `sys.version_info`](https://docs.python.org/3/library/sys.html#sys.version_info)

# sys-version2 (YTT102)

Derived from the **flake8-2020** linter.

## What it does
Checks for uses of `sys.version[2]`.

## Why is this bad?
If the current major or minor version consists of multiple digits,
`sys.version[2]` will select the first digit of the minor number only
(e.g., `"3.10"` would evaluate to `"1"`). This is likely unintended, and
can lead to subtle bugs if the version is used to test against a minor
version number.

Instead, use `sys.version_info.minor` to access the current minor version
number.

## Example
```python
import sys

sys.version[2]  # Evaluates to "1" on Python 3.10.
```

Use instead:
```python
import sys

f"{sys.version_info.minor}"  # Evaluates to "10" on Python 3.10.
```

## References
- [Python documentation: `sys.version`](https://docs.python.org/3/library/sys.html#sys.version)
- [Python documentation: `sys.version_info`](https://docs.python.org/3/library/sys.html#sys.version_info)

# sys-version-cmp-str3 (YTT103)

Derived from the **flake8-2020** linter.

## What it does
Checks for comparisons that test `sys.version` against string literals,
such that the comparison will evaluate to `False` on Python 3.10 or later.

## Why is this bad?
Comparing `sys.version` to a string is error-prone and may cause subtle
bugs, as the comparison will be performed lexicographically, not
semantically. For example, `sys.version > "3.9"` will evaluate to `False`
when using Python 3.10, as `"3.10"` is lexicographically "less" than
`"3.9"`.

Instead, use `sys.version_info` to access the current major and minor
version numbers as a tuple, which can be compared to other tuples
without issue.

## Example
```python
import sys

sys.version > "3.9"  # `False` on Python 3.10.
```

Use instead:
```python
import sys

sys.version_info > (3, 9)  # `True` on Python 3.10.
```

## References
- [Python documentation: `sys.version`](https://docs.python.org/3/library/sys.html#sys.version)
- [Python documentation: `sys.version_info`](https://docs.python.org/3/library/sys.html#sys.version_info)

# sys-version-info0-eq3 (YTT201)

Derived from the **flake8-2020** linter.

## What it does
Checks for equality comparisons against the major version returned by
`sys.version_info` (e.g., `sys.version_info[0] == 3` or `sys.version_info[0] != 3`).

## Why is this bad?
Using `sys.version_info[0] == 3` to verify that the major version is
Python 3 or greater will fail if the major version number is ever
incremented (e.g., to Python 4). This is likely unintended, as code
that uses this comparison is likely intended to be run on Python 2,
but would now run on Python 4 too. Similarly, using `sys.version_info[0] != 3`
to check for Python 2 will also fail if the major version number is
incremented.

Instead, use `>=` to check if the major version number is 3 or greater,
or `<` to check if the major version number is less than 3, to future-proof
the code.

## Example
```python
import sys

if sys.version_info[0] == 3:
    ...
else:
    print("Python 2")  # This will be printed on Python 4.
```

Use instead:
```python
import sys

if sys.version_info >= (3,):
    ...
else:
    print("Python 2")  # This will not be printed on Python 4.
```

## References
- [Python documentation: `sys.version`](https://docs.python.org/3/library/sys.html#sys.version)
- [Python documentation: `sys.version_info`](https://docs.python.org/3/library/sys.html#sys.version_info)

# six-py3 (YTT202)

Derived from the **flake8-2020** linter.

## What it does
Checks for uses of `six.PY3`.

## Why is this bad?
`six.PY3` will evaluate to `False` on Python 4 and greater. This is likely
unintended, and may cause code intended to run on Python 2 to run on Python 4
too.

Instead, use `not six.PY2` to validate that the current Python major version is
_not_ equal to 2, to future-proof the code.

## Example
```python
import six

six.PY3  # `False` on Python 4.
```

Use instead:
```python
import six

not six.PY2  # `True` on Python 4.
```

## References
- [PyPI: `six`](https://pypi.org/project/six/)
- [Six documentation: `six.PY2`](https://six.readthedocs.io/#six.PY2)
- [Six documentation: `six.PY3`](https://six.readthedocs.io/#six.PY3)

# sys-version-info1-cmp-int (YTT203)

Derived from the **flake8-2020** linter.

## What it does
Checks for comparisons that test `sys.version_info[1]` against an integer.

## Why is this bad?
Comparisons based on the current minor version number alone can cause
subtle bugs and would likely lead to unintended effects if the Python
major version number were ever incremented (e.g., to Python 4).

Instead, compare `sys.version_info` to a tuple, including the major and
minor version numbers, to future-proof the code.

## Example
```python
import sys

if sys.version_info[1] < 7:
    print("Python 3.6 or earlier.")  # This will be printed on Python 4.0.
```

Use instead:
```python
import sys

if sys.version_info < (3, 7):
    print("Python 3.6 or earlier.")
```

## References
- [Python documentation: `sys.version`](https://docs.python.org/3/library/sys.html#sys.version)
- [Python documentation: `sys.version_info`](https://docs.python.org/3/library/sys.html#sys.version_info)

# sys-version-info-minor-cmp-int (YTT204)

Derived from the **flake8-2020** linter.

## What it does
Checks for comparisons that test `sys.version_info.minor` against an integer.

## Why is this bad?
Comparisons based on the current minor version number alone can cause
subtle bugs and would likely lead to unintended effects if the Python
major version number were ever incremented (e.g., to Python 4).

Instead, compare `sys.version_info` to a tuple, including the major and
minor version numbers, to future-proof the code.

## Example
```python
import sys

if sys.version_info.minor < 7:
    print("Python 3.6 or earlier.")  # This will be printed on Python 4.0.
```

Use instead:
```python
import sys

if sys.version_info < (3, 7):
    print("Python 3.6 or earlier.")
```

## References
- [Python documentation: `sys.version`](https://docs.python.org/3/library/sys.html#sys.version)
- [Python documentation: `sys.version_info`](https://docs.python.org/3/library/sys.html#sys.version_info)

# sys-version0 (YTT301)

Derived from the **flake8-2020** linter.

## What it does
Checks for uses of `sys.version[0]`.

## Why is this bad?
If the current major or minor version consists of multiple digits,
`sys.version[0]` will select the first digit of the major version number
only (e.g., `"10.2"` would evaluate to `"1"`). This is likely unintended,
and can lead to subtle bugs if the version string is used to test against a
major version number.

Instead, use `sys.version_info.major` to access the current major version
number.

## Example
```python
import sys

sys.version[0]  # If using Python 10, this evaluates to "1".
```

Use instead:
```python
import sys

f"{sys.version_info.major}"  # If using Python 10, this evaluates to "10".
```

## References
- [Python documentation: `sys.version`](https://docs.python.org/3/library/sys.html#sys.version)
- [Python documentation: `sys.version_info`](https://docs.python.org/3/library/sys.html#sys.version_info)

# sys-version-cmp-str10 (YTT302)

Derived from the **flake8-2020** linter.

## What it does
Checks for comparisons that test `sys.version` against string literals,
such that the comparison would fail if the major version number were
ever incremented to Python 10 or higher.

## Why is this bad?
Comparing `sys.version` to a string is error-prone and may cause subtle
bugs, as the comparison will be performed lexicographically, not
semantically.

Instead, use `sys.version_info` to access the current major and minor
version numbers as a tuple, which can be compared to other tuples
without issue.

## Example
```python
import sys

sys.version >= "3"  # `False` on Python 10.
```

Use instead:
```python
import sys

sys.version_info >= (3,)  # `True` on Python 10.
```

## References
- [Python documentation: `sys.version`](https://docs.python.org/3/library/sys.html#sys.version)
- [Python documentation: `sys.version_info`](https://docs.python.org/3/library/sys.html#sys.version_info)

# sys-version-slice1 (YTT303)

Derived from the **flake8-2020** linter.

## What it does
Checks for uses of `sys.version[:1]`.

## Why is this bad?
If the major version number consists of more than one digit, this will
select the first digit of the major version number only (e.g., `"10.0"`
would evaluate to `"1"`). This is likely unintended, and can lead to subtle
bugs in future versions of Python if the version string is used to test
against a specific major version number.

Instead, use `sys.version_info.major` to access the current major version
number.

## Example
```python
import sys

sys.version[:1]  # If using Python 10, this evaluates to "1".
```

Use instead:
```python
import sys

f"{sys.version_info.major}"  # If using Python 10, this evaluates to "10".
```

## References
- [Python documentation: `sys.version`](https://docs.python.org/3/library/sys.html#sys.version)
- [Python documentation: `sys.version_info`](https://docs.python.org/3/library/sys.html#sys.version_info)

# missing-type-function-argument (ANN001)

Derived from the **flake8-annotations** linter.

## What it does
Checks that function arguments have type annotations.

## Why is this bad?
Type annotations are a good way to document the types of function arguments. They also
help catch bugs, when used alongside a type checker, by ensuring that the types of
any provided arguments match expectation.

## Example

```python
def foo(x): ...
```

Use instead:

```python
def foo(x: int): ...
```

## Options
- `lint.flake8-annotations.suppress-dummy-args`

# missing-type-args (ANN002)

Derived from the **flake8-annotations** linter.

## What it does
Checks that function `*args` arguments have type annotations.

## Why is this bad?
Type annotations are a good way to document the types of function arguments. They also
help catch bugs, when used alongside a type checker, by ensuring that the types of
any provided arguments match expectation.

## Example

```python
def foo(*args): ...
```

Use instead:

```python
def foo(*args: int): ...
```

## Options
- `lint.flake8-annotations.suppress-dummy-args`

# missing-type-kwargs (ANN003)

Derived from the **flake8-annotations** linter.

## What it does
Checks that function `**kwargs` arguments have type annotations.

## Why is this bad?
Type annotations are a good way to document the types of function arguments. They also
help catch bugs, when used alongside a type checker, by ensuring that the types of
any provided arguments match expectation.

## Example

```python
def foo(**kwargs): ...
```

Use instead:

```python
def foo(**kwargs: int): ...
```

## Options
- `lint.flake8-annotations.suppress-dummy-args`

# missing-type-self (ANN101)

Derived from the **flake8-annotations** linter.

## Removed
This rule has been removed because type checkers can infer this type without annotation.

## What it does
Checks that instance method `self` arguments have type annotations.

## Why is this bad?
Type annotations are a good way to document the types of function arguments. They also
help catch bugs, when used alongside a type checker, by ensuring that the types of
any provided arguments match expectation.

Note that many type checkers will infer the type of `self` automatically, so this
annotation is not strictly necessary.

## Example

```python
class Foo:
    def bar(self): ...
```

Use instead:

```python
class Foo:
    def bar(self: "Foo"): ...
```

# missing-type-cls (ANN102)

Derived from the **flake8-annotations** linter.

## Removed
This rule has been removed because type checkers can infer this type without annotation.

## What it does
Checks that class method `cls` arguments have type annotations.

## Why is this bad?
Type annotations are a good way to document the types of function arguments. They also
help catch bugs, when used alongside a type checker, by ensuring that the types of
any provided arguments match expectation.

Note that many type checkers will infer the type of `cls` automatically, so this
annotation is not strictly necessary.

## Example

```python
class Foo:
    @classmethod
    def bar(cls): ...
```

Use instead:

```python
class Foo:
    @classmethod
    def bar(cls: Type["Foo"]): ...
```

# missing-return-type-undocumented-public-function (ANN201)

Derived from the **flake8-annotations** linter.

Fix is sometimes available.

## What it does
Checks that public functions and methods have return type annotations.

## Why is this bad?
Type annotations are a good way to document the return types of functions. They also
help catch bugs, when used alongside a type checker, by ensuring that the types of
any returned values, and the types expected by callers, match expectation.

## Example
```python
def add(a, b):
    return a + b
```

Use instead:
```python
def add(a: int, b: int) -> int:
    return a + b
```

## Availability

Because this rule relies on the third-party `typing_extensions` module for some Python versions,
its diagnostic will not be emitted, and no fix will be offered, if `typing_extensions` imports
have been disabled by the [`lint.typing-extensions`] linter option.

## Options

- `lint.typing-extensions`

# missing-return-type-private-function (ANN202)

Derived from the **flake8-annotations** linter.

Fix is sometimes available.

## What it does
Checks that private functions and methods have return type annotations.

## Why is this bad?
Type annotations are a good way to document the return types of functions. They also
help catch bugs, when used alongside a type checker, by ensuring that the types of
any returned values, and the types expected by callers, match expectation.

## Example
```python
def _add(a, b):
    return a + b
```

Use instead:
```python
def _add(a: int, b: int) -> int:
    return a + b
```

## Availability

Because this rule relies on the third-party `typing_extensions` module for some Python versions,
its diagnostic will not be emitted, and no fix will be offered, if `typing_extensions` imports
have been disabled by the [`lint.typing-extensions`] linter option.

## Options

- `lint.typing-extensions`

# missing-return-type-special-method (ANN204)

Derived from the **flake8-annotations** linter.

Fix is sometimes available.

## What it does
Checks that "special" methods, like `__init__`, `__new__`, and `__call__`, have
return type annotations.

## Why is this bad?
Type annotations are a good way to document the return types of functions. They also
help catch bugs, when used alongside a type checker, by ensuring that the types of
any returned values, and the types expected by callers, match expectation.

Note that type checkers often allow you to omit the return type annotation for
`__init__` methods, as long as at least one argument has a type annotation. To
opt in to this behavior, use the `mypy-init-return` setting in your `pyproject.toml`
or `ruff.toml` file:

```toml
[tool.ruff.lint.flake8-annotations]
mypy-init-return = true
```

## Example
```python
class Foo:
    def __init__(self, x: int):
        self.x = x
```

Use instead:
```python
class Foo:
    def __init__(self, x: int) -> None:
        self.x = x
```

# missing-return-type-static-method (ANN205)

Derived from the **flake8-annotations** linter.

Fix is sometimes available.

## What it does
Checks that static methods have return type annotations.

## Why is this bad?
Type annotations are a good way to document the return types of functions. They also
help catch bugs, when used alongside a type checker, by ensuring that the types of
any returned values, and the types expected by callers, match expectation.

## Example
```python
class Foo:
    @staticmethod
    def bar():
        return 1
```

Use instead:
```python
class Foo:
    @staticmethod
    def bar() -> int:
        return 1
```

# missing-return-type-class-method (ANN206)

Derived from the **flake8-annotations** linter.

Fix is sometimes available.

## What it does
Checks that class methods have return type annotations.

## Why is this bad?
Type annotations are a good way to document the return types of functions. They also
help catch bugs, when used alongside a type checker, by ensuring that the types of
any returned values, and the types expected by callers, match expectation.

## Example
```python
class Foo:
    @classmethod
    def bar(cls):
        return 1
```

Use instead:
```python
class Foo:
    @classmethod
    def bar(cls) -> int:
        return 1
```

# any-type (ANN401)

Derived from the **flake8-annotations** linter.

## What it does
Checks that function arguments are annotated with a more specific type than
`Any`.

## Why is this bad?
`Any` is a special type indicating an unconstrained type. When an
expression is annotated with type `Any`, type checkers will allow all
operations on it.

It's better to be explicit about the type of an expression, and to use
`Any` as an "escape hatch" only when it is really needed.

## Example

```python
from typing import Any


def foo(x: Any): ...
```

Use instead:

```python
def foo(x: int): ...
```

## Known problems

Type aliases are unsupported and can lead to false positives.
For example, the following will trigger this rule inadvertently:

```python
from typing import Any

MyAny = Any


def foo(x: MyAny): ...
```

## Options
- `lint.flake8-annotations.allow-star-arg-any`

## References
- [Typing spec: `Any`](https://typing.python.org/en/latest/spec/special-types.html#any)
- [Python documentation: `typing.Any`](https://docs.python.org/3/library/typing.html#typing.Any)
- [Mypy documentation: The Any type](https://mypy.readthedocs.io/en/stable/kinds_of_types.html#the-any-type)

# cancel-scope-no-checkpoint (ASYNC100)

Derived from the **flake8-async** linter.

## What it does
Checks for timeout context managers which do not contain a checkpoint.

For the purposes of this check, `yield` is considered a checkpoint,
since checkpoints may occur in the caller to which we yield.

## Why is this bad?
Some asynchronous context managers, such as `asyncio.timeout` and
`trio.move_on_after`, have no effect unless they contain a checkpoint.
The use of such context managers without an `await`, `async with` or
`async for` statement is likely a mistake.

## Example
```python
import asyncio


async def func():
    async with asyncio.timeout(2):
        do_something()
```

Use instead:
```python
import asyncio


async def func():
    async with asyncio.timeout(2):
        do_something()
        await awaitable()
```

## References
- [`asyncio` timeouts](https://docs.python.org/3/library/asyncio-task.html#timeouts)
- [`anyio` timeouts](https://anyio.readthedocs.io/en/stable/cancellation.html)
- [`trio` timeouts](https://trio.readthedocs.io/en/stable/reference-core.html#cancellation-and-timeouts)

# trio-sync-call (ASYNC105)

Derived from the **flake8-async** linter.

Fix is sometimes available.

## What it does
Checks for calls to trio functions that are not immediately awaited.

## Why is this bad?
Many of the functions exposed by trio are asynchronous, and must be awaited
to take effect. Calling a trio function without an `await` can lead to
`RuntimeWarning` diagnostics and unexpected behaviour.

## Example
```python
import trio


async def double_sleep(x):
    trio.sleep(2 * x)
```

Use instead:
```python
import trio


async def double_sleep(x):
    await trio.sleep(2 * x)
```

## Fix safety
This rule's fix is marked as unsafe, as adding an `await` to a function
call changes its semantics and runtime behavior.

# async-function-with-timeout (ASYNC109)

Derived from the **flake8-async** linter.

## What it does
Checks for `async` function definitions with `timeout` parameters.

## Why is this bad?
Rather than implementing asynchronous timeout behavior manually, prefer
built-in timeout functionality, such as `asyncio.timeout`, `trio.fail_after`,
or `anyio.move_on_after`, among others.

This rule is highly opinionated to enforce a design pattern
called ["structured concurrency"] that allows for
`async` functions to be oblivious to timeouts,
instead letting callers to handle the logic with a context manager.

## Details

This rule attempts to detect which async framework your code is using
by analysing the imports in the file it's checking. If it sees an
`anyio` import in your code, it will assume `anyio` is your framework
of choice; if it sees a `trio` import, it will assume `trio`; if it
sees neither, it will assume `asyncio`. `asyncio.timeout` was added
in Python 3.11, so if `asyncio` is detected as the framework being used,
this rule will be ignored when your configured [`target-version`] is set
to less than Python 3.11.

For functions that wrap `asyncio.timeout`, `trio.fail_after` or
`anyio.move_on_after`, false positives from this rule can be avoided
by using a different parameter name.

## Example

```python
async def long_running_task(timeout): ...


async def main():
    await long_running_task(timeout=2)
```

Use instead:

```python
async def long_running_task(): ...


async def main():
    async with asyncio.timeout(2):
        await long_running_task()
```

## References
- [`asyncio` timeouts](https://docs.python.org/3/library/asyncio-task.html#timeouts)
- [`anyio` timeouts](https://anyio.readthedocs.io/en/stable/cancellation.html)
- [`trio` timeouts](https://trio.readthedocs.io/en/stable/reference-core.html#cancellation-and-timeouts)

["structured concurrency"]: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#timeouts-and-cancellation

# async-busy-wait (ASYNC110)

Derived from the **flake8-async** linter.

## What it does
Checks for the use of an async sleep function in a `while` loop.

## Why is this bad?
Instead of sleeping in a `while` loop, and waiting for a condition
to become true, it's preferable to `await` on an `Event` object such
as: `asyncio.Event`, `trio.Event`, or `anyio.Event`.

## Example
```python
import asyncio

DONE = False


async def func():
    while not DONE:
        await asyncio.sleep(1)
```

Use instead:
```python
import asyncio

DONE = asyncio.Event()


async def func():
    await DONE.wait()
```

## References
- [`asyncio` events](https://docs.python.org/3/library/asyncio-sync.html#asyncio.Event)
- [`anyio` events](https://anyio.readthedocs.io/en/latest/api.html#anyio.Event)
- [`trio` events](https://trio.readthedocs.io/en/latest/reference-core.html#trio.Event)

# async-zero-sleep (ASYNC115)

Derived from the **flake8-async** linter.

Fix is always available.

## What it does
Checks for uses of `trio.sleep(0)` or `anyio.sleep(0)`.

## Why is this bad?
`trio.sleep(0)` is equivalent to calling `trio.lowlevel.checkpoint()`.
However, the latter better conveys the intent of the code.

## Example
```python
import trio


async def func():
    await trio.sleep(0)
```

Use instead:
```python
import trio


async def func():
    await trio.lowlevel.checkpoint()
```
## Fix safety
This rule's fix is marked as unsafe if there's comments in the
`trio.sleep(0)` expression, as comments may be removed.

For example, the fix would be marked as unsafe in the following case:
```python
import trio


async def func():
    await trio.sleep(  # comment
        # comment
        0
    )
```

# long-sleep-not-forever (ASYNC116)

Derived from the **flake8-async** linter.

Fix is sometimes available.

## What it does
Checks for uses of `trio.sleep()` or `anyio.sleep()` with a delay greater than 24 hours.

## Why is this bad?
Calling `sleep()` with a delay greater than 24 hours is usually intended
to sleep indefinitely. Instead of using a large delay,
`trio.sleep_forever()` or `anyio.sleep_forever()` better conveys the intent.


## Example
```python
import trio


async def func():
    await trio.sleep(86401)
```

Use instead:
```python
import trio


async def func():
    await trio.sleep_forever()
```

## Fix safety

This fix is marked as unsafe as it changes program behavior.

# blocking-http-call-in-async-function (ASYNC210)

Derived from the **flake8-async** linter.

## What it does
Checks that async functions do not contain blocking HTTP calls.

## Why is this bad?
Blocking an async function via a blocking HTTP call will block the entire
event loop, preventing it from executing other tasks while waiting for the
HTTP response, negating the benefits of asynchronous programming.

Instead of making a blocking HTTP call, use an asynchronous HTTP client
library such as `aiohttp` or `httpx`.

## Example
```python
import urllib


async def fetch():
    urllib.request.urlopen("https://example.com/foo/bar").read()
```

Use instead:
```python
import aiohttp


async def fetch():
    async with aiohttp.ClientSession() as session:
        async with session.get("https://example.com/foo/bar") as resp:
            ...
```

# blocking-http-call-httpx-in-async-function (ASYNC212)

Derived from the **flake8-async** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks that async functions do not use blocking httpx clients.

## Why is this bad?
Blocking an async function via a blocking HTTP call will block the entire
event loop, preventing it from executing other tasks while waiting for the
HTTP response, negating the benefits of asynchronous programming.

Instead of using the blocking `httpx` client, use the asynchronous client.

## Example
```python
import httpx


async def fetch():
    client = httpx.Client()
    response = client.get(...)
```

Use instead:
```python
import httpx


async def fetch():
    async with httpx.AsyncClient() as client:
        response = await client.get(...)
```

# create-subprocess-in-async-function (ASYNC220)

Derived from the **flake8-async** linter.

## What it does
Checks that async functions do not create subprocesses with blocking methods.

## Why is this bad?
Blocking an async function via a blocking call will block the entire
event loop, preventing it from executing other tasks while waiting for the
call to complete, negating the benefits of asynchronous programming.

Instead of making a blocking call, use an equivalent asynchronous library
or function, like [`trio.run_process()`](https://trio.readthedocs.io/en/stable/reference-io.html#trio.run_process)
or [`anyio.run_process()`](https://anyio.readthedocs.io/en/latest/api.html#anyio.run_process).

## Example
```python
import os


async def foo():
    os.popen(cmd)
```

Use instead:
```python
import asyncio


async def foo():
    asyncio.create_subprocess_shell(cmd)
```

# run-process-in-async-function (ASYNC221)

Derived from the **flake8-async** linter.

## What it does
Checks that async functions do not run processes with blocking methods.

## Why is this bad?
Blocking an async function via a blocking call will block the entire
event loop, preventing it from executing other tasks while waiting for the
call to complete, negating the benefits of asynchronous programming.

Instead of making a blocking call, use an equivalent asynchronous library
or function, like [`trio.run_process()`](https://trio.readthedocs.io/en/stable/reference-io.html#trio.run_process)
or [`anyio.run_process()`](https://anyio.readthedocs.io/en/latest/api.html#anyio.run_process).

## Example
```python
import subprocess


async def foo():
    subprocess.run(cmd)
```

Use instead:
```python
import asyncio


async def foo():
    asyncio.create_subprocess_shell(cmd)
```

# wait-for-process-in-async-function (ASYNC222)

Derived from the **flake8-async** linter.

## What it does
Checks that async functions do not wait on processes with blocking methods.

## Why is this bad?
Blocking an async function via a blocking call will block the entire
event loop, preventing it from executing other tasks while waiting for the
call to complete, negating the benefits of asynchronous programming.

Instead of making a blocking call, use an equivalent asynchronous library
or function, like [`trio.to_thread.run_sync()`](https://trio.readthedocs.io/en/latest/reference-core.html#trio.to_thread.run_sync)
or [`anyio.to_thread.run_sync()`](https://anyio.readthedocs.io/en/latest/api.html#anyio.to_thread.run_sync).

## Example
```python
import os


async def foo():
    os.waitpid(0)
```

Use instead:
```python
import asyncio
import os


def wait_for_process():
    os.waitpid(0)


async def foo():
    await asyncio.loop.run_in_executor(None, wait_for_process)
```

# blocking-open-call-in-async-function (ASYNC230)

Derived from the **flake8-async** linter.

## What it does
Checks that async functions do not open files with blocking methods like `open`.

## Why is this bad?
Blocking an async function via a blocking call will block the entire
event loop, preventing it from executing other tasks while waiting for the
call to complete, negating the benefits of asynchronous programming.

Instead of making a blocking call, use an equivalent asynchronous library
or function.

## Example
```python
async def foo():
    with open("bar.txt") as f:
        contents = f.read()
```

Use instead:
```python
import anyio


async def foo():
    async with await anyio.open_file("bar.txt") as f:
        contents = await f.read()
```

# blocking-path-method-in-async-function (ASYNC240)

Derived from the **flake8-async** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks that async functions do not call blocking `os.path` or `pathlib.Path`
methods.

## Why is this bad?
Calling some `os.path` or `pathlib.Path` methods in an async function will block
the entire event loop, preventing it from executing other tasks while waiting
for the operation. This negates the benefits of asynchronous programming.

Instead, use the methods' async equivalents from `trio.Path` or `anyio.Path`.

## Example
```python
import os


async def func():
    path = "my_file.txt"
    file_exists = os.path.exists(path)
```

Use instead:
```python
import trio


async def func():
    path = trio.Path("my_file.txt")
    file_exists = await path.exists()
```

Non-blocking methods are OK to use:
```python
import pathlib


async def func():
    path = pathlib.Path("my_file.txt")
    file_dirname = path.dirname()
    new_path = os.path.join("/tmp/src/", path)
```

# blocking-input-in-async-function (ASYNC250)

Derived from the **flake8-async** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks that async functions do not contain blocking usage of input from user.

## Why is this bad?
Blocking an async function via a blocking input call will block the entire
event loop, preventing it from executing other tasks while waiting for user
input, negating the benefits of asynchronous programming.

Instead of making a blocking input call directly, wrap the input call in
an executor to execute the blocking call on another thread.

## Example
```python
async def foo():
    username = input("Username:")
```

Use instead:
```python
import asyncio


async def foo():
    loop = asyncio.get_running_loop()
    username = await loop.run_in_executor(None, input, "Username:")
```

# blocking-sleep-in-async-function (ASYNC251)

Derived from the **flake8-async** linter.

## What it does
Checks that async functions do not call `time.sleep`.

## Why is this bad?
Blocking an async function via a `time.sleep` call will block the entire
event loop, preventing it from executing other tasks while waiting for the
`time.sleep`, negating the benefits of asynchronous programming.

Instead of `time.sleep`, use `asyncio.sleep`.

## Example
```python
import time


async def fetch():
    time.sleep(1)
```

Use instead:
```python
import asyncio


async def fetch():
    await asyncio.sleep(1)
```

# assert (S101)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of the `assert` keyword.

## Why is this bad?
Assertions are removed when Python is run with optimization requested
(i.e., when the `-O` flag is present), which is a common practice in
production environments. As such, assertions should not be used for runtime
validation of user input or to enforce  interface constraints.

Consider raising a meaningful error instead of using `assert`.

## Example
```python
assert x > 0, "Expected positive value."
```

Use instead:
```python
if not x > 0:
    raise ValueError("Expected positive value.")

# or even better:
if x <= 0:
    raise ValueError("Expected positive value.")
```

# exec-builtin (S102)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of the builtin `exec` function.

## Why is this bad?
The `exec()` function is insecure as it allows for arbitrary code
execution.

## Example
```python
exec("print('Hello World')")
```

## References
- [Python documentation: `exec`](https://docs.python.org/3/library/functions.html#exec)
- [Common Weakness Enumeration: CWE-78](https://cwe.mitre.org/data/definitions/78.html)

# bad-file-permissions (S103)

Derived from the **flake8-bandit** linter.

## What it does
Checks for files with overly permissive permissions.

## Why is this bad?
Overly permissive file permissions may allow unintended access and
arbitrary code execution.

## Example
```python
import os

os.chmod("/etc/secrets.txt", 0o666)  # rw-rw-rw-
```

Use instead:
```python
import os

os.chmod("/etc/secrets.txt", 0o600)  # rw-------
```

## References
- [Python documentation: `os.chmod`](https://docs.python.org/3/library/os.html#os.chmod)
- [Python documentation: `stat`](https://docs.python.org/3/library/stat.html)
- [Common Weakness Enumeration: CWE-732](https://cwe.mitre.org/data/definitions/732.html)

# hardcoded-bind-all-interfaces (S104)

Derived from the **flake8-bandit** linter.

## What it does
Checks for hardcoded bindings to all network interfaces (`0.0.0.0`).

## Why is this bad?
Binding to all network interfaces is insecure as it allows access from
unintended interfaces, which may be poorly secured or unauthorized.

Instead, bind to specific interfaces.

## Example
```python
ALLOWED_HOSTS = ["0.0.0.0"]
```

Use instead:
```python
ALLOWED_HOSTS = ["127.0.0.1", "localhost"]
```

## References
- [Common Weakness Enumeration: CWE-200](https://cwe.mitre.org/data/definitions/200.html)

# hardcoded-password-string (S105)

Derived from the **flake8-bandit** linter.

## What it does
Checks for potential uses of hardcoded passwords in strings.

## Why is this bad?
Including a hardcoded password in source code is a security risk, as an
attacker could discover the password and use it to gain unauthorized
access.

Instead, store passwords and other secrets in configuration files,
environment variables, or other sources that are excluded from version
control.

## Example
```python
SECRET_KEY = "hunter2"
```

Use instead:
```python
import os

SECRET_KEY = os.environ["SECRET_KEY"]
```

## References
- [Common Weakness Enumeration: CWE-259](https://cwe.mitre.org/data/definitions/259.html)

# hardcoded-password-func-arg (S106)

Derived from the **flake8-bandit** linter.

## What it does
Checks for potential uses of hardcoded passwords in function calls.

## Why is this bad?
Including a hardcoded password in source code is a security risk, as an
attacker could discover the password and use it to gain unauthorized
access.

Instead, store passwords and other secrets in configuration files,
environment variables, or other sources that are excluded from version
control.

## Example
```python
connect_to_server(password="hunter2")
```

Use instead:
```python
import os

connect_to_server(password=os.environ["PASSWORD"])
```

## References
- [Common Weakness Enumeration: CWE-259](https://cwe.mitre.org/data/definitions/259.html)

# hardcoded-password-default (S107)

Derived from the **flake8-bandit** linter.

## What it does
Checks for potential uses of hardcoded passwords in function argument
defaults.

## Why is this bad?
Including a hardcoded password in source code is a security risk, as an
attacker could discover the password and use it to gain unauthorized
access.

Instead, store passwords and other secrets in configuration files,
environment variables, or other sources that are excluded from version
control.

## Example

```python
def connect_to_server(password="hunter2"): ...
```

Use instead:

```python
import os


def connect_to_server(password=os.environ["PASSWORD"]): ...
```

## References
- [Common Weakness Enumeration: CWE-259](https://cwe.mitre.org/data/definitions/259.html)

# hardcoded-temp-file (S108)

Derived from the **flake8-bandit** linter.

## What it does
Checks for the use of hardcoded temporary file or directory paths.

## Why is this bad?
The use of hardcoded paths for temporary files can be insecure. If an
attacker discovers the location of a hardcoded path, they can replace the
contents of the file or directory with a malicious payload.

Other programs may also read or write contents to these hardcoded paths,
causing unexpected behavior.

## Example
```python
with open("/tmp/foo.txt", "w") as file:
    ...
```

Use instead:
```python
import tempfile

with tempfile.NamedTemporaryFile() as file:
    ...
```

## Options
- `lint.flake8-bandit.hardcoded-tmp-directory`
- `lint.flake8-bandit.hardcoded-tmp-directory-extend`

## References
- [Common Weakness Enumeration: CWE-377](https://cwe.mitre.org/data/definitions/377.html)
- [Common Weakness Enumeration: CWE-379](https://cwe.mitre.org/data/definitions/379.html)
- [Python documentation: `tempfile`](https://docs.python.org/3/library/tempfile.html)

# try-except-pass (S110)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of the `try`-`except`-`pass` pattern.

## Why is this bad?
The `try`-`except`-`pass` pattern suppresses all exceptions. Suppressing
exceptions may hide errors that could otherwise reveal unexpected behavior,
security vulnerabilities, or malicious activity. Instead, consider logging
the exception.

## Example
```python
try:
    ...
except Exception:
    pass
```

Use instead:
```python
import logging

try:
    ...
except Exception as exc:
    logging.exception("Exception occurred")
```

## Options
- `lint.flake8-bandit.check-typed-exception`

## References
- [Common Weakness Enumeration: CWE-703](https://cwe.mitre.org/data/definitions/703.html)
- [Python documentation: `logging`](https://docs.python.org/3/library/logging.html)

# try-except-continue (S112)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of the `try`-`except`-`continue` pattern.

## Why is this bad?
The `try`-`except`-`continue` pattern suppresses all exceptions.
Suppressing exceptions may hide errors that could otherwise reveal
unexpected behavior, security vulnerabilities, or malicious activity.
Instead, consider logging the exception.

## Example
```python
import logging

while predicate:
    try:
        ...
    except Exception:
        continue
```

Use instead:
```python
import logging

while predicate:
    try:
        ...
    except Exception as exc:
        logging.exception("Error occurred")
```

## Options
- `lint.flake8-bandit.check-typed-exception`

## References
- [Common Weakness Enumeration: CWE-703](https://cwe.mitre.org/data/definitions/703.html)
- [Python documentation: `logging`](https://docs.python.org/3/library/logging.html)

# request-without-timeout (S113)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of the Python `requests` or `httpx` module that omit the
`timeout` parameter.

## Why is this bad?
The `timeout` parameter is used to set the maximum time to wait for a
response from the server. By omitting the `timeout` parameter, the program
may hang indefinitely while awaiting a response.

## Example
```python
import requests

requests.get("https://www.example.com/")
```

Use instead:
```python
import requests

requests.get("https://www.example.com/", timeout=10)
```

## References
- [Requests documentation: Timeouts](https://requests.readthedocs.io/en/latest/user/advanced/#timeouts)
- [httpx documentation: Timeouts](https://www.python-httpx.org/advanced/timeouts/)

# flask-debug-true (S201)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of `debug=True` in Flask.

## Why is this bad?
Enabling debug mode shows an interactive debugger in the browser if an
error occurs, and allows running arbitrary Python code from the browser.
This could leak sensitive information, or allow an attacker to run
arbitrary code.

## Example
```python
from flask import Flask

app = Flask()

app.run(debug=True)
```

Use instead:
```python
import os

from flask import Flask

app = Flask()

app.run(debug=os.environ["ENV"] == "dev")
```

## References
- [Flask documentation: Debug Mode](https://flask.palletsprojects.com/en/latest/quickstart/#debug-mode)

# tarfile-unsafe-members (S202)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of `tarfile.extractall`.

## Why is this bad?

Extracting archives from untrusted sources without prior inspection is
a security risk, as maliciously crafted archives may contain files that
will be written outside of the target directory. For example, the archive
could include files with absolute paths (e.g., `/etc/passwd`), or relative
paths with parent directory references (e.g., `../etc/passwd`).

On Python 3.12 and later, use `filter='data'` to prevent the most dangerous
security issues (see: [PEP 706]). On earlier versions, set the `members`
argument to a trusted subset of the archive's members.

## Example
```python
import tarfile
import tempfile

tar = tarfile.open(filename)
tar.extractall(path=tempfile.mkdtemp())
tar.close()
```

## References
- [Common Weakness Enumeration: CWE-22](https://cwe.mitre.org/data/definitions/22.html)
- [Python documentation: `TarFile.extractall`](https://docs.python.org/3/library/tarfile.html#tarfile.TarFile.extractall)
- [Python documentation: Extraction filters](https://docs.python.org/3/library/tarfile.html#tarfile-extraction-filter)

[PEP 706]: https://peps.python.org/pep-0706/#backporting-forward-compatibility

# suspicious-pickle-usage (S301)

Derived from the **flake8-bandit** linter.

## What it does
Checks for calls to `pickle` functions or modules that wrap them.

## Why is this bad?
Deserializing untrusted data with `pickle` and other deserialization
modules is insecure as it can allow for the creation of arbitrary objects,
which can then be used to achieve arbitrary code execution and otherwise
unexpected behavior.

Avoid deserializing untrusted data with `pickle` and other deserialization
modules. Instead, consider safer formats, such as JSON.

If you must deserialize untrusted data with `pickle`, consider signing the
data with a secret key and verifying the signature before deserializing the
payload, This will prevent an attacker from injecting arbitrary objects
into the serialized data.

In [preview], this rule will also flag references to `pickle` functions.

## Example
```python
import pickle

with open("foo.pickle", "rb") as file:
    foo = pickle.load(file)
```

Use instead:
```python
import json

with open("foo.json", "rb") as file:
    foo = json.load(file)
```

## References
- [Python documentation: `pickle`  Python object serialization](https://docs.python.org/3/library/pickle.html)
- [Common Weakness Enumeration: CWE-502](https://cwe.mitre.org/data/definitions/502.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-marshal-usage (S302)

Derived from the **flake8-bandit** linter.

## What it does
Checks for calls to `marshal` functions.

## Why is this bad?
Deserializing untrusted data with `marshal` is insecure, as it can allow for
the creation of arbitrary objects, which can then be used to achieve
arbitrary code execution and otherwise unexpected behavior.

Avoid deserializing untrusted data with `marshal`. Instead, consider safer
formats, such as JSON.

If you must deserialize untrusted data with `marshal`, consider signing the
data with a secret key and verifying the signature before deserializing the
payload. This will prevent an attacker from injecting arbitrary objects
into the serialized data.

In [preview], this rule will also flag references to `marshal` functions.

## Example
```python
import marshal

with open("foo.marshal", "rb") as file:
    foo = marshal.load(file)
```

Use instead:
```python
import json

with open("foo.json", "rb") as file:
    foo = json.load(file)
```

## References
- [Python documentation: `marshal`  Internal Python object serialization](https://docs.python.org/3/library/marshal.html)
- [Common Weakness Enumeration: CWE-502](https://cwe.mitre.org/data/definitions/502.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-insecure-hash-usage (S303)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of weak or broken cryptographic hash functions.

## Why is this bad?
Weak or broken cryptographic hash functions may be susceptible to
collision attacks (where two different inputs produce the same hash) or
pre-image attacks (where an attacker can find an input that produces a
given hash). This can lead to security vulnerabilities in applications
that rely on these hash functions.

Avoid using weak or broken cryptographic hash functions in security
contexts. Instead, use a known secure hash function such as SHA-256.

In [preview], this rule will also flag references to insecure hash functions.

## Example
```python
from cryptography.hazmat.primitives import hashes

digest = hashes.Hash(hashes.MD5())
digest.update(b"Hello, world!")
digest.finalize()
```

Use instead:
```python
from cryptography.hazmat.primitives import hashes

digest = hashes.Hash(hashes.SHA256())
digest.update(b"Hello, world!")
digest.finalize()
```

## References
- [Python documentation: `hashlib`  Secure hashes and message digests](https://docs.python.org/3/library/hashlib.html)
- [Common Weakness Enumeration: CWE-327](https://cwe.mitre.org/data/definitions/327.html)
- [Common Weakness Enumeration: CWE-328](https://cwe.mitre.org/data/definitions/328.html)
- [Common Weakness Enumeration: CWE-916](https://cwe.mitre.org/data/definitions/916.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-insecure-cipher-usage (S304)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of weak or broken cryptographic ciphers.

## Why is this bad?
Weak or broken cryptographic ciphers may be susceptible to attacks that
allow an attacker to decrypt ciphertext without knowing the key or
otherwise compromise the security of the cipher, such as forgeries.

Use strong, modern cryptographic ciphers instead of weak or broken ones.

In [preview], this rule will also flag references to insecure ciphers.

## Example
```python
from cryptography.hazmat.primitives.ciphers import Cipher, algorithms

algorithm = algorithms.ARC4(key)
cipher = Cipher(algorithm, mode=None)
encryptor = cipher.encryptor()
```

Use instead:
```python
from cryptography.fernet import Fernet

fernet = Fernet(key)
```

## References
- [Common Weakness Enumeration: CWE-327](https://cwe.mitre.org/data/definitions/327.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-insecure-cipher-mode-usage (S305)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of weak or broken cryptographic cipher modes.

## Why is this bad?
Weak or broken cryptographic ciphers may be susceptible to attacks that
allow an attacker to decrypt ciphertext without knowing the key or
otherwise compromise the security of the cipher, such as forgeries.

Use strong, modern cryptographic ciphers instead of weak or broken ones.

In [preview], this rule will also flag references to insecure cipher modes.

## Example
```python
from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes

algorithm = algorithms.ARC4(key)
cipher = Cipher(algorithm, mode=modes.ECB(iv))
encryptor = cipher.encryptor()
```

Use instead:
```python
from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes

algorithm = algorithms.ARC4(key)
cipher = Cipher(algorithm, mode=modes.CTR(iv))
encryptor = cipher.encryptor()
```

## References
- [Common Weakness Enumeration: CWE-327](https://cwe.mitre.org/data/definitions/327.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-mktemp-usage (S306)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of `tempfile.mktemp`.

## Why is this bad?
`tempfile.mktemp` returns a pathname of a file that does not exist at the
time the call is made; then, the caller is responsible for creating the
file and subsequently using it. This is insecure because another process
could create a file with the same name between the time the function
returns and the time the caller creates the file.

`tempfile.mktemp` is deprecated in favor of `tempfile.mkstemp` which
creates the file when it is called. Consider using `tempfile.mkstemp`
instead, either directly or via a context manager such as
`tempfile.TemporaryFile`.

In [preview], this rule will also flag references to `tempfile.mktemp`.

## Example
```python
import tempfile

tmp_file = tempfile.mktemp()
with open(tmp_file, "w") as file:
    file.write("Hello, world!")
```

Use instead:
```python
import tempfile

with tempfile.TemporaryFile() as file:
    file.write("Hello, world!")
```

## References
- [Python documentation:`mktemp`](https://docs.python.org/3/library/tempfile.html#tempfile.mktemp)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-eval-usage (S307)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of the builtin `eval()` function.

## Why is this bad?
The `eval()` function is insecure as it enables arbitrary code execution.

If you need to evaluate an expression from a string, consider using
`ast.literal_eval()` instead, which will raise an exception if the
expression is not a valid Python literal.

In [preview], this rule will also flag references to `eval`.

## Example
```python
x = eval(input("Enter a number: "))
```

Use instead:
```python
from ast import literal_eval

x = literal_eval(input("Enter a number: "))
```

## References
- [Python documentation: `eval`](https://docs.python.org/3/library/functions.html#eval)
- [Python documentation: `literal_eval`](https://docs.python.org/3/library/ast.html#ast.literal_eval)
- [_Eval really is dangerous_ by Ned Batchelder](https://nedbatchelder.com/blog/201206/eval_really_is_dangerous.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-mark-safe-usage (S308)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of calls to `django.utils.safestring.mark_safe`.

## Why is this bad?
Cross-site scripting (XSS) vulnerabilities allow attackers to execute
arbitrary JavaScript. To guard against XSS attacks, Django templates
assumes that data is unsafe and automatically escapes malicious strings
before rending them.

`django.utils.safestring.mark_safe` marks a string as safe for use in HTML
templates, bypassing XSS protection. Its usage can be dangerous if the
contents of the string are dynamically generated, because it may allow
cross-site scripting attacks if the string is not properly escaped.

For dynamically generated strings, consider utilizing
`django.utils.html.format_html`.

In [preview], this rule will also flag references to `django.utils.safestring.mark_safe`.

## Example
```python
from django.utils.safestring import mark_safe


def render_username(username):
    return mark_safe(f"<i>{username}</i>")  # Dangerous if username is user-provided.
```

Use instead:
```python
from django.utils.html import format_html


def render_username(username):
    return format_html("<i>{}</i>", username)  # username is escaped.
```

## References
- [Django documentation: `mark_safe`](https://docs.djangoproject.com/en/dev/ref/utils/#django.utils.safestring.mark_safe)
- [Django documentation: Cross Site Scripting (XSS) protection](https://docs.djangoproject.com/en/dev/topics/security/#cross-site-scripting-xss-protection)
- [Common Weakness Enumeration: CWE-80](https://cwe.mitre.org/data/definitions/80.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-url-open-usage (S310)

Derived from the **flake8-bandit** linter.

## What it does
Checks for instances where URL open functions are used with unexpected schemes.

## Why is this bad?
Some URL open functions allow the use of `file:` or custom schemes (for use
instead of `http:` or `https:`). An attacker may be able to use these
schemes to access or modify unauthorized resources, and cause unexpected
behavior.

To mitigate this risk, audit all uses of URL open functions and ensure that
only permitted schemes are used (e.g., allowing `http:` and `https:`, and
disallowing `file:` and `ftp:`).

In [preview], this rule will also flag references to URL open functions.

## Example
```python
from urllib.request import urlopen

url = input("Enter a URL: ")

with urlopen(url) as response:
    ...
```

Use instead:
```python
from urllib.request import urlopen

url = input("Enter a URL: ")

if not url.startswith(("http:", "https:")):
    raise ValueError("URL must start with 'http:' or 'https:'")

with urlopen(url) as response:
    ...
```

## References
- [Python documentation: `urlopen`](https://docs.python.org/3/library/urllib.request.html#urllib.request.urlopen)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-non-cryptographic-random-usage (S311)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of cryptographically weak pseudo-random number generators.

## Why is this bad?
Cryptographically weak pseudo-random number generators are insecure, as they
are easily predictable. This can allow an attacker to guess the generated
numbers and compromise the security of the system.

Instead, use a cryptographically secure pseudo-random number generator
(such as using the [`secrets` module](https://docs.python.org/3/library/secrets.html))
when generating random numbers for security purposes.

In [preview], this rule will also flag references to these generators.

## Example
```python
import random

random.randrange(10)
```

Use instead:
```python
import secrets

secrets.randbelow(10)
```

## References
- [Python documentation: `random`  Generate pseudo-random numbers](https://docs.python.org/3/library/random.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-telnet-usage (S312)

Derived from the **flake8-bandit** linter.

## What it does
Checks for the use of Telnet-related functions.

## Why is this bad?
Telnet is considered insecure because it does not encrypt data sent over
the connection and is vulnerable to numerous attacks.

Instead, consider using a more secure protocol such as SSH.

In [preview], this rule will also flag references to Telnet-related functions.

## References
- [Python documentation: `telnetlib`  Telnet client](https://docs.python.org/3/library/telnetlib.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-xmlc-element-tree-usage (S313)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of insecure XML parsers.

## Why is this bad?
Many XML parsers are vulnerable to XML attacks (such as entity expansion),
which cause excessive memory and CPU usage by exploiting recursion. An
attacker could use such methods to access unauthorized resources.

Consider using the `defusedxml` package when parsing untrusted XML data,
to protect against XML attacks.

In [preview], this rule will also flag references to insecure XML parsers.

## Example
```python
from xml.etree.cElementTree import parse

tree = parse("untrusted.xml")  # Vulnerable to XML attacks.
```

Use instead:
```python
from defusedxml.cElementTree import parse

tree = parse("untrusted.xml")
```

## References
- [Python documentation: `xml`  XML processing modules](https://docs.python.org/3/library/xml.html)
- [PyPI: `defusedxml`](https://pypi.org/project/defusedxml/)
- [Common Weakness Enumeration: CWE-400](https://cwe.mitre.org/data/definitions/400.html)
- [Common Weakness Enumeration: CWE-776](https://cwe.mitre.org/data/definitions/776.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-xml-element-tree-usage (S314)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of insecure XML parsers.

## Why is this bad?
Many XML parsers are vulnerable to XML attacks (such as entity expansion),
which cause excessive memory and CPU usage by exploiting recursion. An
attacker could use such methods to access unauthorized resources.

Consider using the `defusedxml` package when parsing untrusted XML data,
to protect against XML attacks.

In [preview], this rule will also flag references to insecure XML parsers.

## Example
```python
from xml.etree.ElementTree import parse

tree = parse("untrusted.xml")  # Vulnerable to XML attacks.
```

Use instead:
```python
from defusedxml.ElementTree import parse

tree = parse("untrusted.xml")
```

## References
- [Python documentation: `xml`  XML processing modules](https://docs.python.org/3/library/xml.html)
- [PyPI: `defusedxml`](https://pypi.org/project/defusedxml/)
- [Common Weakness Enumeration: CWE-400](https://cwe.mitre.org/data/definitions/400.html)
- [Common Weakness Enumeration: CWE-776](https://cwe.mitre.org/data/definitions/776.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-xml-expat-reader-usage (S315)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of insecure XML parsers.

## Why is this bad?
Many XML parsers are vulnerable to XML attacks (such as entity expansion),
which cause excessive memory and CPU usage by exploiting recursion. An
attacker could use such methods to access unauthorized resources.

Consider using the `defusedxml` package when parsing untrusted XML data,
to protect against XML attacks.

In [preview], this rule will also flag references to insecure XML parsers.

## Example
```python
from xml.sax.expatreader import create_parser

parser = create_parser()
```

Use instead:
```python
from defusedxml.sax import create_parser

parser = create_parser()
```

## References
- [Python documentation: `xml`  XML processing modules](https://docs.python.org/3/library/xml.html)
- [PyPI: `defusedxml`](https://pypi.org/project/defusedxml/)
- [Common Weakness Enumeration: CWE-400](https://cwe.mitre.org/data/definitions/400.html)
- [Common Weakness Enumeration: CWE-776](https://cwe.mitre.org/data/definitions/776.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-xml-expat-builder-usage (S316)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of insecure XML parsers.

## Why is this bad?
Many XML parsers are vulnerable to XML attacks (such as entity expansion),
which cause excessive memory and CPU usage by exploiting recursion. An
attacker could use such methods to access unauthorized resources.

Consider using the `defusedxml` package when parsing untrusted XML data,
to protect against XML attacks.

In [preview], this rule will also flag references to insecure XML parsers.

## Example
```python
from xml.dom.expatbuilder import parse

parse("untrusted.xml")
```

Use instead:
```python
from defusedxml.expatbuilder import parse

tree = parse("untrusted.xml")
```

## References
- [Python documentation: `xml`  XML processing modules](https://docs.python.org/3/library/xml.html)
- [PyPI: `defusedxml`](https://pypi.org/project/defusedxml/)
- [Common Weakness Enumeration: CWE-400](https://cwe.mitre.org/data/definitions/400.html)
- [Common Weakness Enumeration: CWE-776](https://cwe.mitre.org/data/definitions/776.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-xml-sax-usage (S317)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of insecure XML parsers.

## Why is this bad?
Many XML parsers are vulnerable to XML attacks (such as entity expansion),
which cause excessive memory and CPU usage by exploiting recursion. An
attacker could use such methods to access unauthorized resources.

Consider using the `defusedxml` package when parsing untrusted XML data,
to protect against XML attacks.

In [preview], this rule will also flag references to insecure XML parsers.

## Example
```python
from xml.sax import make_parser

make_parser()
```

Use instead:
```python
from defusedxml.sax import make_parser

make_parser()
```

## References
- [Python documentation: `xml`  XML processing modules](https://docs.python.org/3/library/xml.html)
- [PyPI: `defusedxml`](https://pypi.org/project/defusedxml/)
- [Common Weakness Enumeration: CWE-400](https://cwe.mitre.org/data/definitions/400.html)
- [Common Weakness Enumeration: CWE-776](https://cwe.mitre.org/data/definitions/776.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-xml-mini-dom-usage (S318)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of insecure XML parsers.

## Why is this bad?
Many XML parsers are vulnerable to XML attacks (such as entity expansion),
which cause excessive memory and CPU usage by exploiting recursion. An
attacker could use such methods to access unauthorized resources.

Consider using the `defusedxml` package when parsing untrusted XML data,
to protect against XML attacks.

In [preview], this rule will also flag references to insecure XML parsers.

## Example
```python
from xml.dom.minidom import parse

content = parse("untrusted.xml")
```

Use instead:
```python
from defusedxml.minidom import parse

content = parse("untrusted.xml")
```

## References
- [Python documentation: `xml`  XML processing modules](https://docs.python.org/3/library/xml.html)
- [PyPI: `defusedxml`](https://pypi.org/project/defusedxml/)
- [Common Weakness Enumeration: CWE-400](https://cwe.mitre.org/data/definitions/400.html)
- [Common Weakness Enumeration: CWE-776](https://cwe.mitre.org/data/definitions/776.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-xml-pull-dom-usage (S319)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of insecure XML parsers.

## Why is this bad?
Many XML parsers are vulnerable to XML attacks (such as entity expansion),
which cause excessive memory and CPU usage by exploiting recursion. An
attacker could use such methods to access unauthorized resources.

Consider using the `defusedxml` package when parsing untrusted XML data,
to protect against XML attacks.

In [preview], this rule will also flag references to insecure XML parsers.

## Example
```python
from xml.dom.pulldom import parse

content = parse("untrusted.xml")
```

Use instead:
```python
from defusedxml.pulldom import parse

content = parse("untrusted.xml")
```

## References
- [Python documentation: `xml`  XML processing modules](https://docs.python.org/3/library/xml.html)
- [PyPI: `defusedxml`](https://pypi.org/project/defusedxml/)
- [Common Weakness Enumeration: CWE-400](https://cwe.mitre.org/data/definitions/400.html)
- [Common Weakness Enumeration: CWE-776](https://cwe.mitre.org/data/definitions/776.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-xmle-tree-usage (S320)

Derived from the **flake8-bandit** linter.

## Removed

This rule was removed as the `lxml` library has been modified to address
known vulnerabilities and unsafe defaults. As such, the `defusedxml`
library is no longer necessary, `defusedxml` has [deprecated] its `lxml`
module.

## What it does
Checks for uses of insecure XML parsers.

## Why is this bad?
Many XML parsers are vulnerable to XML attacks (such as entity expansion),
which cause excessive memory and CPU usage by exploiting recursion. An
attacker could use such methods to access unauthorized resources.

In [preview], this rule will also flag references to insecure XML parsers.

## Example
```python
from lxml import etree

content = etree.parse("untrusted.xml")
```

## References
- [PyPI: `lxml`](https://pypi.org/project/lxml/)
- [Common Weakness Enumeration: CWE-400](https://cwe.mitre.org/data/definitions/400.html)
- [Common Weakness Enumeration: CWE-776](https://cwe.mitre.org/data/definitions/776.html)

[preview]: https://docs.astral.sh/ruff/preview/
[deprecated]: https://pypi.org/project/defusedxml/0.8.0rc2/#defusedxml-lxml

# suspicious-ftp-lib-usage (S321)

Derived from the **flake8-bandit** linter.

## What it does
Checks for the use of FTP-related functions.

## Why is this bad?
FTP is considered insecure as it does not encrypt data sent over the
connection and is thus vulnerable to numerous attacks.

Instead, consider using FTPS (which secures FTP using SSL/TLS) or SFTP.

In [preview], this rule will also flag references to FTP-related functions.

## References
- [Python documentation: `ftplib`  FTP protocol client](https://docs.python.org/3/library/ftplib.html)

[preview]: https://docs.astral.sh/ruff/preview/

# suspicious-unverified-context-usage (S323)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of `ssl._create_unverified_context`.

## Why is this bad?
[PEP 476] enabled certificate and hostname validation by default in Python
standard library HTTP clients. Previously, Python did not validate
certificates by default, which could allow an attacker to perform a "man in
the middle" attack by intercepting and modifying traffic between client and
server.

To support legacy environments, `ssl._create_unverified_context` reverts to
the previous behavior that does perform verification. Otherwise, use
`ssl.create_default_context` to create a secure context.

In [preview], this rule will also flag references to `ssl._create_unverified_context`.

## Example
```python
import ssl

context = ssl._create_unverified_context()
```

Use instead:
```python
import ssl

context = ssl.create_default_context()
```

## References
- [PEP 476  Enabling certificate verification by default for stdlib http clients: Opting out](https://peps.python.org/pep-0476/#opting-out)
- [Python documentation: `ssl`  TLS/SSL wrapper for socket objects](https://docs.python.org/3/library/ssl.html)

[PEP 476]: https://peps.python.org/pep-0476/
[preview]: https://docs.astral.sh/ruff/preview/

# hashlib-insecure-hash-function (S324)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of weak or broken cryptographic hash functions in
`hashlib` and `crypt` libraries.

## Why is this bad?
Weak or broken cryptographic hash functions may be susceptible to
collision attacks (where two different inputs produce the same hash) or
pre-image attacks (where an attacker can find an input that produces a
given hash). This can lead to security vulnerabilities in applications
that rely on these hash functions.

Avoid using weak or broken cryptographic hash functions in security
contexts. Instead, use a known secure hash function such as SHA256.

Note: This rule targets the following weak algorithm names in `hashlib`:
`md4`, `md5`, `sha`, and `sha1`. It also flags uses of `crypt.crypt` and
`crypt.mksalt` when configured with `METHOD_CRYPT`, `METHOD_MD5`, or
`METHOD_BLOWFISH`.

It does not attempt to lint OpenSSL- or platform-specific aliases and OIDs
(for example: `"sha-1"`, `"ssl3-sha1"`, `"ssl3-md5"`, or
`"1.3.14.3.2.26"`), nor variations with trailing spaces, as the set of
accepted aliases depends on the underlying OpenSSL version and varies across
platforms and Python builds.

## Example
```python
import hashlib


def certificate_is_valid(certificate: bytes, known_hash: str) -> bool:
    hash = hashlib.md5(certificate).hexdigest()
    return hash == known_hash
```

Use instead:
```python
import hashlib


def certificate_is_valid(certificate: bytes, known_hash: str) -> bool:
    hash = hashlib.sha256(certificate).hexdigest()
    return hash == known_hash
```

or add `usedforsecurity=False` if the hashing algorithm is not used in a security context, e.g.
as a non-cryptographic one-way compression function:
```python
import hashlib


def certificate_is_valid(certificate: bytes, known_hash: str) -> bool:
    hash = hashlib.md5(certificate, usedforsecurity=False).hexdigest()
    return hash == known_hash
```


## References
- [Python documentation: `hashlib`  Secure hashes and message digests](https://docs.python.org/3/library/hashlib.html)
- [Python documentation: `crypt`  Function to check Unix passwords](https://docs.python.org/3/library/crypt.html)
- [Python documentation: `FIPS` - FIPS compliant hashlib implementation](https://docs.python.org/3/library/hashlib.html#hashlib.algorithms_guaranteed)
- [Common Weakness Enumeration: CWE-327](https://cwe.mitre.org/data/definitions/327.html)
- [Common Weakness Enumeration: CWE-328](https://cwe.mitre.org/data/definitions/328.html)
- [Common Weakness Enumeration: CWE-916](https://cwe.mitre.org/data/definitions/916.html)

# suspicious-telnetlib-import (S401)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of the `telnetlib` module.

## Why is this bad?
Telnet is considered insecure. It is deprecated since version 3.11, and
was removed in version 3.13. Instead, use SSH or another encrypted
protocol.

## Example
```python
import telnetlib
```

## References
- [Python documentation: `telnetlib` - Telnet client](https://docs.python.org/3.12/library/telnetlib.html#module-telnetlib)
- [PEP 594: `telnetlib`](https://peps.python.org/pep-0594/#telnetlib)

# suspicious-ftplib-import (S402)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of the `ftplib` module.

## Why is this bad?
FTP is considered insecure. Instead, use SSH, SFTP, SCP, or another
encrypted protocol.

## Example
```python
import ftplib
```

## References
- [Python documentation: `ftplib` - FTP protocol client](https://docs.python.org/3/library/ftplib.html)

# suspicious-pickle-import (S403)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of the `pickle`, `cPickle`, `dill`, and `shelve` modules.

## Why is this bad?
It is possible to construct malicious pickle data which will execute
arbitrary code during unpickling. Consider possible security implications
associated with these modules.

## Example
```python
import pickle
```

## References
- [Python documentation: `pickle`  Python object serialization](https://docs.python.org/3/library/pickle.html)

# suspicious-subprocess-import (S404)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of the `subprocess` module.

## Why is this bad?
It is possible to inject malicious commands into subprocess calls. Consider
possible security implications associated with this module.

## Example
```python
import subprocess
```

# suspicious-xml-etree-import (S405)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of the `xml.etree.cElementTree` and `xml.etree.ElementTree` modules

## Why is this bad?
Using various methods from these modules to parse untrusted XML data is
known to be vulnerable to XML attacks. Replace vulnerable imports with the
equivalent `defusedxml` package, or make sure `defusedxml.defuse_stdlib()` is
called before parsing XML data.

## Example
```python
import xml.etree.cElementTree
```

# suspicious-xml-sax-import (S406)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of the `xml.sax` module.

## Why is this bad?
Using various methods from these modules to parse untrusted XML data is
known to be vulnerable to XML attacks. Replace vulnerable imports with the
equivalent `defusedxml` package, or make sure `defusedxml.defuse_stdlib()` is
called before parsing XML data.

## Example
```python
import xml.sax
```

# suspicious-xml-expat-import (S407)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of the `xml.dom.expatbuilder` module.

## Why is this bad?
Using various methods from these modules to parse untrusted XML data is
known to be vulnerable to XML attacks. Replace vulnerable imports with the
equivalent `defusedxml` package, or make sure `defusedxml.defuse_stdlib()` is
called before parsing XML data.

## Example
```python
import xml.dom.expatbuilder
```

# suspicious-xml-minidom-import (S408)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of the `xml.dom.minidom` module.

## Why is this bad?
Using various methods from these modules to parse untrusted XML data is
known to be vulnerable to XML attacks. Replace vulnerable imports with the
equivalent `defusedxml` package, or make sure `defusedxml.defuse_stdlib()` is
called before parsing XML data.

## Example
```python
import xml.dom.minidom
```

# suspicious-xml-pulldom-import (S409)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of the `xml.dom.pulldom` module.

## Why is this bad?
Using various methods from these modules to parse untrusted XML data is
known to be vulnerable to XML attacks. Replace vulnerable imports with the
equivalent `defusedxml` package, or make sure `defusedxml.defuse_stdlib()` is
called before parsing XML data.

## Example
```python
import xml.dom.pulldom
```

# suspicious-lxml-import (S410)

Derived from the **flake8-bandit** linter.

## Removed
This rule was removed as the `lxml` library has been modified to address
known vulnerabilities and unsafe defaults. As such, the `defusedxml`
library is no longer necessary, `defusedxml` has [deprecated] its `lxml`
module.

## What it does
Checks for imports of the `lxml` module.

## Why is this bad?
Using various methods from the `lxml` module to parse untrusted XML data is
known to be vulnerable to XML attacks. Replace vulnerable imports with the
equivalent `defusedxml` package.

## Example
```python
import lxml
```

[deprecated]: https://github.com/tiran/defusedxml/blob/c7445887f5e1bcea470a16f61369d29870cfcfe1/README.md#defusedxmllxml

# suspicious-xmlrpc-import (S411)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of the `xmlrpc` module.

## Why is this bad?
XMLRPC is a particularly dangerous XML module, as it is also concerned with
communicating data over a network. Use the `defused.xmlrpc.monkey_patch()`
function to monkey-patch the `xmlrpclib` module and mitigate remote XML
attacks.

## Example
```python
import xmlrpc
```

# suspicious-httpoxy-import (S412)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of `wsgiref.handlers.CGIHandler` and
`twisted.web.twcgi.CGIScript`.

## Why is this bad?
httpoxy is a set of vulnerabilities that affect application code running in
CGI or CGI-like environments. The use of CGI for web applications should be
avoided to prevent this class of attack.

## Example
```python
from wsgiref.handlers import CGIHandler
```

## References
- [httpoxy website](https://httpoxy.org/)

# suspicious-pycrypto-import (S413)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of several unsafe cryptography modules.

## Why is this bad?
The `pycrypto` library is known to have a publicly disclosed buffer
overflow vulnerability. It is no longer actively maintained and has been
deprecated in favor of the `pyca/cryptography` library.

## Example
```python
import Crypto.Random
```

## References
- [Buffer Overflow Issue](https://github.com/pycrypto/pycrypto/issues/176)

# suspicious-pyghmi-import (S415)

Derived from the **flake8-bandit** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for imports of the `pyghmi` module.

## Why is this bad?
`pyghmi` is an IPMI-related module, but IPMI is considered insecure.
Instead, use an encrypted protocol.

## Example
```python
import pyghmi
```

## References
- [Buffer Overflow Issue](https://github.com/pycrypto/pycrypto/issues/176)

# request-with-no-cert-validation (S501)

Derived from the **flake8-bandit** linter.

## What it does
Checks for HTTPS requests that disable SSL certificate checks.

## Why is this bad?
If SSL certificates are not verified, an attacker could perform a "man in
the middle" attack by intercepting and modifying traffic between the client
and server.

## Example
```python
import requests

requests.get("https://www.example.com", verify=False)
```

Use instead:
```python
import requests

requests.get("https://www.example.com")  # By default, `verify=True`.
```

## References
- [Common Weakness Enumeration: CWE-295](https://cwe.mitre.org/data/definitions/295.html)

# ssl-insecure-version (S502)

Derived from the **flake8-bandit** linter.

## What it does
Checks for function calls with parameters that indicate the use of insecure
SSL and TLS protocol versions.

## Why is this bad?
Several highly publicized exploitable flaws have been discovered in all
versions of SSL and early versions of TLS. The following versions are
considered insecure, and should be avoided:
- SSL v2
- SSL v3
- TLS v1
- TLS v1.1

This method supports detection on the Python's built-in `ssl` module and
the `pyOpenSSL` module.

## Example
```python
import ssl

ssl.wrap_socket(ssl_version=ssl.PROTOCOL_TLSv1)
```

Use instead:
```python
import ssl

ssl.wrap_socket(ssl_version=ssl.PROTOCOL_TLSv1_2)
```

# ssl-with-bad-defaults (S503)

Derived from the **flake8-bandit** linter.

## What it does
Checks for function definitions with default arguments set to insecure SSL
and TLS protocol versions.

## Why is this bad?
Several highly publicized exploitable flaws have been discovered in all
versions of SSL and early versions of TLS. The following versions are
considered insecure, and should be avoided:
- SSL v2
- SSL v3
- TLS v1
- TLS v1.1

## Example

```python
import ssl


def func(version=ssl.PROTOCOL_TLSv1): ...
```

Use instead:

```python
import ssl


def func(version=ssl.PROTOCOL_TLSv1_2): ...
```

# ssl-with-no-version (S504)

Derived from the **flake8-bandit** linter.

## What it does
Checks for calls to `ssl.wrap_socket()` without an `ssl_version`.

## Why is this bad?
This method is known to provide a default value that maximizes
compatibility, but permits use of insecure protocols.

## Example
```python
import ssl

ssl.wrap_socket()
```

Use instead:
```python
import ssl

ssl.wrap_socket(ssl_version=ssl.PROTOCOL_TLSv1_2)
```

# weak-cryptographic-key (S505)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of cryptographic keys with vulnerable key sizes.

## Why is this bad?
Small keys are easily breakable. For DSA and RSA, keys should be at least
2048 bits long. For EC, keys should be at least 224 bits long.

## Example
```python
from cryptography.hazmat.primitives.asymmetric import dsa, ec

dsa.generate_private_key(key_size=512)
ec.generate_private_key(curve=ec.SECT163K1())
```

Use instead:
```python
from cryptography.hazmat.primitives.asymmetric import dsa, ec

dsa.generate_private_key(key_size=4096)
ec.generate_private_key(curve=ec.SECP384R1())
```

## References
- [CSRC: Transitioning the Use of Cryptographic Algorithms and Key Lengths](https://csrc.nist.gov/pubs/sp/800/131/a/r2/final)

# unsafe-yaml-load (S506)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of the `yaml.load` function.

## Why is this bad?
Running the `yaml.load` function over untrusted YAML files is insecure, as
`yaml.load` allows for the creation of arbitrary Python objects, which can
then be used to execute arbitrary code.

Instead, consider using `yaml.safe_load`, which allows for the creation of
simple Python objects like integers and lists, but prohibits the creation of
more complex objects like functions and classes.

## Example
```python
import yaml

yaml.load(untrusted_yaml)
```

Use instead:
```python
import yaml

yaml.safe_load(untrusted_yaml)
```

## References
- [PyYAML documentation: Loading YAML](https://pyyaml.org/wiki/PyYAMLDocumentation)
- [Common Weakness Enumeration: CWE-20](https://cwe.mitre.org/data/definitions/20.html)

# ssh-no-host-key-verification (S507)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of policies disabling SSH verification in Paramiko.

## Why is this bad?
By default, Paramiko checks the identity of the remote host when establishing
an SSH connection. Disabling the verification might lead to the client
connecting to a malicious host, without the client knowing.

## Example
```python
from paramiko import client

ssh_client = client.SSHClient()
ssh_client.set_missing_host_key_policy(client.AutoAddPolicy)
```

Use instead:
```python
from paramiko import client

ssh_client = client.SSHClient()
ssh_client.set_missing_host_key_policy(client.RejectPolicy)
```

## References
- [Paramiko documentation: set_missing_host_key_policy](https://docs.paramiko.org/en/latest/api/client.html#paramiko.client.SSHClient.set_missing_host_key_policy)

# snmp-insecure-version (S508)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of SNMPv1 or SNMPv2.

## Why is this bad?
The SNMPv1 and SNMPv2 protocols are considered insecure as they do
not support encryption. Instead, prefer SNMPv3, which supports
encryption.

## Example
```python
from pysnmp.hlapi import CommunityData

CommunityData("public", mpModel=0)
```

Use instead:
```python
from pysnmp.hlapi import CommunityData

CommunityData("public", mpModel=2)
```

## References
- [Cybersecurity and Infrastructure Security Agency (CISA): Alert TA17-156A](https://www.cisa.gov/news-events/alerts/2017/06/05/reducing-risk-snmp-abuse)
- [Common Weakness Enumeration: CWE-319](https://cwe.mitre.org/data/definitions/319.html)

# snmp-weak-cryptography (S509)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of the SNMPv3 protocol without encryption.

## Why is this bad?
Unencrypted SNMPv3 communication can be intercepted and read by
unauthorized parties. Instead, enable encryption when using SNMPv3.

## Example
```python
from pysnmp.hlapi import UsmUserData

UsmUserData("user")
```

Use instead:
```python
from pysnmp.hlapi import UsmUserData

UsmUserData("user", "authkey", "privkey")
```

## References
- [Common Weakness Enumeration: CWE-319](https://cwe.mitre.org/data/definitions/319.html)

# paramiko-call (S601)

Derived from the **flake8-bandit** linter.

## What it does
Checks for `paramiko` calls.

## Why is this bad?
`paramiko` calls allow users to execute arbitrary shell commands on a
remote machine. If the inputs to these calls are not properly sanitized,
they can be vulnerable to shell injection attacks.

## Example
```python
import paramiko

client = paramiko.SSHClient()
client.exec_command("echo $HOME")
```

## References
- [Common Weakness Enumeration: CWE-78](https://cwe.mitre.org/data/definitions/78.html)
- [Paramiko documentation: `SSHClient.exec_command()`](https://docs.paramiko.org/en/stable/api/client.html#paramiko.client.SSHClient.exec_command)

# subprocess-popen-with-shell-equals-true (S602)

Derived from the **flake8-bandit** linter.

## What it does
Check for method calls that initiate a subprocess with a shell.

## Why is this bad?
Starting a subprocess with a shell can allow attackers to execute arbitrary
shell commands. Consider starting the process without a shell call and
sanitize the input to mitigate the risk of shell injection.

## Example
```python
import subprocess

subprocess.run("ls -l", shell=True)
```

Use instead:
```python
import subprocess

subprocess.run(["ls", "-l"])
```

## References
- [Python documentation: `subprocess`  Subprocess management](https://docs.python.org/3/library/subprocess.html)
- [Common Weakness Enumeration: CWE-78](https://cwe.mitre.org/data/definitions/78.html)

# subprocess-without-shell-equals-true (S603)

Derived from the **flake8-bandit** linter.

## What it does
Check for method calls that initiate a subprocess without a shell.

## Why is this bad?
Starting a subprocess without a shell can prevent attackers from executing
arbitrary shell commands; however, it is still error-prone. Consider
validating the input.

## Known problems
Prone to false positives as it is difficult to determine whether the
passed arguments have been validated ([#4045]).

## Example
```python
import subprocess

cmd = input("Enter a command: ").split()
subprocess.run(cmd)
```

## References
- [Python documentation: `subprocess`  Subprocess management](https://docs.python.org/3/library/subprocess.html)

[#4045]: https://github.com/astral-sh/ruff/issues/4045

# call-with-shell-equals-true (S604)

Derived from the **flake8-bandit** linter.

## What it does
Checks for method calls that set the `shell` parameter to `true` or another
truthy value when invoking a subprocess.

## Why is this bad?
Setting the `shell` parameter to `true` or another truthy value when
invoking a subprocess can introduce security vulnerabilities, as it allows
shell metacharacters and whitespace to be passed to child processes,
potentially leading to shell injection attacks.

It is recommended to avoid using `shell=True` unless absolutely necessary
and, when used, to ensure that all inputs are properly sanitized and quoted
to prevent such vulnerabilities.

## Known problems
Prone to false positives as it is triggered on any function call with a
`shell=True` parameter.

## Example
```python
import my_custom_subprocess

user_input = input("Enter a command: ")
my_custom_subprocess.run(user_input, shell=True)
```

## References
- [Python documentation: Security Considerations](https://docs.python.org/3/library/subprocess.html#security-considerations)

# start-process-with-a-shell (S605)

Derived from the **flake8-bandit** linter.

## What it does
Checks for calls that start a process with a shell, providing guidance on
whether the usage is safe or not.

## Why is this bad?
Starting a process with a shell can introduce security risks, such as
code injection vulnerabilities. It's important to be aware of whether the
usage of the shell is safe or not.

This rule triggers on functions like `os.system`, `popen`, etc., which
start processes with a shell. It evaluates whether the provided command
is a literal string or an expression. If the command is a literal string,
it's considered safe. If the command is an expression, it's considered
(potentially) unsafe.

## Example
```python
import os

# Safe usage (literal string)
command = "ls -l"
os.system(command)

# Potentially unsafe usage (expression)
cmd = get_user_input()
os.system(cmd)
```

## Note
The `subprocess` module provides more powerful facilities for spawning new
processes and retrieving their results, and using that module is preferable
to using `os.system` or similar functions. Consider replacing such usages
with `subprocess.call` or related functions.

## References
- [Python documentation: `subprocess`](https://docs.python.org/3/library/subprocess.html)

# start-process-with-no-shell (S606)

Derived from the **flake8-bandit** linter.

## What it does
Checks for functions that start a process without a shell.

## Why is this bad?
Invoking any kind of external executable via a function call can pose
security risks if arbitrary variables are passed to the executable, or if
the input is otherwise unsanitised or unvalidated.

This rule specifically flags functions in the `os` module that spawn
subprocesses *without* the use of a shell. Note that these typically pose a
much smaller security risk than subprocesses that are started *with* a
shell, which are flagged by [`start-process-with-a-shell`][S605] (`S605`).
This gives you the option of enabling one rule while disabling the other
if you decide that the security risk from these functions is acceptable
for your use case.

## Example
```python
import os


def insecure_function(arbitrary_user_input: str):
    os.spawnlp(os.P_NOWAIT, "/bin/mycmd", "mycmd", arbitrary_user_input)
```

[S605]: https://docs.astral.sh/ruff/rules/start-process-with-a-shell

# start-process-with-partial-path (S607)

Derived from the **flake8-bandit** linter.

## What it does
Checks for the starting of a process with a partial executable path.

## Why is this bad?
Starting a process with a partial executable path can allow attackers to
execute an arbitrary executable by adjusting the `PATH` environment variable.
Consider using a full path to the executable instead.

## Example
```python
import subprocess

subprocess.Popen(["ruff", "check", "file.py"])
```

Use instead:
```python
import subprocess

subprocess.Popen(["/usr/bin/ruff", "check", "file.py"])
```

## References
- [Python documentation: `subprocess.Popen()`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen)
- [Common Weakness Enumeration: CWE-426](https://cwe.mitre.org/data/definitions/426.html)

# hardcoded-sql-expression (S608)

Derived from the **flake8-bandit** linter.

## What it does
Checks for strings that resemble SQL statements involved in some form
string building operation.

## Why is this bad?
SQL injection is a common attack vector for web applications. Directly
interpolating user input into SQL statements should always be avoided.
Instead, favor parameterized queries, in which the SQL statement is
provided separately from its parameters, as supported by `psycopg3`
and other database drivers and ORMs.

## Example
```python
query = "DELETE FROM foo WHERE id = '%s'" % identifier
```

## References
- [B608: Test for SQL injection](https://bandit.readthedocs.io/en/latest/plugins/b608_hardcoded_sql_expressions.html)
- [psycopg3: Server-side binding](https://www.psycopg.org/psycopg3/docs/basic/from_pg2.html#server-side-binding)

# unix-command-wildcard-injection (S609)

Derived from the **flake8-bandit** linter.

## What it does
Checks for possible wildcard injections in calls to `subprocess.Popen()`.

## Why is this bad?
Wildcard injections can lead to unexpected behavior if unintended files are
matched by the wildcard. Consider using a more specific path instead.

## Example
```python
import subprocess

subprocess.Popen(["chmod", "777", "*.py"], shell=True)
```

Use instead:
```python
import subprocess

subprocess.Popen(["chmod", "777", "main.py"], shell=True)
```

## References
- [Common Weakness Enumeration: CWE-78](https://cwe.mitre.org/data/definitions/78.html)

# django-extra (S610)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of Django's `extra` function where one or more arguments
passed are not literal expressions.

## Why is this bad?
Django's `extra` function can be used to execute arbitrary SQL queries,
which can in turn lead to SQL injection vulnerabilities.

## Example
```python
from django.contrib.auth.models import User

# String interpolation creates a security loophole that could be used
# for SQL injection:
User.objects.all().extra(select={"test": "%secure" % "nos"})
```

Use instead:
```python
from django.contrib.auth.models import User

# SQL injection is impossible if all arguments are literal expressions:
User.objects.all().extra(select={"test": "secure"})
```

## References
- [Django documentation: SQL injection protection](https://docs.djangoproject.com/en/dev/topics/security/#sql-injection-protection)
- [Common Weakness Enumeration: CWE-89](https://cwe.mitre.org/data/definitions/89.html)

# django-raw-sql (S611)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of Django's `RawSQL` function.

## Why is this bad?
Django's `RawSQL` function can be used to execute arbitrary SQL queries,
which can in turn lead to SQL injection vulnerabilities.

## Example
```python
from django.db.models.expressions import RawSQL
from django.contrib.auth.models import User

User.objects.annotate(val=RawSQL("%s" % input_param, []))
```

## References
- [Django documentation: SQL injection protection](https://docs.djangoproject.com/en/dev/topics/security/#sql-injection-protection)
- [Common Weakness Enumeration: CWE-89](https://cwe.mitre.org/data/definitions/89.html)

# logging-config-insecure-listen (S612)

Derived from the **flake8-bandit** linter.

## What it does
Checks for insecure `logging.config.listen` calls.

## Why is this bad?
`logging.config.listen` starts a server that listens for logging
configuration requests. This is insecure, as parts of the configuration are
passed to the built-in `eval` function, which can be used to execute
arbitrary code.

## Example
```python
import logging

logging.config.listen(9999)
```

## References
- [Python documentation: `logging.config.listen()`](https://docs.python.org/3/library/logging.config.html#logging.config.listen)

# jinja2-autoescape-false (S701)

Derived from the **flake8-bandit** linter.

## What it does
Checks for `jinja2` templates that use `autoescape=False`.

## Why is this bad?
`jinja2` templates that use `autoescape=False` are vulnerable to cross-site
scripting (XSS) attacks that allow attackers to execute arbitrary
JavaScript.

By default, `jinja2` sets `autoescape` to `False`, so it is important to
set `autoescape=True` or use the `select_autoescape` function to mitigate
XSS vulnerabilities.

## Example
```python
import jinja2

jinja2.Environment(loader=jinja2.FileSystemLoader("."))
```

Use instead:
```python
import jinja2

jinja2.Environment(loader=jinja2.FileSystemLoader("."), autoescape=True)
```

## References
- [Jinja documentation: API](https://jinja.palletsprojects.com/en/latest/api/#autoescaping)
- [Common Weakness Enumeration: CWE-94](https://cwe.mitre.org/data/definitions/94.html)

# mako-templates (S702)

Derived from the **flake8-bandit** linter.

## What it does
Checks for uses of the `mako` templates.

## Why is this bad?
Mako templates allow HTML and JavaScript rendering by default, and are
inherently open to XSS attacks. Ensure variables in all templates are
properly sanitized via the `n`, `h` or `x` flags (depending on context).
For example, to HTML escape the variable `data`, use `${ data |h }`.

## Example
```python
from mako.template import Template

Template("hello")
```

Use instead:
```python
from mako.template import Template

Template("hello |h")
```

## References
- [Mako documentation](https://www.makotemplates.org/)
- [OpenStack security: Cross site scripting XSS](https://security.openstack.org/guidelines/dg_cross-site-scripting-xss.html)
- [Common Weakness Enumeration: CWE-80](https://cwe.mitre.org/data/definitions/80.html)

# unsafe-markup-use (S704)

Derived from the **flake8-bandit** linter.

## What it does
Checks for non-literal strings being passed to [`markupsafe.Markup`][markupsafe-markup].

## Why is this bad?
[`markupsafe.Markup`][markupsafe-markup] does not perform any escaping, so passing dynamic
content, like f-strings, variables or interpolated strings will potentially
lead to XSS vulnerabilities.

Instead you should interpolate the `Markup` object.

Using [`lint.flake8-bandit.extend-markup-names`] additional objects can be
treated like `Markup`.

This rule was originally inspired by [flake8-markupsafe] but doesn't carve
out any exceptions for i18n related calls by default.

You can use [`lint.flake8-bandit.allowed-markup-calls`] to specify exceptions.

## Example
Given:
```python
from markupsafe import Markup

content = "<script>alert('Hello, world!')</script>"
html = Markup(f"<b>{content}</b>")  # XSS
```

Use instead:
```python
from markupsafe import Markup

content = "<script>alert('Hello, world!')</script>"
html = Markup("<b>{}</b>").format(content)  # Safe
```

Given:
```python
from markupsafe import Markup

lines = [
    Markup("<b>heading</b>"),
    "<script>alert('XSS attempt')</script>",
]
html = Markup("<br>".join(lines))  # XSS
```

Use instead:
```python
from markupsafe import Markup

lines = [
    Markup("<b>heading</b>"),
    "<script>alert('XSS attempt')</script>",
]
html = Markup("<br>").join(lines)  # Safe
```
## Options
- `lint.flake8-bandit.extend-markup-names`
- `lint.flake8-bandit.allowed-markup-calls`

## References
- [MarkupSafe on PyPI](https://pypi.org/project/MarkupSafe/)
- [`markupsafe.Markup` API documentation](https://markupsafe.palletsprojects.com/en/stable/escaping/#markupsafe.Markup)

[markupsafe-markup]: https://markupsafe.palletsprojects.com/en/stable/escaping/#markupsafe.Markup
[flake8-markupsafe]: https://github.com/vmagamedov/flake8-markupsafe

# blind-except (BLE001)

Derived from the **flake8-blind-except** linter.

## What it does
Checks for `except` clauses that catch all exceptions.  This includes
`except BaseException` and `except Exception`.


## Why is this bad?
Overly broad `except` clauses can lead to unexpected behavior, such as
catching `KeyboardInterrupt` or `SystemExit` exceptions that prevent the
user from exiting the program.

Instead of catching all exceptions, catch only those that are expected to
be raised in the `try` block.

## Example
```python
try:
    foo()
except BaseException:
    ...
```

Use instead:
```python
try:
    foo()
except FileNotFoundError:
    ...
```

Exceptions that are re-raised will _not_ be flagged, as they're expected to
be caught elsewhere:
```python
try:
    foo()
except BaseException:
    raise
```

Exceptions that are logged via `logging.exception()` or are logged via
`logging.error()` or `logging.critical()` with `exc_info` enabled will
_not_ be flagged, as this is a common pattern for propagating exception
traces:
```python
try:
    foo()
except BaseException:
    logging.exception("Something went wrong")
```

## References
- [Python documentation: The `try` statement](https://docs.python.org/3/reference/compound_stmts.html#the-try-statement)
- [Python documentation: Exception hierarchy](https://docs.python.org/3/library/exceptions.html#exception-hierarchy)
- [PEP 8: Programming Recommendations on bare `except`](https://peps.python.org/pep-0008/#programming-recommendations)

# boolean-type-hint-positional-argument (FBT001)

Derived from the **flake8-boolean-trap** linter.

## What it does
Checks for the use of boolean positional arguments in function definitions,
as determined by the presence of a type hint containing `bool` as an
evident subtype - e.g. `bool`, `bool | int`, `typing.Optional[bool]`, etc.

## Why is this bad?
Calling a function with boolean positional arguments is confusing as the
meaning of the boolean value is not clear to the caller and to future
readers of the code.

The use of a boolean will also limit the function to only two possible
behaviors, which makes the function difficult to extend in the future.

Instead, consider refactoring into separate implementations for the
`True` and `False` cases, using an `Enum`, or making the argument a
keyword-only argument, to force callers to be explicit when providing
the argument.

Dunder methods that define operators are exempt from this rule, as are
setters and [`@override`][override] definitions.

## Example

```python
from math import ceil, floor


def round_number(number: float, up: bool) -> int:
    return ceil(number) if up else floor(number)


round_number(1.5, True)  # What does `True` mean?
round_number(1.5, False)  # What does `False` mean?
```

Instead, refactor into separate implementations:

```python
from math import ceil, floor


def round_up(number: float) -> int:
    return ceil(number)


def round_down(number: float) -> int:
    return floor(number)


round_up(1.5)
round_down(1.5)
```

Or, refactor to use an `Enum`:

```python
from enum import Enum


class RoundingMethod(Enum):
    UP = 1
    DOWN = 2


def round_number(value: float, method: RoundingMethod) -> float: ...
```

Or, make the argument a keyword-only argument:

```python
from math import ceil, floor


def round_number(number: float, *, up: bool) -> int:
    return ceil(number) if up else floor(number)


round_number(1.5, up=True)
round_number(1.5, up=False)
```

## References
- [Python documentation: Calls](https://docs.python.org/3/reference/expressions.html#calls)
- [_How to Avoid The Boolean Trap_ by Adam Johnson](https://adamj.eu/tech/2021/07/10/python-type-hints-how-to-avoid-the-boolean-trap/)

[override]: https://docs.python.org/3/library/typing.html#typing.override

# boolean-default-value-positional-argument (FBT002)

Derived from the **flake8-boolean-trap** linter.

## What it does
Checks for the use of boolean positional arguments in function definitions,
as determined by the presence of a boolean default value.

## Why is this bad?
Calling a function with boolean positional arguments is confusing as the
meaning of the boolean value is not clear to the caller and to future
readers of the code.

The use of a boolean will also limit the function to only two possible
behaviors, which makes the function difficult to extend in the future.

Instead, consider refactoring into separate implementations for the
`True` and `False` cases, using an `Enum`, or making the argument a
keyword-only argument, to force callers to be explicit when providing
the argument.

This rule exempts methods decorated with [`@typing.override`][override],
since changing the signature of a subclass method that overrides a
superclass method may cause type checkers to complain about a violation of
the Liskov Substitution Principle.

## Example
```python
from math import ceil, floor


def round_number(number, up=True):
    return ceil(number) if up else floor(number)


round_number(1.5, True)  # What does `True` mean?
round_number(1.5, False)  # What does `False` mean?
```

Instead, refactor into separate implementations:
```python
from math import ceil, floor


def round_up(number):
    return ceil(number)


def round_down(number):
    return floor(number)


round_up(1.5)
round_down(1.5)
```

Or, refactor to use an `Enum`:
```python
from enum import Enum


class RoundingMethod(Enum):
    UP = 1
    DOWN = 2


def round_number(value, method):
    return ceil(number) if method is RoundingMethod.UP else floor(number)


round_number(1.5, RoundingMethod.UP)
round_number(1.5, RoundingMethod.DOWN)
```

Or, make the argument a keyword-only argument:
```python
from math import ceil, floor


def round_number(number, *, up=True):
    return ceil(number) if up else floor(number)


round_number(1.5, up=True)
round_number(1.5, up=False)
```

## References
- [Python documentation: Calls](https://docs.python.org/3/reference/expressions.html#calls)
- [_How to Avoid The Boolean Trap_ by Adam Johnson](https://adamj.eu/tech/2021/07/10/python-type-hints-how-to-avoid-the-boolean-trap/)

[override]: https://docs.python.org/3/library/typing.html#typing.override

# boolean-positional-value-in-call (FBT003)

Derived from the **flake8-boolean-trap** linter.

## What it does
Checks for boolean positional arguments in function calls.

Some functions are whitelisted by default. To extend the list of allowed calls
configure the [`lint.flake8-boolean-trap.extend-allowed-calls`] option.

## Why is this bad?
Calling a function with boolean positional arguments is confusing as the
meaning of the boolean value is not clear to the caller, and to future
readers of the code.

## Example

```python
def func(flag: bool) -> None: ...


func(True)
```

Use instead:

```python
def func(flag: bool) -> None: ...


func(flag=True)
```

## Options
- `lint.flake8-boolean-trap.extend-allowed-calls`

## References
- [Python documentation: Calls](https://docs.python.org/3/reference/expressions.html#calls)
- [_How to Avoid The Boolean Trap_ by Adam Johnson](https://adamj.eu/tech/2021/07/10/python-type-hints-how-to-avoid-the-boolean-trap/)

# unary-prefix-increment-decrement (B002)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for the attempted use of the unary prefix increment (`++`) or
decrement operator (`--`).

## Why is this bad?
Python does not support the unary prefix increment or decrement operator.
Writing `++n` is equivalent to `+(+(n))` and writing `--n` is equivalent to
`-(-(n))`. In both cases, it is equivalent to `n`.

## Example
```python
++x
--y
```

Use instead:
```python
x += 1
y -= 1
```

## References
- [Python documentation: Unary arithmetic and bitwise operations](https://docs.python.org/3/reference/expressions.html#unary-arithmetic-and-bitwise-operations)
- [Python documentation: Augmented assignment statements](https://docs.python.org/3/reference/simple_stmts.html#augmented-assignment-statements)

# assignment-to-os-environ (B003)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for assignments to `os.environ`.

## Why is this bad?
In Python, `os.environ` is a mapping that represents the environment of the
current process.

However, reassigning to `os.environ` does not clear the environment. Instead,
it merely updates the `os.environ` for the current process. This can lead to
unexpected behavior, especially when running the program in a subprocess.

Instead, use `os.environ.clear()` to clear the environment, or use the
`env` argument of `subprocess.Popen` to pass a custom environment to
a subprocess.

## Example
```python
import os

os.environ = {"foo": "bar"}
```

Use instead:
```python
import os

os.environ.clear()
os.environ["foo"] = "bar"
```

## References
- [Python documentation: `os.environ`](https://docs.python.org/3/library/os.html#os.environ)
- [Python documentation: `subprocess.Popen`](https://docs.python.org/3/library/subprocess.html#subprocess.Popen)

# unreliable-callable-check (B004)

Derived from the **flake8-bugbear** linter.

Fix is sometimes available.

## What it does
Checks for uses of `hasattr` to test if an object is callable (e.g.,
`hasattr(obj, "__call__")`).

## Why is this bad?
Using `hasattr` is an unreliable mechanism for testing if an object is
callable. If `obj` implements a custom `__getattr__`, or if its `__call__`
is itself not callable, you may get misleading results.

Instead, use `callable(obj)` to test if `obj` is callable.

## Example
```python
hasattr(obj, "__call__")
```

Use instead:
```python
callable(obj)
```

## Fix safety
This rule's fix is marked as unsafe because the replacement may not be semantically
equivalent to the original expression, potentially changing the behavior of the code.

For example, an imported module may have a `__call__` attribute but is not considered
a callable object:
```python
import operator

assert hasattr(operator, "__call__")
assert callable(operator) is False
```
Additionally, `__call__` may be defined only as an instance method:
```python
class A:
    def __init__(self):
        self.__call__ = None


assert hasattr(A(), "__call__")
assert callable(A()) is False
```

Additionally, if there are comments in the `hasattr` call expression, they may be removed:
```python
hasattr(
    # comment 1
    obj,  # comment 2
    # comment 3
    "__call__",  # comment 4
    # comment 5
)
```

## References
- [Python documentation: `callable`](https://docs.python.org/3/library/functions.html#callable)
- [Python documentation: `hasattr`](https://docs.python.org/3/library/functions.html#hasattr)
- [Python documentation: `__getattr__`](https://docs.python.org/3/reference/datamodel.html#object.__getattr__)
- [Python documentation: `__call__`](https://docs.python.org/3/reference/datamodel.html#object.__call__)

# strip-with-multi-characters (B005)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for uses of multi-character strings in `.strip()`, `.lstrip()`, and
`.rstrip()` calls.

## Why is this bad?
All characters in the call to `.strip()`, `.lstrip()`, or `.rstrip()` are
removed from the leading and trailing ends of the string. If the string
contains multiple characters, the reader may be misled into thinking that
a prefix or suffix is being removed, rather than a set of characters.

In Python 3.9 and later, you can use `str.removeprefix` and
`str.removesuffix` to remove an exact prefix or suffix from a string,
respectively, which should be preferred when possible.

## Known problems
As a heuristic, this rule only flags multi-character strings that contain
duplicate characters. This allows usages like `.strip("xyz")`, which
removes all occurrences of the characters `x`, `y`, and `z` from the
leading and trailing ends of the string, but not `.strip("foo")`.

The use of unique, multi-character strings may be intentional and
consistent with the intent of `.strip()`, `.lstrip()`, or `.rstrip()`,
while the use of duplicate-character strings is very likely to be a
mistake.

## Example
```python
"text.txt".strip(".txt")  # "e"
```

Use instead:
```python
"text.txt".removesuffix(".txt")  # "text"
```

## References
- [Python documentation: `str.strip`](https://docs.python.org/3/library/stdtypes.html#str.strip)

# mutable-argument-default (B006)

Derived from the **flake8-bugbear** linter.

Fix is sometimes available.

## What it does
Checks for uses of mutable objects as function argument defaults.

## Why is this bad?
Function defaults are evaluated once, when the function is defined.

The same mutable object is then shared across all calls to the function.
If the object is modified, those modifications will persist across calls,
which can lead to unexpected behavior.

Instead, prefer to use immutable data structures, or take `None` as a
default, and initialize a new mutable object inside the function body
for each call.

Arguments with immutable type annotations will be ignored by this rule.
Types outside of the standard library can be marked as immutable with the
[`lint.flake8-bugbear.extend-immutable-calls`] configuration option.

## Known problems
Mutable argument defaults can be used intentionally to cache computation
results. Replacing the default with `None` or an immutable data structure
does not work for such usages. Instead, prefer the `@functools.lru_cache`
decorator from the standard library.

## Example
```python
def add_to_list(item, some_list=[]):
    some_list.append(item)
    return some_list


l1 = add_to_list(0)  # [0]
l2 = add_to_list(1)  # [0, 1]
```

Use instead:
```python
def add_to_list(item, some_list=None):
    if some_list is None:
        some_list = []
    some_list.append(item)
    return some_list


l1 = add_to_list(0)  # [0]
l2 = add_to_list(1)  # [1]
```

## Options
- `lint.flake8-bugbear.extend-immutable-calls`

## Fix safety

This fix is marked as unsafe because it replaces the mutable default with `None`
and initializes it in the function body, which may not be what the user intended,
as described above.

## References
- [Python documentation: Default Argument Values](https://docs.python.org/3/tutorial/controlflow.html#default-argument-values)

# unused-loop-control-variable (B007)

Derived from the **flake8-bugbear** linter.

Fix is sometimes available.

## What it does
Checks for unused variables in loops (e.g., `for` and `while` statements).

## Why is this bad?
Defining a variable in a loop statement that is never used can confuse
readers.

If the variable is intended to be unused (e.g., to facilitate
destructuring of a tuple or other object), prefix it with an underscore
to indicate the intent. Otherwise, remove the variable entirely.

## Example
```python
for i, j in foo:
    bar(i)
```

Use instead:
```python
for i, _j in foo:
    bar(i)
```

## References
- [PEP 8: Naming Conventions](https://peps.python.org/pep-0008/#naming-conventions)

# function-call-in-default-argument (B008)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for function calls in default function arguments.

## Why is this bad?
Any function call that's used in a default argument will only be performed
once, at definition time. The returned value will then be reused by all
calls to the function, which can lead to unexpected behaviour.

Parameters with immutable type annotations will be ignored by this rule.
Those whose default arguments are `NewType` calls where the original type
is immutable are also ignored.

Calls and types outside of the standard library can be marked as an exception
to this rule with the [`lint.flake8-bugbear.extend-immutable-calls`] configuration option.

## Example

```python
def create_list() -> list[int]:
    return [1, 2, 3]


def mutable_default(arg: list[int] = create_list()) -> list[int]:
    arg.append(4)
    return arg
```

Use instead:

```python
def better(arg: list[int] | None = None) -> list[int]:
    if arg is None:
        arg = create_list()

    arg.append(4)
    return arg
```

If the use of a singleton is intentional, assign the result call to a
module-level variable, and use that variable in the default argument:

```python
ERROR = ValueError("Hosts weren't successfully added")


def add_host(error: Exception = ERROR) -> None: ...
```

## Options
- `lint.flake8-bugbear.extend-immutable-calls`

# get-attr-with-constant (B009)

Derived from the **flake8-bugbear** linter.

Fix is always available.

## What it does
Checks for uses of `getattr` that take a constant attribute value as an
argument (e.g., `getattr(obj, "foo")`).

## Why is this bad?
`getattr` is used to access attributes dynamically. If the attribute is
defined as a constant, it is no safer than a typical property access. When
possible, prefer property access over `getattr` calls, as the former is
more concise and idiomatic.


## Example
```python
getattr(obj, "foo")
```

Use instead:
```python
obj.foo
```

## Fix safety
The fix is marked as unsafe for attribute names that are not in NFKC (Normalization Form KC)
normalization. Python normalizes identifiers using NFKC when using attribute access syntax
(e.g., `obj.attr`), but does not normalize string arguments passed to `getattr`. Rewriting
`getattr(obj, "")` to `obj.` would be interpreted as `obj.s` at runtime, changing behavior.

For example, the long s character `""` normalizes to `"s"` under NFKC, so:
```python
# This accesses an attribute with the exact name "" (if it exists)
value = getattr(obj, "")

# But this would normalize to "s" and access a different attribute
obj.  # This is interpreted as obj.s, not obj.
```

## References
- [Python documentation: `getattr`](https://docs.python.org/3/library/functions.html#getattr)

# set-attr-with-constant (B010)

Derived from the **flake8-bugbear** linter.

Fix is always available.

## What it does
Checks for uses of `setattr` that take a constant attribute value as an
argument (e.g., `setattr(obj, "foo", 42)`).

## Why is this bad?
`setattr` is used to set attributes dynamically. If the attribute is
defined as a constant, it is no safer than a typical property access. When
possible, prefer property access over `setattr` calls, as the former is
more concise and idiomatic.

## Example
```python
setattr(obj, "foo", 42)
```

Use instead:
```python
obj.foo = 42
```

## Fix safety
The fix is marked as unsafe for attribute names that are not in NFKC (Normalization Form KC)
normalization. Python normalizes identifiers using NFKC when using attribute access syntax
(e.g., `obj.attr = value`), but does not normalize string arguments passed to `setattr`.
Rewriting `setattr(obj, "", 1)` to `obj. = 1` would be interpreted as `obj.s = 1` at
runtime, changing behavior.

For example, the long s character `""` normalizes to `"s"` under NFKC, so:
```python
# This creates an attribute with the exact name ""
setattr(obj, "", 1)
getattr(obj, "")  # Returns 1

# But this would normalize to "s" and set a different attribute
obj. = 1  # This is interpreted as obj.s = 1, not obj. = 1
```

## References
- [Python documentation: `setattr`](https://docs.python.org/3/library/functions.html#setattr)

# assert-false (B011)

Derived from the **flake8-bugbear** linter.

Fix is always available.

## What it does
Checks for uses of `assert False`.

## Why is this bad?
Python removes `assert` statements when running in optimized mode
(`python -O`), making `assert False` an unreliable means of
raising an `AssertionError`.

Instead, raise an `AssertionError` directly.

## Example
```python
assert False
```

Use instead:
```python
raise AssertionError
```

## Fix safety
This rule's fix is marked as unsafe, as changing an `assert` to a
`raise` will change the behavior of your program when running in
optimized mode (`python -O`).

## References
- [Python documentation: `assert`](https://docs.python.org/3/reference/simple_stmts.html#the-assert-statement)

# jump-statement-in-finally (B012)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for `break`, `continue`, and `return` statements in `finally`
blocks.

## Why is this bad?
The use of `break`, `continue`, and `return` statements in `finally` blocks
can cause exceptions to be silenced.

`finally` blocks execute regardless of whether an exception is raised. If a
`break`, `continue`, or `return` statement is reached in a `finally` block,
any exception raised in the `try` or `except` blocks will be silenced.

## Example
```python
def speed(distance, time):
    try:
        return distance / time
    except ZeroDivisionError:
        raise ValueError("Time cannot be zero")
    finally:
        return 299792458  # `ValueError` is silenced
```

Use instead:
```python
def speed(distance, time):
    try:
        return distance / time
    except ZeroDivisionError:
        raise ValueError("Time cannot be zero")
```

## References
- [Python documentation: The `try` statement](https://docs.python.org/3/reference/compound_stmts.html#the-try-statement)

# redundant-tuple-in-exception-handler (B013)

Derived from the **flake8-bugbear** linter.

Fix is always available.

## What it does
Checks for single-element tuples in exception handlers (e.g.,
`except (ValueError,):`).

Note: Single-element tuples consisting of a starred expression
are allowed.

## Why is this bad?
A tuple with a single element can be more concisely and idiomatically
expressed as a single value.

## Example
```python
try:
    ...
except (ValueError,):
    ...
```

Use instead:
```python
try:
    ...
except ValueError:
    ...
```

## References
- [Python documentation: `except` clause](https://docs.python.org/3/reference/compound_stmts.html#except-clause)

# duplicate-handler-exception (B014)

Derived from the **flake8-bugbear** linter.

Fix is always available.

## What it does
Checks for exception handlers that catch duplicate exceptions.

## Why is this bad?
Including the same exception multiple times in the same handler is redundant,
as the first exception will catch the exception, making the second exception
unreachable. The same applies to exception hierarchies, as a handler for a
parent exception (like `Exception`) will also catch child exceptions (like
`ValueError`).

## Example
```python
try:
    ...
except (Exception, ValueError):  # `Exception` includes `ValueError`.
    ...
```

Use instead:
```python
try:
    ...
except Exception:
    ...
```

## References
- [Python documentation: `except` clause](https://docs.python.org/3/reference/compound_stmts.html#except-clause)
- [Python documentation: Exception hierarchy](https://docs.python.org/3/library/exceptions.html#exception-hierarchy)

# useless-comparison (B015)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for useless comparisons.

## Why is this bad?
Useless comparisons have no effect on the program, and are often included
by mistake. If the comparison is intended to enforce an invariant, prepend
the comparison with an `assert`. Otherwise, remove it entirely.

## Example
```python
foo == bar
```

Use instead:
```python
assert foo == bar, "`foo` and `bar` should be equal."
```

## Notebook behavior
For Jupyter Notebooks, this rule is not applied to the last top-level expression in a cell.
This is because it's common to have a notebook cell that ends with an expression,
which will result in the `repr` of the evaluated expression being printed as the cell's output.

## References
- [Python documentation: `assert` statement](https://docs.python.org/3/reference/simple_stmts.html#the-assert-statement)

# raise-literal (B016)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for `raise` statements that raise a literal value.

## Why is this bad?
`raise` must be followed by an exception instance or an exception class,
and exceptions must be instances of `BaseException` or a subclass thereof.
Raising a literal will raise a `TypeError` at runtime.

## Example
```python
raise "foo"
```

Use instead:
```python
raise Exception("foo")
```

## References
- [Python documentation: `raise` statement](https://docs.python.org/3/reference/simple_stmts.html#the-raise-statement)

# assert-raises-exception (B017)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for `assertRaises` and `pytest.raises` context managers that catch
`Exception` or `BaseException`.

## Why is this bad?
These forms catch every `Exception`, which can lead to tests passing even
if, e.g., the code under consideration raises a `SyntaxError` or
`IndentationError`.

Either assert for a more specific exception (builtin or custom), or use
`assertRaisesRegex` or `pytest.raises(..., match=<REGEX>)` respectively.

## Example
```python
self.assertRaises(Exception, foo)
```

Use instead:
```python
self.assertRaises(SomeSpecificException, foo)
```

# useless-expression (B018)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for useless expressions.

## Why is this bad?
Useless expressions have no effect on the program, and are often included
by mistake. Assign a useless expression to a variable, or remove it
entirely.

## Example
```python
1 + 1
```

Use instead:
```python
foo = 1 + 1
```

## Notebook behavior
For Jupyter Notebooks, this rule is not applied to the last top-level expression in a cell.
This is because it's common to have a notebook cell that ends with an expression,
which will result in the `repr` of the evaluated expression being printed as the cell's output.

## Known problems
This rule ignores expression types that are commonly used for their side
effects, such as function calls.

However, if a seemingly useless expression (like an attribute access) is
needed to trigger a side effect, consider assigning it to an anonymous
variable, to indicate that the return value is intentionally ignored.

For example, given:
```python
with errors.ExceptionRaisedContext():
    obj.attribute
```

Use instead:
```python
with errors.ExceptionRaisedContext():
    _ = obj.attribute
```

# cached-instance-method (B019)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for uses of the `functools.lru_cache` and `functools.cache`
decorators on methods.

## Why is this bad?
Using the `functools.lru_cache` and `functools.cache` decorators on methods
can lead to memory leaks, as the global cache will retain a reference to
the instance, preventing it from being garbage collected.

Instead, refactor the method to depend only on its arguments and not on the
instance of the class, or use the `@lru_cache` decorator on a function
outside of the class.

This rule ignores instance methods on enumeration classes, as enum members
are singletons.

## Example
```python
from functools import lru_cache


def square(x: int) -> int:
    return x * x


class Number:
    value: int

    @lru_cache
    def squared(self):
        return square(self.value)
```

Use instead:
```python
from functools import lru_cache


@lru_cache
def square(x: int) -> int:
    return x * x


class Number:
    value: int

    def squared(self):
        return square(self.value)
```

## References
- [Python documentation: `functools.lru_cache`](https://docs.python.org/3/library/functools.html#functools.lru_cache)
- [Python documentation: `functools.cache`](https://docs.python.org/3/library/functools.html#functools.cache)
- [don't lru_cache methods!](https://www.youtube.com/watch?v=sVjtp6tGo0g)

# loop-variable-overrides-iterator (B020)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for loop control variables that override the loop iterable.

## Why is this bad?
Loop control variables should not override the loop iterable, as this can
lead to confusing behavior.

Instead, use a distinct variable name for any loop control variables.

## Example
```python
items = [1, 2, 3]

for items in items:
    print(items)
```

Use instead:
```python
items = [1, 2, 3]

for item in items:
    print(item)
```

## References
- [Python documentation: The `for` statement](https://docs.python.org/3/reference/compound_stmts.html#the-for-statement)

# f-string-docstring (B021)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for docstrings that are written via f-strings.

## Why is this bad?
Python will interpret the f-string as a joined string, rather than as a
docstring. As such, the "docstring" will not be accessible via the
`__doc__` attribute, nor will it be picked up by any automated
documentation tooling.

## Example
```python
def foo():
    f"""Not a docstring."""
```

Use instead:
```python
def foo():
    """A docstring."""
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [Python documentation: Formatted string literals](https://docs.python.org/3/reference/lexical_analysis.html#f-strings)

# useless-contextlib-suppress (B022)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for `contextlib.suppress` without arguments.

## Why is this bad?
`contextlib.suppress` is a context manager that suppresses exceptions. It takes,
as arguments, the exceptions to suppress within the enclosed block. If no
exceptions are specified, then the context manager won't suppress any
exceptions, and is thus redundant.

Consider adding exceptions to the `contextlib.suppress` call, or removing the
context manager entirely.

## Example
```python
import contextlib

with contextlib.suppress():
    foo()
```

Use instead:
```python
import contextlib

with contextlib.suppress(Exception):
    foo()
```

## References
- [Python documentation: `contextlib.suppress`](https://docs.python.org/3/library/contextlib.html#contextlib.suppress)

# function-uses-loop-variable (B023)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for function definitions that use a loop variable.

## Why is this bad?
The loop variable is not bound in the function definition, so it will always
have the value it had in the last iteration when the function is called.

Instead, consider using a default argument to bind the loop variable at
function definition time. Or, use `functools.partial`.

## Example
```python
adders = [lambda x: x + i for i in range(3)]
values = [adder(1) for adder in adders]  # [3, 3, 3]
```

Use instead:
```python
adders = [lambda x, i=i: x + i for i in range(3)]
values = [adder(1) for adder in adders]  # [1, 2, 3]
```

Or:
```python
from functools import partial

adders = [partial(lambda x, i: x + i, i=i) for i in range(3)]
values = [adder(1) for adder in adders]  # [1, 2, 3]
```

## References
- [The Hitchhiker's Guide to Python: Late Binding Closures](https://docs.python-guide.org/writing/gotchas/#late-binding-closures)
- [Python documentation: `functools.partial`](https://docs.python.org/3/library/functools.html#functools.partial)

# abstract-base-class-without-abstract-method (B024)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for abstract classes without abstract methods or properties.
Annotated but unassigned class variables are regarded as abstract.

## Why is this bad?
Abstract base classes are used to define interfaces. If an abstract base
class has no abstract methods or properties, you may have forgotten
to add an abstract method or property to the class,
or omitted an `@abstractmethod` decorator.

If the class is _not_ meant to be used as an interface, consider removing
the `ABC` base class from the class definition.

## Example
```python
from abc import ABC
from typing import ClassVar


class Foo(ABC):
    class_var: ClassVar[str] = "assigned"

    def method(self):
        bar()
```

Use instead:
```python
from abc import ABC, abstractmethod
from typing import ClassVar


class Foo(ABC):
    class_var: ClassVar[str]  # unassigned

    @abstractmethod
    def method(self):
        bar()
```

## References
- [Python documentation: `abc`](https://docs.python.org/3/library/abc.html)
- [Python documentation: `typing.ClassVar`](https://docs.python.org/3/library/typing.html#typing.ClassVar)

# duplicate-try-block-exception (B025)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for `try-except` blocks with duplicate exception handlers.

## Why is this bad?
Duplicate exception handlers are redundant, as the first handler will catch
the exception, making the second handler unreachable.

## Example
```python
try:
    ...
except ValueError:
    ...
except ValueError:
    ...
```

Use instead:
```python
try:
    ...
except ValueError:
    ...
```

## References
- [Python documentation: `except` clause](https://docs.python.org/3/reference/compound_stmts.html#except-clause)

# star-arg-unpacking-after-keyword-arg (B026)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for function calls that use star-argument unpacking after providing a
keyword argument

## Why is this bad?
In Python, you can use star-argument unpacking to pass a list or tuple of
arguments to a function.

Providing a star-argument after a keyword argument can lead to confusing
behavior, and is only supported for backwards compatibility.

## Example
```python
def foo(x, y, z):
    return x, y, z


foo(1, 2, 3)  # (1, 2, 3)
foo(1, *[2, 3])  # (1, 2, 3)
# foo(x=1, *[2, 3])  # TypeError
# foo(y=2, *[1, 3])  # TypeError
foo(z=3, *[1, 2])  # (1, 2, 3)  # No error, but confusing!
```

Use instead:
```python
def foo(x, y, z):
    return x, y, z


foo(1, 2, 3)  # (1, 2, 3)
foo(x=1, y=2, z=3)  # (1, 2, 3)
foo(*[1, 2, 3])  # (1, 2, 3)
foo(*[1, 2], 3)  # (1, 2, 3)
```

## References
- [Python documentation: Calls](https://docs.python.org/3/reference/expressions.html#calls)
- [Disallow iterable argument unpacking after a keyword argument?](https://github.com/python/cpython/issues/82741)

# empty-method-without-abstract-decorator (B027)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for empty methods in abstract base classes without an abstract
decorator.

## Why is this bad?
Empty methods in abstract base classes without an abstract decorator may be
be indicative of a mistake. If the method is meant to be abstract, add an
`@abstractmethod` decorator to the method.

## Example

```python
from abc import ABC


class Foo(ABC):
    def method(self): ...
```

Use instead:

```python
from abc import ABC, abstractmethod


class Foo(ABC):
    @abstractmethod
    def method(self): ...
```

## References
- [Python documentation: `abc`](https://docs.python.org/3/library/abc.html)

# no-explicit-stacklevel (B028)

Derived from the **flake8-bugbear** linter.

Fix is always available.

## What it does
Checks for `warnings.warn` calls without an explicit `stacklevel` keyword
argument.

## Why is this bad?
The `warnings.warn` method uses a `stacklevel` of 1 by default, which
will output a stack frame of the line on which the "warn" method
is called. Setting it to a higher number will output a stack frame
from higher up the stack.

It's recommended to use a `stacklevel` of 2 or higher, to give the caller
more context about the warning.

## Example
```python
import warnings

warnings.warn("This is a warning")
```

Use instead:
```python
import warnings

warnings.warn("This is a warning", stacklevel=2)
```

## Fix safety
This rule's fix is marked as unsafe because it changes
the behavior of the code. Moreover, the fix will assign
a stacklevel of 2, while the user may wish to assign a
higher stacklevel to address the diagnostic.

## References
- [Python documentation: `warnings.warn`](https://docs.python.org/3/library/warnings.html#warnings.warn)

# except-with-empty-tuple (B029)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for exception handlers that catch an empty tuple.

## Why is this bad?
An exception handler that catches an empty tuple will not catch anything,
and is indicative of a mistake. Instead, add exceptions to the `except`
clause.

## Example
```python
try:
    1 / 0
except ():
    ...
```

Use instead:
```python
try:
    1 / 0
except ZeroDivisionError:
    ...
```

## References
- [Python documentation: `except` clause](https://docs.python.org/3/reference/compound_stmts.html#except-clause)

# except-with-non-exception-classes (B030)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for exception handlers that catch non-exception classes.

## Why is this bad?
Catching classes that do not inherit from `BaseException` will raise a
`TypeError`.

## Example
```python
try:
    1 / 0
except 1:
    ...
```

Use instead:
```python
try:
    1 / 0
except ZeroDivisionError:
    ...
```

## References
- [Python documentation: `except` clause](https://docs.python.org/3/reference/compound_stmts.html#except-clause)
- [Python documentation: Built-in Exceptions](https://docs.python.org/3/library/exceptions.html#built-in-exceptions)

# reuse-of-groupby-generator (B031)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for multiple usage of the generator returned from
`itertools.groupby()`.

## Why is this bad?
Using the generator more than once will do nothing on the second usage.
If that data is needed later, it should be stored as a list.

## Example:
```python
import itertools

for name, group in itertools.groupby(data):
    for _ in range(5):
        do_something_with_the_group(group)
```

Use instead:
```python
import itertools

for name, group in itertools.groupby(data):
    values = list(group)
    for _ in range(5):
        do_something_with_the_group(values)
```

# unintentional-type-annotation (B032)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for the unintentional use of type annotations.

## Why is this bad?
The use of a colon (`:`) in lieu of an assignment (`=`) can be syntactically valid, but
is almost certainly a mistake when used in a subscript or attribute assignment.

## Example
```python
a["b"]: 1
```

Use instead:
```python
a["b"] = 1
```

# duplicate-value (B033)

Derived from the **flake8-bugbear** linter.

Fix is sometimes available.

## What it does
Checks for set literals that contain duplicate items.

## Why is this bad?
In Python, sets are unordered collections of unique elements. Including a
duplicate item in a set literal is redundant, as the duplicate item will be
replaced with a single item at runtime.

## Example
```python
{1, 2, 3, 1}
```

Use instead:
```python
{1, 2, 3}
```

# re-sub-positional-args (B034)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for calls to `re.sub`, `re.subn`, and `re.split` that pass `count`,
`maxsplit`, or `flags` as positional arguments.

## Why is this bad?
Passing `count`, `maxsplit`, or `flags` as positional arguments to
`re.sub`, `re.subn`, or `re.split` can lead to confusion, as most methods in
the `re` module accept `flags` as the third positional argument, while
`re.sub`, `re.subn`, and `re.split` have different signatures.

Instead, pass `count`, `maxsplit`, and `flags` as keyword arguments.

## Example
```python
import re

re.split("pattern", "replacement", 1)
```

Use instead:
```python
import re

re.split("pattern", "replacement", maxsplit=1)
```

## References
- [Python documentation: `re.sub`](https://docs.python.org/3/library/re.html#re.sub)
- [Python documentation: `re.subn`](https://docs.python.org/3/library/re.html#re.subn)
- [Python documentation: `re.split`](https://docs.python.org/3/library/re.html#re.split)

# static-key-dict-comprehension (B035)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for dictionary comprehensions that use a static key, like a string
literal or a variable defined outside the comprehension.

## Why is this bad?
Using a static key (like a string literal) in a dictionary comprehension
is usually a mistake, as it will result in a dictionary with only one key,
despite the comprehension iterating over multiple values.

## Example
```python
data = ["some", "Data"]
{"key": value.upper() for value in data}
```

Use instead:
```python
data = ["some", "Data"]
{value: value.upper() for value in data}
```

# mutable-contextvar-default (B039)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for uses of mutable objects as `ContextVar` defaults.

## Why is this bad?

The `ContextVar` default is evaluated once, when the `ContextVar` is defined.

The same mutable object is then shared across all `.get()` method calls to
the `ContextVar`. If the object is modified, those modifications will persist
across calls, which can lead to unexpected behavior.

Instead, prefer to use immutable data structures. Alternatively, take
`None` as a default, and initialize a new mutable object inside for each
call using the `.set()` method.

Types outside the standard library can be marked as immutable with the
[`lint.flake8-bugbear.extend-immutable-calls`] configuration option.

## Example
```python
from contextvars import ContextVar


cv: ContextVar[list] = ContextVar("cv", default=[])
```

Use instead:
```python
from contextvars import ContextVar


cv: ContextVar[list | None] = ContextVar("cv", default=None)

...

if cv.get() is None:
    cv.set([])
```

## Options
- `lint.flake8-bugbear.extend-immutable-calls`

## References
- [Python documentation: `contextvars`  Context Variables](https://docs.python.org/3/library/contextvars.html)

# return-in-generator (B901)

Derived from the **flake8-bugbear** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for `return {value}` statements in functions that also contain `yield`
or `yield from` statements.

## Why is this bad?
Using `return {value}` in a generator function was syntactically invalid in
Python 2. In Python 3 `return {value}` _can_ be used in a generator; however,
the combination of `yield` and `return` can lead to confusing behavior, as
the `return` statement will cause the generator to raise `StopIteration`
with the value provided, rather than returning the value to the caller.

For example, given:
```python
from collections.abc import Iterable
from pathlib import Path


def get_file_paths(file_types: Iterable[str] | None = None) -> Iterable[Path]:
    dir_path = Path(".")
    if file_types is None:
        return dir_path.glob("*")

    for file_type in file_types:
        yield from dir_path.glob(f"*.{file_type}")
```

Readers might assume that `get_file_paths()` would return an iterable of
`Path` objects in the directory; in reality, though, `list(get_file_paths())`
evaluates to `[]`, since the `return` statement causes the generator to raise
`StopIteration` with the value `dir_path.glob("*")`:

```shell
>>> list(get_file_paths(file_types=["cfg", "toml"]))
[PosixPath('setup.cfg'), PosixPath('pyproject.toml')]
>>> list(get_file_paths())
[]
```

For intentional uses of `return` in a generator, consider suppressing this
diagnostic.

## Example
```python
from collections.abc import Iterable
from pathlib import Path


def get_file_paths(file_types: Iterable[str] | None = None) -> Iterable[Path]:
    dir_path = Path(".")
    if file_types is None:
        return dir_path.glob("*")

    for file_type in file_types:
        yield from dir_path.glob(f"*.{file_type}")
```

Use instead:

```python
from collections.abc import Iterable
from pathlib import Path


def get_file_paths(file_types: Iterable[str] | None = None) -> Iterable[Path]:
    dir_path = Path(".")
    if file_types is None:
        yield from dir_path.glob("*")
    else:
        for file_type in file_types:
            yield from dir_path.glob(f"*.{file_type}")
```

# class-as-data-structure (B903)

Derived from the **flake8-bugbear** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for classes that only have a public `__init__` method,
without base classes and decorators.

## Why is this bad?
Classes with just an `__init__` are possibly better off
being a dataclass or a namedtuple, which have less boilerplate.

## Example
```python
class Point:
    def __init__(self, x: float, y: float):
        self.x = x
        self.y = y
```

Use instead:
```python
from dataclasses import dataclass


@dataclass
class Point:
    x: float
    y: float
```

# raise-without-from-inside-except (B904)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for `raise` statements in exception handlers that lack a `from`
clause.

## Why is this bad?
In Python, `raise` can be used with or without an exception from which the
current exception is derived. This is known as exception chaining. When
printing the stack trace, chained exceptions are displayed in such a way
so as make it easier to trace the exception back to its root cause.

When raising an exception from within an `except` clause, always include a
`from` clause to facilitate exception chaining. If the exception is not
chained, it will be difficult to trace the exception back to its root cause.

## Example
```python
try:
    ...
except FileNotFoundError:
    if ...:
        raise RuntimeError("...")
    else:
        raise UserWarning("...")
```

Use instead:
```python
try:
    ...
except FileNotFoundError as exc:
    if ...:
        raise RuntimeError("...") from None
    else:
        raise UserWarning("...") from exc
```

## References
- [Python documentation: `raise` statement](https://docs.python.org/3/reference/simple_stmts.html#the-raise-statement)

# zip-without-explicit-strict (B905)

Derived from the **flake8-bugbear** linter.

Fix is always available.

## What it does
Checks for `zip` calls without an explicit `strict` parameter when called with two or more iterables, or any starred argument.

## Why is this bad?
By default, if the iterables passed to `zip` are of different lengths, the
resulting iterator will be silently truncated to the length of the shortest
iterable. This can lead to subtle bugs.

Pass `strict=True` to raise a `ValueError` if the iterables are of
non-uniform length. Alternatively, if the iterables are deliberately of
different lengths, pass `strict=False` to make the intention explicit.

## Example
```python
zip(a, b)
```

Use instead:
```python
zip(a, b, strict=True)
```

## Fix safety
This rule's fix is marked as unsafe. While adding `strict=False` preserves
the runtime behavior, it can obscure situations where the iterables are of
unequal length. Ruff prefers to alert users so they can choose the intended
behavior themselves.

## References
- [Python documentation: `zip`](https://docs.python.org/3/library/functions.html#zip)

# loop-iterator-mutation (B909)

Derived from the **flake8-bugbear** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for mutations to an iterable during a loop iteration.

## Why is this bad?
When iterating over an iterable, mutating the iterable can lead to unexpected
behavior, like skipping elements or infinite loops.

## Example
```python
items = [1, 2, 3]

for item in items:
    print(item)

    # Create an infinite loop by appending to the list.
    items.append(item)
```

## References
- [Python documentation: Mutable Sequence Types](https://docs.python.org/3/library/stdtypes.html#typesseq-mutable)

# batched-without-explicit-strict (B911)

Derived from the **flake8-bugbear** linter.

## What it does
Checks for `itertools.batched` calls without an explicit `strict` parameter.

## Why is this bad?
By default, if the length of the iterable is not divisible by
the second argument to `itertools.batched`, the last batch
will be shorter than the rest.

In Python 3.13, a `strict` parameter was added which allows controlling if the batches must be of uniform length.
Pass `strict=True` to raise a `ValueError` if the batches are of non-uniform length.
Otherwise, pass `strict=False` to make the intention explicit.

## Example
```python
import itertools

itertools.batched(iterable, n)
```

Use instead if the batches must be of uniform length:
```python
import itertools

itertools.batched(iterable, n, strict=True)
```

Or if the batches can be of non-uniform length:
```python
import itertools

itertools.batched(iterable, n, strict=False)
```

## Known deviations
Unlike the upstream `B911`, this rule will not report infinite iterators
(e.g., `itertools.cycle(...)`).

## Options
- `target-version`

## References
- [Python documentation: `batched`](https://docs.python.org/3/library/itertools.html#batched)

# map-without-explicit-strict (B912)

Derived from the **flake8-bugbear** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for `map` calls without an explicit `strict` parameter when called with two or more iterables, or any starred argument.

This rule applies to Python 3.14 and later, where `map` accepts a `strict` keyword
argument. For details, see: [Whats New in Python 3.14](https://docs.python.org/dev/whatsnew/3.14.html).

## Why is this bad?
By default, if the iterables passed to `map` are of different lengths, the
resulting iterator will be silently truncated to the length of the shortest
iterable. This can lead to subtle bugs.

Pass `strict=True` to raise a `ValueError` if the iterables are of
non-uniform length. Alternatively, if the iterables are deliberately of
different lengths, pass `strict=False` to make the intention explicit.

## Example
```python
map(f, a, b)
```

Use instead:
```python
map(f, a, b, strict=True)
```

## Fix safety
This rule's fix is marked as unsafe. While adding `strict=False` preserves
the runtime behavior, it can obscure situations where the iterables are of
unequal length. Ruff prefers to alert users so they can choose the intended
behavior themselves.

## References
- [Python documentation: `map`](https://docs.python.org/3/library/functions.html#map)
- [Whats New in Python 3.14](https://docs.python.org/dev/whatsnew/3.14.html)

# builtin-variable-shadowing (A001)

Derived from the **flake8-builtins** linter.

## What it does
Checks for variable (and function) assignments that use the same names
as builtins.

## Why is this bad?
Reusing a builtin name for the name of a variable increases the
difficulty of reading and maintaining the code, and can cause
non-obvious errors, as readers may mistake the variable for the
builtin and vice versa.

Builtins can be marked as exceptions to this rule via the
[`lint.flake8-builtins.ignorelist`] configuration option.

## Example
```python
def find_max(list_of_lists):
    max = 0
    for flat_list in list_of_lists:
        for value in flat_list:
            max = max(max, value)  # TypeError: 'int' object is not callable
    return max
```

Use instead:
```python
def find_max(list_of_lists):
    result = 0
    for flat_list in list_of_lists:
        for value in flat_list:
            result = max(result, value)
    return result
```

## Options
- `lint.flake8-builtins.ignorelist`

## References
- [_Why is it a bad idea to name a variable `id` in Python?_](https://stackoverflow.com/questions/77552/id-is-a-bad-variable-name-in-python)

# builtin-argument-shadowing (A002)

Derived from the **flake8-builtins** linter.

## What it does
Checks for function arguments that use the same names as builtins.

## Why is this bad?
Reusing a builtin name for the name of an argument increases the
difficulty of reading and maintaining the code, and can cause
non-obvious errors, as readers may mistake the argument for the
builtin and vice versa.

Function definitions decorated with [`@override`][override] or
[`@overload`][overload] are exempt from this rule by default.
Builtins can be marked as exceptions to this rule via the
[`lint.flake8-builtins.ignorelist`] configuration option.

## Example
```python
def remove_duplicates(list, list2):
    result = set()
    for value in list:
        result.add(value)
    for value in list2:
        result.add(value)
    return list(result)  # TypeError: 'list' object is not callable
```

Use instead:
```python
def remove_duplicates(list1, list2):
    result = set()
    for value in list1:
        result.add(value)
    for value in list2:
        result.add(value)
    return list(result)
```

## Options
- `lint.flake8-builtins.ignorelist`

## References
- [_Is it bad practice to use a built-in function name as an attribute or method identifier?_](https://stackoverflow.com/questions/9109333/is-it-bad-practice-to-use-a-built-in-function-name-as-an-attribute-or-method-ide)
- [_Why is it a bad idea to name a variable `id` in Python?_](https://stackoverflow.com/questions/77552/id-is-a-bad-variable-name-in-python)

[override]: https://docs.python.org/3/library/typing.html#typing.override
[overload]: https://docs.python.org/3/library/typing.html#typing.overload

# builtin-attribute-shadowing (A003)

Derived from the **flake8-builtins** linter.

## What it does
Checks for class attributes and methods that use the same names as
Python builtins.

## Why is this bad?
Reusing a builtin name for the name of an attribute increases the
difficulty of reading and maintaining the code, and can cause
non-obvious errors, as readers may mistake the attribute for the
builtin and vice versa.

Since methods and class attributes typically cannot be referenced directly
from outside the class scope, this rule only applies to those methods
and attributes that both shadow a builtin _and_ are referenced from within
the class scope, as in the following example, where the `list[int]` return
type annotation resolves to the `list` method, rather than the builtin:

```python
class Class:
    @staticmethod
    def list() -> None:
        pass

    @staticmethod
    def repeat(value: int, times: int) -> list[int]:
        return [value] * times
```

Builtins can be marked as exceptions to this rule via the
[`lint.flake8-builtins.ignorelist`] configuration option, or
converted to the appropriate dunder method. Methods decorated with
`@typing.override` or `@typing_extensions.override` are also
ignored.

## Example
```python
class Class:
    @staticmethod
    def list() -> None:
        pass

    @staticmethod
    def repeat(value: int, times: int) -> list[int]:
        return [value] * times
```

## Options
- `lint.flake8-builtins.ignorelist`

# builtin-import-shadowing (A004)

Derived from the **flake8-builtins** linter.

## What it does
Checks for imports that use the same names as builtins.

## Why is this bad?
Reusing a builtin for the name of an import increases the difficulty
of reading and maintaining the code, and can cause non-obvious errors,
as readers may mistake the variable for the builtin and vice versa.

Builtins can be marked as exceptions to this rule via the
[`lint.flake8-builtins.ignorelist`] configuration option.

## Example
```python
from rich import print

print("Some message")
```

Use instead:
```python
from rich import print as rich_print

rich_print("Some message")
```

or:
```python
import rich

rich.print("Some message")
```

## Options
- `lint.flake8-builtins.ignorelist`
- `target-version`

# stdlib-module-shadowing (A005)

Derived from the **flake8-builtins** linter.

## What it does
Checks for modules that use the same names as Python standard-library
modules.

## Why is this bad?
Reusing a standard-library module name for the name of a module increases
the difficulty of reading and maintaining the code, and can cause
non-obvious errors. Readers may mistake the first-party module for the
standard-library module and vice versa.

Standard-library modules can be marked as exceptions to this rule via the
[`lint.flake8-builtins.allowed-modules`] configuration option.

By default, the module path relative to the project root or [`src`] directories is considered,
so a top-level `logging.py` or `logging/__init__.py` will clash with the builtin `logging`
module, but `utils/logging.py`, for example, will not. With the
[`lint.flake8-builtins.strict-checking`] option set to `true`, only the last component
of the module name is considered, so `logging.py`, `utils/logging.py`, and
`utils/logging/__init__.py` will all trigger the rule.

This rule is not applied to stub files, as the name of a stub module is out
of the control of the author of the stub file. Instead, a stub should aim to
faithfully emulate the runtime module it is stubbing.

As of Python 3.13, errors from modules that use the same name as
standard-library modules now display a custom message.

## Example

```console
$ touch random.py
$ python3 -c 'from random import choice'
Traceback (most recent call last):
  File "<string>", line 1, in <module>
    from random import choice
ImportError: cannot import name 'choice' from 'random' (consider renaming '/random.py' since it has the same name as the standard library module named 'random' and prevents importing that standard library module)
```

## Options
- `lint.flake8-builtins.allowed-modules`
- `lint.flake8-builtins.strict-checking`

# builtin-lambda-argument-shadowing (A006)

Derived from the **flake8-builtins** linter.

## What it does
Checks for lambda arguments that use the same names as Python builtins.

## Why is this bad?
Reusing a builtin name for the name of a lambda argument increases the
difficulty of reading and maintaining the code and can cause
non-obvious errors. Readers may mistake the variable for the
builtin, and vice versa.

Builtins can be marked as exceptions to this rule via the
[`lint.flake8-builtins.ignorelist`] configuration option.

## Options
- `lint.flake8-builtins.ignorelist`

# missing-trailing-comma (COM812)

Derived from the **flake8-commas** linter.

Fix is always available.

## What it does
Checks for the absence of trailing commas.

## Why is this bad?
The presence of a trailing comma can reduce diff size when parameters or
elements are added or removed from function calls, function definitions,
literals, etc.

## Example
```python
foo = {
    "bar": 1,
    "baz": 2
}
```

Use instead:
```python
foo = {
    "bar": 1,
    "baz": 2,
}
```

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces consistent use of trailing commas, making the rule redundant.

[formatter]:https://docs.astral.sh/ruff/formatter/

# trailing-comma-on-bare-tuple (COM818)

Derived from the **flake8-commas** linter.

## What it does
Checks for the presence of trailing commas on bare (i.e., unparenthesized)
tuples.

## Why is this bad?
The presence of a misplaced comma will cause Python to interpret the value
as a tuple, which can lead to unexpected behaviour.

## Example
```python
import json


foo = json.dumps({"bar": 1}),
```

Use instead:
```python
import json


foo = json.dumps({"bar": 1})
```

In the event that a tuple is intended, then use instead:
```python
import json


foo = (json.dumps({"bar": 1}),)
```

# prohibited-trailing-comma (COM819)

Derived from the **flake8-commas** linter.

Fix is always available.

## What it does
Checks for the presence of prohibited trailing commas.

## Why is this bad?
Trailing commas are not essential in some cases and can therefore be viewed
as unnecessary.

## Example
```python
foo = (1, 2, 3,)
```

Use instead:
```python
foo = (1, 2, 3)
```

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces consistent use of trailing commas, making the rule redundant.

[formatter]:https://docs.astral.sh/ruff/formatter/

# unnecessary-generator-list (C400)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for unnecessary generators that can be rewritten as list
comprehensions (or with `list()` directly).

## Why is this bad?
It is unnecessary to use `list()` around a generator expression, since
there are equivalent comprehensions for these types. Using a
comprehension is clearer and more idiomatic.

Further, if the comprehension can be removed entirely, as in the case of
`list(x for x in foo)`, it's better to use `list(foo)` directly, since it's
even more direct.

## Example
```python
list(f(x) for x in foo)
list(x for x in foo)
list((x for x in foo))
```

Use instead:
```python
[f(x) for x in foo]
list(foo)
list(foo)
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-generator-set (C401)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for unnecessary generators that can be rewritten as set
comprehensions (or with `set()` directly).

## Why is this bad?
It is unnecessary to use `set` around a generator expression, since
there are equivalent comprehensions for these types. Using a
comprehension is clearer and more idiomatic.

Further, if the comprehension can be removed entirely, as in the case of
`set(x for x in foo)`, it's better to use `set(foo)` directly, since it's
even more direct.

## Example
```python
set(f(x) for x in foo)
set(x for x in foo)
set((x for x in foo))
```

Use instead:
```python
{f(x) for x in foo}
set(foo)
set(foo)
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-generator-dict (C402)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for unnecessary generators that can be rewritten as dict
comprehensions.

## Why is this bad?
It is unnecessary to use `dict()` around a generator expression, since
there are equivalent comprehensions for these types. Using a
comprehension is clearer and more idiomatic.

## Example
```python
dict((x, f(x)) for x in foo)
```

Use instead:
```python
{x: f(x) for x in foo}
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-list-comprehension-set (C403)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for unnecessary list comprehensions.

## Why is this bad?
It's unnecessary to use a list comprehension inside a call to `set()`,
since there is an equivalent comprehension for this type.

## Example
```python
set([f(x) for x in foo])
```

Use instead:
```python
{f(x) for x in foo}
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-list-comprehension-dict (C404)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for unnecessary list comprehensions.

## Why is this bad?
It's unnecessary to use a list comprehension inside a call to `dict()`,
since there is an equivalent comprehension for this type.

## Example
```python
dict([(x, f(x)) for x in foo])
```

Use instead:
```python
{x: f(x) for x in foo}
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-literal-set (C405)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for `set()` calls that take unnecessary list or tuple literals
as arguments.

## Why is this bad?
It's unnecessary to use a list or tuple literal within a call to `set()`.
Instead, the expression can be rewritten as a set literal.

## Example
```python
set([1, 2])
set((1, 2))
set([])
```

Use instead:
```python
{1, 2}
{1, 2}
set()
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-literal-dict (C406)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for unnecessary list or tuple literals.

## Why is this bad?
It's unnecessary to use a list or tuple literal within a call to `dict()`.
It can be rewritten as a dict literal (`{}`).

## Example
```python
dict([(1, 2), (3, 4)])
dict(((1, 2), (3, 4)))
dict([])
```

Use instead:
```python
{1: 2, 3: 4}
{1: 2, 3: 4}
{}
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-collection-call (C408)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for unnecessary `dict()`, `list()` or `tuple()` calls that can be
rewritten as empty literals.

## Why is this bad?
It's unnecessary to call, e.g., `dict()` as opposed to using an empty
literal (`{}`). The former is slower because the name `dict` must be
looked up in the global scope in case it has been rebound.

## Example
```python
dict()
dict(a=1, b=2)
list()
tuple()
```

Use instead:
```python
{}
{"a": 1, "b": 2}
[]
()
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

## Options
- `lint.flake8-comprehensions.allow-dict-calls-with-keyword-arguments`

# unnecessary-literal-within-tuple-call (C409)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for `tuple` calls that take unnecessary list or tuple literals as
arguments. In [preview], this also includes unnecessary list comprehensions
within tuple calls.

## Why is this bad?
It's unnecessary to use a list or tuple literal within a `tuple()` call,
since there is a literal syntax for these types.

If a list literal was passed, then it should be rewritten as a `tuple`
literal. Otherwise, if a tuple literal was passed, then the outer call
to `tuple()` should be removed.

In [preview], this rule also checks for list comprehensions within `tuple()`
calls. If a list comprehension is found, it should be rewritten as a
generator expression.

## Example
```python
tuple([1, 2])
tuple((1, 2))
tuple([x for x in range(10)])
```

Use instead:
```python
(1, 2)
(1, 2)
tuple(x for x in range(10))
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

[preview]: https://docs.astral.sh/ruff/preview/

# unnecessary-literal-within-list-call (C410)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for `list()` calls that take unnecessary list or tuple literals as
arguments.

## Why is this bad?
It's unnecessary to use a list or tuple literal within a `list()` call,
since there is a literal syntax for these types.

If a list literal is passed in, then the outer call to `list()` should be
removed. Otherwise, if a tuple literal is passed in, then it should be
rewritten as a list literal.

## Example
```python
list([1, 2])
list((1, 2))
```

Use instead:
```python
[1, 2]
[1, 2]
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-list-call (C411)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for unnecessary `list()` calls around list comprehensions.

## Why is this bad?
It is redundant to use a `list()` call around a list comprehension.

## Example
```python
list([f(x) for x in foo])
```

Use instead
```python
[f(x) for x in foo]
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-call-around-sorted (C413)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for unnecessary `list()` or `reversed()` calls around `sorted()`
calls.

## Why is this bad?
It is unnecessary to use `list()` around `sorted()`, as the latter already
returns a list.

It is also unnecessary to use `reversed()` around `sorted()`, as the latter
has a `reverse` argument that can be used in lieu of an additional
`reversed()` call.

In both cases, it's clearer and more efficient to avoid the redundant call.

## Example
```python
reversed(sorted(iterable))
```

Use instead:
```python
sorted(iterable, reverse=True)
```

## Fix safety
This rule's fix is marked as unsafe for `reversed()` cases, as `reversed()`
and `reverse=True` will yield different results in the event of custom sort
keys or equality functions. Specifically, `reversed()` will reverse the order
of the collection, while `sorted()` with `reverse=True` will perform a stable
reverse sort, which will preserve the order of elements that compare as
equal.

The fix is marked as safe for `list()` cases, as removing `list()` around
`sorted()` does not change the behavior.

# unnecessary-double-cast-or-process (C414)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for unnecessary `list()`, `reversed()`, `set()`, `sorted()`, and
`tuple()` call within `list()`, `set()`, `sorted()`, and `tuple()` calls.

## Why is this bad?
It's unnecessary to double-cast or double-process iterables by wrapping
the listed functions within an additional `list()`, `set()`, `sorted()`, or
`tuple()` call. Doing so is redundant and can be confusing for readers.

## Example
```python
list(tuple(iterable))
```

Use instead:
```python
list(iterable)
```

This rule applies to a variety of functions, including `list()`, `reversed()`,
`set()`, `sorted()`, and `tuple()`. For example:

- Instead of `list(list(iterable))`, use `list(iterable)`.
- Instead of `list(tuple(iterable))`, use `list(iterable)`.
- Instead of `tuple(list(iterable))`, use `tuple(iterable)`.
- Instead of `tuple(tuple(iterable))`, use `tuple(iterable)`.
- Instead of `set(set(iterable))`, use `set(iterable)`.
- Instead of `set(list(iterable))`, use `set(iterable)`.
- Instead of `set(tuple(iterable))`, use `set(iterable)`.
- Instead of `set(sorted(iterable))`, use `set(iterable)`.
- Instead of `set(reversed(iterable))`, use `set(iterable)`.
- Instead of `sorted(list(iterable))`, use `sorted(iterable)`.
- Instead of `sorted(tuple(iterable))`, use `sorted(iterable)`.
- Instead of `sorted(sorted(iterable))`, use `sorted(iterable)`.
- Instead of `sorted(reversed(iterable))`, use `sorted(iterable)`.

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-subscript-reversal (C415)

Derived from the **flake8-comprehensions** linter.

## What it does
Checks for unnecessary subscript reversal of iterable.

## Why is this bad?
It's unnecessary to reverse the order of an iterable when passing it
into `reversed()`, `set()` or `sorted()` functions as they will change
the order of the elements again.

## Example
```python
sorted(iterable[::-1])
set(iterable[::-1])
reversed(iterable[::-1])
```

Use instead:
```python
sorted(iterable)
set(iterable)
iterable
```

# unnecessary-comprehension (C416)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for unnecessary dict, list, and set comprehension.

## Why is this bad?
It's unnecessary to use a dict/list/set comprehension to build a data structure if the
elements are unchanged. Wrap the iterable with `dict()`, `list()`, or `set()` instead.

## Example
```python
{a: b for a, b in iterable}
[x for x in iterable]
{x for x in iterable}
```

Use instead:
```python
dict(iterable)
list(iterable)
set(iterable)
```

## Known problems

This rule may produce false positives for dictionary comprehensions that iterate over a mapping.
The dict constructor behaves differently depending on if it receives a sequence (e.g., a
list) or a mapping (e.g., a dict). When a comprehension iterates over the keys of a mapping,
replacing it with a `dict()` constructor call will give a different result.

For example:

```pycon
>>> d1 = {(1, 2): 3, (4, 5): 6}
>>> {x: y for x, y in d1}  # Iterates over the keys of a mapping
{1: 2, 4: 5}
>>> dict(d1)               # Ruff's incorrect suggested fix
{(1, 2): 3, (4, 5): 6}
>>> dict(d1.keys())        # Correct fix
{1: 2, 4: 5}
```

When the comprehension iterates over a sequence, Ruff's suggested fix is correct. However, Ruff
cannot consistently infer if the iterable type is a sequence or a mapping and cannot suggest
the correct fix for mappings.

## Fix safety
Due to the known problem with dictionary comprehensions, this fix is marked as unsafe.

Additionally, this fix may drop comments when rewriting the comprehension.

# unnecessary-map (C417)

Derived from the **flake8-comprehensions** linter.

Fix is sometimes available.

## What it does
Checks for unnecessary `map()` calls with lambda functions.

## Why is this bad?
Using `map(func, iterable)` when `func` is a lambda is slower than
using a generator expression or a comprehension, as the latter approach
avoids the function call overhead, in addition to being more readable.

This rule also applies to `map()` calls within `list()`, `set()`, and
`dict()` calls. For example:

- Instead of `list(map(lambda num: num * 2, nums))`, use
  `[num * 2 for num in nums]`.
- Instead of `set(map(lambda num: num % 2 == 0, nums))`, use
  `{num % 2 == 0 for num in nums}`.
- Instead of `dict(map(lambda v: (v, v ** 2), values))`, use
  `{v: v ** 2 for v in values}`.

## Example
```python
map(lambda x: x + 1, iterable)
```

Use instead:
```python
(x + 1 for x in iterable)
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-literal-within-dict-call (C418)

Derived from the **flake8-comprehensions** linter.

Fix is always available.

## What it does
Checks for `dict()` calls that take unnecessary dict literals or dict
comprehensions as arguments.

## Why is this bad?
It's unnecessary to wrap a dict literal or comprehension within a `dict()`
call, since the literal or comprehension syntax already returns a
dictionary.

## Example
```python
dict({})
dict({"a": 1})
```

Use instead:
```python
{}
{"a": 1}
```

## Fix safety
This rule's fix is marked as unsafe, as it may occasionally drop comments
when rewriting the call. In most cases, though, comments will be preserved.

# unnecessary-comprehension-in-call (C419)

Derived from the **flake8-comprehensions** linter.

Fix is sometimes available.

## What it does
Checks for unnecessary list or set comprehensions passed to builtin functions that take an iterable.

Set comprehensions are only a violation in the case where the builtin function does not care about
duplication of elements in the passed iterable.

## Why is this bad?
Many builtin functions (this rule currently covers `any` and `all` in stable, along with `min`,
`max`, and `sum` in [preview]) accept any iterable, including a generator. Constructing a
temporary list via list comprehension is unnecessary and wastes memory for large iterables.

`any` and `all` can also short-circuit iteration, saving a lot of time. The unnecessary
comprehension forces a full iteration of the input iterable, giving up the benefits of
short-circuiting. For example, compare the performance of `all` with a list comprehension
against that of a generator in a case where an early short-circuit is possible (almost 40x
faster):

```console
In [1]: %timeit all([i for i in range(1000)])
8.14 s  25.4 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)

In [2]: %timeit all(i for i in range(1000))
212 ns  0.892 ns per loop (mean  std. dev. of 7 runs, 1,000,000 loops each)
```

This performance improvement is due to short-circuiting. If the entire iterable has to be
traversed, the comprehension version may even be a bit faster: list allocation overhead is not
necessarily greater than generator overhead.

Applying this rule simplifies the code and will usually save memory, but in the absence of
short-circuiting it may not improve performance. (It may even slightly regress performance,
though the difference will usually be small.)

## Example
```python
any([x.id for x in bar])
all([x.id for x in bar])
sum([x.val for x in bar])
min([x.val for x in bar])
max([x.val for x in bar])
```

Use instead:
```python
any(x.id for x in bar)
all(x.id for x in bar)
sum(x.val for x in bar)
min(x.val for x in bar)
max(x.val for x in bar)
```

## Fix safety
This rule's fix is marked as unsafe, as it can change the behavior of the code if the iteration
has side effects (due to laziness and short-circuiting). The fix may also drop comments when
rewriting some comprehensions.

[preview]: https://docs.astral.sh/ruff/preview/

# unnecessary-dict-comprehension-for-iterable (C420)

Derived from the **flake8-comprehensions** linter.

Fix is sometimes available.

## What it does
Checks for unnecessary dict comprehension when creating a dictionary from
an iterable.

## Why is this bad?
It's unnecessary to use a dict comprehension to build a dictionary from
an iterable when the value is static.

Prefer `dict.fromkeys(iterable)` over `{value: None for value in iterable}`,
as `dict.fromkeys` is more readable and efficient.

## Example
```python
{a: None for a in iterable}
{a: 1 for a in iterable}
```

Use instead:
```python
dict.fromkeys(iterable)
dict.fromkeys(iterable, 1)
```

## Fix safety
This rule's fix is marked as unsafe if there's comments inside the dict comprehension,
as comments may be removed.

For example, the fix would be marked as unsafe in the following case:
```python
{  # comment 1
    a:  # comment 2
    None  # comment 3
    for a in iterable  # comment 4
}
```

## References
- [Python documentation: `dict.fromkeys`](https://docs.python.org/3/library/stdtypes.html#dict.fromkeys)

# missing-copyright-notice (CPY001)

Derived from the **flake8-copyright** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for the absence of copyright notices within Python files.

Note that this check only searches within the first 4096 bytes of the file.

## Why is this bad?
In some codebases, it's common to have a license header at the top of every
file. This rule ensures that the license header is present.

## Options
- `lint.flake8-copyright.author`
- `lint.flake8-copyright.min-file-size`
- `lint.flake8-copyright.notice-rgx`

# call-datetime-without-tzinfo (DTZ001)

Derived from the **flake8-datetimez** linter.

## What it does
Checks for `datetime` instantiations that do not specify a timezone.

## Why is this bad?
`datetime` objects are "naive" by default, in that they do not include
timezone information. "Naive" objects are easy to understand, but ignore
some aspects of reality, which can lead to subtle bugs. Timezone-aware
`datetime` objects are preferred, as they represent a specific moment in
time, unlike "naive" objects.

By providing a non-`None` value for `tzinfo`, a `datetime` can be made
timezone-aware.

## Example
```python
import datetime

datetime.datetime(2000, 1, 1, 0, 0, 0)
```

Use instead:
```python
import datetime

datetime.datetime(2000, 1, 1, 0, 0, 0, tzinfo=datetime.timezone.utc)
```

Or, on Python 3.11 and later:
```python
import datetime

datetime.datetime(2000, 1, 1, 0, 0, 0, tzinfo=datetime.UTC)
```

## References
- [Python documentation: Aware and Naive Objects](https://docs.python.org/3/library/datetime.html#aware-and-naive-objects)

# call-datetime-today (DTZ002)

Derived from the **flake8-datetimez** linter.

## What it does
Checks for usage of `datetime.datetime.today()`.

## Why is this bad?
`datetime` objects are "naive" by default, in that they do not include
timezone information. "Naive" objects are easy to understand, but ignore
some aspects of reality, which can lead to subtle bugs. Timezone-aware
`datetime` objects are preferred, as they represent a specific moment in
time, unlike "naive" objects.

`datetime.datetime.today()` creates a "naive" object; instead, use
`datetime.datetime.now(tz=...)` to create a timezone-aware object.

## Example
```python
import datetime

datetime.datetime.today()
```

Use instead:
```python
import datetime

datetime.datetime.now(tz=datetime.timezone.utc)
```

Or, for Python 3.11 and later:
```python
import datetime

datetime.datetime.now(tz=datetime.UTC)
```

## References
- [Python documentation: Aware and Naive Objects](https://docs.python.org/3/library/datetime.html#aware-and-naive-objects)

# call-datetime-utcnow (DTZ003)

Derived from the **flake8-datetimez** linter.

## What it does
Checks for usage of `datetime.datetime.utcnow()`.

## Why is this bad?
Python datetime objects can be naive or timezone-aware. While an aware
object represents a specific moment in time, a naive object does not
contain enough information to unambiguously locate itself relative to other
datetime objects. Since this can lead to errors, it is recommended to
always use timezone-aware objects.

`datetime.datetime.utcnow()` returns a naive datetime object; instead, use
`datetime.datetime.now(tz=...)` to create a timezone-aware object.

## Example
```python
import datetime

datetime.datetime.utcnow()
```

Use instead:
```python
import datetime

datetime.datetime.now(tz=datetime.timezone.utc)
```

Or, for Python 3.11 and later:
```python
import datetime

datetime.datetime.now(tz=datetime.UTC)
```

## References
- [Python documentation: Aware and Naive Objects](https://docs.python.org/3/library/datetime.html#aware-and-naive-objects)

# call-datetime-utcfromtimestamp (DTZ004)

Derived from the **flake8-datetimez** linter.

## What it does
Checks for usage of `datetime.datetime.utcfromtimestamp()`.

## Why is this bad?
Python datetime objects can be naive or timezone-aware. While an aware
object represents a specific moment in time, a naive object does not
contain enough information to unambiguously locate itself relative to other
datetime objects. Since this can lead to errors, it is recommended to
always use timezone-aware objects.

`datetime.datetime.utcfromtimestamp()` returns a naive datetime
object; instead, use `datetime.datetime.fromtimestamp(ts, tz=...)`
to create a timezone-aware object.

## Example
```python
import datetime

datetime.datetime.utcfromtimestamp(946684800)
```

Use instead:
```python
import datetime

datetime.datetime.fromtimestamp(946684800, tz=datetime.timezone.utc)
```

Or, on Python 3.11 and later:
```python
import datetime

datetime.datetime.fromtimestamp(946684800, tz=datetime.UTC)
```

## References
- [Python documentation: Aware and Naive Objects](https://docs.python.org/3/library/datetime.html#aware-and-naive-objects)

# call-datetime-now-without-tzinfo (DTZ005)

Derived from the **flake8-datetimez** linter.

## What it does
Checks for usages of `datetime.datetime.now()` that do not specify a timezone.

## Why is this bad?
Python datetime objects can be naive or timezone-aware. While an aware
object represents a specific moment in time, a naive object does not
contain enough information to unambiguously locate itself relative to other
datetime objects. Since this can lead to errors, it is recommended to
always use timezone-aware objects.

`datetime.datetime.now()` or `datetime.datetime.now(tz=None)` returns a naive
datetime object. Instead, use `datetime.datetime.now(tz=<timezone>)` to create
a timezone-aware object.

## Example
```python
import datetime

datetime.datetime.now()
```

Use instead:
```python
import datetime

datetime.datetime.now(tz=datetime.timezone.utc)
```

Or, for Python 3.11 and later:
```python
import datetime

datetime.datetime.now(tz=datetime.UTC)
```

## References
- [Python documentation: Aware and Naive Objects](https://docs.python.org/3/library/datetime.html#aware-and-naive-objects)

# call-datetime-fromtimestamp (DTZ006)

Derived from the **flake8-datetimez** linter.

## What it does
Checks for usage of `datetime.datetime.fromtimestamp()` that do not specify
a timezone.

## Why is this bad?
Python datetime objects can be naive or timezone-aware. While an aware
object represents a specific moment in time, a naive object does not
contain enough information to unambiguously locate itself relative to other
datetime objects. Since this can lead to errors, it is recommended to
always use timezone-aware objects.

`datetime.datetime.fromtimestamp(ts)` or
`datetime.datetime.fromtimestampe(ts, tz=None)` returns a naive datetime
object. Instead, use `datetime.datetime.fromtimestamp(ts, tz=<timezone>)`
to create a timezone-aware object.

## Example
```python
import datetime

datetime.datetime.fromtimestamp(946684800)
```

Use instead:
```python
import datetime

datetime.datetime.fromtimestamp(946684800, tz=datetime.timezone.utc)
```

Or, on Python 3.11 and later:
```python
import datetime

datetime.datetime.fromtimestamp(946684800, tz=datetime.UTC)
```

## References
- [Python documentation: Aware and Naive Objects](https://docs.python.org/3/library/datetime.html#aware-and-naive-objects)

# call-datetime-strptime-without-zone (DTZ007)

Derived from the **flake8-datetimez** linter.

## What it does
Checks for uses of `datetime.datetime.strptime()` that lead to naive
datetime objects.

## Why is this bad?
Python datetime objects can be naive or timezone-aware. While an aware
object represents a specific moment in time, a naive object does not
contain enough information to unambiguously locate itself relative to other
datetime objects. Since this can lead to errors, it is recommended to
always use timezone-aware objects.

`datetime.datetime.strptime()` without `%z` returns a naive datetime
object. Follow it with `.replace(tzinfo=<timezone>)` or `.astimezone()`.

## Example
```python
import datetime

datetime.datetime.strptime("2022/01/31", "%Y/%m/%d")
```

Instead, use `.replace(tzinfo=<timezone>)`:
```python
import datetime

datetime.datetime.strptime("2022/01/31", "%Y/%m/%d").replace(
    tzinfo=datetime.timezone.utc
)
```

Or, use `.astimezone()`:
```python
import datetime

datetime.datetime.strptime("2022/01/31", "%Y/%m/%d").astimezone(datetime.timezone.utc)
```

On Python 3.11 and later, `datetime.timezone.utc` can be replaced with
`datetime.UTC`.

## References
- [Python documentation: Aware and Naive Objects](https://docs.python.org/3/library/datetime.html#aware-and-naive-objects)
- [Python documentation: `strftime()` and `strptime()` Behavior](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior)

# call-date-today (DTZ011)

Derived from the **flake8-datetimez** linter.

## What it does
Checks for usage of `datetime.date.today()`.

## Why is this bad?
Python date objects are naive, that is, not timezone-aware. While an aware
object represents a specific moment in time, a naive object does not
contain enough information to unambiguously locate itself relative to other
datetime objects. Since this can lead to errors, it is recommended to
always use timezone-aware objects.

`datetime.date.today` returns a naive date object without taking timezones
into account. Instead, use `datetime.datetime.now(tz=...).date()` to
create a timezone-aware object and retrieve its date component.

## Example
```python
import datetime

datetime.date.today()
```

Use instead:
```python
import datetime

datetime.datetime.now(tz=datetime.timezone.utc).date()
```

Or, for Python 3.11 and later:
```python
import datetime

datetime.datetime.now(tz=datetime.UTC).date()
```

## References
- [Python documentation: Aware and Naive Objects](https://docs.python.org/3/library/datetime.html#aware-and-naive-objects)

# call-date-fromtimestamp (DTZ012)

Derived from the **flake8-datetimez** linter.

## What it does
Checks for usage of `datetime.date.fromtimestamp()`.

## Why is this bad?
Python date objects are naive, that is, not timezone-aware. While an aware
object represents a specific moment in time, a naive object does not
contain enough information to unambiguously locate itself relative to other
datetime objects. Since this can lead to errors, it is recommended to
always use timezone-aware objects.

`datetime.date.fromtimestamp(ts)` returns a naive date object.
Instead, use `datetime.datetime.fromtimestamp(ts, tz=...).date()` to
create a timezone-aware datetime object and retrieve its date component.

## Example
```python
import datetime

datetime.date.fromtimestamp(946684800)
```

Use instead:
```python
import datetime

datetime.datetime.fromtimestamp(946684800, tz=datetime.timezone.utc).date()
```

Or, for Python 3.11 and later:
```python
import datetime

datetime.datetime.fromtimestamp(946684800, tz=datetime.UTC).date()
```

## References
- [Python documentation: Aware and Naive Objects](https://docs.python.org/3/library/datetime.html#aware-and-naive-objects)

# datetime-min-max (DTZ901)

Derived from the **flake8-datetimez** linter.

## What it does
Checks for uses of `datetime.datetime.min` and `datetime.datetime.max`.

## Why is this bad?
`datetime.min` and `datetime.max` are non-timezone-aware datetime objects.

As such, operations on `datetime.min` and `datetime.max` may behave
unexpectedly, as in:

```python
import datetime

# Timezone: UTC-14
datetime.datetime.min.timestamp()  # ValueError: year 0 is out of range
datetime.datetime.max.timestamp()  # ValueError: year 10000 is out of range
```

## Example
```python
import datetime

datetime.datetime.max
```

Use instead:
```python
import datetime

datetime.datetime.max.replace(tzinfo=datetime.UTC)
```

## References
- [Python documentation: Aware and Naive Objects](https://docs.python.org/3/library/datetime.html#aware-and-naive-objects)

# debugger (T100)

Derived from the **flake8-debugger** linter.

## What it does
Checks for the presence of debugger calls and imports.

## Why is this bad?
Debugger calls and imports should be used for debugging purposes only. The
presence of a debugger call or import in production code is likely a
mistake and may cause unintended behavior, such as exposing sensitive
information or causing the program to hang.

Instead, consider using a logging library to log information about the
program's state, and writing tests to verify that the program behaves
as expected.

## Example
```python
def foo():
    breakpoint()
```

## References
- [Python documentation: `pdb`  The Python Debugger](https://docs.python.org/3/library/pdb.html)
- [Python documentation: `logging`  Logging facility for Python](https://docs.python.org/3/library/logging.html)

# django-nullable-model-string-field (DJ001)

Derived from the **flake8-django** linter.

## What it does
Checks nullable string-based fields (like `CharField` and `TextField`)
in Django models.

## Why is this bad?
If a string-based field is nullable, then your model will have two possible
representations for "no data": `None` and the empty string. This can lead to
confusion, as clients of the API have to check for both `None` and the
empty string when trying to determine if the field has data.

The Django convention is to use the empty string in lieu of `None` for
string-based fields.

## Example
```python
from django.db import models


class MyModel(models.Model):
    field = models.CharField(max_length=255, null=True)
```

Use instead:
```python
from django.db import models


class MyModel(models.Model):
    field = models.CharField(max_length=255, default="")
```

# django-locals-in-render-function (DJ003)

Derived from the **flake8-django** linter.

## What it does
Checks for the use of `locals()` in `render` functions.

## Why is this bad?
Using `locals()` can expose internal variables or other unintentional
data to the rendered template.

## Example
```python
from django.shortcuts import render


def index(request):
    posts = Post.objects.all()
    return render(request, "app/index.html", locals())
```

Use instead:
```python
from django.shortcuts import render


def index(request):
    posts = Post.objects.all()
    context = {"posts": posts}
    return render(request, "app/index.html", context)
```

# django-exclude-with-model-form (DJ006)

Derived from the **flake8-django** linter.

## What it does
Checks for the use of `exclude` in Django `ModelForm` classes.

## Why is this bad?
If a `ModelForm` includes the `exclude` attribute, any new field that
is added to the model will automatically be exposed for modification.

## Example
```python
from django.forms import ModelForm


class PostForm(ModelForm):
    class Meta:
        model = Post
        exclude = ["author"]
```

Use instead:
```python
from django.forms import ModelForm


class PostForm(ModelForm):
    class Meta:
        model = Post
        fields = ["title", "content"]
```

# django-all-with-model-form (DJ007)

Derived from the **flake8-django** linter.

## What it does
Checks for the use of `fields = "__all__"` in Django `ModelForm`
classes.

## Why is this bad?
If a `ModelForm` includes the `fields = "__all__"` attribute, any new
field that is added to the model will automatically be exposed for
modification.

## Example
```python
from django.forms import ModelForm


class PostForm(ModelForm):
    class Meta:
        model = Post
        fields = "__all__"
```

Use instead:
```python
from django.forms import ModelForm


class PostForm(ModelForm):
    class Meta:
        model = Post
        fields = ["title", "content"]
```

# django-model-without-dunder-str (DJ008)

Derived from the **flake8-django** linter.

## What it does
Checks that a `__str__` method is defined in Django models.

## Why is this bad?
Django models should define a `__str__` method to return a string representation
of the model instance, as Django calls this method to display the object in
the Django Admin and elsewhere.

Models without a `__str__` method will display a non-meaningful representation
of the object in the Django Admin.

## Example
```python
from django.db import models


class MyModel(models.Model):
    field = models.CharField(max_length=255)
```

Use instead:
```python
from django.db import models


class MyModel(models.Model):
    field = models.CharField(max_length=255)

    def __str__(self):
        return f"{self.field}"
```

# django-unordered-body-content-in-model (DJ012)

Derived from the **flake8-django** linter.

## What it does
Checks for the order of Model's inner classes, methods, and fields as per
the [Django Style Guide].

## Why is this bad?
The [Django Style Guide] specifies that the order of Model inner classes,
attributes and methods should be as follows:

1. All database fields
2. Custom manager attributes
3. `class Meta`
4. `def __str__()`
5. `def save()`
6. `def get_absolute_url()`
7. Any custom methods

## Example
```python
from django.db import models


class StrBeforeFieldModel(models.Model):
    class Meta:
        verbose_name = "test"
        verbose_name_plural = "tests"

    def __str__(self):
        return "foobar"

    first_name = models.CharField(max_length=32)
    last_name = models.CharField(max_length=40)
```

Use instead:
```python
from django.db import models


class StrBeforeFieldModel(models.Model):
    first_name = models.CharField(max_length=32)
    last_name = models.CharField(max_length=40)

    class Meta:
        verbose_name = "test"
        verbose_name_plural = "tests"

    def __str__(self):
        return "foobar"
```

[Django Style Guide]: https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#model-style

# django-non-leading-receiver-decorator (DJ013)

Derived from the **flake8-django** linter.

## What it does
Checks that Django's `@receiver` decorator is listed first, prior to
any other decorators.

## Why is this bad?
Django's `@receiver` decorator is special in that it does not return
a wrapped function. Rather, `@receiver` connects the decorated function
to a signal. If any other decorators are listed before `@receiver`,
the decorated function will not be connected to the signal.

## Example
```python
from django.dispatch import receiver
from django.db.models.signals import post_save


@transaction.atomic
@receiver(post_save, sender=MyModel)
def my_handler(sender, instance, created, **kwargs):
    pass
```

Use instead:
```python
from django.dispatch import receiver
from django.db.models.signals import post_save


@receiver(post_save, sender=MyModel)
@transaction.atomic
def my_handler(sender, instance, created, **kwargs):
    pass
```

# raw-string-in-exception (EM101)

Derived from the **flake8-errmsg** linter.

Fix is sometimes available.

## What it does
Checks for the use of string literals in exception constructors.

## Why is this bad?
Python includes the `raise` in the default traceback (and formatters
like Rich and IPython do too).

By using a string literal, the error message will be duplicated in the
traceback, which can make the traceback less readable.

## Example
Given:
```python
raise RuntimeError("'Some value' is incorrect")
```

Python will produce a traceback like:
```console
Traceback (most recent call last):
  File "tmp.py", line 2, in <module>
    raise RuntimeError("'Some value' is incorrect")
RuntimeError: 'Some value' is incorrect
```

Instead, assign the string to a variable:
```python
msg = "'Some value' is incorrect"
raise RuntimeError(msg)
```

Which will produce a traceback like:
```console
Traceback (most recent call last):
  File "tmp.py", line 3, in <module>
    raise RuntimeError(msg)
RuntimeError: 'Some value' is incorrect
```

# f-string-in-exception (EM102)

Derived from the **flake8-errmsg** linter.

Fix is sometimes available.

## What it does
Checks for the use of f-strings in exception constructors.

## Why is this bad?
Python includes the `raise` in the default traceback (and formatters
like Rich and IPython do too).

By using an f-string, the error message will be duplicated in the
traceback, which can make the traceback less readable.

## Example
Given:
```python
sub = "Some value"
raise RuntimeError(f"{sub!r} is incorrect")
```

Python will produce a traceback like:
```console
Traceback (most recent call last):
  File "tmp.py", line 2, in <module>
    raise RuntimeError(f"{sub!r} is incorrect")
RuntimeError: 'Some value' is incorrect
```

Instead, assign the string to a variable:
```python
sub = "Some value"
msg = f"{sub!r} is incorrect"
raise RuntimeError(msg)
```

Which will produce a traceback like:
```console
Traceback (most recent call last):
  File "tmp.py", line 3, in <module>
    raise RuntimeError(msg)
RuntimeError: 'Some value' is incorrect
```

# dot-format-in-exception (EM103)

Derived from the **flake8-errmsg** linter.

Fix is sometimes available.

## What it does
Checks for the use of `.format` calls on string literals in exception
constructors.

## Why is this bad?
Python includes the `raise` in the default traceback (and formatters
like Rich and IPython do too).

By using a `.format` call, the error message will be duplicated in the
traceback, which can make the traceback less readable.

## Example
Given:
```python
sub = "Some value"
raise RuntimeError("'{}' is incorrect".format(sub))
```

Python will produce a traceback like:
```console
Traceback (most recent call last):
  File "tmp.py", line 2, in <module>
    raise RuntimeError("'{}' is incorrect".format(sub))
RuntimeError: 'Some value' is incorrect
```

Instead, assign the string to a variable:
```python
sub = "Some value"
msg = "'{}' is incorrect".format(sub)
raise RuntimeError(msg)
```

Which will produce a traceback like:
```console
Traceback (most recent call last):
  File "tmp.py", line 3, in <module>
    raise RuntimeError(msg)
RuntimeError: 'Some value' is incorrect
```

# shebang-not-executable (EXE001)

Derived from the **flake8-executable** linter.

## What it does
Checks for a shebang directive in a file that is not executable.

## Why is this bad?
In Python, a shebang (also known as a hashbang) is the first line of a
script, which specifies the interpreter that should be used to run the
script.

The presence of a shebang suggests that a file is intended to be
executable. If a file contains a shebang but is not executable, then the
shebang is misleading, or the file is missing the executable bit.

If the file is meant to be executable, add the executable bit to the file
(e.g., `chmod +x __main__.py` or `git update-index --chmod=+x __main__.py`).

Otherwise, remove the shebang.

A file is considered executable if it has the executable bit set (i.e., its
permissions mode intersects with `0o111`). As such, _this rule is only
available on Unix-like systems_, and is not enforced on Windows or WSL.

## Example
```python
#!/usr/bin/env python
```

## References
- [Python documentation: Executable Python Scripts](https://docs.python.org/3/tutorial/appendix.html#executable-python-scripts)
- [Git documentation: `git update-index --chmod`](https://git-scm.com/docs/git-update-index#Documentation/git-update-index.txt---chmod-x)

# shebang-missing-executable-file (EXE002)

Derived from the **flake8-executable** linter.

## What it does
Checks for executable `.py` files that do not have a shebang.

## Why is this bad?
In Python, a shebang (also known as a hashbang) is the first line of a
script, which specifies the interpreter that should be used to run the
script.

If a `.py` file is executable, but does not have a shebang, it may be run
with the wrong interpreter, or fail to run at all.

If the file is meant to be executable, add a shebang, as in:
```python
#!/usr/bin/env python
```

Otherwise, remove the executable bit from the file
(e.g., `chmod -x __main__.py` or `git update-index --chmod=-x __main__.py`).

A file is considered executable if it has the executable bit set (i.e., its
permissions mode intersects with `0o111`). As such, _this rule is only
available on Unix-like systems_, and is not enforced on Windows or WSL.

## References
- [Python documentation: Executable Python Scripts](https://docs.python.org/3/tutorial/appendix.html#executable-python-scripts)
- [Git documentation: `git update-index --chmod`](https://git-scm.com/docs/git-update-index#Documentation/git-update-index.txt---chmod-x)

# shebang-missing-python (EXE003)

Derived from the **flake8-executable** linter.

## What it does
Checks for a shebang directive in `.py` files that does not contain `python`,
`pytest`, or `uv run`.

## Why is this bad?
In Python, a shebang (also known as a hashbang) is the first line of a
script, which specifies the command that should be used to run the
script.

For Python scripts, if the shebang does not include a command that explicitly
or implicitly specifies an interpreter, then the file will be executed with
the default interpreter, which is likely a mistake.

## Example
```python
#!/usr/bin/env bash
```

Use instead:
```python
#!/usr/bin/env python3
```

## References
- [Python documentation: Executable Python Scripts](https://docs.python.org/3/tutorial/appendix.html#executable-python-scripts)

# shebang-leading-whitespace (EXE004)

Derived from the **flake8-executable** linter.

Fix is always available.

## What it does
Checks for whitespace before a shebang directive.

## Why is this bad?
In Python, a shebang (also known as a hashbang) is the first line of a
script, which specifies the interpreter that should be used to run the
script.

The shebang's `#!` prefix must be the first two characters of a file. The
presence of whitespace before the shebang will cause the shebang to be
ignored, which is likely a mistake.

## Example
```python
 #!/usr/bin/env python3
```

Use instead:
```python
#!/usr/bin/env python3
```

## References
- [Python documentation: Executable Python Scripts](https://docs.python.org/3/tutorial/appendix.html#executable-python-scripts)

# shebang-not-first-line (EXE005)

Derived from the **flake8-executable** linter.

## What it does
Checks for a shebang directive that is not at the beginning of the file.

## Why is this bad?
In Python, a shebang (also known as a hashbang) is the first line of a
script, which specifies the interpreter that should be used to run the
script.

The shebang's `#!` prefix must be the first two characters of a file. If
the shebang is not at the beginning of the file, it will be ignored, which
is likely a mistake.

## Example
```python
foo = 1
#!/usr/bin/env python3
```

Use instead:
```python
#!/usr/bin/env python3
foo = 1
```

## References
- [Python documentation: Executable Python Scripts](https://docs.python.org/3/tutorial/appendix.html#executable-python-scripts)

# line-contains-fixme (FIX001)

Derived from the **flake8-fixme** linter.

## What it does
Checks for "FIXME" comments.

## Why is this bad?
"FIXME" comments are used to describe an issue that should be resolved
(usually, a bug or unexpected behavior).

Consider resolving the issue before deploying the code.

Note that if you use "FIXME" comments as a form of documentation, this
rule may not be appropriate for your project.

## Example
```python
def speed(distance, time):
    return distance / time  # FIXME: Raises ZeroDivisionError for time = 0.
```

# line-contains-todo (FIX002)

Derived from the **flake8-fixme** linter.

## What it does
Checks for "TODO" comments.

## Why is this bad?
"TODO" comments are used to describe an issue that should be resolved
(usually, a missing feature, optimization, or refactoring opportunity).

Consider resolving the issue before deploying the code.

Note that if you use "TODO" comments as a form of documentation (e.g.,
to [provide context for future work](https://gist.github.com/dmnd/ed5d8ef8de2e4cfea174bd5dafcda382)),
this rule may not be appropriate for your project.

## Example
```python
def greet(name):
    return f"Hello, {name}!"  # TODO: Add support for custom greetings.
```

# line-contains-xxx (FIX003)

Derived from the **flake8-fixme** linter.

## What it does
Checks for "XXX" comments.

## Why is this bad?
"XXX" comments are used to describe an issue that should be resolved.

Consider resolving the issue before deploying the code, or, at minimum,
using a more descriptive comment tag (e.g, "TODO").

## Example
```python
def speed(distance, time):
    return distance / time  # XXX: Raises ZeroDivisionError for time = 0.
```

# line-contains-hack (FIX004)

Derived from the **flake8-fixme** linter.

## What it does
Checks for "HACK" comments.

## Why is this bad?
"HACK" comments are used to describe an issue that should be resolved
(usually, a suboptimal solution or temporary workaround).

Consider resolving the issue before deploying the code.

Note that if you use "HACK" comments as a form of documentation, this
rule may not be appropriate for your project.

## Example
```python
import os


def running_windows():  # HACK: Use platform module instead.
    try:
        os.mkdir("C:\\Windows\\System32\\")
    except FileExistsError:
        return True
    else:
        os.rmdir("C:\\Windows\\System32\\")
        return False
```

# future-rewritable-type-annotation (FA100)

Derived from the **flake8-future-annotations** linter.

Fix is always available.

## What it does
Checks for missing `from __future__ import annotations` imports upon
detecting type annotations that can be written more succinctly under
PEP 563.

## Why is this bad?
PEP 585 enabled the use of a number of convenient type annotations, such as
`list[str]` instead of `List[str]`. However, these annotations are only
available on Python 3.9 and higher, _unless_ the `from __future__ import annotations`
import is present.

Similarly, PEP 604 enabled the use of the `|` operator for unions, such as
`str | None` instead of `Optional[str]`. However, these annotations are only
available on Python 3.10 and higher, _unless_ the `from __future__ import annotations`
import is present.

By adding the `__future__` import, the pyupgrade rules can automatically
migrate existing code to use the new syntax, even for older Python versions.
This rule thus pairs well with pyupgrade and with Ruff's pyupgrade rules.

This rule respects the [`target-version`] setting. For example, if your
project targets Python 3.10 and above, adding `from __future__ import annotations`
does not impact your ability to leverage PEP 604-style unions (e.g., to
convert `Optional[str]` to `str | None`). As such, this rule will only
flag such usages if your project targets Python 3.9 or below.

## Example

```python
from typing import List, Dict, Optional


def func(obj: Dict[str, Optional[int]]) -> None: ...
```

Use instead:

```python
from __future__ import annotations

from typing import List, Dict, Optional


def func(obj: Dict[str, Optional[int]]) -> None: ...
```

After running the additional pyupgrade rules:

```python
from __future__ import annotations


def func(obj: dict[str, int | None]) -> None: ...
```

## Fix safety
This rule's fix is marked as unsafe, as adding `from __future__ import annotations`
may change the semantics of the program.

## Options
- `target-version`

# future-required-type-annotation (FA102)

Derived from the **flake8-future-annotations** linter.

Fix is always available.

## What it does
Checks for uses of PEP 585- and PEP 604-style type annotations in Python
modules that lack the required `from __future__ import annotations` import
for compatibility with older Python versions.

## Why is this bad?
Using PEP 585 and PEP 604 style annotations without a `from __future__ import
annotations` import will cause runtime errors on Python versions prior to
3.9 and 3.10, respectively.

By adding the `__future__` import, the interpreter will no longer interpret
annotations at evaluation time, making the code compatible with both past
and future Python versions.

This rule respects the [`target-version`] setting. For example, if your
project targets Python 3.10 and above, adding `from __future__ import annotations`
does not impact your ability to leverage PEP 604-style unions (e.g., to
convert `Optional[str]` to `str | None`). As such, this rule will only
flag such usages if your project targets Python 3.9 or below.

## Example

```python
def func(obj: dict[str, int | None]) -> None: ...
```

Use instead:

```python
from __future__ import annotations


def func(obj: dict[str, int | None]) -> None: ...
```

## Fix safety
This rule's fix is marked as unsafe, as adding `from __future__ import annotations`
may change the semantics of the program.

## Options
- `target-version`

# f-string-in-get-text-func-call (INT001)

Derived from the **flake8-gettext** linter.

## What it does
Checks for f-strings in `gettext` function calls.

## Why is this bad?
In the `gettext` API, the `gettext` function (often aliased to `_`) returns
a translation of its input argument by looking it up in a translation
catalog.

Calling `gettext` with an f-string as its argument can cause unexpected
behavior. Since the f-string is resolved before the function call, the
translation catalog will look up the formatted string, rather than the
f-string template.

Instead, format the value returned by the function call, rather than
its argument.

## Example
```python
from gettext import gettext as _

name = "Maria"
_(f"Hello, {name}!")  # Looks for "Hello, Maria!".
```

Use instead:
```python
from gettext import gettext as _

name = "Maria"
_("Hello, %s!") % name  # Looks for "Hello, %s!".
```

## References
- [Python documentation: `gettext`  Multilingual internationalization services](https://docs.python.org/3/library/gettext.html)

# format-in-get-text-func-call (INT002)

Derived from the **flake8-gettext** linter.

## What it does
Checks for `str.format` calls in `gettext` function calls.

## Why is this bad?
In the `gettext` API, the `gettext` function (often aliased to `_`) returns
a translation of its input argument by looking it up in a translation
catalog.

Calling `gettext` with a formatted string as its argument can cause
unexpected behavior. Since the formatted string is resolved before the
function call, the translation catalog will look up the formatted string,
rather than the `str.format`-style template.

Instead, format the value returned by the function call, rather than
its argument.

## Example
```python
from gettext import gettext as _

name = "Maria"
_("Hello, {}!".format(name))  # Looks for "Hello, Maria!".
```

Use instead:
```python
from gettext import gettext as _

name = "Maria"
_("Hello, %s!") % name  # Looks for "Hello, %s!".
```

## References
- [Python documentation: `gettext`  Multilingual internationalization services](https://docs.python.org/3/library/gettext.html)

# printf-in-get-text-func-call (INT003)

Derived from the **flake8-gettext** linter.

## What it does
Checks for printf-style formatted strings in `gettext` function calls.

## Why is this bad?
In the `gettext` API, the `gettext` function (often aliased to `_`) returns
a translation of its input argument by looking it up in a translation
catalog.

Calling `gettext` with a formatted string as its argument can cause
unexpected behavior. Since the formatted string is resolved before the
function call, the translation catalog will look up the formatted string,
rather than the printf-style template.

Instead, format the value returned by the function call, rather than
its argument.

## Example
```python
from gettext import gettext as _

name = "Maria"
_("Hello, %s!" % name)  # Looks for "Hello, Maria!".
```

Use instead:
```python
from gettext import gettext as _

name = "Maria"
_("Hello, %s!") % name  # Looks for "Hello, %s!".
```

## References
- [Python documentation: `gettext`  Multilingual internationalization services](https://docs.python.org/3/library/gettext.html)

# single-line-implicit-string-concatenation (ISC001)

Derived from the **flake8-implicit-str-concat** linter.

Fix is sometimes available.

## What it does
Checks for implicitly concatenated strings on a single line.

## Why is this bad?
While it is valid Python syntax to concatenate multiple string or byte
literals implicitly (via whitespace delimiters), it is unnecessary and
negatively affects code readability.

In some cases, the implicit concatenation may also be unintentional, as
code formatters are capable of introducing single-line implicit
concatenations when collapsing long lines.

## Example
```python
z = "The quick " "brown fox."
```

Use instead:
```python
z = "The quick brown fox."
```

# multi-line-implicit-string-concatenation (ISC002)

Derived from the **flake8-implicit-str-concat** linter.

## What it does
Checks for implicitly concatenated strings that span multiple lines.

## Why is this bad?
For string literals that wrap across multiple lines, [PEP 8] recommends
the use of implicit string concatenation within parentheses instead of
using a backslash for line continuation, as the former is more readable
than the latter.

By default, this rule will only trigger if the string literal is
concatenated via a backslash. To disallow implicit string concatenation
altogether, set the [`lint.flake8-implicit-str-concat.allow-multiline`] option
to `false`.

## Example
```python
z = "The quick brown fox jumps over the lazy "\
    "dog."
```

Use instead:
```python
z = (
    "The quick brown fox jumps over the lazy "
    "dog."
)
```

## Options
- `lint.flake8-implicit-str-concat.allow-multiline`

## Formatter compatibility
Using this rule with `allow-multiline = false` can be incompatible with the
formatter because the [formatter] can introduce new multi-line implicitly
concatenated strings. We recommend to either:

* Enable `ISC001` to disallow all implicit concatenated strings
* Setting `allow-multiline = true`

[PEP 8]: https://peps.python.org/pep-0008/#maximum-line-length
[formatter]:https://docs.astral.sh/ruff/formatter/

# explicit-string-concatenation (ISC003)

Derived from the **flake8-implicit-str-concat** linter.

Fix is sometimes available.

## What it does
Checks for string literals that are explicitly concatenated (using the
`+` operator).

## Why is this bad?
For string literals that wrap across multiple lines, implicit string
concatenation within parentheses is preferred over explicit
concatenation using the `+` operator, as the former is more readable.

## Example
```python
z = (
    "The quick brown fox jumps over the lazy "
    + "dog"
)
```

Use instead:
```python
z = (
    "The quick brown fox jumps over the lazy "
    "dog"
)
```

# implicit-string-concatenation-in-collection-literal (ISC004)

Derived from the **flake8-implicit-str-concat** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for implicitly concatenated strings inside list, tuple, and set literals.

## Why is this bad?
In collection literals, implicit string concatenation is often the result of
a missing comma between elements, which can silently merge items together.

## Example
```python
facts = (
    "Lobsters have blue blood.",
    "The liver is the only human organ that can fully regenerate itself.",
    "Clarinets are made almost entirely out of wood from the mpingo tree."
    "In 1971, astronaut Alan Shepard played golf on the moon.",
)
```

Instead, you likely intended:
```python
facts = (
    "Lobsters have blue blood.",
    "The liver is the only human organ that can fully regenerate itself.",
    "Clarinets are made almost entirely out of wood from the mpingo tree.",
    "In 1971, astronaut Alan Shepard played golf on the moon.",
)
```

If the concatenation is intentional, wrap it in parentheses to make it
explicit:
```python
facts = (
    "Lobsters have blue blood.",
    "The liver is the only human organ that can fully regenerate itself.",
    (
        "Clarinets are made almost entirely out of wood from the mpingo tree."
        "In 1971, astronaut Alan Shepard played golf on the moon."
    ),
)
```

## Fix safety
The fix is safe in that it does not change the semantics of your code.
However, the issue is that you may often want to change semantics
by adding a missing comma.

# unconventional-import-alias (ICN001)

Derived from the **flake8-import-conventions** linter.

Fix is sometimes available.

## What it does
Checks for imports that are typically imported using a common convention,
like `import pandas as pd`, and enforces that convention.

## Why is this bad?
Consistency is good. Use a common convention for imports to make your code
more readable and idiomatic.

For example, `import pandas as pd` is a common
convention for importing the `pandas` library, and users typically expect
Pandas to be aliased as `pd`.

## Example
```python
import pandas
```

Use instead:
```python
import pandas as pd
```

## Options
- `lint.flake8-import-conventions.aliases`
- `lint.flake8-import-conventions.extend-aliases`

# banned-import-alias (ICN002)

Derived from the **flake8-import-conventions** linter.

## What it does
Checks for imports that use non-standard naming conventions, like
`import tensorflow.keras.backend as K`.

## Why is this bad?
Consistency is good. Avoid using a non-standard naming convention for
imports, and, in particular, choosing import aliases that violate PEP 8.

For example, aliasing via `import tensorflow.keras.backend as K` violates
the guidance of PEP 8, and is thus avoided in some projects.

## Example
```python
import tensorflow.keras.backend as K
```

Use instead:
```python
import tensorflow as tf

tf.keras.backend
```

## Options
- `lint.flake8-import-conventions.banned-aliases`

# banned-import-from (ICN003)

Derived from the **flake8-import-conventions** linter.

## What it does
Checks for member imports that should instead be accessed by importing the
module.

## Why is this bad?
Consistency is good. Use a common convention for imports to make your code
more readable and idiomatic.

For example, it's common to import `pandas` as `pd`, and then access
members like `Series` via `pd.Series`, rather than importing `Series`
directly.

## Example
```python
from pandas import Series
```

Use instead:
```python
import pandas as pd

pd.Series
```

## Options
- `lint.flake8-import-conventions.banned-from`

# direct-logger-instantiation (LOG001)

Derived from the **flake8-logging** linter.

Fix is sometimes available.

## What it does
Checks for direct instantiation of `logging.Logger`, as opposed to using
`logging.getLogger()`.

## Why is this bad?
The [Logger Objects] documentation states that:

> Note that Loggers should NEVER be instantiated directly, but always
> through the module-level function `logging.getLogger(name)`.

If a logger is directly instantiated, it won't be added to the logger
tree, and will bypass all configuration. Messages logged to it will
only be sent to the "handler of last resort", skipping any filtering
or formatting.

## Example
```python
import logging

logger = logging.Logger(__name__)
```

Use instead:
```python
import logging

logger = logging.getLogger(__name__)
```

## Fix safety
This fix is always unsafe, as changing from `Logger` to `getLogger`
changes program behavior by will adding the logger to the logging tree.

[Logger Objects]: https://docs.python.org/3/library/logging.html#logger-objects

# invalid-get-logger-argument (LOG002)

Derived from the **flake8-logging** linter.

Fix is sometimes available.

## What it does
Checks for any usage of `__cached__` and `__file__` as an argument to
`logging.getLogger()`.

## Why is this bad?
The [logging documentation] recommends this pattern:

```python
logging.getLogger(__name__)
```

Here, `__name__` is the fully qualified module name, such as `foo.bar`,
which is the intended format for logger names.

This rule detects probably-mistaken usage of similar module-level dunder constants:

* `__cached__` - the pathname of the module's compiled version, such as `foo/__pycache__/bar.cpython-311.pyc`.
* `__file__` - the pathname of the module, such as `foo/bar.py`.

## Example
```python
import logging

logger = logging.getLogger(__file__)
```

Use instead:
```python
import logging

logger = logging.getLogger(__name__)
```

## Fix safety
This fix is always unsafe, as changing the arguments to `getLogger` can change the
received logger object, and thus program behavior.

[logging documentation]: https://docs.python.org/3/library/logging.html#logger-objects

# log-exception-outside-except-handler (LOG004)

Derived from the **flake8-logging** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for `.exception()` logging calls outside of exception handlers.

## Why is this bad?
[The documentation] states:
> This function should only be called from an exception handler.

Calling `.exception()` outside of an exception handler
attaches `None` as exception information, leading to confusing messages:

```pycon
>>> logging.exception("example")
ERROR:root:example
NoneType: None
```

## Example

```python
import logging

logging.exception("Foobar")
```

Use instead:

```python
import logging

logging.error("Foobar")
```

## Fix safety
The fix, if available, will always be marked as unsafe, as it changes runtime behavior.

[The documentation]: https://docs.python.org/3/library/logging.html#logging.exception

# exception-without-exc-info (LOG007)

Derived from the **flake8-logging** linter.

## What it does
Checks for uses of `logging.exception()` with `exc_info` set to `False`.

## Why is this bad?
The `logging.exception()` method captures the exception automatically, but
accepts an optional `exc_info` argument to override this behavior. Setting
`exc_info` to `False` disables the automatic capture of the exception and
stack trace.

Instead of setting `exc_info` to `False`, prefer `logging.error()`, which
has equivalent behavior to `logging.exception()` with `exc_info` set to
`False`, but is clearer in intent.

## Example
```python
logging.exception("...", exc_info=False)
```

Use instead:
```python
logging.error("...")
```

# undocumented-warn (LOG009)

Derived from the **flake8-logging** linter.

Fix is sometimes available.

## What it does
Checks for uses of `logging.WARN`.

## Why is this bad?
The `logging.WARN` constant is an undocumented alias for `logging.WARNING`.

Although its not explicitly deprecated, `logging.WARN` is not mentioned
in the `logging` documentation. Prefer `logging.WARNING` instead.

## Example
```python
import logging


logging.basicConfig(level=logging.WARN)
```

Use instead:
```python
import logging


logging.basicConfig(level=logging.WARNING)
```

# exc-info-outside-except-handler (LOG014)

Derived from the **flake8-logging** linter.

Fix is sometimes available.

## What it does
Checks for logging calls with `exc_info=` outside exception handlers.

## Why is this bad?
Using `exc_info=True` outside of an exception handler
attaches `None` as the exception information, leading to confusing messages:

```pycon
>>> logging.warning("Uh oh", exc_info=True)
WARNING:root:Uh oh
NoneType: None
```

## Example

```python
import logging


logging.warning("Foobar", exc_info=True)
```

Use instead:

```python
import logging


logging.warning("Foobar")
```

## Fix safety
The fix is always marked as unsafe, as it changes runtime behavior.

# root-logger-call (LOG015)

Derived from the **flake8-logging** linter.

## What it does
Checks for usages of the following `logging` top-level functions:
`debug`, `info`, `warn`, `warning`, `error`, `critical`, `log`, `exception`.

## Why is this bad?
Using the root logger causes the messages to have no source information,
making them less useful for debugging.

## Example
```python
import logging

logging.info("Foobar")
```

Use instead:
```python
import logging

logger = logging.getLogger(__name__)
logger.info("Foobar")
```

# logging-string-format (G001)

Derived from the **flake8-logging-format** linter.

## What it does
Checks for uses of `str.format` to format logging messages.

## Why is this bad?
The `logging` module provides a mechanism for passing additional values to
be logged using the `extra` keyword argument. This is more consistent, more
efficient, and less error-prone than formatting the string directly.

Using `str.format` to format a logging message requires that Python eagerly
format the string, even if the logging statement is never executed (e.g.,
if the log level is above the level of the logging statement), whereas
using the `extra` keyword argument defers formatting until required.

Additionally, the use of `extra` will ensure that the values are made
available to all handlers, which can then be configured to log the values
in a consistent manner.

As an alternative to `extra`, passing values as arguments to the logging
method can also be used to defer string formatting until required.

## Known problems

This rule detects uses of the `logging` module via a heuristic.
Specifically, it matches against:

- Uses of the `logging` module itself (e.g., `import logging; logging.info(...)`).
- Uses of `flask.current_app.logger` (e.g., `from flask import current_app; current_app.logger.info(...)`).
- Objects whose name starts with `log` or ends with `logger` or `logging`,
  when used in the same file in which they are defined (e.g., `logger = logging.getLogger(); logger.info(...)`).
- Imported objects marked as loggers via the [`lint.logger-objects`] setting, which can be
  used to enforce these rules against shared logger objects (e.g., `from module import logger; logger.info(...)`,
  when [`lint.logger-objects`] is set to `["module.logger"]`).

## Example
```python
import logging

logging.basicConfig(format="%(message)s", level=logging.INFO)

user = "Maria"

logging.info("{} - Something happened".format(user))
```

Use instead:
```python
import logging

logging.basicConfig(format="%(user_id)s - %(message)s", level=logging.INFO)

user = "Maria"

logging.info("Something happened", extra={"user_id": user})
```

Or:
```python
import logging

logging.basicConfig(format="%(message)s", level=logging.INFO)

user = "Maria"

logging.info("%s - Something happened", user)
```

## Options
- `lint.logger-objects`

## References
- [Python documentation: `logging`](https://docs.python.org/3/library/logging.html)
- [Python documentation: Optimization](https://docs.python.org/3/howto/logging.html#optimization)

# logging-percent-format (G002)

Derived from the **flake8-logging-format** linter.

## What it does
Checks for uses of `printf`-style format strings to format logging
messages.

## Why is this bad?
The `logging` module provides a mechanism for passing additional values to
be logged using the `extra` keyword argument. This is more consistent, more
efficient, and less error-prone than formatting the string directly.

Using `printf`-style format strings to format a logging message requires
that Python eagerly format the string, even if the logging statement is
never executed (e.g., if the log level is above the level of the logging
statement), whereas using the `extra` keyword argument defers formatting
until required.

Additionally, the use of `extra` will ensure that the values are made
available to all handlers, which can then be configured to log the values
in a consistent manner.

As an alternative to `extra`, passing values as arguments to the logging
method can also be used to defer string formatting until required.

## Known problems

This rule detects uses of the `logging` module via a heuristic.
Specifically, it matches against:

- Uses of the `logging` module itself (e.g., `import logging; logging.info(...)`).
- Uses of `flask.current_app.logger` (e.g., `from flask import current_app; current_app.logger.info(...)`).
- Objects whose name starts with `log` or ends with `logger` or `logging`,
  when used in the same file in which they are defined (e.g., `logger = logging.getLogger(); logger.info(...)`).
- Imported objects marked as loggers via the [`lint.logger-objects`] setting, which can be
  used to enforce these rules against shared logger objects (e.g., `from module import logger; logger.info(...)`,
  when [`lint.logger-objects`] is set to `["module.logger"]`).

## Example
```python
import logging

logging.basicConfig(format="%(message)s", level=logging.INFO)

user = "Maria"

logging.info("%s - Something happened" % user)
```

Use instead:
```python
import logging

logging.basicConfig(format="%(user_id)s - %(message)s", level=logging.INFO)

user = "Maria"

logging.info("Something happened", extra=dict(user_id=user))
```

Or:
```python
import logging

logging.basicConfig(format="%(message)s", level=logging.INFO)

user = "Maria"

logging.info("%s - Something happened", user)
```

## Options
- `lint.logger-objects`

## References
- [Python documentation: `logging`](https://docs.python.org/3/library/logging.html)
- [Python documentation: Optimization](https://docs.python.org/3/howto/logging.html#optimization)

# logging-string-concat (G003)

Derived from the **flake8-logging-format** linter.

## What it does
Checks for uses string concatenation via the `+` operator to format logging
messages.

## Why is this bad?
The `logging` module provides a mechanism for passing additional values to
be logged using the `extra` keyword argument. This is more consistent, more
efficient, and less error-prone than formatting the string directly.

Using concatenation to format a logging message requires that Python
eagerly format the string, even if the logging statement is never executed
(e.g., if the log level is above the level of the logging statement),
whereas using the `extra` keyword argument defers formatting until required.

Additionally, the use of `extra` will ensure that the values are made
available to all handlers, which can then be configured to log the values
in a consistent manner.

As an alternative to `extra`, passing values as arguments to the logging
method can also be used to defer string formatting until required.

## Known problems

This rule detects uses of the `logging` module via a heuristic.
Specifically, it matches against:

- Uses of the `logging` module itself (e.g., `import logging; logging.info(...)`).
- Uses of `flask.current_app.logger` (e.g., `from flask import current_app; current_app.logger.info(...)`).
- Objects whose name starts with `log` or ends with `logger` or `logging`,
  when used in the same file in which they are defined (e.g., `logger = logging.getLogger(); logger.info(...)`).
- Imported objects marked as loggers via the [`lint.logger-objects`] setting, which can be
  used to enforce these rules against shared logger objects (e.g., `from module import logger; logger.info(...)`,
  when [`lint.logger-objects`] is set to `["module.logger"]`).

## Example
```python
import logging

logging.basicConfig(format="%(message)s", level=logging.INFO)

user = "Maria"

logging.info(user + " - Something happened")
```

Use instead:
```python
import logging

logging.basicConfig(format="%(user_id)s - %(message)s", level=logging.INFO)

user = "Maria"

logging.info("Something happened", extra=dict(user_id=user))
```

Or:
```python
import logging

logging.basicConfig(format="%(message)s", level=logging.INFO)

user = "Maria"

logging.info("%s - Something happened", user)
```

## Options
- `lint.logger-objects`

## References
- [Python documentation: `logging`](https://docs.python.org/3/library/logging.html)
- [Python documentation: Optimization](https://docs.python.org/3/howto/logging.html#optimization)

# logging-f-string (G004)

Derived from the **flake8-logging-format** linter.

Fix is sometimes available.

## What it does
Checks for uses of f-strings to format logging messages.

## Why is this bad?
The `logging` module provides a mechanism for passing additional values to
be logged using the `extra` keyword argument. This is more consistent, more
efficient, and less error-prone than formatting the string directly.

Using f-strings to format a logging message requires that Python eagerly
format the string, even if the logging statement is never executed (e.g.,
if the log level is above the level of the logging statement), whereas
using the `extra` keyword argument defers formatting until required.

Additionally, the use of `extra` will ensure that the values are made
available to all handlers, which can then be configured to log the values
in a consistent manner.

As an alternative to `extra`, passing values as arguments to the logging
method can also be used to defer string formatting until required.

## Known problems

This rule detects uses of the `logging` module via a heuristic.
Specifically, it matches against:

- Uses of the `logging` module itself (e.g., `import logging; logging.info(...)`).
- Uses of `flask.current_app.logger` (e.g., `from flask import current_app; current_app.logger.info(...)`).
- Objects whose name starts with `log` or ends with `logger` or `logging`,
  when used in the same file in which they are defined (e.g., `logger = logging.getLogger(); logger.info(...)`).
- Imported objects marked as loggers via the [`lint.logger-objects`] setting, which can be
  used to enforce these rules against shared logger objects (e.g., `from module import logger; logger.info(...)`,
  when [`lint.logger-objects`] is set to `["module.logger"]`).

## Example
```python
import logging

logging.basicConfig(format="%(message)s", level=logging.INFO)

user = "Maria"

logging.info(f"{user} - Something happened")
```

Use instead:
```python
import logging

logging.basicConfig(format="%(user_id)s - %(message)s", level=logging.INFO)

user = "Maria"

logging.info("Something happened", extra=dict(user_id=user))
```

Or:
```python
import logging

logging.basicConfig(format="%(message)s", level=logging.INFO)

user = "Maria"

logging.info("%s - Something happened", user)
```

## Options
- `lint.logger-objects`

## References
- [Python documentation: `logging`](https://docs.python.org/3/library/logging.html)
- [Python documentation: Optimization](https://docs.python.org/3/howto/logging.html#optimization)

# logging-warn (G010)

Derived from the **flake8-logging-format** linter.

Fix is always available.

## What it does
Checks for uses of `logging.warn` and `logging.Logger.warn`.

## Why is this bad?
`logging.warn` and `logging.Logger.warn` are deprecated in favor of
`logging.warning` and `logging.Logger.warning`, which are functionally
equivalent.

## Known problems

This rule detects uses of the `logging` module via a heuristic.
Specifically, it matches against:

- Uses of the `logging` module itself (e.g., `import logging; logging.info(...)`).
- Uses of `flask.current_app.logger` (e.g., `from flask import current_app; current_app.logger.info(...)`).
- Objects whose name starts with `log` or ends with `logger` or `logging`,
  when used in the same file in which they are defined (e.g., `logger = logging.getLogger(); logger.info(...)`).
- Imported objects marked as loggers via the [`lint.logger-objects`] setting, which can be
  used to enforce these rules against shared logger objects (e.g., `from module import logger; logger.info(...)`,
  when [`lint.logger-objects`] is set to `["module.logger"]`).

## Example
```python
import logging

logging.warn("Something happened")
```

Use instead:
```python
import logging

logging.warning("Something happened")
```

## Options
- `lint.logger-objects`

## References
- [Python documentation: `logging.warning`](https://docs.python.org/3/library/logging.html#logging.warning)
- [Python documentation: `logging.Logger.warning`](https://docs.python.org/3/library/logging.html#logging.Logger.warning)

# logging-extra-attr-clash (G101)

Derived from the **flake8-logging-format** linter.

## What it does
Checks for `extra` keywords in logging statements that clash with
`LogRecord` attributes.

## Why is this bad?
The `logging` module provides a mechanism for passing additional values to
be logged using the `extra` keyword argument. These values are then passed
to the `LogRecord` constructor.

Providing a value via `extra` that clashes with one of the attributes of
the `LogRecord` constructor will raise a `KeyError` when the `LogRecord` is
constructed.

## Known problems

This rule detects uses of the `logging` module via a heuristic.
Specifically, it matches against:

- Uses of the `logging` module itself (e.g., `import logging; logging.info(...)`).
- Uses of `flask.current_app.logger` (e.g., `from flask import current_app; current_app.logger.info(...)`).
- Objects whose name starts with `log` or ends with `logger` or `logging`,
  when used in the same file in which they are defined (e.g., `logger = logging.getLogger(); logger.info(...)`).
- Imported objects marked as loggers via the [`lint.logger-objects`] setting, which can be
  used to enforce these rules against shared logger objects (e.g., `from module import logger; logger.info(...)`,
  when [`lint.logger-objects`] is set to `["module.logger"]`).

## Example
```python
import logging

logging.basicConfig(format="%(name) - %(message)s", level=logging.INFO)

username = "Maria"

logging.info("Something happened", extra=dict(name=username))
```

Use instead:
```python
import logging

logging.basicConfig(format="%(user_id)s - %(message)s", level=logging.INFO)

username = "Maria"

logging.info("Something happened", extra=dict(user_id=username))
```

## Options
- `lint.logger-objects`

## References
- [Python documentation: LogRecord attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes)

# logging-exc-info (G201)

Derived from the **flake8-logging-format** linter.

## What it does
Checks for uses of `logging.error` that pass `exc_info=True`.

## Why is this bad?
Calling `logging.error` with `exc_info=True` is equivalent to calling
`logging.exception`. Using `logging.exception` is more concise, more
readable, and conveys the intent of the logging statement more clearly.

## Known problems

This rule detects uses of the `logging` module via a heuristic.
Specifically, it matches against:

- Uses of the `logging` module itself (e.g., `import logging; logging.info(...)`).
- Uses of `flask.current_app.logger` (e.g., `from flask import current_app; current_app.logger.info(...)`).
- Objects whose name starts with `log` or ends with `logger` or `logging`,
  when used in the same file in which they are defined (e.g., `logger = logging.getLogger(); logger.info(...)`).
- Imported objects marked as loggers via the [`lint.logger-objects`] setting, which can be
  used to enforce these rules against shared logger objects (e.g., `from module import logger; logger.info(...)`,
  when [`lint.logger-objects`] is set to `["module.logger"]`).

## Example
```python
import logging

try:
    ...
except ValueError:
    logging.error("Exception occurred", exc_info=True)
```

Use instead:
```python
import logging

try:
    ...
except ValueError:
    logging.exception("Exception occurred")
```

## Options
- `lint.logger-objects`

## References
- [Python documentation: `logging.exception`](https://docs.python.org/3/library/logging.html#logging.exception)
- [Python documentation: `exception`](https://docs.python.org/3/library/logging.html#logging.Logger.exception)
- [Python documentation: `logging.error`](https://docs.python.org/3/library/logging.html#logging.error)
- [Python documentation: `error`](https://docs.python.org/3/library/logging.html#logging.Logger.error)

# logging-redundant-exc-info (G202)

Derived from the **flake8-logging-format** linter.

## What it does
Checks for redundant `exc_info` keyword arguments in logging statements.

## Why is this bad?
`exc_info` is `True` by default for `logging.exception`, and `False` by
default for `logging.error`.

Passing `exc_info=True` to `logging.exception` calls is redundant, as is
passing `exc_info=False` to `logging.error` calls.

## Known problems

This rule detects uses of the `logging` module via a heuristic.
Specifically, it matches against:

- Uses of the `logging` module itself (e.g., `import logging; logging.info(...)`).
- Uses of `flask.current_app.logger` (e.g., `from flask import current_app; current_app.logger.info(...)`).
- Objects whose name starts with `log` or ends with `logger` or `logging`,
  when used in the same file in which they are defined (e.g., `logger = logging.getLogger(); logger.info(...)`).
- Imported objects marked as loggers via the [`lint.logger-objects`] setting, which can be
  used to enforce these rules against shared logger objects (e.g., `from module import logger; logger.info(...)`,
  when [`lint.logger-objects`] is set to `["module.logger"]`).

## Example
```python
import logging

try:
    ...
except ValueError:
    logging.exception("Exception occurred", exc_info=True)
```

Use instead:
```python
import logging

try:
    ...
except ValueError:
    logging.exception("Exception occurred")
```

## Options
- `lint.logger-objects`

## References
- [Python documentation: `logging.exception`](https://docs.python.org/3/library/logging.html#logging.exception)
- [Python documentation: `exception`](https://docs.python.org/3/library/logging.html#logging.Logger.exception)
- [Python documentation: `logging.error`](https://docs.python.org/3/library/logging.html#logging.error)
- [Python documentation: `error`](https://docs.python.org/3/library/logging.html#logging.Logger.error)

# implicit-namespace-package (INP001)

Derived from the **flake8-no-pep420** linter.

## What it does
Checks for packages that are missing an `__init__.py` file.

## Why is this bad?
Python packages are directories that contain a file named `__init__.py`.
The existence of this file indicates that the directory is a Python
package, and so it can be imported the same way a module can be
imported.

Directories that lack an `__init__.py` file can still be imported, but
they're indicative of a special kind of package, known as a "namespace
package" (see: [PEP 420](https://peps.python.org/pep-0420/)).
Namespace packages are less widely used, so a package that lacks an
`__init__.py` file is typically meant to be a regular package, and
the absence of the `__init__.py` file is probably an oversight.

## Options
- `namespace-packages`

# unnecessary-placeholder (PIE790)

Derived from the **flake8-pie** linter.

Fix is always available.

## What it does
Checks for unnecessary `pass` statements and ellipsis (`...`) literals in
functions, classes, and other blocks.

## Why is this bad?
In Python, the `pass` statement and ellipsis (`...`) literal serve as
placeholders, allowing for syntactically correct empty code blocks. The
primary purpose of these nodes is to avoid syntax errors in situations
where a statement or expression is syntactically required, but no code
needs to be executed.

If a `pass` or ellipsis is present in a code block that includes at least
one other statement (even, e.g., a docstring), it is unnecessary and should
be removed.

## Example
```python
def func():
    """Placeholder docstring."""
    pass
```

Use instead:
```python
def func():
    """Placeholder docstring."""
```

Or, given:
```python
def func():
    """Placeholder docstring."""
    ...
```

Use instead:
```python
def func():
    """Placeholder docstring."""
```

## Fix safety
This rule's fix is marked as unsafe in the rare case that the `pass` or ellipsis
is followed by a string literal, since removal of the placeholder would convert the
subsequent string literal into a docstring.

## References
- [Python documentation: The `pass` statement](https://docs.python.org/3/reference/simple_stmts.html#the-pass-statement)

# duplicate-class-field-definition (PIE794)

Derived from the **flake8-pie** linter.

Fix is always available.

## What it does
Checks for duplicate field definitions in classes.

## Why is this bad?
Defining a field multiple times in a class body is redundant and likely a
mistake.

## Example
```python
class Person:
    name = Tom
    ...
    name = Ben
```

Use instead:
```python
class Person:
    name = Tom
    ...
```

## Fix safety
This fix is always marked as unsafe since we cannot know
for certain which assignment was intended.

# non-unique-enums (PIE796)

Derived from the **flake8-pie** linter.

## What it does
Checks for enums that contain duplicate values.

## Why is this bad?
Enum values should be unique. Non-unique values are redundant and likely a
mistake.

## Example
```python
from enum import Enum


class Foo(Enum):
    A = 1
    B = 2
    C = 1
```

Use instead:
```python
from enum import Enum


class Foo(Enum):
    A = 1
    B = 2
    C = 3
```

## References
- [Python documentation: `enum.Enum`](https://docs.python.org/3/library/enum.html#enum.Enum)

# unnecessary-spread (PIE800)

Derived from the **flake8-pie** linter.

Fix is sometimes available.

## What it does
Checks for unnecessary dictionary unpacking operators (`**`).

## Why is this bad?
Unpacking a dictionary into another dictionary is redundant. The unpacking
operator can be removed, making the code more readable.

## Example
```python
foo = {"A": 1, "B": 2}
bar = {**foo, **{"C": 3}}
```

Use instead:
```python
foo = {"A": 1, "B": 2}
bar = {**foo, "C": 3}
```

## References
- [Python documentation: Dictionary displays](https://docs.python.org/3/reference/expressions.html#dictionary-displays)

# unnecessary-dict-kwargs (PIE804)

Derived from the **flake8-pie** linter.

Fix is sometimes available.

## What it does
Checks for unnecessary `dict` kwargs.

## Why is this bad?
If the `dict` keys are valid identifiers, they can be passed as keyword
arguments directly, without constructing unnecessary dictionary.
This also makes code more type-safe as type checkers often cannot
precisely verify dynamic keyword arguments.

## Example

```python
def foo(bar):
    return bar + 1


print(foo(**{"bar": 2}))  # prints 3

# No typing errors, but results in an exception at runtime.
print(foo(**{"bar": 2, "baz": 3}))
```

Use instead:

```python
def foo(bar):
    return bar + 1


print(foo(bar=2))  # prints 3

# Typing error detected: No parameter named "baz".
print(foo(bar=2, baz=3))
```

## Fix safety

This rule's fix is marked as unsafe for dictionaries with comments interleaved between
the items, as comments may be removed.

For example, the fix would be marked as unsafe in the following case:

```python
foo(
    **{
        # comment
        "x": 1.0,
        # comment
        "y": 2.0,
    }
)
```

as this is converted to `foo(x=1.0, y=2.0)` without any of the comments.

## References
- [Python documentation: Dictionary displays](https://docs.python.org/3/reference/expressions.html#dictionary-displays)
- [Python documentation: Calls](https://docs.python.org/3/reference/expressions.html#calls)

# reimplemented-container-builtin (PIE807)

Derived from the **flake8-pie** linter.

Fix is sometimes available.

## What it does
Checks for lambdas that can be replaced with the `list` or `dict` builtins.

## Why is this bad?
Using container builtins are more succinct and idiomatic than wrapping
the literal in a lambda.

## Example
```python
from dataclasses import dataclass, field


@dataclass
class Foo:
    bar: list[int] = field(default_factory=lambda: [])
```

Use instead:
```python
from dataclasses import dataclass, field


@dataclass
class Foo:
    bar: list[int] = field(default_factory=list)
    baz: dict[str, int] = field(default_factory=dict)
```

## References
- [Python documentation: `list`](https://docs.python.org/3/library/functions.html#func-list)

# unnecessary-range-start (PIE808)

Derived from the **flake8-pie** linter.

Fix is always available.

## What it does
Checks for `range` calls with an unnecessary `start` argument.

## Why is this bad?
`range(0, x)` is equivalent to `range(x)`, as `0` is the default value for
the `start` argument. Omitting the `start` argument makes the code more
concise and idiomatic.

## Example
```python
range(0, 3)
```

Use instead:
```python
range(3)
```

## References
- [Python documentation: `range`](https://docs.python.org/3/library/stdtypes.html#range)

# multiple-starts-ends-with (PIE810)

Derived from the **flake8-pie** linter.

Fix is always available.

## What it does
Checks for `startswith` or `endswith` calls on the same value with
different prefixes or suffixes.

## Why is this bad?
The `startswith` and `endswith` methods accept tuples of prefixes or
suffixes respectively. Passing a tuple of prefixes or suffixes is more
efficient and readable than calling the method multiple times.

## Example
```python
msg = "Hello, world!"
if msg.startswith("Hello") or msg.startswith("Hi"):
    print("Greetings!")
```

Use instead:
```python
msg = "Hello, world!"
if msg.startswith(("Hello", "Hi")):
    print("Greetings!")
```

## Fix safety
This rule's fix is unsafe, as in some cases, it will be unable to determine
whether the argument to an existing `.startswith` or `.endswith` call is a
tuple. For example, given `msg.startswith(x) or msg.startswith(y)`, if `x`
or `y` is a tuple, and the semantic model is unable to detect it as such,
the rule will suggest `msg.startswith((x, y))`, which will error at
runtime.

## References
- [Python documentation: `str.startswith`](https://docs.python.org/3/library/stdtypes.html#str.startswith)
- [Python documentation: `str.endswith`](https://docs.python.org/3/library/stdtypes.html#str.endswith)

# print (T201)

Derived from the **flake8-print** linter.

Fix is sometimes available.

## What it does
Checks for `print` statements.

## Why is this bad?
`print` statements used for debugging should be omitted from production
code. They can lead the accidental inclusion of sensitive information in
logs, and are not configurable by clients, unlike `logging` statements.

`print` statements used to produce output as a part of a command-line
interface program are not typically a problem.

## Example
```python
def sum_less_than_four(a, b):
    print(f"Calling sum_less_than_four")
    return a + b < 4
```

The automatic fix will remove the print statement entirely:

```python
def sum_less_than_four(a, b):
    return a + b < 4
```

To keep the line for logging purposes, instead use something like:

```python
import logging

logging.basicConfig(level=logging.INFO)


def sum_less_than_four(a, b):
    logging.debug("Calling sum_less_than_four")
    return a + b < 4
```

## Fix safety
This rule's fix is marked as unsafe, as it will remove `print` statements
that are used beyond debugging purposes.

# p-print (T203)

Derived from the **flake8-print** linter.

Fix is sometimes available.

## What it does
Checks for `pprint` statements.

## Why is this bad?
Like `print` statements, `pprint` statements used for debugging should
be omitted from production code. They can lead the accidental inclusion
of sensitive information in logs, and are not configurable by clients,
unlike `logging` statements.

`pprint` statements used to produce output as a part of a command-line
interface program are not typically a problem.

## Example
```python
import pprint


def merge_dicts(dict_a, dict_b):
    dict_c = {**dict_a, **dict_b}
    pprint.pprint(dict_c)
    return dict_c
```

Use instead:
```python
def merge_dicts(dict_a, dict_b):
    dict_c = {**dict_a, **dict_b}
    return dict_c
```

## Fix safety
This rule's fix is marked as unsafe, as it will remove `pprint` statements
that are used beyond debugging purposes.

# unprefixed-type-param (PYI001)

Derived from the **flake8-pyi** linter.

## What it does
Checks that type `TypeVar`s, `ParamSpec`s, and `TypeVarTuple`s in stubs
have names prefixed with `_`.

## Why is this bad?
Prefixing type parameters with `_` avoids accidentally exposing names
internal to the stub.

## Example
```pyi
from typing import TypeVar

T = TypeVar("T")
```

Use instead:
```pyi
from typing import TypeVar

_T = TypeVar("_T")
```

# complex-if-statement-in-stub (PYI002)

Derived from the **flake8-pyi** linter.

## What it does
Checks for `if` statements with complex conditionals in stubs.

## Why is this bad?
Type checkers understand simple conditionals to express variations between
different Python versions and platforms. However, complex tests may not be
understood by a type checker, leading to incorrect inferences when they
analyze your code.

## Example
```pyi
import sys

if (3, 10) <= sys.version_info < (3, 12): ...
```

Use instead:
```pyi
import sys

if sys.version_info >= (3, 10) and sys.version_info < (3, 12): ...
```

## References
- [Typing documentation: Version and platform checking](https://typing.python.org/en/latest/spec/directives.html#version-and-platform-checks)

# unrecognized-version-info-check (PYI003)

Derived from the **flake8-pyi** linter.

## What it does
Checks for problematic `sys.version_info`-related conditions in stubs.

## Why is this bad?
Stub files support simple conditionals to test for differences in Python
versions using `sys.version_info`. However, there are a number of common
mistakes involving `sys.version_info` comparisons that should be avoided.
For example, comparing against a string can lead to unexpected behavior.

## Example
```pyi
import sys

if sys.version_info[0] == "2": ...
```

Use instead:
```pyi
import sys

if sys.version_info[0] == 2: ...
```

## References
- [Typing documentation: Version and Platform checking](https://typing.python.org/en/latest/spec/directives.html#version-and-platform-checks)

# patch-version-comparison (PYI004)

Derived from the **flake8-pyi** linter.

## What it does
Checks for Python version comparisons in stubs that compare against patch
versions (e.g., Python 3.8.3) instead of major and minor versions (e.g.,
Python 3.8).

## Why is this bad?
Stub files support simple conditionals to test for differences in Python
versions and platforms. However, type checkers only understand a limited
subset of these conditionals. In particular, type checkers don't support
patch versions (e.g., Python 3.8.3), only major and minor versions (e.g.,
Python 3.8). Therefore, version checks in stubs should only use the major
and minor versions.

## Example
```pyi
import sys

if sys.version_info >= (3, 4, 3): ...
```

Use instead:
```pyi
import sys

if sys.version_info >= (3, 4): ...
```

## References
- [Typing documentation: Version and Platform checking](https://typing.python.org/en/latest/spec/directives.html#version-and-platform-checks)

# wrong-tuple-length-version-comparison (PYI005)

Derived from the **flake8-pyi** linter.

## What it does
Checks for Python version comparisons that compare against a tuple of the
wrong length.

## Why is this bad?
Stub files support simple conditionals to test for differences in Python
versions and platforms. When comparing against `sys.version_info`, avoid
comparing against tuples of the wrong length, which can lead to unexpected
behavior.

## Example
```pyi
import sys

if sys.version_info[:2] == (3,): ...
```

Use instead:
```pyi
import sys

if sys.version_info[0] == 3: ...
```

## References
- [Typing documentation: Version and Platform checking](https://typing.python.org/en/latest/spec/directives.html#version-and-platform-checks)

# bad-version-info-comparison (PYI006)

Derived from the **flake8-pyi** linter.

## What it does
Checks for uses of comparators other than `<` and `>=` for
`sys.version_info` checks. All other comparators, such
as `>`, `<=`, and `==`, are banned.

## Why is this bad?
Comparing `sys.version_info` with `==` or `<=` has unexpected behavior
and can lead to bugs.

For example, `sys.version_info > (3, 8, 1)` will resolve to `True` if your
Python version is 3.8.1; meanwhile, `sys.version_info <= (3, 8)` will _not_
resolve to `True` if your Python version is 3.8.10:

```python
>>> import sys
>>> print(sys.version_info)
sys.version_info(major=3, minor=8, micro=10, releaselevel='final', serial=0)
>>> print(sys.version_info > (3, 8))
True
>>> print(sys.version_info == (3, 8))
False
>>> print(sys.version_info <= (3, 8))
False
>>> print(sys.version_info in (3, 8))
False
```

## Example
```py
import sys

if sys.version_info > (3, 8): ...
```

Use instead:
```py
import sys

if sys.version_info >= (3, 9): ...
```

[preview]: https://docs.astral.sh/ruff/preview/

# unrecognized-platform-check (PYI007)

Derived from the **flake8-pyi** linter.

## What it does
Check for unrecognized `sys.platform` checks. Platform checks should be
simple string comparisons.

**Note**: this rule is only enabled in `.pyi` stub files.

## Why is this bad?
Some `sys.platform` checks are too complex for type checkers to
understand, and thus result in incorrect inferences by these tools.
`sys.platform` checks should be simple string comparisons, like
`if sys.platform == "linux"`.

## Example
```pyi
import sys

if sys.platform == "xunil"[::-1]:
    # Linux specific definitions
    ...
else:
    # Posix specific definitions
    ...
```

Instead, use a simple string comparison, such as `==` or `!=`:
```pyi
import sys

if sys.platform == "linux":
    # Linux specific definitions
    ...
else:
    # Posix specific definitions
    ...
```

## References
- [Typing documentation: Version and Platform checking](https://typing.python.org/en/latest/spec/directives.html#version-and-platform-checks)

# unrecognized-platform-name (PYI008)

Derived from the **flake8-pyi** linter.

## What it does
Check for unrecognized platform names in `sys.platform` checks.

**Note**: this rule is only enabled in `.pyi` stub files.

## Why is this bad?
If a `sys.platform` check compares to a platform name outside of a
small set of known platforms (e.g. "linux", "win32", etc.), it's likely
a typo or a platform name that is not recognized by type checkers.

The list of known platforms is: "linux", "win32", "cygwin", "darwin".

## Example
```pyi
import sys

if sys.platform == "linus": ...
```

Use instead:
```pyi
import sys

if sys.platform == "linux": ...
```

## References
- [Typing documentation: Version and Platform checking](https://typing.python.org/en/latest/spec/directives.html#version-and-platform-checks)

# pass-statement-stub-body (PYI009)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for `pass` statements in empty stub bodies.

## Why is this bad?
For stylistic consistency, `...` should always be used rather than `pass`
in stub files.

## Example
```pyi
def foo(bar: int) -> list[int]: pass
```

Use instead:
```pyi
def foo(bar: int) -> list[int]: ...
```

## References
- [Typing documentation - Writing and Maintaining Stub Files](https://typing.python.org/en/latest/guides/writing_stubs.html)

# non-empty-stub-body (PYI010)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for non-empty function stub bodies.

## Why is this bad?
Stub files are never executed at runtime; they should be thought of as
"data files" for type checkers or IDEs. Function bodies are redundant
for this purpose.

## Example
```pyi
def double(x: int) -> int:
    return x * 2
```

Use instead:
```pyi
def double(x: int) -> int: ...
```

## References
- [Typing documentation - Writing and Maintaining Stub Files](https://typing.python.org/en/latest/guides/writing_stubs.html)

# typed-argument-default-in-stub (PYI011)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for typed function arguments in stubs with complex default values.

## Why is this bad?
Stub (`.pyi`) files exist as "data files" for static analysis tools, and
are not evaluated at runtime. While simple default values may be useful for
some tools that consume stubs, such as IDEs, they are ignored by type
checkers.

Instead of including and reproducing a complex value, use `...` to indicate
that the assignment has a default value, but that the value is "complex" or
varies according to the current platform or Python version. For the
purposes of this rule, any default value counts as "complex" unless it is
a literal `int`, `float`, `complex`, `bytes`, `str`, `bool`, `None`, `...`,
or a simple container literal.

## Example

```pyi
def foo(arg: list[int] = list(range(10_000))) -> None: ...
```

Use instead:

```pyi
def foo(arg: list[int] = ...) -> None: ...
```

## References
- [`flake8-pyi`](https://github.com/PyCQA/flake8-pyi/blob/main/ERRORCODES.md)

# pass-in-class-body (PYI012)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for the presence of the `pass` statement in non-empty class bodies
in `.pyi` files.

## Why is this bad?
The `pass` statement is always unnecessary in non-empty class bodies in
stubs.

## Example
```pyi
class MyClass:
    x: int
    pass
```

Use instead:
```pyi
class MyClass:
    x: int
```

# ellipsis-in-non-empty-class-body (PYI013)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Removes ellipses (`...`) in otherwise non-empty class bodies.

## Why is this bad?
An ellipsis in a class body is only necessary if the class body is
otherwise empty. If the class body is non-empty, then the ellipsis
is redundant.

## Example
```pyi
class Foo:
    ...
    value: int
```

Use instead:
```pyi
class Foo:
    value: int
```

# argument-default-in-stub (PYI014)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for untyped function arguments in stubs with default values that
are not "simple" /// (i.e., `int`, `float`, `complex`, `bytes`, `str`,
`bool`, `None`, `...`, or simple container literals).

## Why is this bad?
Stub (`.pyi`) files exist to define type hints, and are not evaluated at
runtime. As such, function arguments in stub files should not have default
values, as they are ignored by type checkers.

However, the use of default values may be useful for IDEs and other
consumers of stub files, and so "simple" values may be worth including and
are permitted by this rule.

Instead of including and reproducing a complex value, use `...` to indicate
that the assignment has a default value, but that the value is non-simple
or varies according to the current platform or Python version.

## Example

```pyi
def foo(arg=bar()) -> None: ...
```

Use instead:

```pyi
def foo(arg=...) -> None: ...
```

## References
- [`flake8-pyi`](https://github.com/PyCQA/flake8-pyi/blob/main/ERRORCODES.md)

# assignment-default-in-stub (PYI015)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for assignments in stubs with default values that are not "simple"
(i.e., `int`, `float`, `complex`, `bytes`, `str`, `bool`, `None`, `...`, or
simple container literals).

## Why is this bad?
Stub (`.pyi`) files exist to define type hints, and are not evaluated at
runtime. As such, assignments in stub files should not include values,
as they are ignored by type checkers.

However, the use of such values may be useful for IDEs and other consumers
of stub files, and so "simple" values may be worth including and are
permitted by this rule.

Instead of including and reproducing a complex value, use `...` to indicate
that the assignment has a default value, but that the value is non-simple
or varies according to the current platform or Python version.

## Example
```pyi
foo: str = bar()
```

Use instead:
```pyi
foo: str = ...
```

## References
- [`flake8-pyi`](https://github.com/PyCQA/flake8-pyi/blob/main/ERRORCODES.md)

# duplicate-union-member (PYI016)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for duplicate union members.

## Why is this bad?
Duplicate union members are redundant and should be removed.

## Example
```python
foo: str | str
```

Use instead:
```python
foo: str
```

## Fix safety
This rule's fix is marked as safe unless the union contains comments.

For nested union, the fix will flatten type expressions into a single
top-level union.

## References
- [Python documentation: `typing.Union`](https://docs.python.org/3/library/typing.html#typing.Union)

# complex-assignment-in-stub (PYI017)

Derived from the **flake8-pyi** linter.

## What it does
Checks for assignments with multiple or non-name targets in stub files.

## Why is this bad?
In general, stub files should be thought of as "data files" for a type
checker, and are not intended to be executed. As such, it's useful to
enforce that only a subset of Python syntax is allowed in a stub file, to
ensure that everything in the stub is unambiguous for the type checker.

The need to perform multi-assignment, or assignment to a non-name target,
likely indicates a misunderstanding of how stub files are intended to be
used.

## Example

```pyi
from typing import TypeAlias

a = b = int

class Klass: ...

Klass.X: TypeAlias = int
```

Use instead:

```pyi
from typing import TypeAlias

a: TypeAlias = int
b: TypeAlias = int

class Klass:
    X: TypeAlias = int
```

# unused-private-type-var (PYI018)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for the presence of unused private `TypeVar`, `ParamSpec` or
`TypeVarTuple` declarations.

## Why is this bad?
A private `TypeVar` that is defined but not used is likely a mistake. It
should either be used, made public, or removed to avoid confusion. A type
variable is considered "private" if its name starts with an underscore.

## Example
```pyi
import typing
import typing_extensions

_T = typing.TypeVar("_T")
_Ts = typing_extensions.TypeVarTuple("_Ts")
```

## Fix safety
The fix is always marked as unsafe, as it would break your code if the type
variable is imported by another module.

# custom-type-var-for-self (PYI019)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for methods that use custom [`TypeVar`s][typing_TypeVar] in their
annotations when they could use [`Self`][Self] instead.

## Why is this bad?
While the semantics are often identical, using `Self` is more intuitive
and succinct (per [PEP 673]) than a custom `TypeVar`. For example, the
use of `Self` will typically allow for the omission of type parameters
on the `self` and `cls` arguments.

This check currently applies to instance methods that return `self`,
class methods that return an instance of `cls`, class methods that return
`cls`, and `__new__` methods.

## Example

```pyi
from typing import TypeVar

_S = TypeVar("_S", bound="Foo")

class Foo:
    def __new__(cls: type[_S], *args: str, **kwargs: int) -> _S: ...
    def foo(self: _S, arg: bytes) -> _S: ...
    @classmethod
    def bar(cls: type[_S], arg: int) -> _S: ...
```

Use instead:

```pyi
from typing import Self

class Foo:
    def __new__(cls, *args: str, **kwargs: int) -> Self: ...
    def foo(self, arg: bytes) -> Self: ...
    @classmethod
    def bar(cls, arg: int) -> Self: ...
```

## Fix behaviour
The fix replaces all references to the custom type variable in the method's header and body
with references to `Self`. The fix also adds an import of `Self` if neither `Self` nor `typing`
is already imported in the module. If your [`target-version`] setting is set to Python 3.11 or
newer, the fix imports `Self` from the standard-library `typing` module; otherwise, the fix
imports `Self` from the third-party [`typing_extensions`][typing_extensions] backport package.

If the custom type variable is a [PEP-695]-style `TypeVar`, the fix also removes the `TypeVar`
declaration from the method's [type parameter list]. However, if the type variable is an
old-style `TypeVar`, the declaration of the type variable will not be removed by this rule's
fix, as the type variable could still be used by other functions, methods or classes. See
[`unused-private-type-var`][PYI018] for a rule that will clean up unused private type
variables.

## Fix safety
The fix is only marked as unsafe if there is the possibility that it might delete a comment
from your code.

## Availability

Because this rule relies on the third-party `typing_extensions` module for Python versions
before 3.11, its diagnostic will not be emitted, and no fix will be offered, if
`typing_extensions` imports have been disabled by the [`lint.typing-extensions`] linter option.

## Options

- `lint.typing-extensions`

[PEP 673]: https://peps.python.org/pep-0673/#motivation
[PEP-695]: https://peps.python.org/pep-0695/
[PYI018]: https://docs.astral.sh/ruff/rules/unused-private-type-var/
[type parameter list]: https://docs.python.org/3/reference/compound_stmts.html#type-params
[Self]: https://docs.python.org/3/library/typing.html#typing.Self
[typing_TypeVar]: https://docs.python.org/3/library/typing.html#typing.TypeVar
[typing_extensions]: https://typing-extensions.readthedocs.io/en/latest/

# quoted-annotation-in-stub (PYI020)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for quoted type annotations in stub (`.pyi`) files, which should be avoided.

## Why is this bad?
Stub files natively support forward references in all contexts, as stubs
are never executed at runtime. (They should be thought of as "data files"
for type checkers and IDEs.) As such, quotes are never required for type
annotations in stub files, and should be omitted.

## Example

```pyi
def function() -> "int": ...
```

Use instead:

```pyi
def function() -> int: ...
```

## References
- [Typing documentation - Writing and Maintaining Stub Files](https://typing.python.org/en/latest/guides/writing_stubs.html)

# docstring-in-stub (PYI021)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for the presence of docstrings in stub files.

## Why is this bad?
Stub files should omit docstrings, as they're intended to provide type
hints, rather than documentation.

## Example

```pyi
def func(param: int) -> str:
    """This is a docstring."""
    ...
```

Use instead:

```pyi
def func(param: int) -> str: ...
```

# collections-named-tuple (PYI024)

Derived from the **flake8-pyi** linter.

## What it does
Checks for uses of `collections.namedtuple` in stub files.

## Why is this bad?
`typing.NamedTuple` is the "typed version" of `collections.namedtuple`.

Inheriting from `typing.NamedTuple` creates a custom `tuple` subclass in
the same way as using the `collections.namedtuple` factory function.
However, using `typing.NamedTuple` allows you to provide a type annotation
for each field in the class. This means that type checkers will have more
information to work with, and will be able to analyze your code more
precisely.

## Example
```pyi
from collections import namedtuple

Person = namedtuple("Person", ["name", "age"])
```

Use instead:
```pyi
from typing import NamedTuple

class Person(NamedTuple):
    name: str
    age: int
```

# unaliased-collections-abc-set-import (PYI025)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for `from collections.abc import Set` imports that do not alias
`Set` to `AbstractSet`.

## Why is this bad?
The `Set` type in `collections.abc` is an abstract base class for set-like types.
It is easily confused with, and not equivalent to, the `set` builtin.

To avoid confusion, `Set` should be aliased to `AbstractSet` when imported. This
makes it clear that the imported type is an abstract base class, and not the
`set` builtin.

## Example
```pyi
from collections.abc import Set
```

Use instead:
```pyi
from collections.abc import Set as AbstractSet
```

## Fix safety
This rule's fix is marked as unsafe for `Set` imports defined at the
top-level of a `.py` module. Top-level symbols are implicitly exported by the
module, and so renaming a top-level symbol may break downstream modules
that import it.

The same is not true for `.pyi` files, where imported symbols are only
re-exported if they are included in `__all__`, use a "redundant"
`import foo as foo` alias, or are imported via a `*` import. As such, the
fix is marked as safe in more cases for `.pyi` files.

# type-alias-without-annotation (PYI026)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for type alias definitions that are not annotated with
`typing.TypeAlias`.

## Why is this bad?
In Python, a type alias is defined by assigning a type to a variable (e.g.,
`Vector = list[float]`).

It's best to annotate type aliases with the `typing.TypeAlias` type to
make it clear that the statement is a type alias declaration, as opposed
to a normal variable assignment.

## Example
```pyi
Vector = list[float]
```

Use instead:
```pyi
from typing import TypeAlias

Vector: TypeAlias = list[float]
```

## Availability

Because this rule relies on the third-party `typing_extensions` module for Python versions
before 3.10, its diagnostic will not be emitted, and no fix will be offered, if
`typing_extensions` imports have been disabled by the [`lint.typing-extensions`] linter option.

## Options

- `lint.typing-extensions`

# str-or-repr-defined-in-stub (PYI029)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for redundant definitions of `__str__` or `__repr__` in stubs.

## Why is this bad?
Defining `__str__` or `__repr__` in a stub is almost always redundant,
as the signatures are almost always identical to those of the default
equivalent, `object.__str__` and `object.__repr__`, respectively.

## Example

```pyi
class Foo:
    def __repr__(self) -> str: ...
```

# unnecessary-literal-union (PYI030)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for the presence of multiple literal types in a union.

## Why is this bad?
`Literal["foo", 42]` has identical semantics to
`Literal["foo"] | Literal[42]`, but is clearer and more concise.

## Example
```pyi
from typing import Literal

field: Literal[1] | Literal[2] | str
```

Use instead:
```pyi
from typing import Literal

field: Literal[1, 2] | str
```

## Fix safety
This fix is marked unsafe if it would delete any comments within the replacement range.

An example to illustrate where comments are preserved and where they are not:

```pyi
from typing import Literal

field: (
    # deleted comment
    Literal["a", "b"]  # deleted comment
    # deleted comment
    | Literal["c", "d"]  # preserved comment
)
```

## References
- [Python documentation: `typing.Literal`](https://docs.python.org/3/library/typing.html#typing.Literal)

# any-eq-ne-annotation (PYI032)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for `__eq__` and `__ne__` implementations that use `typing.Any` as
the type annotation for their second parameter.

## Why is this bad?
The Python documentation recommends the use of `object` to "indicate that a
value could be any type in a typesafe manner". `Any`, on the other hand,
should be seen as an "escape hatch when you need to mix dynamically and
statically typed code". Since using `Any` allows you to write highly unsafe
code, you should generally only use `Any` when the semantics of your code
would otherwise be inexpressible to the type checker.

The expectation in Python is that a comparison of two arbitrary objects
using `==` or `!=` should never raise an exception. This contract can be
fully expressed in the type system and does not involve requesting unsound
behaviour from a type checker. As such, `object` is a more appropriate
annotation than `Any` for the second parameter of the methods implementing
these comparison operators -- `__eq__` and `__ne__`.

## Example

```pyi
from typing import Any

class Foo:
    def __eq__(self, obj: Any) -> bool: ...
```

Use instead:

```pyi
class Foo:
    def __eq__(self, obj: object) -> bool: ...
```
## References
- [Python documentation: The `Any` type](https://docs.python.org/3/library/typing.html#the-any-type)
- [Mypy documentation: Any vs. object](https://mypy.readthedocs.io/en/latest/dynamic_typing.html#any-vs-object)

# type-comment-in-stub (PYI033)

Derived from the **flake8-pyi** linter.

## What it does
Checks for the use of type comments (e.g., `x = 1  # type: int`) in stub
files.

## Why is this bad?
Stub (`.pyi`) files should use type annotations directly, rather
than type comments, even if they're intended to support Python 2, since
stub files are not executed at runtime. The one exception is `# type: ignore`.

## Example
```pyi
x = 1  # type: int
```

Use instead:
```pyi
x: int = 1
```

# non-self-return-type (PYI034)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for methods that are annotated with a fixed return type which
should instead be returning `Self`.

## Why is this bad?
If methods that generally return `self` at runtime are annotated with a
fixed return type, and the class is subclassed, type checkers will not be
able to infer the correct return type.

For example:
```python
class Shape:
    def set_scale(self, scale: float) -> Shape:
        self.scale = scale
        return self

class Circle(Shape):
    def set_radius(self, radius: float) -> Circle:
        self.radius = radius
        return self

# Type checker infers return type as `Shape`, not `Circle`.
Circle().set_scale(0.5)

# Thus, this expression is invalid, as `Shape` has no attribute `set_radius`.
Circle().set_scale(0.5).set_radius(2.7)
```

Specifically, this check enforces that the return type of the following
methods is `Self`:

1. In-place binary-operation dunder methods, like `__iadd__`, `__imul__`, etc.
1. `__new__`, `__enter__`, and `__aenter__`, if those methods return the
   class name.
1. `__iter__` methods that return `Iterator`, despite the class inheriting
   directly from `Iterator`.
1. `__aiter__` methods that return `AsyncIterator`, despite the class
   inheriting directly from `AsyncIterator`.

The rule attempts to avoid flagging methods on metaclasses, since
[PEP 673] specifies that `Self` is disallowed in metaclasses. Ruff can
detect a class as being a metaclass if it inherits from a stdlib
metaclass such as `builtins.type` or `abc.ABCMeta`, and additionally
infers that a class may be a metaclass if it has a `__new__` method
with a similar signature to `type.__new__`. The heuristic used to
identify a metaclass-like `__new__` method signature is that it:

1. Has exactly 5 parameters (including `cls`)
1. Has a second parameter annotated with `str`
1. Has a third parameter annotated with a `tuple` type
1. Has a fourth parameter annotated with a `dict` type
1. Has a fifth parameter is keyword-variadic (`**kwargs`)

For example, the following class would be detected as a metaclass, disabling
the rule:

```python
class MyMetaclass(django.db.models.base.ModelBase):
    def __new__(cls, name: str, bases: tuple[Any, ...], attrs: dict[str, Any], **kwargs: Any) -> MyMetaclass:
        ...
```

## Example

```pyi
class Foo:
    def __new__(cls, *args: Any, **kwargs: Any) -> Foo: ...
    def __enter__(self) -> Foo: ...
    async def __aenter__(self) -> Foo: ...
    def __iadd__(self, other: Foo) -> Foo: ...
```

Use instead:

```pyi
from typing_extensions import Self

class Foo:
    def __new__(cls, *args: Any, **kwargs: Any) -> Self: ...
    def __enter__(self) -> Self: ...
    async def __aenter__(self) -> Self: ...
    def __iadd__(self, other: Foo) -> Self: ...
```

## Fix safety
This rule's fix is marked as unsafe as it changes the meaning of your type annotations.

## Availability

Because this rule relies on the third-party `typing_extensions` module for Python versions
before 3.11, its diagnostic will not be emitted, and no fix will be offered, if
`typing_extensions` imports have been disabled by the [`lint.typing-extensions`] linter option.

## Options

- `lint.typing-extensions`

## References
- [Python documentation: `typing.Self`](https://docs.python.org/3/library/typing.html#typing.Self)

[PEP 673]: https://peps.python.org/pep-0673/#valid-locations-for-self

# unassigned-special-variable-in-stub (PYI035)

Derived from the **flake8-pyi** linter.

## What it does
Checks that `__all__`, `__match_args__`, and `__slots__` variables are
assigned to values when defined in stub files.

## Why is this bad?
Special variables like `__all__` have the same semantics in stub files
as they do in Python modules, and so should be consistent with their
runtime counterparts.

## Example
```pyi
__all__: list[str]
```

Use instead:
```pyi
__all__: list[str] = ["foo", "bar"]
```

# bad-exit-annotation (PYI036)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for incorrect function signatures on `__exit__` and `__aexit__`
methods.

## Why is this bad?
Improperly annotated `__exit__` and `__aexit__` methods can cause
unexpected behavior when interacting with type checkers.

## Example

```pyi
from types import TracebackType

class Foo:
    def __exit__(
        self, typ: BaseException, exc: BaseException, tb: TracebackType
    ) -> None: ...
```

Use instead:

```pyi
from types import TracebackType

class Foo:
    def __exit__(
        self,
        typ: type[BaseException] | None,
        exc: BaseException | None,
        tb: TracebackType | None,
    ) -> None: ...
```

# redundant-numeric-union (PYI041)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for parameter annotations that contain redundant unions between
builtin numeric types (e.g., `int | float`).

## Why is this bad?
The [typing specification] states:

> Pythons numeric types `complex`, `float` and `int` are not subtypes of
> each other, but to support common use cases, the type system contains a
> straightforward shortcut: when an argument is annotated as having type
> `float`, an argument of type `int` is acceptable; similar, for an
> argument annotated as having type `complex`, arguments of type `float` or
> `int` are acceptable.

As such, a union that includes both `int` and `float` is redundant in the
specific context of a parameter annotation, as it is equivalent to a union
that only includes `float`. For readability and clarity, unions should omit
redundant elements.

## Example

```pyi
def foo(x: float | int | str) -> None: ...
```

Use instead:

```pyi
def foo(x: float | str) -> None: ...
```

## Fix safety
This rule's fix is marked as safe, unless the type annotation contains comments.

Note that while the fix may flatten nested unions into a single top-level union,
the semantics of the annotation will remain unchanged.

## References
- [Python documentation: The numeric tower](https://docs.python.org/3/library/numbers.html#the-numeric-tower)
- [PEP 484: The numeric tower](https://peps.python.org/pep-0484/#the-numeric-tower)

[typing specification]: https://typing.python.org/en/latest/spec/special-types.html#special-cases-for-float-and-complex

# snake-case-type-alias (PYI042)

Derived from the **flake8-pyi** linter.

## What it does
Checks for type aliases that do not use the CamelCase naming convention.

## Why is this bad?
It's conventional to use the CamelCase naming convention for type aliases,
to distinguish them from other variables.

## Example
```pyi
from typing import TypeAlias

type_alias_name: TypeAlias = int
```

Use instead:
```pyi
from typing import TypeAlias

TypeAliasName: TypeAlias = int
```

# t-suffixed-type-alias (PYI043)

Derived from the **flake8-pyi** linter.

## What it does
Checks for private type alias definitions suffixed with 'T'.

## Why is this bad?
It's conventional to use the 'T' suffix for type variables; the use of
such a suffix implies that the object is a `TypeVar`.

Adding the 'T' suffix to a non-`TypeVar`, it can be misleading and should
be avoided.

## Example
```pyi
from typing import TypeAlias

_MyTypeT: TypeAlias = int
```

Use instead:
```pyi
from typing import TypeAlias

_MyType: TypeAlias = int
```

## References
- [PEP 484: Type Aliases](https://peps.python.org/pep-0484/#type-aliases)

# future-annotations-in-stub (PYI044)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for the presence of the `from __future__ import annotations` import
statement in stub files.

## Why is this bad?
Stub files natively support forward references in all contexts, as stubs are
never executed at runtime. (They should be thought of as "data files" for
type checkers.) As such, the `from __future__ import annotations` import
statement has no effect and should be omitted.

## References
- [Typing Style Guide](https://typing.python.org/en/latest/guides/writing_stubs.html#language-features)

# iter-method-return-iterable (PYI045)

Derived from the **flake8-pyi** linter.

## What it does
Checks for `__iter__` methods in stubs that return `Iterable[T]` instead
of an `Iterator[T]`.

## Why is this bad?
`__iter__` methods should always should return an `Iterator` of some kind,
not an `Iterable`.

In Python, an `Iterable` is an object that has an `__iter__` method; an
`Iterator` is an object that has `__iter__` and `__next__` methods. All
`__iter__` methods are expected to return `Iterator`s. Type checkers may
not always recognize an object as being iterable if its `__iter__` method
does not return an `Iterator`.

Every `Iterator` is an `Iterable`, but not every `Iterable` is an `Iterator`.
For example, `list` is an `Iterable`, but not an `Iterator`; you can obtain
an iterator over a list's elements by passing the list to `iter()`:

```pycon
>>> import collections.abc
>>> x = [42]
>>> isinstance(x, collections.abc.Iterable)
True
>>> isinstance(x, collections.abc.Iterator)
False
>>> next(x)
Traceback (most recent call last):
 File "<stdin>", line 1, in <module>
TypeError: 'list' object is not an iterator
>>> y = iter(x)
>>> isinstance(y, collections.abc.Iterable)
True
>>> isinstance(y, collections.abc.Iterator)
True
>>> next(y)
42
```

Using `Iterable` rather than `Iterator` as a return type for an `__iter__`
methods would imply that you would not necessarily be able to call `next()`
on the returned object, violating the expectations of the interface.

## Example

```python
import collections.abc


class Klass:
    def __iter__(self) -> collections.abc.Iterable[str]: ...
```

Use instead:

```python
import collections.abc


class Klass:
    def __iter__(self) -> collections.abc.Iterator[str]: ...
```

# unused-private-protocol (PYI046)

Derived from the **flake8-pyi** linter.

## What it does
Checks for the presence of unused private `typing.Protocol` definitions.

## Why is this bad?
A private `typing.Protocol` that is defined but not used is likely a
mistake. It should either be used, made public, or removed to avoid
confusion.

## Example

```pyi
import typing

class _PrivateProtocol(typing.Protocol):
    foo: int
```

Use instead:

```pyi
import typing

class _PrivateProtocol(typing.Protocol):
    foo: int

def func(arg: _PrivateProtocol) -> None: ...
```

# unused-private-type-alias (PYI047)

Derived from the **flake8-pyi** linter.

## What it does
Checks for the presence of unused private type aliases.

## Why is this bad?
A private type alias that is defined but not used is likely a
mistake. It should either be used, made public, or removed to avoid
confusion.

## Example

```pyi
import typing

_UnusedTypeAlias: typing.TypeAlias = int
```

Use instead:

```pyi
import typing

_UsedTypeAlias: typing.TypeAlias = int

def func(arg: _UsedTypeAlias) -> _UsedTypeAlias: ...
```

# stub-body-multiple-statements (PYI048)

Derived from the **flake8-pyi** linter.

## What it does
Checks for functions in stub (`.pyi`) files that contain multiple
statements.

## Why is this bad?
Stub files are never executed, and are only intended to define type hints.
As such, functions in stub files should not contain functional code, and
should instead contain only a single statement (e.g., `...`).

## Example

```pyi
def function():
    x = 1
    y = 2
    return x + y
```

Use instead:

```pyi
def function(): ...
```

# unused-private-typed-dict (PYI049)

Derived from the **flake8-pyi** linter.

## What it does
Checks for the presence of unused private `typing.TypedDict` definitions.

## Why is this bad?
A private `typing.TypedDict` that is defined but not used is likely a
mistake. It should either be used, made public, or removed to avoid
confusion.

## Example

```pyi
import typing

class _UnusedPrivateTypedDict(typing.TypedDict):
    foo: list[int]
```

Use instead:

```pyi
import typing

class _UsedPrivateTypedDict(typing.TypedDict):
    foo: set[str]

def func(arg: _UsedPrivateTypedDict) -> _UsedPrivateTypedDict: ...
```

# no-return-argument-annotation-in-stub (PYI050)

Derived from the **flake8-pyi** linter.

## What it does
Checks for uses of `typing.NoReturn` (and `typing_extensions.NoReturn`) for
parameter annotations.

## Why is this bad?
Prefer `Never` over `NoReturn` for parameter annotations. `Never` has a
clearer name in these contexts, since it makes little sense to talk about a
parameter annotation "not returning".

This is a purely stylistic lint: the two types have identical semantics for
type checkers. Both represent Python's "[bottom type]" (a type that has no
members).

## Example
```pyi
from typing import NoReturn

def foo(x: NoReturn): ...
```

Use instead:
```pyi
from typing import Never

def foo(x: Never): ...
```

## References
- [Python documentation: `typing.Never`](https://docs.python.org/3/library/typing.html#typing.Never)
- [Python documentation: `typing.NoReturn`](https://docs.python.org/3/library/typing.html#typing.NoReturn)

[bottom type]: https://en.wikipedia.org/wiki/Bottom_type

# redundant-literal-union (PYI051)

Derived from the **flake8-pyi** linter.

## What it does
Checks for redundant unions between a `Literal` and a builtin supertype of
that `Literal`.

## Why is this bad?
Using a `Literal` type in a union with its builtin supertype is redundant,
as the supertype will be strictly more general than the `Literal` type.
For example, `Literal["A"] | str` is equivalent to `str`, and
`Literal[1] | int` is equivalent to `int`, as `str` and `int` are the
supertypes of `"A"` and `1` respectively.

## Example
```pyi
from typing import Literal

x: Literal["A", b"B"] | str
```

Use instead:
```pyi
from typing import Literal

x: Literal[b"B"] | str
```

# unannotated-assignment-in-stub (PYI052)

Derived from the **flake8-pyi** linter.

## What it does
Checks for unannotated assignments in stub (`.pyi`) files.

## Why is this bad?
Stub files exist to provide type hints, and are never executed. As such,
all assignments in stub files should be annotated with a type.

# string-or-bytes-too-long (PYI053)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for the use of string and bytes literals longer than 50 characters
in stub (`.pyi`) files.

## Why is this bad?
If a function or variable has a default value where the string or bytes
representation is greater than 50 characters long, it is likely to be an
implementation detail or a constant that varies depending on the system
you're running on.

Although IDEs may find them useful, default values are ignored by type
checkers, the primary consumers of stub files. Replace very long constants
with ellipses (`...`) to simplify the stub.

## Example

```pyi
def foo(arg: str = "51 character stringgggggggggggggggggggggggggggggggg") -> None: ...
```

Use instead:

```pyi
def foo(arg: str = ...) -> None: ...
```

# numeric-literal-too-long (PYI054)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for numeric literals with a string representation longer than ten
characters.

## Why is this bad?
If a function has a default value where the literal representation is
greater than 10 characters, the value is likely to be an implementation
detail or a constant that varies depending on the system you're running on.

Default values like these should generally be omitted from stubs. Use
ellipses (`...`) instead.

## Example

```pyi
def foo(arg: int = 693568516352839939918568862861217771399698285293568) -> None: ...
```

Use instead:

```pyi
def foo(arg: int = ...) -> None: ...
```

# unnecessary-type-union (PYI055)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for the presence of multiple `type`s in a union.

## Why is this bad?
`type[T | S]` has identical semantics to `type[T] | type[S]` in a type
annotation, but is cleaner and more concise.

## Example
```pyi
field: type[int] | type[float] | str
```

Use instead:
```pyi
field: type[int | float] | str
```

## Fix safety
This rule's fix is marked as safe, unless the type annotation contains comments.

Note that while the fix may flatten nested unions into a single top-level union,
the semantics of the annotation will remain unchanged.

# unsupported-method-call-on-all (PYI056)

Derived from the **flake8-pyi** linter.

## What it does
Checks that `append`, `extend` and `remove` methods are not called on
`__all__`.

## Why is this bad?
Different type checkers have varying levels of support for calling these
methods on `__all__`. Instead, use the `+=` operator to add items to
`__all__`, which is known to be supported by all major type checkers.

## Example
```pyi
import sys

__all__ = ["A", "B"]

if sys.version_info >= (3, 10):
    __all__.append("C")

if sys.version_info >= (3, 11):
    __all__.remove("B")
```

Use instead:
```pyi
import sys

__all__ = ["A"]

if sys.version_info < (3, 11):
    __all__ += ["B"]

if sys.version_info >= (3, 10):
    __all__ += ["C"]
```

# byte-string-usage (PYI057)

Derived from the **flake8-pyi** linter.

## What it does
Checks for uses of `typing.ByteString` or `collections.abc.ByteString`.

## Why is this bad?
`ByteString` has been deprecated since Python 3.9 and will be removed in
Python 3.14. The Python documentation recommends using either
`collections.abc.Buffer` (or the `typing_extensions` backport
on Python <3.12) or a union like `bytes | bytearray | memoryview` instead.

## Example
```python
from typing import ByteString
```

Use instead:
```python
from collections.abc import Buffer
```

## References
- [Python documentation: The `ByteString` type](https://docs.python.org/3/library/typing.html#typing.ByteString)

# generator-return-from-iter-method (PYI058)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for simple `__iter__` methods that return `Generator`, and for
simple `__aiter__` methods that return `AsyncGenerator`.

## Why is this bad?
Using `(Async)Iterator` for these methods is simpler and more elegant. More
importantly, it also reflects the fact that the precise kind of iterator
returned from an `__iter__` method is usually an implementation detail that
could change at any time. Type annotations help define a contract for a
function; implementation details should not leak into that contract.

For example:
```python
from collections.abc import AsyncGenerator, Generator
from typing import Any


class CustomIterator:
    def __iter__(self) -> Generator:
        yield from range(42)


class CustomIterator2:
    def __iter__(self) -> Generator[str, Any, None]:
        yield from "abcdefg"
```

Use instead:
```python
from collections.abc import Iterator


class CustomIterator:
    def __iter__(self) -> Iterator:
        yield from range(42)


class CustomIterator2:
    def __iter__(self) -> Iterator[str]:
        yield from "abdefg"
```

## Fix safety
This rule tries hard to avoid false-positive errors, and the rule's fix
should always be safe for `.pyi` stub files. However, there is a slightly
higher chance that a false positive might be emitted by this rule when
applied to runtime Python (`.py` files). As such, the fix is marked as
unsafe for any `__iter__` or `__aiter__` method in a `.py` file that has
more than two statements (including docstrings) in its body.

# generic-not-last-base-class (PYI059)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for classes inheriting from `typing.Generic[]` where `Generic[]` is
not the last base class in the bases tuple.

## Why is this bad?
If `Generic[]` is not the final class in the bases tuple, unexpected
behaviour can occur at runtime (See [this CPython issue][1] for an example).

The rule is also applied to stub files, where it won't cause issues at
runtime. This is because type checkers may not be able to infer an
accurate [MRO] for the class, which could lead to unexpected or
inaccurate results when they analyze your code.

For example:
```python
from collections.abc import Container, Iterable, Sized
from typing import Generic, TypeVar


T = TypeVar("T")
K = TypeVar("K")
V = TypeVar("V")


class LinkedList(Generic[T], Sized):
    def push(self, item: T) -> None:
        self._items.append(item)


class MyMapping(
    Generic[K, V],
    Iterable[tuple[K, V]],
    Container[tuple[K, V]],
):
    ...
```

Use instead:
```python
from collections.abc import Container, Iterable, Sized
from typing import Generic, TypeVar


T = TypeVar("T")
K = TypeVar("K")
V = TypeVar("V")


class LinkedList(Sized, Generic[T]):
    def push(self, item: T) -> None:
        self._items.append(item)


class MyMapping(
    Iterable[tuple[K, V]],
    Container[tuple[K, V]],
    Generic[K, V],
):
    ...
```

## Fix safety

This rule's fix is always unsafe because reordering base classes can change
the behavior of the code by modifying the class's MRO. The fix will also
delete trailing comments after the `Generic` base class in multi-line base
class lists, if any are present.

## Fix availability

This rule's fix is only available when there are no `*args` present in the base class list.

## References
- [`typing.Generic` documentation](https://docs.python.org/3/library/typing.html#typing.Generic)

[1]: https://github.com/python/cpython/issues/106102
[MRO]: https://docs.python.org/3/glossary.html#term-method-resolution-order

# redundant-none-literal (PYI061)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for redundant `Literal[None]` annotations.

## Why is this bad?
While `Literal[None]` is a valid type annotation, it is semantically equivalent to `None`.
Prefer `None` over `Literal[None]` for both consistency and readability.

## Example
```python
from typing import Literal

Literal[None]
Literal[1, 2, 3, "foo", 5, None]
```

Use instead:
```python
from typing import Literal

None
Literal[1, 2, 3, "foo", 5] | None
```

## Fix safety and availability
This rule's fix is marked as safe unless the literal contains comments.

There is currently no fix available when applying the fix would lead to
a `TypeError` from an expression of the form `None | None` or when we
are unable to import the symbol `typing.Optional` and the Python version
is 3.9 or below.

## References
- [Typing documentation: Legal parameters for `Literal` at type check time](https://typing.python.org/en/latest/spec/literal.html#legal-parameters-for-literal-at-type-check-time)

# duplicate-literal-member (PYI062)

Derived from the **flake8-pyi** linter.

Fix is always available.

## What it does
Checks for duplicate members in a `typing.Literal[]` slice.

## Why is this bad?
Duplicate literal members are redundant and should be removed.

## Example
```python
from typing import Literal

foo: Literal["a", "b", "a"]
```

Use instead:
```python
from typing import Literal

foo: Literal["a", "b"]
```

## Fix safety
This rule's fix is marked as safe, unless the type annotation contains comments.

Note that while the fix may flatten nested literals into a single top-level literal,
the semantics of the annotation will remain unchanged.

## References
- [Python documentation: `typing.Literal`](https://docs.python.org/3/library/typing.html#typing.Literal)

# pep484-style-positional-only-parameter (PYI063)

Derived from the **flake8-pyi** linter.

## What it does
Checks for the presence of [PEP 484]-style positional-only parameters.

## Why is this bad?
Historically, [PEP 484] recommended prefixing parameter names with double
underscores (`__`) to indicate to a type checker that they were
positional-only. However, [PEP 570] (introduced in Python 3.8) introduced
dedicated syntax for positional-only arguments. If a forward slash (`/`) is
present in a function signature on Python 3.8+, all parameters prior to the
slash are interpreted as positional-only.

The new syntax should be preferred as it is more widely used, more concise
and more readable. It is also respected by Python at runtime, whereas the
old-style syntax was only understood by type checkers.

## Example

```pyi
def foo(__x: int) -> None: ...
```

Use instead:

```pyi
def foo(x: int, /) -> None: ...
```

## Options
- `target-version`

[PEP 484]: https://peps.python.org/pep-0484/#positional-only-arguments
[PEP 570]: https://peps.python.org/pep-0570

# redundant-final-literal (PYI064)

Derived from the **flake8-pyi** linter.

Fix is sometimes available.

## What it does
Checks for redundant `Final[Literal[...]]` annotations.

## Why is this bad?
All constant variables annotated as `Final` are understood as implicitly
having `Literal` types by a type checker. As such, a `Final[Literal[...]]`
annotation can often be replaced with a bare `Final`, annotation, which
will have the same meaning to the type checker while being more concise and
more readable.

## Example

```pyi
from typing import Final, Literal

x: Final[Literal[42]]
y: Final[Literal[42]] = 42
```

Use instead:
```pyi
from typing import Final, Literal

x: Final = 42
y: Final = 42
```

# bad-version-info-order (PYI066)

Derived from the **flake8-pyi** linter.

## What it does
Checks for code that branches on `sys.version_info` comparisons where
branches corresponding to older Python versions come before branches
corresponding to newer Python versions.

## Why is this bad?
As a convention, branches that correspond to newer Python versions should
come first. This makes it easier to understand the desired behavior, which
typically corresponds to the latest Python versions.

This rule enforces the convention by checking for `if` tests that compare
`sys.version_info` with `<` rather than `>=`.

By default, this rule only applies to stub files.
In [preview], it will also flag this anti-pattern in non-stub files.

## Example

```pyi
import sys

if sys.version_info < (3, 10):
    def read_data(x, *, preserve_order=True): ...

else:
    def read_data(x): ...
```

Use instead:

```pyi
if sys.version_info >= (3, 10):
    def read_data(x): ...

else:
    def read_data(x, *, preserve_order=True): ...
```

[preview]: https://docs.astral.sh/ruff/preview/

# pytest-fixture-incorrect-parentheses-style (PT001)

Derived from the **flake8-pytest-style** linter.

Fix is always available.

## What it does
Checks for argument-free `@pytest.fixture()` decorators with or without
parentheses, depending on the [`lint.flake8-pytest-style.fixture-parentheses`]
setting.

## Why is this bad?
If a `@pytest.fixture()` doesn't take any arguments, the parentheses are
optional.

Either removing those unnecessary parentheses _or_ requiring them for all
fixtures is fine, but it's best to be consistent. The rule defaults to
removing unnecessary parentheses, to match the documentation of the
official pytest projects.

## Example

```python
import pytest


@pytest.fixture()
def my_fixture(): ...
```

Use instead:

```python
import pytest


@pytest.fixture
def my_fixture(): ...
```

## Fix safety
This rule's fix is marked as unsafe if there's comments in the
`pytest.fixture` decorator.

For example, the fix would be marked as unsafe in the following case:
```python
import pytest


@pytest.fixture(
    # comment
    # scope = "module"
)
def my_fixture(): ...
```

## Options
- `lint.flake8-pytest-style.fixture-parentheses`

## References
- [`pytest` documentation: API Reference: Fixtures](https://docs.pytest.org/en/latest/reference/reference.html#fixtures-api)

# pytest-fixture-positional-args (PT002)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for `pytest.fixture` calls with positional arguments.

## Why is this bad?
For clarity and consistency, prefer using keyword arguments to specify
fixture configuration.

## Example

```python
import pytest


@pytest.fixture("module")
def my_fixture(): ...
```

Use instead:

```python
import pytest


@pytest.fixture(scope="module")
def my_fixture(): ...
```

## References
- [`pytest` documentation: `@pytest.fixture` functions](https://docs.pytest.org/en/latest/reference/reference.html#pytest-fixture)

# pytest-extraneous-scope-function (PT003)

Derived from the **flake8-pytest-style** linter.

Fix is always available.

## What it does
Checks for `pytest.fixture` calls with `scope="function"`.

## Why is this bad?
`scope="function"` can be omitted, as it is the default.

## Example

```python
import pytest


@pytest.fixture(scope="function")
def my_fixture(): ...
```

Use instead:

```python
import pytest


@pytest.fixture()
def my_fixture(): ...
```

## References
- [`pytest` documentation: `@pytest.fixture` functions](https://docs.pytest.org/en/latest/reference/reference.html#pytest-fixture)

# pytest-missing-fixture-name-underscore (PT004)

Derived from the **flake8-pytest-style** linter.

## Removal
This rule has been removed because marking fixtures that do not return a value with an underscore
isn't a practice recommended by the pytest community.

## What it does
Checks for `pytest` fixtures that do not return a value, but are not named
with a leading underscore.

## Why is this bad?
By convention, fixtures that don't return a value should be named with a
leading underscore, while fixtures that do return a value should not.

This rule ignores abstract fixtures and generators.

## Example
```python
import pytest


@pytest.fixture()
def patch_something(mocker):
    mocker.patch("module.object")


@pytest.fixture()
def use_context():
    with create_context():
        yield
```

Use instead:
```python
import pytest


@pytest.fixture()
def _patch_something(mocker):
    mocker.patch("module.object")


@pytest.fixture()
def _use_context():
    with create_context():
        yield
```

## References
- [`pytest` documentation: `@pytest.fixture` functions](https://docs.pytest.org/en/latest/reference/reference.html#pytest-fixture)

# pytest-incorrect-fixture-name-underscore (PT005)

Derived from the **flake8-pytest-style** linter.

## Removal
This rule has been removed because marking fixtures that do not return a value with an underscore
isn't a practice recommended by the pytest community.

## What it does
Checks for `pytest` fixtures that return a value, but are named with a
leading underscore.

## Why is this bad?
By convention, fixtures that don't return a value should be named with a
leading underscore, while fixtures that do return a value should not.

This rule ignores abstract fixtures.

## Example
```python
import pytest


@pytest.fixture()
def _some_object():
    return SomeClass()


@pytest.fixture()
def _some_object_with_cleanup():
    obj = SomeClass()
    yield obj
    obj.cleanup()
```

Use instead:
```python
import pytest


@pytest.fixture()
def some_object():
    return SomeClass()


@pytest.fixture()
def some_object_with_cleanup():
    obj = SomeClass()
    yield obj
    obj.cleanup()
```

## References
- [`pytest` documentation: `@pytest.fixture` functions](https://docs.pytest.org/en/latest/reference/reference.html#pytest-fixture)

# pytest-parametrize-names-wrong-type (PT006)

Derived from the **flake8-pytest-style** linter.

Fix is sometimes available.

## What it does
Checks for the type of parameter names passed to `pytest.mark.parametrize`.

## Why is this bad?
The `argnames` argument of `pytest.mark.parametrize` takes a string or
a sequence of strings. For a single parameter, it's preferable to use a
string. For multiple parameters, it's preferable to use the style
configured via the [`lint.flake8-pytest-style.parametrize-names-type`] setting.

## Example

```python
import pytest


# single parameter, always expecting string
@pytest.mark.parametrize(("param",), [1, 2, 3])
def test_foo(param): ...


# multiple parameters, expecting tuple
@pytest.mark.parametrize(["param1", "param2"], [(1, 2), (3, 4)])
def test_bar(param1, param2): ...


# multiple parameters, expecting tuple
@pytest.mark.parametrize("param1,param2", [(1, 2), (3, 4)])
def test_baz(param1, param2): ...
```

Use instead:

```python
import pytest


@pytest.mark.parametrize("param", [1, 2, 3])
def test_foo(param): ...


@pytest.mark.parametrize(("param1", "param2"), [(1, 2), (3, 4)])
def test_bar(param1, param2): ...
```

## Options
- `lint.flake8-pytest-style.parametrize-names-type`

## References
- [`pytest` documentation: How to parametrize fixtures and test functions](https://docs.pytest.org/en/latest/how-to/parametrize.html#pytest-mark-parametrize)

# pytest-parametrize-values-wrong-type (PT007)

Derived from the **flake8-pytest-style** linter.

Fix is sometimes available.

## What it does
Checks for the type of parameter values passed to `pytest.mark.parametrize`.

## Why is this bad?
The `argvalues` argument of `pytest.mark.parametrize` takes an iterator of
parameter values, which can be provided as lists or tuples.

To aid in readability, it's recommended to use a consistent style for the
list of values rows, and, in the case of multiple parameters, for each row
of values.

The style for the list of values rows can be configured via the
[`lint.flake8-pytest-style.parametrize-values-type`] setting, while the
style for each row of values can be configured via the
[`lint.flake8-pytest-style.parametrize-values-row-type`] setting.

For example, [`lint.flake8-pytest-style.parametrize-values-type`] will lead to
the following expectations:

- `tuple`: `@pytest.mark.parametrize("value", ("a", "b", "c"))`
- `list`: `@pytest.mark.parametrize("value", ["a", "b", "c"])`

Similarly, [`lint.flake8-pytest-style.parametrize-values-row-type`] will lead to
the following expectations:

- `tuple`: `@pytest.mark.parametrize(("key", "value"), [("a", "b"), ("c", "d")])`
- `list`: `@pytest.mark.parametrize(("key", "value"), [["a", "b"], ["c", "d"]])`

## Example

```python
import pytest


# expected list, got tuple
@pytest.mark.parametrize("param", (1, 2))
def test_foo(param): ...


# expected top-level list, got tuple
@pytest.mark.parametrize(
    ("param1", "param2"),
    (
        (1, 2),
        (3, 4),
    ),
)
def test_bar(param1, param2): ...


# expected individual rows to be tuples, got lists
@pytest.mark.parametrize(
    ("param1", "param2"),
    [
        [1, 2],
        [3, 4],
    ],
)
def test_baz(param1, param2): ...
```

Use instead:

```python
import pytest


@pytest.mark.parametrize("param", [1, 2, 3])
def test_foo(param): ...


@pytest.mark.parametrize(("param1", "param2"), [(1, 2), (3, 4)])
def test_bar(param1, param2): ...
```

## Options
- `lint.flake8-pytest-style.parametrize-values-type`
- `lint.flake8-pytest-style.parametrize-values-row-type`

## References
- [`pytest` documentation: How to parametrize fixtures and test functions](https://docs.pytest.org/en/latest/how-to/parametrize.html#pytest-mark-parametrize)

# pytest-patch-with-lambda (PT008)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for mocked calls that use a dummy `lambda` function instead of
`return_value`.

## Why is this bad?
When patching calls, an explicit `return_value` better conveys the intent
than a `lambda` function, assuming the `lambda` does not use the arguments
passed to it.

`return_value` is also robust to changes in the patched function's
signature, and enables additional assertions to verify behavior. For
example, `return_value` allows for verification of the number of calls or
the arguments passed to the patched function via `assert_called_once_with`
and related methods.

## Example
```python
def test_foo(mocker):
    mocker.patch("module.target", lambda x, y: 7)
```

Use instead:
```python
def test_foo(mocker):
    mocker.patch("module.target", return_value=7)

    # If the lambda makes use of the arguments, no diagnostic is emitted.
    mocker.patch("module.other_target", lambda x, y: x)
```

## References
- [Python documentation: `unittest.mock.patch`](https://docs.python.org/3/library/unittest.mock.html#unittest.mock.patch)
- [PyPI: `pytest-mock`](https://pypi.org/project/pytest-mock/)

# pytest-unittest-assertion (PT009)

Derived from the **flake8-pytest-style** linter.

Fix is sometimes available.

## What it does
Checks for uses of assertion methods from the `unittest` module.

## Why is this bad?
To make use of `pytest`'s assertion rewriting, a regular `assert` statement
is preferred over `unittest`'s assertion methods.

## Example
```python
import unittest


class TestFoo(unittest.TestCase):
    def test_foo(self):
        self.assertEqual(a, b)
```

Use instead:
```python
import unittest


class TestFoo(unittest.TestCase):
    def test_foo(self):
        assert a == b
```

## References
- [`pytest` documentation: Assertion introspection details](https://docs.pytest.org/en/7.1.x/how-to/assert.html#assertion-introspection-details)

# pytest-raises-without-exception (PT010)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for `pytest.raises` calls without an expected exception.

## Why is this bad?
`pytest.raises` expects to receive an expected exception as its first
argument. If omitted, the `pytest.raises` call will fail at runtime.
The rule will also accept calls without an expected exception but with
`match` and/or `check` keyword arguments, which are also valid after
pytest version 8.4.0.

## Example
```python
import pytest


def test_foo():
    with pytest.raises():
        do_something()
```

Use instead:
```python
import pytest


def test_foo():
    with pytest.raises(SomeException):
        do_something()
```

## References
- [`pytest` documentation: `pytest.raises`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-raises)

# pytest-raises-too-broad (PT011)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for `pytest.raises` calls without a `match` parameter.

## Why is this bad?
`pytest.raises(Error)` will catch any `Error` and may catch errors that are
unrelated to the code under test. To avoid this, `pytest.raises` should be
called with a `match` parameter. The exception names that require a `match`
parameter can be configured via the
[`lint.flake8-pytest-style.raises-require-match-for`] and
[`lint.flake8-pytest-style.raises-extend-require-match-for`] settings.

## Example
```python
import pytest


def test_foo():
    with pytest.raises(ValueError):
        ...

    # empty string is also an error
    with pytest.raises(ValueError, match=""):
        ...
```

Use instead:
```python
import pytest


def test_foo():
    with pytest.raises(ValueError, match="expected message"):
        ...
```

## Options
- `lint.flake8-pytest-style.raises-require-match-for`
- `lint.flake8-pytest-style.raises-extend-require-match-for`

## References
- [`pytest` documentation: `pytest.raises`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-raises)

# pytest-raises-with-multiple-statements (PT012)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for `pytest.raises` context managers with multiple statements.

This rule allows `pytest.raises` bodies to contain `for`
loops with empty bodies (e.g., `pass` or `...` statements), to test
iterator behavior.

## Why is this bad?
When a `pytest.raises` is used as a context manager and contains multiple
statements, it can lead to the test passing when it actually should fail.

A `pytest.raises` context manager should only contain a single simple
statement that raises the expected exception.

## Example
```python
import pytest


def test_foo():
    with pytest.raises(MyError):
        setup()
        func_to_test()  # not executed if `setup()` raises `MyError`
        assert foo()  # not executed
```

Use instead:
```python
import pytest


def test_foo():
    setup()
    with pytest.raises(MyError):
        func_to_test()
    assert foo()
```

## References
- [`pytest` documentation: `pytest.raises`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-raises)

# pytest-incorrect-pytest-import (PT013)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for incorrect import of pytest.

## Why is this bad?
For consistency, `pytest` should be imported as `import pytest` and its members should be
accessed in the form of `pytest.xxx.yyy` for consistency

## Example
```python
import pytest as pt
from pytest import fixture
```

Use instead:
```python
import pytest
```

# pytest-duplicate-parametrize-test-cases (PT014)

Derived from the **flake8-pytest-style** linter.

Fix is sometimes available.

## What it does
Checks for duplicate test cases in `pytest.mark.parametrize`.

## Why is this bad?
Duplicate test cases are redundant and should be removed.

## Example

```python
import pytest


@pytest.mark.parametrize(
    ("param1", "param2"),
    [
        (1, 2),
        (1, 2),
    ],
)
def test_foo(param1, param2): ...
```

Use instead:

```python
import pytest


@pytest.mark.parametrize(
    ("param1", "param2"),
    [
        (1, 2),
    ],
)
def test_foo(param1, param2): ...
```

## Fix safety
This rule's fix is marked as unsafe, as tests that rely on mutable global
state may be affected by removing duplicate test cases.

## References
- [`pytest` documentation: How to parametrize fixtures and test functions](https://docs.pytest.org/en/latest/how-to/parametrize.html#pytest-mark-parametrize)

# pytest-assert-always-false (PT015)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for `assert` statements whose test expression is a falsy value.

## Why is this bad?
`pytest.fail` conveys the intent more clearly than `assert falsy_value`.

## Example
```python
def test_foo():
    if some_condition:
        assert False, "some_condition was True"
```

Use instead:
```python
import pytest


def test_foo():
    if some_condition:
        pytest.fail("some_condition was True")
    ...
```

## References
- [`pytest` documentation: `pytest.fail`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-fail)

# pytest-fail-without-message (PT016)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for `pytest.fail` calls without a message.

## Why is this bad?
`pytest.fail` calls without a message make it harder to understand and debug test failures.

## Example
```python
import pytest


def test_foo():
    pytest.fail()


def test_bar():
    pytest.fail("")


def test_baz():
    pytest.fail(reason="")
```

Use instead:
```python
import pytest


def test_foo():
    pytest.fail("...")


def test_bar():
    pytest.fail(reason="...")
```

## References
- [`pytest` documentation: `pytest.fail`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-fail)

# pytest-assert-in-except (PT017)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for `assert` statements in `except` clauses.

## Why is this bad?
When testing for exceptions, `pytest.raises()` should be used instead of
`assert` statements in `except` clauses, as it's more explicit and
idiomatic. Further, `pytest.raises()` will fail if the exception is _not_
raised, unlike the `assert` statement.

## Example
```python
def test_foo():
    try:
        1 / 0
    except ZeroDivisionError as e:
        assert e.args
```

Use instead:
```python
import pytest


def test_foo():
    with pytest.raises(ZeroDivisionError) as exc_info:
        1 / 0
    assert exc_info.value.args
```

## References
- [`pytest` documentation: `pytest.raises`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-raises)

# pytest-composite-assertion (PT018)

Derived from the **flake8-pytest-style** linter.

Fix is sometimes available.

## What it does
Checks for assertions that combine multiple independent conditions.

## Why is this bad?
Composite assertion statements are harder to debug upon failure, as the
failure message will not indicate which condition failed.

## Example
```python
def test_foo():
    assert something and something_else


def test_bar():
    assert not (something or something_else)
```

Use instead:
```python
def test_foo():
    assert something
    assert something_else


def test_bar():
    assert not something
    assert not something_else
```

# pytest-fixture-param-without-value (PT019)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for `pytest` test functions that should be decorated with
`@pytest.mark.usefixtures`.

## Why is this bad?
In `pytest`, fixture injection is used to activate fixtures in a test
function.

Fixtures can be injected either by passing them as parameters to the test
function, or by using the `@pytest.mark.usefixtures` decorator.

If the test function depends on the fixture being activated, but does not
use it in the test body or otherwise rely on its return value, prefer
the `@pytest.mark.usefixtures` decorator, to make the dependency explicit
and avoid the confusion caused by unused arguments.

## Example

```python
import pytest


@pytest.fixture
def _patch_something(): ...


def test_foo(_patch_something): ...
```

Use instead:

```python
import pytest


@pytest.fixture
def _patch_something(): ...


@pytest.mark.usefixtures("_patch_something")
def test_foo(): ...
```

## References
- [`pytest` documentation: `pytest.mark.usefixtures`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-mark-usefixtures)

# pytest-deprecated-yield-fixture (PT020)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for `pytest.yield_fixture` usage.

## Why is this bad?
`pytest.yield_fixture` is deprecated. `pytest.fixture` should be used instead.

## Example
```python
import pytest


@pytest.yield_fixture()
def my_fixture():
    obj = SomeClass()
    yield obj
    obj.cleanup()
```

Use instead:
```python
import pytest


@pytest.fixture()
def my_fixture():
    obj = SomeClass()
    yield obj
    obj.cleanup()
```

## References
- [`pytest` documentation: `yield_fixture` functions](https://docs.pytest.org/en/latest/yieldfixture.html)

# pytest-fixture-finalizer-callback (PT021)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for unnecessary `request.addfinalizer` usages in `pytest` fixtures.

## Why is this bad?
`pytest` offers two ways to perform cleanup in fixture code. The first is
sequential (via the `yield` statement), the second callback-based (via
`request.addfinalizer`).

The sequential approach is more readable and should be preferred, unless
the fixture uses the "factory as fixture" pattern.

## Example
```python
import pytest


@pytest.fixture()
def my_fixture(request):
    resource = acquire_resource()
    request.addfinalizer(resource.release)
    return resource
```

Use instead:
```python
import pytest


@pytest.fixture()
def my_fixture():
    resource = acquire_resource()
    yield resource
    resource.release()


# "factory-as-fixture" pattern
@pytest.fixture()
def my_factory(request):
    def create_resource(arg):
        resource = acquire_resource(arg)
        request.addfinalizer(resource.release)
        return resource

    return create_resource
```

## References
- [`pytest` documentation: Adding finalizers directly](https://docs.pytest.org/en/latest/how-to/fixtures.html#adding-finalizers-directly)
- [`pytest` documentation: Factories as fixtures](https://docs.pytest.org/en/latest/how-to/fixtures.html#factories-as-fixtures)

# pytest-useless-yield-fixture (PT022)

Derived from the **flake8-pytest-style** linter.

Fix is always available.

## What it does
Checks for unnecessary `yield` expressions in `pytest` fixtures.

## Why is this bad?
In `pytest` fixtures, the `yield` expression should only be used for fixtures
that include teardown code, to clean up the fixture after the test function
has finished executing.

## Example
```python
import pytest


@pytest.fixture()
def my_fixture():
    resource = acquire_resource()
    yield resource
```

Use instead:
```python
import pytest


@pytest.fixture()
def my_fixture_with_teardown():
    resource = acquire_resource()
    yield resource
    resource.release()


@pytest.fixture()
def my_fixture_without_teardown():
    resource = acquire_resource()
    return resource
```

## References
- [`pytest` documentation: Teardown/Cleanup](https://docs.pytest.org/en/latest/how-to/fixtures.html#teardown-cleanup-aka-fixture-finalization)

# pytest-incorrect-mark-parentheses-style (PT023)

Derived from the **flake8-pytest-style** linter.

Fix is always available.

## What it does
Checks for argument-free `@pytest.mark.<marker>()` decorators with or
without parentheses, depending on the [`lint.flake8-pytest-style.mark-parentheses`]
setting.

The rule defaults to removing unnecessary parentheses,
to match the documentation of the official pytest projects.

## Why is this bad?
If a `@pytest.mark.<marker>()` doesn't take any arguments, the parentheses are
optional.

Either removing those unnecessary parentheses _or_ requiring them for all
fixtures is fine, but it's best to be consistent.

## Example

```python
import pytest


@pytest.mark.foo()
def test_something(): ...
```

Use instead:

```python
import pytest


@pytest.mark.foo
def test_something(): ...
```

## Fix safety
This rule's fix is marked as unsafe if there's comments in the
`pytest.mark.<marker>` decorator.
```python
import pytest


@pytest.mark.foo(
    # comment
)
def test_something(): ...
```

## Options
- `lint.flake8-pytest-style.mark-parentheses`

## References
- [`pytest` documentation: Marks](https://docs.pytest.org/en/latest/reference/reference.html#marks)

# pytest-unnecessary-asyncio-mark-on-fixture (PT024)

Derived from the **flake8-pytest-style** linter.

Fix is always available.

## What it does
Checks for unnecessary `@pytest.mark.asyncio` decorators applied to fixtures.

## Why is this bad?
`pytest.mark.asyncio` is unnecessary for fixtures.

## Example
```python
import pytest


@pytest.mark.asyncio()
@pytest.fixture()
async def my_fixture():
    return 0
```

Use instead:
```python
import pytest


@pytest.fixture()
async def my_fixture():
    return 0
```

## References
- [PyPI: `pytest-asyncio`](https://pypi.org/project/pytest-asyncio/)

# pytest-erroneous-use-fixtures-on-fixture (PT025)

Derived from the **flake8-pytest-style** linter.

Fix is always available.

## What it does
Checks for `pytest.mark.usefixtures` decorators applied to `pytest`
fixtures.

## Why is this bad?
The `pytest.mark.usefixtures` decorator has no effect on `pytest` fixtures.

## Example
```python
import pytest


@pytest.fixture()
def a():
    pass


@pytest.mark.usefixtures("a")
@pytest.fixture()
def b(a):
    pass
```

Use instead:
```python
import pytest


@pytest.fixture()
def a():
    pass


@pytest.fixture()
def b(a):
    pass
```

## References
- [`pytest` documentation: `pytest.mark.usefixtures`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-mark-usefixtures)

# pytest-use-fixtures-without-parameters (PT026)

Derived from the **flake8-pytest-style** linter.

Fix is always available.

## What it does
Checks for `@pytest.mark.usefixtures()` decorators that aren't passed any
arguments.

## Why is this bad?
A `@pytest.mark.usefixtures()` decorator that isn't passed any arguments is
useless and should be removed.

## Example

```python
import pytest


@pytest.mark.usefixtures()
def test_something(): ...
```

Use instead:

```python
def test_something(): ...
```

## References
- [`pytest` documentation: `pytest.mark.usefixtures`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-mark-usefixtures)

# pytest-unittest-raises-assertion (PT027)

Derived from the **flake8-pytest-style** linter.

Fix is sometimes available.

## What it does
Checks for uses of exception-related assertion methods from the `unittest`
module.

## Why is this bad?
To enforce the assertion style recommended by `pytest`, `pytest.raises` is
preferred over the exception-related assertion methods in `unittest`, like
`assertRaises`.

## Example
```python
import unittest


class TestFoo(unittest.TestCase):
    def test_foo(self):
        with self.assertRaises(ValueError):
            raise ValueError("foo")
```

Use instead:
```python
import unittest
import pytest


class TestFoo(unittest.TestCase):
    def test_foo(self):
        with pytest.raises(ValueError):
            raise ValueError("foo")
```

## References
- [`pytest` documentation: Assertions about expected exceptions](https://docs.pytest.org/en/latest/how-to/assert.html#assertions-about-expected-exceptions)

# pytest-parameter-with-default-argument (PT028)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for parameters of test functions with default arguments.

## Why is this bad?
Such a parameter will always have the default value during the test
regardless of whether a fixture with the same name is defined.

## Example

```python
def test_foo(a=1): ...
```

Use instead:

```python
def test_foo(a): ...
```

## Fix safety
This rule's fix is marked as unsafe, as modifying a function signature can
change the behavior of the code.

## References
- [Original Pytest issue](https://github.com/pytest-dev/pytest/issues/12693)

# pytest-warns-without-warning (PT029)

Derived from the **flake8-pytest-style** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for `pytest.warns` calls without an expected warning.

## Why is this bad?
`pytest.warns` expects to receive an expected warning as its first
argument. If omitted, the `pytest.warns` call will fail at runtime.

## Example
```python
import pytest


def test_foo():
    with pytest.warns():
        do_something()
```

Use instead:
```python
import pytest


def test_foo():
    with pytest.warns(SomeWarning):
        do_something()
```

## References
- [`pytest` documentation: `pytest.warns`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-warns)

# pytest-warns-too-broad (PT030)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for `pytest.warns` calls without a `match` parameter.

## Why is this bad?
`pytest.warns(Warning)` will catch any `Warning` and may catch warnings that
are unrelated to the code under test. To avoid this, `pytest.warns` should
be called with a `match` parameter. The warning names that require a `match`
parameter can be configured via the
[`lint.flake8-pytest-style.warns-require-match-for`] and
[`lint.flake8-pytest-style.warns-extend-require-match-for`] settings.

## Example
```python
import pytest


def test_foo():
    with pytest.warns(Warning):
        ...

    # empty string is also an error
    with pytest.warns(Warning, match=""):
        ...
```

Use instead:
```python
import pytest


def test_foo():
    with pytest.warns(Warning, match="expected message"):
        ...
```

## Options
- `lint.flake8-pytest-style.warns-require-match-for`
- `lint.flake8-pytest-style.warns-extend-require-match-for`

## References
- [`pytest` documentation: `pytest.warns`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-warns)

# pytest-warns-with-multiple-statements (PT031)

Derived from the **flake8-pytest-style** linter.

## What it does
Checks for `pytest.warns` context managers with multiple statements.

This rule allows `pytest.warns` bodies to contain `for`
loops with empty bodies (e.g., `pass` or `...` statements), to test
iterator behavior.

## Why is this bad?
When `pytest.warns` is used as a context manager and contains multiple
statements, it can lead to the test passing when it should instead fail.

A `pytest.warns` context manager should only contain a single
simple statement that triggers the expected warning.


## Example
```python
import pytest


def test_foo_warns():
    with pytest.warns(Warning):
        setup()  # False negative if setup triggers a warning but foo does not.
        foo()
```

Use instead:
```python
import pytest


def test_foo_warns():
    setup()
    with pytest.warns(Warning):
        foo()
```

## References
- [`pytest` documentation: `pytest.warns`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-warns)

# bad-quotes-inline-string (Q000)

Derived from the **flake8-quotes** linter.

Fix is sometimes available.

## What it does
Checks for inline strings that use single quotes or double quotes,
depending on the value of the [`lint.flake8-quotes.inline-quotes`] option.

## Why is this bad?
Consistency is good. Use either single or double quotes for inline
strings, but be consistent.

## Example
```python
foo = 'bar'
```

Assuming `inline-quotes` is set to `double`, use instead:
```python
foo = "bar"
```

## Options
- `lint.flake8-quotes.inline-quotes`

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces consistent quotes for inline strings, making the rule
redundant.

[formatter]: https://docs.astral.sh/ruff/formatter

# bad-quotes-multiline-string (Q001)

Derived from the **flake8-quotes** linter.

Fix is always available.

## What it does
Checks for multiline strings that use single quotes or double quotes,
depending on the value of the [`lint.flake8-quotes.multiline-quotes`]
setting.

## Why is this bad?
Consistency is good. Use either single or double quotes for multiline
strings, but be consistent.

## Example
```python
foo = '''
bar
'''
```

Assuming `multiline-quotes` is set to `double`, use instead:
```python
foo = """
bar
"""
```

## Options
- `lint.flake8-quotes.multiline-quotes`

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces double quotes for multiline strings, making the rule
redundant.

[formatter]: https://docs.astral.sh/ruff/formatter

# bad-quotes-docstring (Q002)

Derived from the **flake8-quotes** linter.

Fix is sometimes available.

## What it does
Checks for docstrings that use single quotes or double quotes, depending
on the value of the [`lint.flake8-quotes.docstring-quotes`] setting.

## Why is this bad?
Consistency is good. Use either single or double quotes for docstring
strings, but be consistent.

## Example
```python
'''
bar
'''
```

Assuming `docstring-quotes` is set to `double`, use instead:
```python
"""
bar
"""
```

## Options
- `lint.flake8-quotes.docstring-quotes`

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces double quotes for docstrings, making the rule
redundant.

[formatter]: https://docs.astral.sh/ruff/formatter

# avoidable-escaped-quote (Q003)

Derived from the **flake8-quotes** linter.

Fix is always available.

## What it does
Checks for strings that include escaped quotes, and suggests changing
the quote style to avoid the need to escape them.

## Why is this bad?
It's preferable to avoid escaped quotes in strings. By changing the
outer quote style, you can avoid escaping inner quotes.

## Example
```python
foo = "bar\"s"
```

Use instead:
```python
foo = 'bar"s'
```

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter automatically removes unnecessary escapes, making the rule
redundant.

[formatter]: https://docs.astral.sh/ruff/formatter

# unnecessary-escaped-quote (Q004)

Derived from the **flake8-quotes** linter.

Fix is always available.

## What it does
Checks for strings that include unnecessarily escaped quotes.

## Why is this bad?
If a string contains an escaped quote that doesn't match the quote
character used for the string, it's unnecessary and can be removed.

## Example
```python
foo = "bar\'s"
```

Use instead:
```python
foo = "bar's"
```

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter automatically removes unnecessary escapes, making the rule
redundant.

[formatter]: https://docs.astral.sh/ruff/formatter

# unnecessary-paren-on-raise-exception (RSE102)

Derived from the **flake8-raise** linter.

Fix is always available.

## What it does
Checks for unnecessary parentheses on raised exceptions.

## Why is this bad?
If an exception is raised without any arguments, parentheses are not
required, as the `raise` statement accepts either an exception instance
or an exception class (which is then implicitly instantiated).

Removing the parentheses makes the code more concise.

## Known problems
Parentheses can only be omitted if the exception is a class, as opposed to
a function call. This rule isn't always capable of distinguishing between
the two.

For example, if you import a function `module.get_exception` from another
module, and `module.get_exception` returns an exception object, this rule will
incorrectly mark the parentheses in `raise module.get_exception()` as
unnecessary.

## Example
```python
raise TypeError()
```

Use instead:
```python
raise TypeError
```

## Fix Safety
This rule's fix is marked as unsafe if removing the parentheses would also remove comments
or if its unclear whether the expression is a class or a function call.

## References
- [Python documentation: The `raise` statement](https://docs.python.org/3/reference/simple_stmts.html#the-raise-statement)

# unnecessary-return-none (RET501)

Derived from the **flake8-return** linter.

Fix is always available.

## What it does
Checks for the presence of a `return None` statement when `None` is the only
possible return value.

## Why is this bad?
Python implicitly assumes `return None` if an explicit `return` value is
omitted. Therefore, explicitly returning `None` is redundant and should be
avoided when it is the only possible `return` value across all code paths
in a given function.

## Example
```python
def foo(bar):
    if not bar:
        return
    return None
```

Use instead:
```python
def foo(bar):
    if not bar:
        return
    return
```

## Fix safety
This rule's fix is marked as unsafe for cases in which comments would be
dropped from the `return` statement.

# implicit-return-value (RET502)

Derived from the **flake8-return** linter.

Fix is always available.

## What it does
Checks for the presence of a `return` statement with no explicit value,
for functions that return non-`None` values elsewhere.

## Why is this bad?
Including a `return` statement with no explicit value can cause confusion
when other `return` statements in the function return non-`None` values.
Python implicitly assumes return `None` if no other return value is present.
Adding an explicit `return None` can make the code more readable by clarifying
intent.

## Example
```python
def foo(bar):
    if not bar:
        return
    return 1
```

Use instead:
```python
def foo(bar):
    if not bar:
        return None
    return 1
```

# implicit-return (RET503)

Derived from the **flake8-return** linter.

Fix is always available.

## What it does
Checks for missing explicit `return` statements at the end of functions
that can return non-`None` values.

## Why is this bad?
The lack of an explicit `return` statement at the end of a function that
can return non-`None` values can cause confusion. Python implicitly returns
`None` if no other return value is present. Adding an explicit
`return None` can make the code more readable by clarifying intent.

## Example
```python
def foo(bar):
    if not bar:
        return 1
```

Use instead:
```python
def foo(bar):
    if not bar:
        return 1
    return None
```

# unnecessary-assign (RET504)

Derived from the **flake8-return** linter.

Fix is always available.

## What it does
Checks for variable assignments that immediately precede a `return` of the
assigned variable.

## Why is this bad?
The variable assignment is not necessary, as the value can be returned
directly.

## Example
```python
def foo():
    bar = 1
    return bar
```

Use instead:
```python
def foo():
    return 1
```

# superfluous-else-return (RET505)

Derived from the **flake8-return** linter.

Fix is sometimes available.

## What it does
Checks for `else` statements with a `return` statement in the preceding
`if` block.

## Why is this bad?
The `else` statement is not needed as the `return` statement will always
break out of the enclosing function. Removing the `else` will reduce
nesting and make the code more readable.

## Example
```python
def foo(bar, baz):
    if bar:
        return 1
    else:
        return baz
```

Use instead:
```python
def foo(bar, baz):
    if bar:
        return 1
    return baz
```

# superfluous-else-raise (RET506)

Derived from the **flake8-return** linter.

Fix is sometimes available.

## What it does
Checks for `else` statements with a `raise` statement in the preceding `if`
block.

## Why is this bad?
The `else` statement is not needed as the `raise` statement will always
break out of the current scope. Removing the `else` will reduce nesting
and make the code more readable.

## Example
```python
def foo(bar, baz):
    if bar == "Specific Error":
        raise Exception(bar)
    else:
        raise Exception(baz)
```

Use instead:
```python
def foo(bar, baz):
    if bar == "Specific Error":
        raise Exception(bar)
    raise Exception(baz)
```

# superfluous-else-continue (RET507)

Derived from the **flake8-return** linter.

Fix is sometimes available.

## What it does
Checks for `else` statements with a `continue` statement in the preceding
`if` block.

## Why is this bad?
The `else` statement is not needed, as the `continue` statement will always
continue onto the next iteration of a loop. Removing the `else` will reduce
nesting and make the code more readable.

## Example
```python
def foo(bar, baz):
    for i in bar:
        if i < baz:
            continue
        else:
            x = 0
```

Use instead:
```python
def foo(bar, baz):
    for i in bar:
        if i < baz:
            continue
        x = 0
```

# superfluous-else-break (RET508)

Derived from the **flake8-return** linter.

Fix is sometimes available.

## What it does
Checks for `else` statements with a `break` statement in the preceding `if`
block.

## Why is this bad?
The `else` statement is not needed, as the `break` statement will always
break out of the loop. Removing the `else` will reduce nesting and make the
code more readable.

## Example
```python
def foo(bar, baz):
    for i in bar:
        if i > baz:
            break
        else:
            x = 0
```

Use instead:
```python
def foo(bar, baz):
    for i in bar:
        if i > baz:
            break
        x = 0
```

# private-member-access (SLF001)

Derived from the **flake8-self** linter.

## What it does
Checks for accesses on "private" class members.

## Why is this bad?
In Python, the convention is such that class members that are prefixed
with a single underscore, or prefixed but not suffixed with a double
underscore, are considered private and intended for internal use.

Using such "private" members is considered a misuse of the class, as
there are no guarantees that the member will be present in future
versions, that it will have the same type, or that it will have the same
behavior. Instead, use the class's public interface.

This rule ignores accesses on dunder methods (e.g., `__init__`) and sunder
methods (e.g., `_missing_`).

## Example
```python
class Class:
    def __init__(self):
        self._private_member = "..."


var = Class()
print(var._private_member)
```

Use instead:
```python
class Class:
    def __init__(self):
        self.public_member = "..."


var = Class()
print(var.public_member)
```

## Options
- `lint.flake8-self.ignore-names`

## References
- [_What is the meaning of single or double underscores before an object name?_](https://stackoverflow.com/questions/1301346/what-is-the-meaning-of-single-and-double-underscore-before-an-object-name)

# duplicate-isinstance-call (SIM101)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Checks for multiple `isinstance` calls on the same target.

## Why is this bad?
To check if an object is an instance of any one of multiple types
or classes, it is unnecessary to use multiple `isinstance` calls, as
the second argument of the `isinstance` built-in function accepts a
tuple of types and classes.

Using a single `isinstance` call implements the same behavior with more
concise code and clearer intent.

## Example
```python
if isinstance(obj, int) or isinstance(obj, float):
    pass
```

Use instead:
```python
if isinstance(obj, (int, float)):
    pass
```

## References
- [Python documentation: `isinstance`](https://docs.python.org/3/library/functions.html#isinstance)

# collapsible-if (SIM102)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Checks for nested `if` statements that can be collapsed into a single `if`
statement.

## Why is this bad?
Nesting `if` statements leads to deeper indentation and makes code harder to
read. Instead, combine the conditions into a single `if` statement with an
`and` operator.

## Example
```python
if foo:
    if bar:
        ...
```

Use instead:
```python
if foo and bar:
    ...
```

## References
- [Python documentation: The `if` statement](https://docs.python.org/3/reference/compound_stmts.html#the-if-statement)
- [Python documentation: Boolean operations](https://docs.python.org/3/reference/expressions.html#boolean-operations)

# needless-bool (SIM103)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Checks for `if` statements that can be replaced with `bool`.

## Why is this bad?
`if` statements that return `True` for a truthy condition and `False` for
a falsy condition can be replaced with boolean casts.

## Example
Given:
```python
def foo(x: int) -> bool:
    if x > 0:
        return True
    else:
        return False
```

Use instead:
```python
def foo(x: int) -> bool:
    return x > 0
```

Or, given:
```python
def foo(x: int) -> bool:
    if x > 0:
        return True
    return False
```

Use instead:
```python
def foo(x: int) -> bool:
    return x > 0
```

## Fix safety

This fix is marked as unsafe because it may change the programs behavior if the condition does not
return a proper Boolean. While the fix will try to wrap non-boolean values in a call to bool,
custom implementations of comparison functions like `__eq__` can avoid the bool call and still
lead to altered behavior.

## References
- [Python documentation: Truth Value Testing](https://docs.python.org/3/library/stdtypes.html#truth-value-testing)

# suppressible-exception (SIM105)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Checks for `try`-`except`-`pass` blocks that can be replaced with the
`contextlib.suppress` context manager.

## Why is this bad?
Using `contextlib.suppress` is more concise and directly communicates the
intent of the code: to suppress a given exception.

Note that `contextlib.suppress` is slower than using `try`-`except`-`pass`
directly. For performance-critical code, consider retaining the
`try`-`except`-`pass` pattern.

## Example
```python
try:
    1 / 0
except ZeroDivisionError:
    pass
```

Use instead:
```python
import contextlib

with contextlib.suppress(ZeroDivisionError):
    1 / 0
```

## References
- [Python documentation: `contextlib.suppress`](https://docs.python.org/3/library/contextlib.html#contextlib.suppress)
- [Python documentation: `try` statement](https://docs.python.org/3/reference/compound_stmts.html#the-try-statement)
- [a simpler `try`/`except` (and why maybe shouldn't)](https://www.youtube.com/watch?v=MZAJ8qnC7mk)

# return-in-try-except-finally (SIM107)

Derived from the **flake8-simplify** linter.

## What it does
Checks for `return` statements in `try`-`except` and `finally` blocks.

## Why is this bad?
The `return` statement in a `finally` block will always be executed, even if
an exception is raised in the `try` or `except` block. This can lead to
unexpected behavior.

## Example
```python
def squared(n):
    try:
        sqr = n**2
        return sqr
    except Exception:
        return "An exception occurred"
    finally:
        return -1  # Always returns -1.
```

Use instead:
```python
def squared(n):
    try:
        return_value = n**2
    except Exception:
        return_value = "An exception occurred"
    finally:
        return_value = -1
    return return_value
```

## References
- [Python documentation: Defining Clean-up Actions](https://docs.python.org/3/tutorial/errors.html#defining-clean-up-actions)

# if-else-block-instead-of-if-exp (SIM108)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Check for `if`-`else`-blocks that can be replaced with a ternary
or binary operator.

The lint is suppressed if the suggested replacement would exceed
the maximum line length configured in [pycodestyle.max-line-length].

## Why is this bad?
`if`-`else`-blocks that assign a value to a variable in both branches can
be expressed more concisely by using a ternary or binary operator.

## Example

```python
if foo:
    bar = x
else:
    bar = y
```

Use instead:
```python
bar = x if foo else y
```

Or:

```python
if cond:
    z = cond
else:
    z = other_cond
```

Use instead:

```python
z = cond or other_cond
```

## Known issues
This is an opinionated style rule that may not always be to everyone's
taste, especially for code that makes use of complex `if` conditions.
Ternary operators can also make it harder to measure [code coverage]
with tools that use line profiling.

## References
- [Python documentation: Conditional expressions](https://docs.python.org/3/reference/expressions.html#conditional-expressions)

[code coverage]: https://github.com/nedbat/coveragepy/issues/509
[pycodestyle.max-line-length]: https://docs.astral.sh/ruff/settings/#lint_pycodestyle_max-line-length

# compare-with-tuple (SIM109)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for boolean expressions that contain multiple equality comparisons
to the same value.

## Why is this bad?
To check if an object is equal to any one of multiple values, it's more
concise to use the `in` operator with a tuple of values.

## Example
```python
if foo == x or foo == y:
    ...
```

Use instead:
```python
if foo in (x, y):
    ...
```

## References
- [Python documentation: Membership test operations](https://docs.python.org/3/reference/expressions.html#membership-test-operations)

# reimplemented-builtin (SIM110)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Checks for `for` loops that can be replaced with a builtin function, like
`any` or `all`.

## Why is this bad?
Using a builtin function is more concise and readable.

## Example
```python
def foo():
    for item in iterable:
        if predicate(item):
            return True
    return False
```

Use instead:
```python
def foo():
    return any(predicate(item) for item in iterable)
```

## Fix safety

This fix is always marked as unsafe because it might remove comments.

## References
- [Python documentation: `any`](https://docs.python.org/3/library/functions.html#any)
- [Python documentation: `all`](https://docs.python.org/3/library/functions.html#all)

# uncapitalized-environment-variables (SIM112)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Check for environment variables that are not capitalized.

## Why is this bad?
By convention, environment variables should be capitalized.

On Windows, environment variables are case-insensitive and are converted to
uppercase, so using lowercase environment variables can lead to subtle bugs.

## Example
```python
import os

os.environ["foo"]
```

Use instead:
```python
import os

os.environ["FOO"]
```

## Fix safety

This fix is always marked as unsafe because automatically capitalizing environment variable names
can change program behavior in environments where the variable names are case-sensitive, such as most
Unix-like systems.

## References
- [Python documentation: `os.environ`](https://docs.python.org/3/library/os.html#os.environ)

# enumerate-for-loop (SIM113)

Derived from the **flake8-simplify** linter.

## What it does
Checks for `for` loops with explicit loop-index variables that can be replaced
with `enumerate()`.

In [preview], this rule checks for index variables initialized with any integer rather than only
a literal zero.

## Why is this bad?
When iterating over a sequence, it's often desirable to keep track of the
index of each element alongside the element itself. Prefer the `enumerate`
builtin over manually incrementing a counter variable within the loop, as
`enumerate` is more concise and idiomatic.

## Example
```python
fruits = ["apple", "banana", "cherry"]
i = 0
for fruit in fruits:
    print(f"{i + 1}. {fruit}")
    i += 1
```

Use instead:
```python
fruits = ["apple", "banana", "cherry"]
for i, fruit in enumerate(fruits):
    print(f"{i + 1}. {fruit}")
```

## References
- [Python documentation: `enumerate`](https://docs.python.org/3/library/functions.html#enumerate)

[preview]: https://docs.astral.sh/ruff/preview/

# if-with-same-arms (SIM114)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Checks for `if` branches with identical arm bodies.

## Why is this bad?
If multiple arms of an `if` statement have the same body, using `or`
better signals the intent of the statement.

## Example
```python
if x == 1:
    print("Hello")
elif x == 2:
    print("Hello")
```

Use instead:
```python
if x == 1 or x == 2:
    print("Hello")
```

# open-file-with-context-handler (SIM115)

Derived from the **flake8-simplify** linter.

## What it does
Checks for cases where files are opened (e.g., using the builtin `open()` function)
without using a context manager.

## Why is this bad?
If a file is opened without a context manager, it is not guaranteed that
the file will be closed (e.g., if an exception is raised), which can cause
resource leaks. The rule detects a wide array of IO calls where context managers
could be used, such as `open`, `pathlib.Path(...).open()`, `tempfile.TemporaryFile()`
or`tarfile.TarFile(...).gzopen()`.

## Example
```python
file = open("foo.txt")
...
file.close()
```

Use instead:
```python
with open("foo.txt") as file:
    ...
```

## References
- [Python documentation: `open`](https://docs.python.org/3/library/functions.html#open)

# if-else-block-instead-of-dict-lookup (SIM116)

Derived from the **flake8-simplify** linter.

## What it does
Checks for three or more consecutive if-statements with direct returns

## Why is this bad?
These can be simplified by using a dictionary

## Example
```python
def find_phrase(x):
    if x == 1:
        return "Hello"
    elif x == 2:
        return "Goodbye"
    elif x == 3:
        return "Good morning"
    else:
        return "Goodnight"
```

Use instead:
```python
def find_phrase(x):
    phrases = {1: "Hello", 2: "Goodye", 3: "Good morning"}
    return phrases.get(x, "Goodnight")
```

# multiple-with-statements (SIM117)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Checks for the unnecessary nesting of multiple consecutive context
managers.

## Why is this bad?
In Python 3, a single `with` block can include multiple context
managers.

Combining multiple context managers into a single `with` statement
will minimize the indentation depth of the code, making it more
readable.

The following context managers are exempt when used as standalone
statements:

 - `anyio`.{`CancelScope`, `fail_after`, `move_on_after`}
 - `asyncio`.{`timeout`, `timeout_at`}
 - `trio`.{`fail_after`, `fail_at`, `move_on_after`, `move_on_at`}

## Example
```python
with A() as a:
    with B() as b:
        pass
```

Use instead:
```python
with A() as a, B() as b:
    pass
```

## References
- [Python documentation: The `with` statement](https://docs.python.org/3/reference/compound_stmts.html#the-with-statement)

# in-dict-keys (SIM118)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for key-existence checks against `dict.keys()` calls.

## Why is this bad?
When checking for the existence of a key in a given dictionary, using
`key in dict` is more readable and efficient than `key in dict.keys()`,
while having the same semantics.

## Example
```python
key in foo.keys()
```

Use instead:
```python
key in foo
```

## Fix safety
Given `key in obj.keys()`, `obj` _could_ be a dictionary, or it could be
another type that defines a `.keys()` method. In the latter case, removing
the `.keys()` attribute could lead to a runtime error. The fix is marked
as safe when the type of `obj` is known to be a dictionary; otherwise, it
is marked as unsafe.

## References
- [Python documentation: Mapping Types](https://docs.python.org/3/library/stdtypes.html#mapping-types-dict)

# negate-equal-op (SIM201)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for negated `==` operators.

## Why is this bad?
Negated `==` operators are less readable than `!=` operators. When testing
for non-equality, it is more common to use `!=` than `==`.

## Example
```python
not a == b
```

Use instead:
```python
a != b
```

## Fix safety
The fix is marked as unsafe, as it might change the behaviour
if `a` and/or `b` overrides `__eq__`/`__ne__`
in such a manner that they don't return booleans.

## References
- [Python documentation: Comparisons](https://docs.python.org/3/reference/expressions.html#comparisons)

# negate-not-equal-op (SIM202)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for negated `!=` operators.

## Why is this bad?
Negated `!=` operators are less readable than `==` operators, as they avoid a
double negation.

## Example
```python
not a != b
```

Use instead:
```python
a == b
```

## Fix safety
The fix is marked as unsafe, as it might change the behaviour
if `a` and/or `b` overrides `__ne__`/`__eq__`
in such a manner that they don't return booleans.

## References
- [Python documentation: Comparisons](https://docs.python.org/3/reference/expressions.html#comparisons)

# double-negation (SIM208)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for double negations (i.e., multiple `not` operators).

## Why is this bad?
A double negation is redundant and less readable than omitting the `not`
operators entirely.

## Example
```python
not (not a)
```

Use instead:
```python
a
```

## References
- [Python documentation: Comparisons](https://docs.python.org/3/reference/expressions.html#comparisons)

# if-expr-with-true-false (SIM210)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Checks for `if` expressions that can be replaced with `bool()` calls.

## Why is this bad?
`if` expressions that evaluate to `True` for a truthy condition an `False`
for a falsey condition can be replaced with `bool()` calls, which are more
concise and readable.

## Example
```python
True if a else False
```

Use instead:
```python
bool(a)
```

## Fix safety

This fix is marked as unsafe because it may change the programs behavior if the condition does not
return a proper Boolean. While the fix will try to wrap non-boolean values in a call to bool,
custom implementations of comparison functions like `__eq__` can avoid the bool call and still
lead to altered behavior. Moreover, the fix may remove comments.

## References
- [Python documentation: Truth Value Testing](https://docs.python.org/3/library/stdtypes.html#truth-value-testing)

# if-expr-with-false-true (SIM211)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for `if` expressions that can be replaced by negating a given
condition.

## Why is this bad?
`if` expressions that evaluate to `False` for a truthy condition and `True`
for a falsey condition can be replaced with `not` operators, which are more
concise and readable.

## Example
```python
False if a else True
```

Use instead:
```python
not a
```

## References
- [Python documentation: Truth Value Testing](https://docs.python.org/3/library/stdtypes.html#truth-value-testing)

# if-expr-with-twisted-arms (SIM212)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for `if` expressions that check against a negated condition.

## Why is this bad?
`if` expressions that check against a negated condition are more difficult
to read than `if` expressions that check against the condition directly.

## Example
```python
b if not a else a
```

Use instead:
```python
a if a else b
```

## References
- [Python documentation: Truth Value Testing](https://docs.python.org/3/library/stdtypes.html#truth-value-testing)

# expr-and-not-expr (SIM220)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for `and` expressions that include both an expression and its
negation.

## Why is this bad?
An `and` expression that includes both an expression and its negation will
always evaluate to `False`.

## Example
```python
x and not x
```

## References
- [Python documentation: Boolean operations](https://docs.python.org/3/reference/expressions.html#boolean-operations)

# expr-or-not-expr (SIM221)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for `or` expressions that include both an expression and its
negation.

## Why is this bad?
An `or` expression that includes both an expression and its negation will
always evaluate to `True`.

## Example
```python
x or not x
```

## References
- [Python documentation: Boolean operations](https://docs.python.org/3/reference/expressions.html#boolean-operations)

# expr-or-true (SIM222)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for `or` expressions that contain truthy values.

## Why is this bad?
If the expression is used as a condition, it can be replaced in-full with
`True`.

In other cases, the expression can be short-circuited to the first truthy
value.

By using `True` (or the first truthy value), the code is more concise
and easier to understand, since it no longer contains redundant conditions.

## Example
```python
if x or [1] or y:
    pass

a = x or [1] or y
```

Use instead:
```python
if True:
    pass

a = x or [1]
```

# expr-and-false (SIM223)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for `and` expressions that contain falsey values.

## Why is this bad?
If the expression is used as a condition, it can be replaced in-full with
`False`.

In other cases, the expression can be short-circuited to the first falsey
value.

By using `False` (or the first falsey value), the code is more concise
and easier to understand, since it no longer contains redundant conditions.

## Example
```python
if x and [] and y:
    pass

a = x and [] and y
```

Use instead:
```python
if False:
    pass

a = x and []
```

# yoda-conditions (SIM300)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Checks for conditions that position a constant on the left-hand side of the
comparison operator, rather than the right-hand side.

## Why is this bad?
These conditions (sometimes referred to as "Yoda conditions") are less
readable than conditions that place the variable on the left-hand side of
the comparison operator.

In some languages, Yoda conditions are used to prevent accidental
assignment in conditions (i.e., accidental uses of the `=` operator,
instead of the `==` operator). However, Python does not allow assignments
in conditions unless using the `:=` operator, so Yoda conditions provide
no benefit in this regard.

## Example
```python
if "Foo" == foo:
    ...
```

Use instead:
```python
if foo == "Foo":
    ...
```

## References
- [Python documentation: Comparisons](https://docs.python.org/3/reference/expressions.html#comparisons)
- [Python documentation: Assignment statements](https://docs.python.org/3/reference/simple_stmts.html#assignment-statements)

# if-else-block-instead-of-dict-get (SIM401)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Checks for `if` statements that can be replaced with `dict.get` calls.

## Why is this bad?
`dict.get()` calls can be used to replace `if` statements that assign a
value to a variable in both branches, falling back to a default value if
the key is not found. When possible, using `dict.get` is more concise and
more idiomatic.

Under [preview mode](https://docs.astral.sh/ruff/preview), this rule will
also suggest replacing `if`-`else` _expressions_ with `dict.get` calls.

## Example
```python
foo = {}
if "bar" in foo:
    value = foo["bar"]
else:
    value = 0
```

Use instead:
```python
foo = {}
value = foo.get("bar", 0)
```

If preview mode is enabled:
```python
value = foo["bar"] if "bar" in foo else 0
```

Use instead:
```python
value = foo.get("bar", 0)
```

## References
- [Python documentation: Mapping Types](https://docs.python.org/3/library/stdtypes.html#mapping-types-dict)

# split-static-string (SIM905)

Derived from the **flake8-simplify** linter.

Fix is sometimes available.

## What it does
Checks for static `str.split` calls that can be replaced with list literals.

## Why is this bad?
List literals are more readable and do not require the overhead of calling `str.split`.

## Example
```python
"a,b,c,d".split(",")
```

Use instead:
```python
["a", "b", "c", "d"]
```

## Fix safety
This rule's fix is marked as unsafe for implicit string concatenations with comments interleaved
between segments, as comments may be removed.

For example, the fix would be marked as unsafe in the following case:
```python
(
    "a"  # comment
    ","  # comment
    "b"  # comment
).split(",")
```

as this is converted to `["a", "b"]` without any of the comments.

## References
- [Python documentation: `str.split`](https://docs.python.org/3/library/stdtypes.html#str.split)

# dict-get-with-none-default (SIM910)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for `dict.get()` calls that pass `None` as the default value.

## Why is this bad?
`None` is the default value for `dict.get()`, so it is redundant to pass it
explicitly.

## Example
```python
ages = {"Tom": 23, "Maria": 23, "Dog": 11}
age = ages.get("Cat", None)
```

Use instead:
```python
ages = {"Tom": 23, "Maria": 23, "Dog": 11}
age = ages.get("Cat")
```

## References
- [Python documentation: `dict.get`](https://docs.python.org/3/library/stdtypes.html#dict.get)

# zip-dict-keys-and-values (SIM911)

Derived from the **flake8-simplify** linter.

Fix is always available.

## What it does
Checks for use of `zip()` to iterate over keys and values of a dictionary at once.

## Why is this bad?
The `dict` type provides an `.items()` method which is faster and more readable.

## Example
```python
flag_stars = {"USA": 50, "Slovenia": 3, "Panama": 2, "Australia": 6}

for country, stars in zip(flag_stars.keys(), flag_stars.values()):
    print(f"{country}'s flag has {stars} stars.")
```

Use instead:
```python
flag_stars = {"USA": 50, "Slovenia": 3, "Panama": 2, "Australia": 6}

for country, stars in flag_stars.items():
    print(f"{country}'s flag has {stars} stars.")
```

## References
- [Python documentation: `dict.items`](https://docs.python.org/3/library/stdtypes.html#dict.items)

# no-slots-in-str-subclass (SLOT000)

Derived from the **flake8-slots** linter.

## What it does
Checks for subclasses of `str` that lack a `__slots__` definition.

## Why is this bad?
In Python, the `__slots__` attribute allows you to explicitly define the
attributes (instance variables) that a class can have. By default, Python
uses a dictionary to store an object's attributes, which incurs some memory
overhead. However, when `__slots__` is defined, Python uses a more compact
internal structure to store the object's attributes, resulting in memory
savings.

Subclasses of `str` inherit all the attributes and methods of the built-in
`str` class. Since strings are typically immutable, they don't require
additional attributes beyond what the `str` class provides. Defining
`__slots__` for subclasses of `str` prevents the creation of a dictionary
for each instance, reducing memory consumption.

## Example
```python
class Foo(str):
    pass
```

Use instead:
```python
class Foo(str):
    __slots__ = ()
```

## References
- [Python documentation: `__slots__`](https://docs.python.org/3/reference/datamodel.html#slots)

# no-slots-in-tuple-subclass (SLOT001)

Derived from the **flake8-slots** linter.

## What it does
Checks for subclasses of `tuple` that lack a `__slots__` definition.

## Why is this bad?
In Python, the `__slots__` attribute allows you to explicitly define the
attributes (instance variables) that a class can have. By default, Python
uses a dictionary to store an object's attributes, which incurs some memory
overhead. However, when `__slots__` is defined, Python uses a more compact
internal structure to store the object's attributes, resulting in memory
savings.

Subclasses of `tuple` inherit all the attributes and methods of the
built-in `tuple` class. Since tuples are typically immutable, they don't
require additional attributes beyond what the `tuple` class provides.
Defining `__slots__` for subclasses of `tuple` prevents the creation of a
dictionary for each instance, reducing memory consumption.

## Example
```python
class Foo(tuple):
    pass
```

Use instead:
```python
class Foo(tuple):
    __slots__ = ()
```

## References
- [Python documentation: `__slots__`](https://docs.python.org/3/reference/datamodel.html#slots)

# no-slots-in-namedtuple-subclass (SLOT002)

Derived from the **flake8-slots** linter.

## What it does
Checks for subclasses of `collections.namedtuple` or `typing.NamedTuple`
that lack a `__slots__` definition.

## Why is this bad?
In Python, the `__slots__` attribute allows you to explicitly define the
attributes (instance variables) that a class can have. By default, Python
uses a dictionary to store an object's attributes, which incurs some memory
overhead. However, when `__slots__` is defined, Python uses a more compact
internal structure to store the object's attributes, resulting in memory
savings.

Subclasses of `namedtuple` inherit all the attributes and methods of the
built-in `namedtuple` class. Since tuples are typically immutable, they
don't require additional attributes beyond what the `namedtuple` class
provides. Defining `__slots__` for subclasses of `namedtuple` prevents the
creation of a dictionary for each instance, reducing memory consumption.

## Example
```python
from collections import namedtuple


class Foo(namedtuple("foo", ["str", "int"])):
    pass
```

Use instead:
```python
from collections import namedtuple


class Foo(namedtuple("foo", ["str", "int"])):
    __slots__ = ()
```

## References
- [Python documentation: `__slots__`](https://docs.python.org/3/reference/datamodel.html#slots)

# banned-api (TID251)

Derived from the **flake8-tidy-imports** linter.

## What it does
Checks for banned imports.

## Why is this bad?
Projects may want to ensure that specific modules or module members are
not imported or accessed.

Security or other company policies may be a reason to impose
restrictions on importing external Python libraries. In some cases,
projects may adopt conventions around the use of certain modules or
module members that are not enforceable by the language itself.

This rule enforces certain import conventions project-wide automatically.

## Options
- `lint.flake8-tidy-imports.banned-api`

# relative-imports (TID252)

Derived from the **flake8-tidy-imports** linter.

Fix is sometimes available.

## What it does
Checks for relative imports.

## Why is this bad?
Absolute imports, or relative imports from siblings, are recommended by [PEP 8]:

> Absolute imports are recommended, as they are usually more readable and tend to be better behaved...
> ```python
> import mypkg.sibling
> from mypkg import sibling
> from mypkg.sibling import example
> ```
> However, explicit relative imports are an acceptable alternative to absolute imports,
> especially when dealing with complex package layouts where using absolute imports would be
> unnecessarily verbose:
> ```python
> from . import sibling
> from .sibling import example
> ```

## Example
```python
from .. import foo
```

Use instead:
```python
from mypkg import foo
```

## Options
- `lint.flake8-tidy-imports.ban-relative-imports`

[PEP 8]: https://peps.python.org/pep-0008/#imports

# banned-module-level-imports (TID253)

Derived from the **flake8-tidy-imports** linter.

## What it does
Checks for module-level imports that should instead be imported lazily
(e.g., within a function definition, or an `if TYPE_CHECKING:` block, or
some other nested context).

## Why is this bad?
Some modules are expensive to import. For example, importing `torch` or
`tensorflow` can introduce a noticeable delay in the startup time of a
Python program.

In such cases, you may want to enforce that the module is imported lazily
as needed, rather than at the top of the file. This could involve inlining
the import into the function that uses it, rather than importing it
unconditionally, to ensure that the module is only imported when necessary.

## Example
```python
import tensorflow as tf


def show_version():
    print(tf.__version__)
```

Use instead:
```python
def show_version():
    import tensorflow as tf

    print(tf.__version__)
```

## Options
- `lint.flake8-tidy-imports.banned-module-level-imports`

# invalid-todo-tag (TD001)

Derived from the **flake8-todos** linter.

## What it does
Checks that a TODO comment is labelled with "TODO".

## Why is this bad?
Ambiguous tags reduce code visibility and can lead to dangling TODOs.
For example, if a comment is tagged with "FIXME" rather than "TODO", it may
be overlooked by future readers.

Note that this rule will only flag "FIXME" and "XXX" tags as incorrect.

## Example
```python
# FIXME(ruff): this should get fixed!
```

Use instead:
```python
# TODO(ruff): this is now fixed!
```

# missing-todo-author (TD002)

Derived from the **flake8-todos** linter.

## What it does
Checks that a TODO comment includes an author.

## Why is this bad?
Including an author on a TODO provides future readers with context around
the issue. While the TODO author is not always considered responsible for
fixing the issue, they are typically the individual with the most context.

## Example
```python
# TODO: should assign an author here
```

Use instead
```python
# TODO(charlie): now an author is assigned
```

# missing-todo-link (TD003)

Derived from the **flake8-todos** linter.

## What it does
Checks that a TODO comment is associated with a link to a relevant issue
or ticket.

## Why is this bad?
Including an issue link near a TODO makes it easier for resolvers
to get context around the issue.

## Example
```python
# TODO: this link has no issue
```

Use one of these instead:
```python
# TODO(charlie): this comment has an issue link
# https://github.com/astral-sh/ruff/issues/3870

# TODO(charlie): this comment has a 3-digit issue code
# 003

# TODO(charlie): https://github.com/astral-sh/ruff/issues/3870
# this comment has an issue link

# TODO(charlie): #003 this comment has a 3-digit issue code
# with leading character `#`

# TODO(charlie): this comment has an issue code (matches the regex `[A-Z]+\-?\d+`)
# SIXCHR-003
```

# missing-todo-colon (TD004)

Derived from the **flake8-todos** linter.

## What it does
Checks that a "TODO" tag is followed by a colon.

## Why is this bad?
"TODO" tags are typically followed by a parenthesized author name, a colon,
a space, and a description of the issue, in that order.

Deviating from this pattern can lead to inconsistent and non-idiomatic
comments.

## Example
```python
# TODO(charlie) fix this colon
```

Used instead:
```python
# TODO(charlie): colon fixed
```

# missing-todo-description (TD005)

Derived from the **flake8-todos** linter.

## What it does
Checks that a "TODO" tag contains a description of the issue following the
tag itself.

## Why is this bad?
TODO comments should include a description of the issue to provide context
for future readers.

## Example
```python
# TODO(charlie)
```

Use instead:
```python
# TODO(charlie): fix some issue
```

# invalid-todo-capitalization (TD006)

Derived from the **flake8-todos** linter.

Fix is always available.

## What it does
Checks that a "TODO" tag is properly capitalized (i.e., that the tag is
uppercase).

## Why is this bad?
Capitalizing the "TODO" in a TODO comment is a convention that makes it
easier for future readers to identify TODOs.

## Example
```python
# todo(charlie): capitalize this
```

Use instead:
```python
# TODO(charlie): this is capitalized
```

# missing-space-after-todo-colon (TD007)

Derived from the **flake8-todos** linter.

## What it does
Checks that the colon after a "TODO" tag is followed by a space.

## Why is this bad?
"TODO" tags are typically followed by a parenthesized author name, a colon,
a space, and a description of the issue, in that order.

Deviating from this pattern can lead to inconsistent and non-idiomatic
comments.

## Example
```python
# TODO(charlie):fix this
```

Use instead:
```python
# TODO(charlie): fix this
```

# typing-only-first-party-import (TC001)

Derived from the **flake8-type-checking** linter.

Fix is sometimes available.

## What it does
Checks for first-party imports that are only used for type annotations, but
aren't defined in a type-checking block.

## Why is this bad?
Unused imports add a performance overhead at runtime, and risk creating
import cycles. If an import is _only_ used in typing-only contexts, it can
instead be imported conditionally under an `if TYPE_CHECKING:` block to
minimize runtime overhead.

If [`lint.flake8-type-checking.quote-annotations`] is set to `true`,
annotations will be wrapped in quotes if doing so would enable the
corresponding import to be moved into an `if TYPE_CHECKING:` block.

If a class _requires_ that type annotations be available at runtime (as is
the case for Pydantic, SQLAlchemy, and other libraries), consider using
the [`lint.flake8-type-checking.runtime-evaluated-base-classes`] and
[`lint.flake8-type-checking.runtime-evaluated-decorators`] settings to mark them
as such.

If [`lint.future-annotations`] is set to `true`, `from __future__ import
annotations` will be added if doing so would enable an import to be
moved into an `if TYPE_CHECKING:` block. This takes precedence over the
[`lint.flake8-type-checking.quote-annotations`] setting described above if
both settings are enabled.


## Example
```python
from __future__ import annotations

from . import local_module


def func(sized: local_module.Container) -> int:
    return len(sized)
```

Use instead:
```python
from __future__ import annotations

from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from . import local_module


def func(sized: local_module.Container) -> int:
    return len(sized)
```

## Options
- `lint.flake8-type-checking.quote-annotations`
- `lint.flake8-type-checking.runtime-evaluated-base-classes`
- `lint.flake8-type-checking.runtime-evaluated-decorators`
- `lint.flake8-type-checking.strict`
- `lint.typing-modules`
- `lint.future-annotations`

## References
- [PEP 563: Runtime annotation resolution and `TYPE_CHECKING`](https://peps.python.org/pep-0563/#runtime-annotation-resolution-and-type-checking)

# typing-only-third-party-import (TC002)

Derived from the **flake8-type-checking** linter.

Fix is sometimes available.

## What it does
Checks for third-party imports that are only used for type annotations, but
aren't defined in a type-checking block.

## Why is this bad?
Unused imports add a performance overhead at runtime, and risk creating
import cycles. If an import is _only_ used in typing-only contexts, it can
instead be imported conditionally under an `if TYPE_CHECKING:` block to
minimize runtime overhead.

If [`lint.flake8-type-checking.quote-annotations`] is set to `true`,
annotations will be wrapped in quotes if doing so would enable the
corresponding import to be moved into an `if TYPE_CHECKING:` block.

If a class _requires_ that type annotations be available at runtime (as is
the case for Pydantic, SQLAlchemy, and other libraries), consider using
the [`lint.flake8-type-checking.runtime-evaluated-base-classes`] and
[`lint.flake8-type-checking.runtime-evaluated-decorators`] settings to mark them
as such.

If [`lint.future-annotations`] is set to `true`, `from __future__ import
annotations` will be added if doing so would enable an import to be
moved into an `if TYPE_CHECKING:` block. This takes precedence over the
[`lint.flake8-type-checking.quote-annotations`] setting described above if
both settings are enabled.

## Example
```python
from __future__ import annotations

import pandas as pd


def func(df: pd.DataFrame) -> int:
    return len(df)
```

Use instead:
```python
from __future__ import annotations

from typing import TYPE_CHECKING

if TYPE_CHECKING:
    import pandas as pd


def func(df: pd.DataFrame) -> int:
    return len(df)
```

## Options
- `lint.flake8-type-checking.quote-annotations`
- `lint.flake8-type-checking.runtime-evaluated-base-classes`
- `lint.flake8-type-checking.runtime-evaluated-decorators`
- `lint.flake8-type-checking.strict`
- `lint.typing-modules`
- `lint.future-annotations`

## References
- [PEP 563: Runtime annotation resolution and `TYPE_CHECKING`](https://peps.python.org/pep-0563/#runtime-annotation-resolution-and-type-checking)

# typing-only-standard-library-import (TC003)

Derived from the **flake8-type-checking** linter.

Fix is sometimes available.

## What it does
Checks for standard library imports that are only used for type
annotations, but aren't defined in a type-checking block.

## Why is this bad?
Unused imports add a performance overhead at runtime, and risk creating
import cycles. If an import is _only_ used in typing-only contexts, it can
instead be imported conditionally under an `if TYPE_CHECKING:` block to
minimize runtime overhead.

If [`lint.flake8-type-checking.quote-annotations`] is set to `true`,
annotations will be wrapped in quotes if doing so would enable the
corresponding import to be moved into an `if TYPE_CHECKING:` block.

If a class _requires_ that type annotations be available at runtime (as is
the case for Pydantic, SQLAlchemy, and other libraries), consider using
the [`lint.flake8-type-checking.runtime-evaluated-base-classes`] and
[`lint.flake8-type-checking.runtime-evaluated-decorators`] settings to mark them
as such.

If [`lint.future-annotations`] is set to `true`, `from __future__ import
annotations` will be added if doing so would enable an import to be
moved into an `if TYPE_CHECKING:` block. This takes precedence over the
[`lint.flake8-type-checking.quote-annotations`] setting described above if
both settings are enabled.

## Example
```python
from __future__ import annotations

from pathlib import Path


def func(path: Path) -> str:
    return str(path)
```

Use instead:
```python
from __future__ import annotations

from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from pathlib import Path


def func(path: Path) -> str:
    return str(path)
```

## Options
- `lint.flake8-type-checking.quote-annotations`
- `lint.flake8-type-checking.runtime-evaluated-base-classes`
- `lint.flake8-type-checking.runtime-evaluated-decorators`
- `lint.flake8-type-checking.strict`
- `lint.typing-modules`
- `lint.future-annotations`

## References
- [PEP 563: Runtime annotation resolution and `TYPE_CHECKING`](https://peps.python.org/pep-0563/#runtime-annotation-resolution-and-type-checking)

# runtime-import-in-type-checking-block (TC004)

Derived from the **flake8-type-checking** linter.

Fix is sometimes available.

## What it does
Checks for imports that are required at runtime but are only defined in
type-checking blocks.

## Why is this bad?
The type-checking block is not executed at runtime, so if the only definition
of a symbol is in a type-checking block, it will not be available at runtime.

If [`lint.flake8-type-checking.quote-annotations`] is set to `true`,
annotations will be wrapped in quotes if doing so would enable the
corresponding import to remain in the type-checking block.

## Example
```python
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    import foo


def bar() -> None:
    foo.bar()  # raises NameError: name 'foo' is not defined
```

Use instead:
```python
import foo


def bar() -> None:
    foo.bar()
```

## Options
- `lint.flake8-type-checking.quote-annotations`

## References
- [PEP 563: Runtime annotation resolution and `TYPE_CHECKING`](https://peps.python.org/pep-0563/#runtime-annotation-resolution-and-type-checking)

# empty-type-checking-block (TC005)

Derived from the **flake8-type-checking** linter.

Fix is always available.

## What it does
Checks for an empty type-checking block.

## Why is this bad?
The type-checking block does not do anything and should be removed to avoid
confusion.

## Example
```python
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    pass

print("Hello, world!")
```

Use instead:
```python
print("Hello, world!")
```

## References
- [PEP 563: Runtime annotation resolution and `TYPE_CHECKING`](https://peps.python.org/pep-0563/#runtime-annotation-resolution-and-type-checking)

# runtime-cast-value (TC006)

Derived from the **flake8-type-checking** linter.

Fix is always available.

## What it does
Checks for unquoted type expressions in `typing.cast()` calls.

## Why is this bad?
This rule helps enforce a consistent style across your codebase.

It's often necessary to quote the first argument passed to `cast()`,
as type expressions can involve forward references, or references
to symbols which are only imported in `typing.TYPE_CHECKING` blocks.
This can lead to a visual inconsistency across different `cast()` calls,
where some type expressions are quoted but others are not. By enabling
this rule, you ensure that all type expressions passed to `cast()` are
quoted, enforcing stylistic consistency across all of your `cast()` calls.

In some cases where `cast()` is used in a hot loop, this rule may also
help avoid overhead from repeatedly evaluating complex type expressions at
runtime.

## Example
```python
from typing import cast

x = cast(dict[str, int], foo)
```

Use instead:
```python
from typing import cast

x = cast("dict[str, int]", foo)
```

## Fix safety
This fix is safe as long as the type expression doesn't span multiple
lines and includes comments on any of the lines apart from the last one.

# unquoted-type-alias (TC007)

Derived from the **flake8-type-checking** linter.

Fix is sometimes available.

## What it does
Checks if [PEP 613] explicit type aliases contain references to
symbols that are not available at runtime.

## Why is this bad?
Referencing type-checking only symbols results in a `NameError` at runtime.

## Example
```python
from typing import TYPE_CHECKING, TypeAlias

if TYPE_CHECKING:
    from foo import Foo
OptFoo: TypeAlias = Foo | None
```

Use instead:
```python
from typing import TYPE_CHECKING, TypeAlias

if TYPE_CHECKING:
    from foo import Foo
OptFoo: TypeAlias = "Foo | None"
```

## Fix safety
This rule's fix is currently always marked as unsafe, since runtime
typing libraries may try to access/resolve the type alias in a way
that we can't statically determine during analysis and relies on the
type alias not containing any forward references.

## References
- [PEP 613  Explicit Type Aliases](https://peps.python.org/pep-0613/)

[PEP 613]: https://peps.python.org/pep-0613/

# quoted-type-alias (TC008)

Derived from the **flake8-type-checking** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for unnecessary quotes in [PEP 613] explicit type aliases
and [PEP 695] type statements.

## Why is this bad?
Unnecessary string forward references can lead to additional overhead
in runtime libraries making use of type hints. They can also have bad
interactions with other runtime uses like [PEP 604] type unions.

PEP-613 type aliases are only flagged by the rule if Ruff can have high
confidence that the quotes are unnecessary. Specifically, any PEP-613
type alias where the type expression on the right-hand side contains
subscripts or attribute accesses will not be flagged. This is because
type aliases can reference types that are, for example, generic in stub
files but not at runtime. That can mean that a type checker expects the
referenced type to be subscripted with type arguments despite the fact
that doing so would fail at runtime if the type alias value was not
quoted. Similarly, a type alias might need to reference a module-level
attribute that exists in a stub file but not at runtime, meaning that
the type alias value would need to be quoted to avoid a runtime error.

## Example
Given:
```python
from typing import TypeAlias

OptInt: TypeAlias = "int | None"
```

Use instead:
```python
from typing import TypeAlias

OptInt: TypeAlias = int | None
```

Given:
```python
type OptInt = "int | None"
```

Use instead:
```python
type OptInt = int | None
```

## Fix safety
This rule's fix is marked as safe, unless the type annotation contains comments.

## See also
This rule only applies to type aliases in non-stub files. For removing quotes in other
contexts or in stub files, see:

- [`quoted-annotation-in-stub`][PYI020]: A rule that
  removes all quoted annotations from stub files
- [`quoted-annotation`][UP037]: A rule that removes unnecessary quotes
  from *annotations* in runtime files.

## References
- [PEP 613  Explicit Type Aliases](https://peps.python.org/pep-0613/)
- [PEP 695: Generic Type Alias](https://peps.python.org/pep-0695/#generic-type-alias)
- [PEP 604  Allow writing union types as `X | Y`](https://peps.python.org/pep-0604/)

[PEP 604]: https://peps.python.org/pep-0604/
[PEP 613]: https://peps.python.org/pep-0613/
[PEP 695]: https://peps.python.org/pep-0695/#generic-type-alias
[PYI020]: https://docs.astral.sh/ruff/rules/quoted-annotation-in-stub/
[UP037]: https://docs.astral.sh/ruff/rules/quoted-annotation/

# runtime-string-union (TC010)

Derived from the **flake8-type-checking** linter.

## What it does
Checks for the presence of string literals in `X | Y`-style union types.

## Why is this bad?
[PEP 604] introduced a new syntax for union type annotations based on the
`|` operator.

While Python's type annotations can typically be wrapped in strings to
avoid runtime evaluation, the use of a string member within an `X | Y`-style
union type will cause a runtime error.

Instead, remove the quotes, wrap the _entire_ union in quotes, or use
`from __future__ import annotations` to disable runtime evaluation of
annotations entirely.

## Example
```python
var: "Foo" | None


class Foo: ...
```

Use instead:
```python
from __future__ import annotations

var: Foo | None


class Foo: ...
```

Or, extend the quotes to include the entire union:
```python
var: "Foo | None"


class Foo: ...
```

## References
- [PEP 563 - Postponed Evaluation of Annotations](https://peps.python.org/pep-0563/)
- [PEP 604  Allow writing union types as `X | Y`](https://peps.python.org/pep-0604/)

[PEP 604]: https://peps.python.org/pep-0604/

# unused-function-argument (ARG001)

Derived from the **flake8-unused-arguments** linter.

## What it does
Checks for the presence of unused arguments in function definitions.

## Why is this bad?
An argument that is defined but not used is likely a mistake, and should
be removed to avoid confusion.

If a variable is intentionally defined-but-not-used, it should be
prefixed with an underscore, or some other value that adheres to the
[`lint.dummy-variable-rgx`] pattern.

## Example
```python
def foo(bar, baz):
    return bar * 2
```

Use instead:
```python
def foo(bar):
    return bar * 2
```

## Options
- `lint.dummy-variable-rgx`

# unused-method-argument (ARG002)

Derived from the **flake8-unused-arguments** linter.

## What it does
Checks for the presence of unused arguments in instance method definitions.

## Why is this bad?
An argument that is defined but not used is likely a mistake, and should
be removed to avoid confusion.

If a variable is intentionally defined-but-not-used, it should be
prefixed with an underscore, or some other value that adheres to the
[`lint.dummy-variable-rgx`] pattern.

This rule exempts methods decorated with [`@typing.override`][override].
Removing a parameter from a subclass method (or changing a parameter's
name) may cause type checkers to complain about a violation of the Liskov
Substitution Principle if it means that the method now incompatibly
overrides a method defined on a superclass. Explicitly decorating an
overriding method with `@override` signals to Ruff that the method is
intended to override a superclass method and that a type checker will
enforce that it does so; Ruff therefore knows that it should not enforce
rules about unused arguments on such methods.

## Example
```python
class Class:
    def foo(self, arg1, arg2):
        print(arg1)
```

Use instead:
```python
class Class:
    def foo(self, arg1):
        print(arg1)
```

## Options
- `lint.dummy-variable-rgx`

[override]: https://docs.python.org/3/library/typing.html#typing.override

# unused-class-method-argument (ARG003)

Derived from the **flake8-unused-arguments** linter.

## What it does
Checks for the presence of unused arguments in class method definitions.

## Why is this bad?
An argument that is defined but not used is likely a mistake, and should
be removed to avoid confusion.

If a variable is intentionally defined-but-not-used, it should be
prefixed with an underscore, or some other value that adheres to the
[`lint.dummy-variable-rgx`] pattern.

This rule exempts methods decorated with [`@typing.override`][override].
Removing a parameter from a subclass method (or changing a parameter's
name) may cause type checkers to complain about a violation of the Liskov
Substitution Principle if it means that the method now incompatibly
overrides a method defined on a superclass. Explicitly decorating an
overriding method with `@override` signals to Ruff that the method is
intended to override a superclass method and that a type checker will
enforce that it does so; Ruff therefore knows that it should not enforce
rules about unused arguments on such methods.

## Example
```python
class Class:
    @classmethod
    def foo(cls, arg1, arg2):
        print(arg1)
```

Use instead:
```python
class Class:
    @classmethod
    def foo(cls, arg1):
        print(arg1)
```

## Options
- `lint.dummy-variable-rgx`

[override]: https://docs.python.org/3/library/typing.html#typing.override

# unused-static-method-argument (ARG004)

Derived from the **flake8-unused-arguments** linter.

## What it does
Checks for the presence of unused arguments in static method definitions.

## Why is this bad?
An argument that is defined but not used is likely a mistake, and should
be removed to avoid confusion.

If a variable is intentionally defined-but-not-used, it should be
prefixed with an underscore, or some other value that adheres to the
[`lint.dummy-variable-rgx`] pattern.

This rule exempts methods decorated with [`@typing.override`][override].
Removing a parameter from a subclass method (or changing a parameter's
name) may cause type checkers to complain about a violation of the Liskov
Substitution Principle if it means that the method now incompatibly
overrides a method defined on a superclass. Explicitly decorating an
overriding method with `@override` signals to Ruff that the method is
intended to override a superclass method, and that a type checker will
enforce that it does so; Ruff therefore knows that it should not enforce
rules about unused arguments on such methods.

## Example
```python
class Class:
    @staticmethod
    def foo(arg1, arg2):
        print(arg1)
```

Use instead:
```python
class Class:
    @staticmethod
    def foo(arg1):
        print(arg1)
```

## Options
- `lint.dummy-variable-rgx`

[override]: https://docs.python.org/3/library/typing.html#typing.override

# unused-lambda-argument (ARG005)

Derived from the **flake8-unused-arguments** linter.

## What it does
Checks for the presence of unused arguments in lambda expression
definitions.

## Why is this bad?
An argument that is defined but not used is likely a mistake, and should
be removed to avoid confusion.

If a variable is intentionally defined-but-not-used, it should be
prefixed with an underscore, or some other value that adheres to the
[`lint.dummy-variable-rgx`] pattern.

## Example
```python
my_list = [1, 2, 3, 4, 5]
squares = map(lambda x, y: x**2, my_list)
```

Use instead:
```python
my_list = [1, 2, 3, 4, 5]
squares = map(lambda x: x**2, my_list)
```

## Options
- `lint.dummy-variable-rgx`

# os-path-abspath (PTH100)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.abspath`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.resolve()` can improve readability over the `os.path`
module's counterparts (e.g., `os.path.abspath()`).

## Examples
```python
import os

file_path = os.path.abspath("../path/to/file")
```

Use instead:
```python
from pathlib import Path

file_path = Path("../path/to/file").resolve()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is always marked as unsafe because `Path.resolve()` resolves symlinks, while
`os.path.abspath()` does not. If resolving symlinks is important, you may need to use
`Path.absolute()`. However, `Path.absolute()` also does not remove any `..` components in a
path, unlike `os.path.abspath()` and `Path.resolve()`, so if that specific combination of
behaviors is required, there's no existing `pathlib` alternative. See CPython issue
[#69200](https://github.com/python/cpython/issues/69200).

Additionally, the fix is marked as unsafe because `os.path.abspath()` returns `str` or `bytes` (`AnyStr`),
while `Path.resolve()` returns a `Path` object. This change in return type can break code that uses
the return value.

## References
- [Python documentation: `Path.resolve`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.resolve)
- [Python documentation: `os.path.abspath`](https://docs.python.org/3/library/os.path.html#os.path.abspath)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-chmod (PTH101)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.chmod`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `Path` object
methods such as `Path.chmod()` can improve readability over the `os`
module's counterparts (e.g., `os.chmod()`).

## Examples
```python
import os

os.chmod("file.py", 0o444)
```

Use instead:
```python
from pathlib import Path

Path("file.py").chmod(0o444)
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.chmod`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.chmod)
- [Python documentation: `os.chmod`](https://docs.python.org/3/library/os.html#os.chmod)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-mkdir (PTH102)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.mkdir`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `Path` object
methods such as `Path.mkdir()` can improve readability over the `os`
module's counterparts (e.g., `os.mkdir()`).

## Examples
```python
import os

os.mkdir("./directory/")
```

Use instead:
```python
from pathlib import Path

Path("./directory/").mkdir()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.mkdir`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir)
- [Python documentation: `os.mkdir`](https://docs.python.org/3/library/os.html#os.mkdir)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-makedirs (PTH103)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.makedirs`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `Path` object
methods such as `Path.mkdir(parents=True)` can improve readability over the
`os` module's counterparts (e.g., `os.makedirs()`.

## Examples
```python
import os

os.makedirs("./nested/directory/")
```

Use instead:
```python
from pathlib import Path

Path("./nested/directory/").mkdir(parents=True)
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.mkdir`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir)
- [Python documentation: `os.makedirs`](https://docs.python.org/3/library/os.html#os.makedirs)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-rename (PTH104)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.rename`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `Path` object
methods such as `Path.rename()` can improve readability over the `os`
module's counterparts (e.g., `os.rename()`).

## Examples
```python
import os

os.rename("old.py", "new.py")
```

Use instead:
```python
from pathlib import Path

Path("old.py").rename("new.py")
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.
Additionally, the fix is marked as unsafe when the return value is used because the type changes
from `None` to a `Path` object.

## References
- [Python documentation: `Path.rename`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.rename)
- [Python documentation: `os.rename`](https://docs.python.org/3/library/os.html#os.rename)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-replace (PTH105)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.replace`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `Path` object
methods such as `Path.replace()` can improve readability over the `os`
module's counterparts (e.g., `os.replace()`).

Note that `os` functions may be preferable if performance is a concern,
e.g., in hot loops.

## Examples
```python
import os

os.replace("old.py", "new.py")
```

Use instead:
```python
from pathlib import Path

Path("old.py").replace("new.py")
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.
Additionally, the fix is marked as unsafe when the return value is used because the type changes
from `None` to a `Path` object.

## References
- [Python documentation: `Path.replace`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.replace)
- [Python documentation: `os.replace`](https://docs.python.org/3/library/os.html#os.replace)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-rmdir (PTH106)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.rmdir`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `Path` object
methods such as `Path.rmdir()` can improve readability over the `os`
module's counterparts (e.g., `os.rmdir()`).

## Examples
```python
import os

os.rmdir("folder/")
```

Use instead:
```python
from pathlib import Path

Path("folder/").rmdir()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.rmdir`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.rmdir)
- [Python documentation: `os.rmdir`](https://docs.python.org/3/library/os.html#os.rmdir)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-remove (PTH107)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.remove`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `Path` object
methods such as `Path.unlink()` can improve readability over the `os`
module's counterparts (e.g., `os.remove()`).

## Examples
```python
import os

os.remove("file.py")
```

Use instead:
```python
from pathlib import Path

Path("file.py").unlink()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.unlink`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink)
- [Python documentation: `os.remove`](https://docs.python.org/3/library/os.html#os.remove)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-unlink (PTH108)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.unlink`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `Path` object
methods such as `Path.unlink()` can improve readability over the `os`
module's counterparts (e.g., `os.unlink()`).

## Examples
```python
import os

os.unlink("file.py")
```

Use instead:
```python
from pathlib import Path

Path("file.py").unlink()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.unlink`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink)
- [Python documentation: `os.unlink`](https://docs.python.org/3/library/os.html#os.unlink)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-getcwd (PTH109)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.getcwd` and `os.getcwdb`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `Path` object
methods such as `Path.cwd()` can improve readability over the `os`
module's counterparts (e.g., `os.getcwd()`).

## Examples
```python
import os

cwd = os.getcwd()
```

Use instead:
```python
from pathlib import Path

cwd = Path.cwd()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.
Additionally, the fix is marked as unsafe when the return value is used because the type changes
from `str` or `bytes` to a `Path` object.

## References
- [Python documentation: `Path.cwd`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.cwd)
- [Python documentation: `os.getcwd`](https://docs.python.org/3/library/os.html#os.getcwd)
- [Python documentation: `os.getcwdb`](https://docs.python.org/3/library/os.html#os.getcwdb)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-exists (PTH110)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.exists`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.exists()` can improve readability over the `os.path`
module's counterparts (e.g., `os.path.exists()`).

## Examples
```python
import os

os.path.exists("file.py")
```

Use instead:
```python
from pathlib import Path

Path("file.py").exists()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.exists`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.exists)
- [Python documentation: `os.path.exists`](https://docs.python.org/3/library/os.path.html#os.path.exists)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-expanduser (PTH111)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.expanduser`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.expanduser()` can improve readability over the `os.path`
module's counterparts (e.g., as `os.path.expanduser()`).

## Examples
```python
import os

os.path.expanduser("~/films/Monty Python")
```

Use instead:
```python
from pathlib import Path

Path("~/films/Monty Python").expanduser()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is always marked as unsafe because the behaviors of
`os.path.expanduser` and `Path.expanduser` differ when a user's home
directory can't be resolved: `os.path.expanduser` returns the
input unchanged, while `Path.expanduser` raises `RuntimeError`.

Additionally, the fix is marked as unsafe because `os.path.expanduser()` returns `str` or `bytes` (`AnyStr`),
while `Path.expanduser()` returns a `Path` object. This change in return type can break code that uses
the return value.

## References
- [Python documentation: `Path.expanduser`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.expanduser)
- [Python documentation: `os.path.expanduser`](https://docs.python.org/3/library/os.path.html#os.path.expanduser)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-isdir (PTH112)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.isdir`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.is_dir()` can improve readability over the `os.path`
module's counterparts (e.g., `os.path.isdir()`).

## Examples
```python
import os

os.path.isdir("docs")
```

Use instead:
```python
from pathlib import Path

Path("docs").is_dir()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.is_dir`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_dir)
- [Python documentation: `os.path.isdir`](https://docs.python.org/3/library/os.path.html#os.path.isdir)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-isfile (PTH113)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.isfile`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.is_file()` can improve readability over the `os.path`
module's counterparts (e.g., `os.path.isfile()`).

## Examples
```python
import os

os.path.isfile("docs")
```

Use instead:
```python
from pathlib import Path

Path("docs").is_file()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.is_file`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_file)
- [Python documentation: `os.path.isfile`](https://docs.python.org/3/library/os.path.html#os.path.isfile)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-islink (PTH114)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.islink`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.is_symlink()` can improve readability over the `os.path`
module's counterparts (e.g., `os.path.islink()`).

## Examples
```python
import os

os.path.islink("docs")
```

Use instead:
```python
from pathlib import Path

Path("docs").is_symlink()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.is_symlink`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.is_symlink)
- [Python documentation: `os.path.islink`](https://docs.python.org/3/library/os.path.html#os.path.islink)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-readlink (PTH115)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.readlink`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `Path` object
methods such as `Path.readlink()` can improve readability over the `os`
module's counterparts (e.g., `os.readlink()`).

## Examples
```python
import os

os.readlink(file_name)
```

Use instead:
```python
from pathlib import Path

Path(file_name).readlink()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.
Additionally, the fix is marked as unsafe when the return value is used because the type changes
from `str` or `bytes` (`AnyStr`) to a `Path` object.

## References
- [Python documentation: `Path.readlink`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.readline)
- [Python documentation: `os.readlink`](https://docs.python.org/3/library/os.html#os.readlink)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-stat (PTH116)

Derived from the **flake8-use-pathlib** linter.

## What it does
Checks for uses of `os.stat`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `Path` object
methods such as `Path.stat()` can improve readability over the `os`
module's counterparts (e.g., `os.path.stat()`).

## Examples
```python
import os
from pwd import getpwuid
from grp import getgrgid

stat = os.stat(file_name)
owner_name = getpwuid(stat.st_uid).pw_name
group_name = getgrgid(stat.st_gid).gr_name
```

Use instead:
```python
from pathlib import Path

file_path = Path(file_name)
stat = file_path.stat()
owner_name = file_path.owner()
group_name = file_path.group()
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## References
- [Python documentation: `Path.stat`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.stat)
- [Python documentation: `Path.group`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.group)
- [Python documentation: `Path.owner`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.owner)
- [Python documentation: `os.stat`](https://docs.python.org/3/library/os.html#os.stat)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-isabs (PTH117)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.isabs`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.is_absolute()` can improve readability over the `os.path`
module's counterparts (e.g.,  as `os.path.isabs()`).

## Examples
```python
import os

if os.path.isabs(file_name):
    print("Absolute path!")
```

Use instead:
```python
from pathlib import Path

if Path(file_name).is_absolute():
    print("Absolute path!")
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## References
- [Python documentation: `PurePath.is_absolute`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.is_absolute)
- [Python documentation: `os.path.isabs`](https://docs.python.org/3/library/os.path.html#os.path.isabs)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-join (PTH118)

Derived from the **flake8-use-pathlib** linter.

## What it does
Checks for uses of `os.path.join`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.joinpath()` or the `/` operator can improve
readability over the `os.path` module's counterparts (e.g., `os.path.join()`).

## Examples
```python
import os

os.path.join(os.path.join(ROOT_PATH, "folder"), "file.py")
```

Use instead:
```python
from pathlib import Path

Path(ROOT_PATH) / "folder" / "file.py"
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## References
- [Python documentation: `PurePath.joinpath`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.joinpath)
- [Python documentation: `os.path.join`](https://docs.python.org/3/library/os.path.html#os.path.join)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-basename (PTH119)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.basename`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.name` can improve readability over the `os.path`
module's counterparts (e.g., `os.path.basename()`).

## Examples
```python
import os

os.path.basename(__file__)
```

Use instead:
```python
from pathlib import Path

Path(__file__).name
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is always marked as unsafe because the replacement is not always semantically
equivalent to the original code. In particular, `pathlib` performs path normalization,
which can alter the result compared to `os.path.basename`. For example, this normalization:

- Collapses consecutive slashes (e.g., `"a//b"`  `"a/b"`).
- Removes trailing slashes (e.g., `"a/b/"`  `"a/b"`).
- Eliminates `"."` (e.g., `"a/./b"`  `"a/b"`).

As a result, code relying on the exact string returned by `os.path.basename`
may behave differently after the fix.

## References
- [Python documentation: `PurePath.name`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.name)
- [Python documentation: `os.path.basename`](https://docs.python.org/3/library/os.path.html#os.path.basename)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-dirname (PTH120)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.dirname`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.parent` can improve readability over the `os.path`
module's counterparts (e.g., `os.path.dirname()`).

## Examples
```python
import os

os.path.dirname(__file__)
```

Use instead:
```python
from pathlib import Path

Path(__file__).parent
```

## Fix Safety
This rule's fix is always marked as unsafe because the replacement is not always semantically
equivalent to the original code. In particular, `pathlib` performs path normalization,
which can alter the result compared to `os.path.dirname`. For example, this normalization:

- Collapses consecutive slashes (e.g., `"a//b"`  `"a/b"`).
- Removes trailing slashes (e.g., `"a/b/"`  `"a/b"`).
- Eliminates `"."` (e.g., `"a/./b"`  `"a/b"`).

As a result, code relying on the exact string returned by `os.path.dirname`
may behave differently after the fix.

Additionally, the fix is marked as unsafe because `os.path.dirname()` returns `str` or `bytes` (`AnyStr`),
while `Path.parent` returns a `Path` object. This change in return type can break code that uses
the return value.

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## References
- [Python documentation: `PurePath.parent`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.parent)
- [Python documentation: `os.path.dirname`](https://docs.python.org/3/library/os.path.html#os.path.dirname)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-samefile (PTH121)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.samefile`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.samefile()` can improve readability over the `os.path`
module's counterparts (e.g., `os.path.samefile()`).

## Examples
```python
import os

os.path.samefile("f1.py", "f2.py")
```

Use instead:
```python
from pathlib import Path

Path("f1.py").samefile("f2.py")
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.samefile`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.samefile)
- [Python documentation: `os.path.samefile`](https://docs.python.org/3/library/os.path.html#os.path.samefile)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-splitext (PTH122)

Derived from the **flake8-use-pathlib** linter.

## What it does
Checks for uses of `os.path.splitext`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`. When possible, using `Path` object
methods such as `Path.suffix` and `Path.stem` can improve readability over
the `os.path` module's counterparts (e.g., `os.path.splitext()`).

`os.path.splitext()` specifically returns a tuple of the file root and
extension (e.g., given `splitext('/foo/bar.py')`, `os.path.splitext()`
returns `("foo/bar", ".py")`. These outputs can be reconstructed through a
combination of `Path.suffix` (`".py"`), `Path.stem` (`"bar"`), and
`Path.parent` (`"foo"`).

## Examples
```python
import os

(root, ext) = os.path.splitext("foo/bar.py")
```

Use instead:
```python
from pathlib import Path

path = Path("foo/bar.py")
root = path.parent / path.stem
ext = path.suffix
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## References
- [Python documentation: `Path.suffix`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.suffix)
- [Python documentation: `Path.suffixes`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.suffixes)
- [Python documentation: `os.path.splitext`](https://docs.python.org/3/library/os.path.html#os.path.splitext)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# builtin-open (PTH123)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of the `open()` builtin.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation. When possible,
using `Path` object methods such as `Path.open()` can improve readability
over the `open` builtin.

## Examples
```python
with open("f1.py", "wb") as fp:
    ...
```

Use instead:
```python
from pathlib import Path

with Path("f1.py").open("wb") as fp:
    ...
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than working directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.open`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.open)
- [Python documentation: `open`](https://docs.python.org/3/library/functions.html#open)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# py-path (PTH124)

Derived from the **flake8-use-pathlib** linter.

## What it does
Checks for uses of the `py.path` library.

## Why is this bad?
The `py.path` library is in maintenance mode. Instead, prefer the standard
library's `pathlib` module, or third-party modules like `path` (formerly
`py.path`).

## Examples
```python
import py.path

p = py.path.local("/foo/bar").join("baz/qux")
```

Use instead:
```python
from pathlib import Path

p = Path("/foo/bar") / "bar" / "qux"
```

## References
- [Python documentation: `Pathlib`](https://docs.python.org/3/library/pathlib.html)
- [Path repository](https://github.com/jaraco/path)

# path-constructor-current-directory (PTH201)

Derived from the **flake8-use-pathlib** linter.

Fix is always available.

## What it does
Checks for `pathlib.Path` objects that are initialized with the current
directory.

## Why is this bad?
The `Path()` constructor defaults to the current directory, so passing it
in explicitly (as `"."`) is unnecessary.

## Example
```python
from pathlib import Path

_ = Path(".")
```

Use instead:
```python
from pathlib import Path

_ = Path()
```

## Fix safety
This fix is marked unsafe if there are comments inside the parentheses, as applying
the fix will delete them.

## References
- [Python documentation: `Path`](https://docs.python.org/3/library/pathlib.html#pathlib.Path)

# os-path-getsize (PTH202)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.getsize`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`.

When possible, using `Path` object methods such as `Path.stat()` can
improve readability over the `os.path` module's counterparts (e.g.,
`os.path.getsize()`).

## Example
```python
import os

os.path.getsize(__file__)
```

Use instead:
```python
from pathlib import Path

Path(__file__).stat().st_size
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.stat`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.stat)
- [Python documentation: `os.path.getsize`](https://docs.python.org/3/library/os.path.html#os.path.getsize)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-getatime (PTH203)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.getatime`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`.

When possible, using `Path` object methods such as `Path.stat()` can
improve readability over the `os.path` module's counterparts (e.g.,
`os.path.getatime()`).

## Example
```python
import os

os.path.getatime(__file__)
```

Use instead:
```python
from pathlib import Path

Path(__file__).stat().st_atime
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.stat`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.stat)
- [Python documentation: `os.path.getatime`](https://docs.python.org/3/library/os.path.html#os.path.getatime)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-getmtime (PTH204)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.getmtime`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`.

When possible, using `Path` object methods such as `Path.stat()` can
improve readability over the `os.path` module's counterparts (e.g.,
`os.path.getmtime()`).

## Example
```python
import os

os.path.getmtime(__file__)
```

Use instead:
```python
from pathlib import Path

Path(__file__).stat().st_mtime
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.stat`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.stat)
- [Python documentation: `os.path.getmtime`](https://docs.python.org/3/library/os.path.html#os.path.getmtime)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-path-getctime (PTH205)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.path.getctime`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.path`.

When possible, using `Path` object methods such as `Path.stat()` can
improve readability over the `os.path` module's counterparts (e.g.,
`os.path.getctime()`).

## Example
```python
import os

os.path.getctime(__file__)
```

Use instead:
```python
from pathlib import Path

Path(__file__).stat().st_ctime
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.stat`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.stat)
- [Python documentation: `os.path.getctime`](https://docs.python.org/3/library/os.path.html#os.path.getctime)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-sep-split (PTH206)

Derived from the **flake8-use-pathlib** linter.

## What it does
Checks for uses of `.split(os.sep)`

## Why is this bad?
The `pathlib` module in the standard library should be used for path
manipulation. It provides a high-level API with the functionality
needed for common operations on `Path` objects.

## Example
If not all parts of the path are needed, then the `name` and `parent`
attributes of the `Path` object should be used. Otherwise, the `parts`
attribute can be used as shown in the last example.
```python
import os

"path/to/file_name.txt".split(os.sep)[-1]

"path/to/file_name.txt".split(os.sep)[-2]

# Iterating over the path parts
if any(part in blocklist for part in "my/file/path".split(os.sep)):
    ...
```

Use instead:
```python
from pathlib import Path

Path("path/to/file_name.txt").name

Path("path/to/file_name.txt").parent.name

# Iterating over the path parts
if any(part in blocklist for part in Path("my/file/path").parts):
    ...
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than working directly with strings,
especially on older versions of Python.

## References
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# glob (PTH207)

Derived from the **flake8-use-pathlib** linter.

## What it does
Checks for the use of `glob.glob()` and `glob.iglob()`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os` and `glob`.

When possible, using `Path` object methods such as `Path.glob()` can
improve readability over their low-level counterparts (e.g.,
`glob.glob()`).

Note that `glob.glob()` and `Path.glob()` are not exact equivalents:

|                   | `glob`-module functions                                                                                                                              | `Path.glob()`                                                                                                                                |
|-------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|
| Hidden files      | Hidden files are excluded by default. On Python 3.11+, the `include_hidden` keyword can be used to include hidden directories.                       | Includes hidden files by default.                                                                                                            |
| Eagerness         | `glob.iglob()` returns a lazy iterator. Under the hood, `glob.glob()` simply converts the iterator to a list.                                        | `Path.glob()` returns a lazy iterator.                                                                                                       |
| Working directory | `glob.glob()` and `glob.iglob()` take a `root_dir` keyword to set the current working directory.                                                     | `Path.rglob()` can be used to return the relative path.                                                                                      |
| Globstar (`**`)   | The `recursive` flag must be set to `True` for the `**` pattern to match any files and zero or more directories, subdirectories, and symbolic links. | The `**` pattern in `Path.glob()` means "this directory and all subdirectories, recursively". In other words, it enables recursive globbing. |

## Example
```python
import glob
import os

glob.glob(os.path.join("my_path", "requirements*.txt"))
```

Use instead:
```python
from pathlib import Path

Path("my_path").glob("requirements*.txt")
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## References
- [Python documentation: `Path.glob`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.glob)
- [Python documentation: `Path.rglob`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.rglob)
- [Python documentation: `glob.glob`](https://docs.python.org/3/library/glob.html#glob.glob)
- [Python documentation: `glob.iglob`](https://docs.python.org/3/library/glob.html#glob.iglob)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# os-listdir (PTH208)

Derived from the **flake8-use-pathlib** linter.

## What it does
Checks for uses of `os.listdir`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os`. When possible, using `pathlib`'s
`Path.iterdir()` can improve readability over `os.listdir()`.

## Example

```python
p = "."
for d in os.listdir(p):
    ...

if os.listdir(p):
    ...

if "file" in os.listdir(p):
    ...
```

Use instead:

```python
p = Path(".")
for d in p.iterdir():
    ...

if any(p.iterdir()):
    ...

if (p / "file").exists():
    ...
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## References
- [Python documentation: `Path.iterdir`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.iterdir)
- [Python documentation: `os.listdir`](https://docs.python.org/3/library/os.html#os.listdir)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# invalid-pathlib-with-suffix (PTH210)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for `pathlib.Path.with_suffix()` calls where
the given suffix does not have a leading dot
or the given suffix is a single dot `"."` and the
Python version is less than 3.14.

## Why is this bad?
`Path.with_suffix()` will raise an error at runtime
if the given suffix is not prefixed with a dot
or, in versions prior to Python 3.14, if it is a single dot `"."`.

## Example

```python
from pathlib import Path

path = Path()

path.with_suffix("py")
```

Use instead:

```python
from pathlib import Path

path = Path()

path.with_suffix(".py")
```

## Known problems
This rule is likely to have false negatives, as Ruff can only emit the
lint if it can say for sure that a binding refers to a `Path` object at
runtime. Due to type inference limitations, Ruff is currently only
confident about this if it can see that the binding originates from a
function parameter annotated with `Path` or from a direct assignment to a
`Path()` constructor call.

## Fix safety
The fix for this rule adds a leading period to the string passed
to the `with_suffix()` call. This fix is marked as unsafe, as it
changes runtime behaviour: the call would previously always have
raised an exception, but no longer will.

Moreover, it's impossible to determine if this is the correct fix
for a given situation (it's possible that the string was correct
but was being passed to the wrong method entirely, for example).

No fix is offered if the suffix `"."` is given, since the intent is unclear.

# os-symlink (PTH211)

Derived from the **flake8-use-pathlib** linter.

Fix is sometimes available.

## What it does
Checks for uses of `os.symlink`.

## Why is this bad?
`pathlib` offers a high-level API for path manipulation, as compared to
the lower-level API offered by `os.symlink`.

## Example
```python
import os

os.symlink("usr/bin/python", "tmp/python", target_is_directory=False)
```

Use instead:
```python
from pathlib import Path

Path("tmp/python").symlink_to("usr/bin/python")
```

## Known issues
While using `pathlib` can improve the readability and type safety of your code,
it can be less performant than the lower-level alternatives that work directly with strings,
especially on older versions of Python.

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.symlink_to`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.symlink_to)
- [PEP 428  The pathlib module  object-oriented filesystem paths](https://peps.python.org/pep-0428/)
- [Correspondence between `os` and `pathlib`](https://docs.python.org/3/library/pathlib.html#corresponding-tools)
- [Why you should be using pathlib](https://treyhunner.com/2018/12/why-you-should-be-using-pathlib/)
- [No really, pathlib is great](https://treyhunner.com/2019/01/no-really-pathlib-is-great/)

# static-join-to-f-string (FLY002)

Derived from the **flynt** linter.

Fix is always available.

## What it does
Checks for `str.join` calls that can be replaced with f-strings.

## Why is this bad?
f-strings are more readable and generally preferred over `str.join` calls.

## Example
```python
" ".join((foo, bar))
```

Use instead:
```python
f"{foo} {bar}"
```

## Fix safety
The fix is always marked unsafe because the evaluation of the f-string
expressions will default to calling the `__format__` method of each
object, whereas `str.join` expects each object to be an instance of
`str` and uses the corresponding string. Therefore it is possible for
the values of the resulting strings to differ, or for one expression
to raise an exception while the other does not.

## References
- [Python documentation: f-strings](https://docs.python.org/3/reference/lexical_analysis.html#f-strings)

# unsorted-imports (I001)

Derived from the **isort** linter.

Fix is sometimes available.

## What it does
De-duplicates, groups, and sorts imports based on the provided `isort` settings.

## Why is this bad?
Consistency is good. Use a common convention for imports to make your code
more readable and idiomatic.

## Example
```python
import pandas
import numpy as np
```

Use instead:
```python
import numpy as np
import pandas
```

# missing-required-import (I002)

Derived from the **isort** linter.

Fix is always available.

## What it does
Adds any required imports, as specified by the user, to the top of the
file.

## Why is this bad?
In some projects, certain imports are required to be present in all
files. For example, some projects assume that
`from __future__ import annotations` is enabled,
and thus require that import to be
present in all files. Omitting a "required" import (as specified by
the user) can cause errors or unexpected behavior.

## Example
```python
import typing
```

Use instead:
```python
from __future__ import annotations

import typing
```

## Options
- `lint.isort.required-imports`

# complex-structure (C901)

Derived from the **mccabe** linter.

## What it does
Checks for functions with a high `McCabe` complexity.

## Why is this bad?
The `McCabe` complexity of a function is a measure of the complexity of
the control flow graph of the function. It is calculated by adding
one to the number of decision points in the function. A decision
point is a place in the code where the program has a choice of two
or more paths to follow.

Functions with a high complexity are hard to understand and maintain.

## Example
```python
def foo(a, b, c):
    if a:
        if b:
            if c:
                return 1
            else:
                return 2
        else:
            return 3
    else:
        return 4
```

Use instead:
```python
def foo(a, b, c):
    if not a:
        return 4
    if not b:
        return 3
    if not c:
        return 2
    return 1
```

## Options
- `lint.mccabe.max-complexity`

# numpy-deprecated-type-alias (NPY001)

Derived from the **NumPy-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for deprecated NumPy type aliases.

## Why is this bad?
NumPy's `np.int` has long been an alias of the builtin `int`; the same
is true of `np.float` and others. These aliases exist primarily
for historic reasons, and have been a cause of frequent confusion
for newcomers.

These aliases were deprecated in 1.20, and removed in 1.24.
Note, however, that `np.bool` and `np.long` were reintroduced in 2.0 with
different semantics, and are thus omitted from this rule.

## Example
```python
import numpy as np

np.int
```

Use instead:
```python
int
```

# numpy-legacy-random (NPY002)

Derived from the **NumPy-specific rules** linter.

## What it does
Checks for the use of legacy `np.random` function calls.

## Why is this bad?
According to the NumPy documentation's [Legacy Random Generation]:

> The `RandomState` provides access to legacy generators... This class
> should only be used if it is essential to have randoms that are
> identical to what would have been produced by previous versions of
> NumPy.

The members exposed directly on the `random` module are convenience
functions that alias to methods on a global singleton `RandomState`
instance. NumPy recommends using a dedicated `Generator` instance
rather than the random variate generation methods exposed directly on
the `random` module, as the new `Generator` is both faster and has
better statistical properties.

See the documentation on [Random Sampling] and [NEP 19] for further
details.

## Example
```python
import numpy as np

np.random.seed(1337)
np.random.normal()
```

Use instead:
```python
rng = np.random.default_rng(1337)
rng.normal()
```

[Legacy Random Generation]: https://numpy.org/doc/stable/reference/random/legacy.html#legacy
[Random Sampling]: https://numpy.org/doc/stable/reference/random/index.html#random-quick-start
[NEP 19]: https://numpy.org/neps/nep-0019-rng-policy.html

# numpy-deprecated-function (NPY003)

Derived from the **NumPy-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for uses of deprecated NumPy functions.

## Why is this bad?
When NumPy functions are deprecated, they are usually replaced with
newer, more efficient versions, or with functions that are more
consistent with the rest of the NumPy API.

Prefer newer APIs over deprecated ones.

## Example
```python
import numpy as np

np.alltrue([True, False])
```

Use instead:
```python
import numpy as np

np.all([True, False])
```

# numpy2-deprecation (NPY201)

Derived from the **NumPy-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for uses of NumPy functions and constants that were removed from
the main namespace in NumPy 2.0.

## Why is this bad?
NumPy 2.0 includes an overhaul of NumPy's Python API, intended to remove
redundant aliases and routines, and establish unambiguous mechanisms for
accessing constants, dtypes, and functions.

As part of this overhaul, a variety of deprecated NumPy functions and
constants were removed from the main namespace.

The majority of these functions and constants can be automatically replaced
by other members of the NumPy API or by equivalents from the Python
standard library. With the exception of renaming `numpy.byte_bounds` to
`numpy.lib.array_utils.byte_bounds`, all such replacements are backwards
compatible with earlier versions of NumPy.

This rule flags all uses of removed members, along with automatic fixes for
any backwards-compatible replacements.

## Example
```python
import numpy as np

arr1 = [np.Infinity, np.NaN, np.nan, np.PINF, np.inf]
arr2 = [np.float_(1.5), np.float64(5.1)]
np.round_(arr2)
```

Use instead:
```python
import numpy as np

arr1 = [np.inf, np.nan, np.nan, np.inf, np.inf]
arr2 = [np.float64(1.5), np.float64(5.1)]
np.round(arr2)
```

# invalid-class-name (N801)

Derived from the **pep8-naming** linter.

## What it does
Checks for class names that do not follow the `CamelCase` convention.

## Why is this bad?
[PEP 8] recommends the use of the `CapWords` (or `CamelCase`) convention
for class names:

> Class names should normally use the `CapWords` convention.
>
> The naming convention for functions may be used instead in cases where the interface is
> documented and used primarily as a callable.
>
> Note that there is a separate convention for builtin names: most builtin names are single
> words (or two words run together), with the `CapWords` convention used only for exception
> names and builtin constants.

## Example
```python
class my_class:
    pass
```

Use instead:
```python
class MyClass:
    pass
```

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/#class-names

# invalid-function-name (N802)

Derived from the **pep8-naming** linter.

## What it does
Checks for functions names that do not follow the `snake_case` naming
convention.

## Why is this bad?
[PEP 8] recommends that function names follow `snake_case`:

> Function names should be lowercase, with words separated by underscores as necessary to
> improve readability. mixedCase is allowed only in contexts where thats already the
> prevailing style (e.g. threading.py), to retain backwards compatibility.

Names can be excluded from this rule using the [`lint.pep8-naming.ignore-names`]
or [`lint.pep8-naming.extend-ignore-names`] configuration options. For example,
to ignore all functions starting with `test_` from this rule, set the
[`lint.pep8-naming.extend-ignore-names`] option to `["test_*"]`.

This rule exempts methods decorated with [`@typing.override`][override].
Explicitly decorating a method with `@override` signals to Ruff that the method is intended
to override a superclass method, and that a type checker will enforce that it does so. Ruff
therefore knows that it should not enforce naming conventions on such methods.

## Example
```python
def myFunction():
    pass
```

Use instead:
```python
def my_function():
    pass
```

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/#function-and-variable-names
[override]: https://docs.python.org/3/library/typing.html#typing.override

# invalid-argument-name (N803)

Derived from the **pep8-naming** linter.

## What it does
Checks for argument names that do not follow the `snake_case` convention.

## Why is this bad?
[PEP 8] recommends that function names should be lower case and separated
by underscores (also known as `snake_case`).

> Function names should be lowercase, with words separated by underscores
> as necessary to improve readability.
>
> Variable names follow the same convention as function names.
>
> mixedCase is allowed only in contexts where thats already the
> prevailing style (e.g. threading.py), to retain backwards compatibility.

Methods decorated with [`@typing.override`][override] are ignored.

## Example
```python
def my_function(A, myArg):
    pass
```

Use instead:
```python
def my_function(a, my_arg):
    pass
```

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/#function-and-method-arguments
[preview]: https://docs.astral.sh/ruff/preview/

[override]: https://docs.python.org/3/library/typing.html#typing.override

# invalid-first-argument-name-for-class-method (N804)

Derived from the **pep8-naming** linter.

Fix is sometimes available.

## What it does
Checks for class methods that use a name other than `cls` for their
first argument.

The method `__new__` is exempted from this
check and the corresponding violation is caught by
[`bad-staticmethod-argument`][PLW0211].

## Why is this bad?
[PEP 8] recommends the use of `cls` as the first argument for all class
methods:

> Always use `cls` for the first argument to class methods.
>
> If a function arguments name clashes with a reserved keyword, it is generally better to
> append a single trailing underscore rather than use an abbreviation or spelling corruption.
> Thus `class_` is better than `clss`. (Perhaps better is to avoid such clashes by using a synonym.)

Names can be excluded from this rule using the [`lint.pep8-naming.ignore-names`]
or [`lint.pep8-naming.extend-ignore-names`] configuration options. For example,
to allow the use of `klass` as the first argument to class methods, set
the [`lint.pep8-naming.extend-ignore-names`] option to `["klass"]`.

## Example

```python
class Example:
    @classmethod
    def function(self, data): ...
```

Use instead:

```python
class Example:
    @classmethod
    def function(cls, data): ...
```

## Fix safety
This rule's fix is marked as unsafe, as renaming a method parameter
can change the behavior of the program.

## Options
- `lint.pep8-naming.classmethod-decorators`
- `lint.pep8-naming.staticmethod-decorators`
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/#function-and-method-arguments
[PLW0211]: https://docs.astral.sh/ruff/rules/bad-staticmethod-argument/

# invalid-first-argument-name-for-method (N805)

Derived from the **pep8-naming** linter.

Fix is sometimes available.

## What it does
Checks for instance methods that use a name other than `self` for their
first argument.

## Why is this bad?
[PEP 8] recommends the use of `self` as first argument for all instance
methods:

> Always use self for the first argument to instance methods.
>
> If a function arguments name clashes with a reserved keyword, it is generally better to
> append a single trailing underscore rather than use an abbreviation or spelling corruption.
> Thus `class_` is better than `clss`. (Perhaps better is to avoid such clashes by using a synonym.)

Names can be excluded from this rule using the [`lint.pep8-naming.ignore-names`]
or [`lint.pep8-naming.extend-ignore-names`] configuration options. For example,
to allow the use of `this` as the first argument to instance methods, set
the [`lint.pep8-naming.extend-ignore-names`] option to `["this"]`.

## Example

```python
class Example:
    def function(cls, data): ...
```

Use instead:

```python
class Example:
    def function(self, data): ...
```

## Fix safety
This rule's fix is marked as unsafe, as renaming a method parameter
can change the behavior of the program.

## Options
- `lint.pep8-naming.classmethod-decorators`
- `lint.pep8-naming.staticmethod-decorators`
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/#function-and-method-arguments

# non-lowercase-variable-in-function (N806)

Derived from the **pep8-naming** linter.

## What it does
Checks for the use of non-lowercase variable names in functions.

## Why is this bad?
[PEP 8] recommends that all function variables use lowercase names:

> Function names should be lowercase, with words separated by underscores as necessary to
> improve readability. Variable names follow the same convention as function names. mixedCase
> is allowed only in contexts where that's already the prevailing style (e.g. threading.py),
> to retain backwards compatibility.

## Example
```python
def my_function(a):
    B = a + 3
    return B
```

Use instead:
```python
def my_function(a):
    b = a + 3
    return b
```

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/#function-and-variable-names

# dunder-function-name (N807)

Derived from the **pep8-naming** linter.

## What it does
Checks for functions with "dunder" names (that is, names with two
leading and trailing underscores) that are not documented.

## Why is this bad?
[PEP 8] recommends that only documented "dunder" methods are used:

> ..."magic" objects or attributes that live in user-controlled
> namespaces. E.g. `__init__`, `__import__` or `__file__`. Never invent
> such names; only use them as documented.

## Example
```python
def __my_function__():
    pass
```

Use instead:
```python
def my_function():
    pass
```

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/

# constant-imported-as-non-constant (N811)

Derived from the **pep8-naming** linter.

## What it does
Checks for constant imports that are aliased to non-constant-style
names.

## Why is this bad?
[PEP 8] recommends naming conventions for classes, functions,
constants, and more. The use of inconsistent naming styles between
import and alias names may lead readers to expect an import to be of
another type (e.g., confuse a Python class with a constant).

Import aliases should thus follow the same naming style as the member
being imported.

## Example
```python
from example import CONSTANT_VALUE as ConstantValue
```

Use instead:
```python
from example import CONSTANT_VALUE
```

## Note
Identifiers consisting of a single uppercase character are ambiguous under
the rules of [PEP 8], which specifies `CamelCase` for classes and
`ALL_CAPS_SNAKE_CASE` for constants. Without a second character, it is not
possible to reliably guess whether the identifier is intended to be part
of a `CamelCase` string for a class or an `ALL_CAPS_SNAKE_CASE` string for
a constant, since both conventions will produce the same output when given
a single input character. Therefore, this lint rule does not apply to cases
where the imported identifier consists of a single uppercase character.

A common example of a single uppercase character being used for a class
name can be found in Django's `django.db.models.Q` class.

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/

# lowercase-imported-as-non-lowercase (N812)

Derived from the **pep8-naming** linter.

## What it does
Checks for lowercase imports that are aliased to non-lowercase names.

## Why is this bad?
[PEP 8] recommends naming conventions for classes, functions,
constants, and more. The use of inconsistent naming styles between
import and alias names may lead readers to expect an import to be of
another type (e.g., confuse a Python class with a constant).

Import aliases should thus follow the same naming style as the member
being imported.

## Example
```python
from example import myclassname as MyClassName
```

Use instead:
```python
from example import myclassname
```

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/

# camelcase-imported-as-lowercase (N813)

Derived from the **pep8-naming** linter.

## What it does
Checks for `CamelCase` imports that are aliased to lowercase names.

## Why is this bad?
[PEP 8] recommends naming conventions for classes, functions,
constants, and more. The use of inconsistent naming styles between
import and alias names may lead readers to expect an import to be of
another type (e.g., confuse a Python class with a constant).

Import aliases should thus follow the same naming style as the member
being imported.

## Example
```python
from example import MyClassName as myclassname
```

Use instead:
```python
from example import MyClassName
```

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/

# camelcase-imported-as-constant (N814)

Derived from the **pep8-naming** linter.

## What it does
Checks for `CamelCase` imports that are aliased to constant-style names.

## Why is this bad?
[PEP 8] recommends naming conventions for classes, functions,
constants, and more. The use of inconsistent naming styles between
import and alias names may lead readers to expect an import to be of
another type (e.g., confuse a Python class with a constant).

Import aliases should thus follow the same naming style as the member
being imported.

## Example
```python
from example import MyClassName as MY_CLASS_NAME
```

Use instead:
```python
from example import MyClassName
```

## Note
Identifiers consisting of a single uppercase character are ambiguous under
the rules of [PEP 8], which specifies `CamelCase` for classes and
`ALL_CAPS_SNAKE_CASE` for constants. Without a second character, it is not
possible to reliably guess whether the identifier is intended to be part
of a `CamelCase` string for a class or an `ALL_CAPS_SNAKE_CASE` string for
a constant, since both conventions will produce the same output when given
a single input character. Therefore, this lint rule does not apply to cases
where the alias for the imported identifier consists of a single uppercase
character.

A common example of a single uppercase character being used for a class
name can be found in Django's `django.db.models.Q` class.

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/

# mixed-case-variable-in-class-scope (N815)

Derived from the **pep8-naming** linter.

## What it does
Checks for class variable names that follow the `mixedCase` convention.

## Why is this bad?
[PEP 8] recommends that variable names should be lower case and separated
by underscores (also known as `snake_case`).

> Function names should be lowercase, with words separated by underscores
> as necessary to improve readability.
>
> Variable names follow the same convention as function names.
>
> mixedCase is allowed only in contexts where thats already the
> prevailing style (e.g. threading.py), to retain backwards compatibility.

## Example
```python
class MyClass:
    myVariable = "hello"
    another_variable = "world"
```

Use instead:
```python
class MyClass:
    my_variable = "hello"
    another_variable = "world"
```

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/#function-and-method-arguments

# mixed-case-variable-in-global-scope (N816)

Derived from the **pep8-naming** linter.

## What it does
Checks for global variable names that follow the `mixedCase` convention.

## Why is this bad?
[PEP 8] recommends that global variable names should be lower case and
separated by underscores (also known as `snake_case`).

> ### Global Variable Names
> (Lets hope that these variables are meant for use inside one module
> only.) The conventions are about the same as those for functions.
>
> Modules that are designed for use via `from M import *` should use the
> `__all__` mechanism to prevent exporting globals, or use the older
> convention of prefixing such globals with an underscore (which you might
> want to do to indicate these globals are module non-public).
>
> ### Function and Variable Names
> Function names should be lowercase, with words separated by underscores
> as necessary to improve readability.
>
> Variable names follow the same convention as function names.
>
> mixedCase is allowed only in contexts where thats already the prevailing
> style (e.g. threading.py), to retain backwards compatibility.

## Example
```python
myVariable = "hello"
another_variable = "world"
yet_anotherVariable = "foo"
```

Use instead:
```python
my_variable = "hello"
another_variable = "world"
yet_another_variable = "foo"
```

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/#global-variable-names

# camelcase-imported-as-acronym (N817)

Derived from the **pep8-naming** linter.

## What it does
Checks for `CamelCase` imports that are aliased as acronyms.

## Why is this bad?
[PEP 8] recommends naming conventions for classes, functions,
constants, and more. The use of inconsistent naming styles between
import and alias names may lead readers to expect an import to be of
another type (e.g., confuse a Python class with a constant).

Import aliases should thus follow the same naming style as the member
being imported.

Note that this rule is distinct from `camelcase-imported-as-constant`
to accommodate selective enforcement.

Also note that import aliases following an import convention according to the
[`lint.flake8-import-conventions.aliases`] option are allowed.

## Example
```python
from example import MyClassName as MCN
```

Use instead:
```python
from example import MyClassName
```

## Options
- `lint.flake8-import-conventions.aliases`
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/

# error-suffix-on-exception-name (N818)

Derived from the **pep8-naming** linter.

## What it does
Checks for custom exception definitions that omit the `Error` suffix.

## Why is this bad?
The `Error` suffix is recommended by [PEP 8]:

> Because exceptions should be classes, the class naming convention
> applies here. However, you should use the suffix `"Error"` on your
> exception names (if the exception actually is an error).

## Example

```python
class Validation(Exception): ...
```

Use instead:

```python
class ValidationError(Exception): ...
```

## Options
- `lint.pep8-naming.ignore-names`
- `lint.pep8-naming.extend-ignore-names`

[PEP 8]: https://peps.python.org/pep-0008/#exception-names

# invalid-module-name (N999)

Derived from the **pep8-naming** linter.

## What it does
Checks for module names that do not follow the `snake_case` naming
convention or are otherwise invalid.

## Why is this bad?
[PEP 8] recommends the use of the `snake_case` naming convention for
module names:

> Modules should have short, all-lowercase names. Underscores can be used in the
> module name if it improves readability. Python packages should also have short,
> all-lowercase names, although the use of underscores is discouraged.
>
> When an extension module written in C or C++ has an accompanying Python module that
> provides a higher level (e.g. more object-oriented) interface, the C/C++ module has
> a leading underscore (e.g. `_socket`).

Further, in order for Python modules to be importable, they must be valid
identifiers. As such, they cannot start with a digit, or collide with hard
keywords, like `import` or `class`.

## Example
- Instead of `example-module-name` or `example module name`, use `example_module_name`.
- Instead of `ExampleModule`, use `example_module`.

[PEP 8]: https://peps.python.org/pep-0008/#package-and-module-names

# pandas-use-of-inplace-argument (PD002)

Derived from the **pandas-vet** linter.

Fix is sometimes available.

## What it does
Checks for `inplace=True` usages in `pandas` function and method
calls.

## Why is this bad?
Using `inplace=True` encourages mutation rather than immutable data,
which is harder to reason about and may cause bugs. It also removes the
ability to use the method chaining style for `pandas` operations.

Further, in many cases, `inplace=True` does not provide a performance
benefit, as `pandas` will often copy `DataFrames` in the background.

## Example
```python
df.sort_values("col1", inplace=True)
```

Use instead:
```python
sorted_df = df.sort_values("col1")
```

## References
- [_Why You Should Probably Never Use pandas `inplace=True`_](https://towardsdatascience.com/why-you-should-probably-never-use-pandas-inplace-true-9f9f211849e4)

# pandas-use-of-dot-is-null (PD003)

Derived from the **pandas-vet** linter.

## What it does
Checks for uses of `.isnull` on Pandas objects.

## Why is this bad?
In the Pandas API, `.isna` and `.isnull` are equivalent. For consistency,
prefer `.isna` over `.isnull`.

As a name, `.isna` more accurately reflects the behavior of the method,
since these methods check for `NaN` and `NaT` values in addition to `None`
values.

## Example
```python
import pandas as pd

animals_df = pd.read_csv("animals.csv")
pd.isnull(animals_df)
```

Use instead:
```python
import pandas as pd

animals_df = pd.read_csv("animals.csv")
pd.isna(animals_df)
```

## References
- [Pandas documentation: `isnull`](https://pandas.pydata.org/docs/reference/api/pandas.isnull.html#pandas.isnull)
- [Pandas documentation: `isna`](https://pandas.pydata.org/docs/reference/api/pandas.isna.html#pandas.isna)

# pandas-use-of-dot-not-null (PD004)

Derived from the **pandas-vet** linter.

## What it does
Checks for uses of `.notnull` on Pandas objects.

## Why is this bad?
In the Pandas API, `.notna` and `.notnull` are equivalent. For consistency,
prefer `.notna` over `.notnull`.

As a name, `.notna` more accurately reflects the behavior of the method,
since these methods check for `NaN` and `NaT` values in addition to `None`
values.

## Example
```python
import pandas as pd

animals_df = pd.read_csv("animals.csv")
pd.notnull(animals_df)
```

Use instead:
```python
import pandas as pd

animals_df = pd.read_csv("animals.csv")
pd.notna(animals_df)
```

## References
- [Pandas documentation: `notnull`](https://pandas.pydata.org/docs/reference/api/pandas.notnull.html#pandas.notnull)
- [Pandas documentation: `notna`](https://pandas.pydata.org/docs/reference/api/pandas.notna.html#pandas.notna)

# pandas-use-of-dot-ix (PD007)

Derived from the **pandas-vet** linter.

## What it does
Checks for uses of `.ix` on Pandas objects.

## Why is this bad?
The `.ix` method is deprecated as its behavior is ambiguous. Specifically,
it's often unclear whether `.ix` is indexing by label or by ordinal position.

Instead, prefer the `.loc` method for label-based indexing, and `.iloc` for
ordinal indexing.

## Example
```python
import pandas as pd

students_df = pd.read_csv("students.csv")
students_df.ix[0]  # 0th row or row with label 0?
```

Use instead:
```python
import pandas as pd

students_df = pd.read_csv("students.csv")
students_df.iloc[0]  # 0th row.
```

## References
- [Pandas release notes: Deprecate `.ix`](https://pandas.pydata.org/pandas-docs/version/0.20/whatsnew.html#deprecate-ix)
- [Pandas documentation: `loc`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)
- [Pandas documentation: `iloc`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html)

# pandas-use-of-dot-at (PD008)

Derived from the **pandas-vet** linter.

## What it does
Checks for uses of `.at` on Pandas objects.

## Why is this bad?
The `.at` method selects a single value from a `DataFrame` or Series based on
a label index, and is slightly faster than using `.loc`. However, `.loc` is
more idiomatic and versatile, as it can be used to select multiple values at
once.

If performance is an important consideration, convert the object to a NumPy
array, which will provide a much greater performance boost than using `.at`
over `.loc`.

## Example
```python
import pandas as pd

students_df = pd.read_csv("students.csv")
students_df.at["Maria"]
```

Use instead:
```python
import pandas as pd

students_df = pd.read_csv("students.csv")
students_df.loc["Maria"]
```

## References
- [Pandas documentation: `loc`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)
- [Pandas documentation: `at`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html)

# pandas-use-of-dot-iat (PD009)

Derived from the **pandas-vet** linter.

## What it does
Checks for uses of `.iat` on Pandas objects.

## Why is this bad?
The `.iat` method selects a single value from a `DataFrame` or Series based
on an ordinal index, and is slightly faster than using `.iloc`. However,
`.iloc` is more idiomatic and versatile, as it can be used to select
multiple values at once.

If performance is an important consideration, convert the object to a NumPy
array, which will provide a much greater performance boost than using `.iat`
over `.iloc`.

## Example
```python
import pandas as pd

students_df = pd.read_csv("students.csv")
students_df.iat[0]
```

Use instead:
```python
import pandas as pd

students_df = pd.read_csv("students.csv")
students_df.iloc[0]
```

Or, using NumPy:
```python
import numpy as np
import pandas as pd

students_df = pd.read_csv("students.csv")
students_df.to_numpy()[0]
```

## References
- [Pandas documentation: `iloc`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html)
- [Pandas documentation: `iat`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iat.html)

# pandas-use-of-dot-pivot-or-unstack (PD010)

Derived from the **pandas-vet** linter.

## What it does
Checks for uses of `.pivot` or `.unstack` on Pandas objects.

## Why is this bad?
Prefer `.pivot_table` to `.pivot` or `.unstack`. `.pivot_table` is more general
and can be used to implement the same behavior as `.pivot` and `.unstack`.

## Example
```python
import pandas as pd

df = pd.read_csv("cities.csv")
df.pivot(index="city", columns="year", values="population")
```

Use instead:
```python
import pandas as pd

df = pd.read_csv("cities.csv")
df.pivot_table(index="city", columns="year", values="population")
```

## References
- [Pandas documentation: Reshaping and pivot tables](https://pandas.pydata.org/docs/user_guide/reshaping.html)
- [Pandas documentation: `pivot_table`](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html#pandas.pivot_table)

# pandas-use-of-dot-values (PD011)

Derived from the **pandas-vet** linter.

## What it does
Checks for uses of `.values` on Pandas Series and Index objects.

## Why is this bad?
The `.values` attribute is ambiguous as its return type is unclear. As
such, it is no longer recommended by the Pandas documentation.

Instead, use `.to_numpy()` to return a NumPy array, or `.array` to return a
Pandas `ExtensionArray`.

## Example
```python
import pandas as pd

animals = pd.read_csv("animals.csv").values  # Ambiguous.
```

Use instead:
```python
import pandas as pd

animals = pd.read_csv("animals.csv").to_numpy()  # Explicit.
```

## References
- [Pandas documentation: Accessing the values in a Series or Index](https://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html#accessing-the-values-in-a-series-or-index)

# pandas-use-of-dot-read-table (PD012)

Derived from the **pandas-vet** linter.

## What it does
Checks for uses of `pd.read_table` to read CSV files.

## Why is this bad?
In the Pandas API, `pd.read_csv` and `pd.read_table` are equivalent apart
from their default separator: `pd.read_csv` defaults to a comma (`,`),
while `pd.read_table` defaults to a tab (`\t`) as the default separator.

Prefer `pd.read_csv` over `pd.read_table` when reading comma-separated
data (like CSV files), as it is more idiomatic.

## Example
```python
import pandas as pd

cities_df = pd.read_table("cities.csv", sep=",")
```

Use instead:
```python
import pandas as pd

cities_df = pd.read_csv("cities.csv")
```

## References
- [Pandas documentation: `read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv)
- [Pandas documentation: `read_table`](https://pandas.pydata.org/docs/reference/api/pandas.read_table.html#pandas.read_table)

# pandas-use-of-dot-stack (PD013)

Derived from the **pandas-vet** linter.

## What it does
Checks for uses of `.stack` on Pandas objects.

## Why is this bad?
Prefer `.melt` to `.stack`, which has the same functionality but with
support for direct column renaming and no dependence on `MultiIndex`.

## Example
```python
import pandas as pd

cities_df = pd.read_csv("cities.csv")
cities_df.set_index("city").stack()
```

Use instead:
```python
import pandas as pd

cities_df = pd.read_csv("cities.csv")
cities_df.melt(id_vars="city")
```

## References
- [Pandas documentation: `melt`](https://pandas.pydata.org/docs/reference/api/pandas.melt.html)
- [Pandas documentation: `stack`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html)

# pandas-use-of-pd-merge (PD015)

Derived from the **pandas-vet** linter.

## What it does
Checks for uses of `pd.merge` on Pandas objects.

## Why is this bad?
In Pandas, the `.merge` method (exposed on, e.g., `DataFrame` objects) and
the `pd.merge` function (exposed on the Pandas module) are equivalent.

For consistency, prefer calling `.merge` on an object over calling
`pd.merge` on the Pandas module, as the former is more idiomatic.

Further, `pd.merge` is not a method, but a function, which prohibits it
from being used in method chains, a common pattern in Pandas code.

## Example
```python
import pandas as pd

cats_df = pd.read_csv("cats.csv")
dogs_df = pd.read_csv("dogs.csv")
rabbits_df = pd.read_csv("rabbits.csv")
pets_df = pd.merge(pd.merge(cats_df, dogs_df), rabbits_df)  # Hard to read.
```

Use instead:
```python
import pandas as pd

cats_df = pd.read_csv("cats.csv")
dogs_df = pd.read_csv("dogs.csv")
rabbits_df = pd.read_csv("rabbits.csv")
pets_df = cats_df.merge(dogs_df).merge(rabbits_df)
```

## References
- [Pandas documentation: `merge`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html#pandas.DataFrame.merge)
- [Pandas documentation: `pd.merge`](https://pandas.pydata.org/docs/reference/api/pandas.merge.html#pandas.merge)

# pandas-nunique-constant-series-check (PD101)

Derived from the **pandas-vet** linter.

## What it does
Check for uses of `.nunique()` to check if a Pandas Series is constant
(i.e., contains only one unique value).

## Why is this bad?
`.nunique()` is computationally inefficient for checking if a Series is
constant.

Consider, for example, a Series of length `n` that consists of increasing
integer values (e.g., 1, 2, 3, 4). The `.nunique()` method will iterate
over the entire Series to count the number of unique values. But in this
case, we can detect that the Series is non-constant after visiting the
first two values, which are non-equal.

In general, `.nunique()` requires iterating over the entire Series, while a
more efficient approach allows short-circuiting the operation as soon as a
non-equal value is found.

Instead of calling `.nunique()`, convert the Series to a NumPy array, and
check if all values in the array are equal to the first observed value.

## Example
```python
import pandas as pd

data = pd.Series(range(1000))
if data.nunique() <= 1:
    print("Series is constant")
```

Use instead:
```python
import pandas as pd

data = pd.Series(range(1000))
array = data.to_numpy()
if array.shape[0] == 0 or (array[0] == array).all():
    print("Series is constant")
```

## References
- [Pandas Cookbook: "Constant Series"](https://pandas.pydata.org/docs/user_guide/cookbook.html#constant-series)
- [Pandas documentation: `nunique`](https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html)

# pandas-df-variable-name (PD901)

Derived from the **pandas-vet** linter.

## Removed

This rule has been removed as it's highly opinionated and overly strict in most cases.

## What it does
Checks for assignments to the variable `df`.

## Why is this bad?
Although `df` is a common variable name for a Pandas `DataFrame`, it's not a
great variable name for production code, as it's non-descriptive and
prone to name conflicts.

Instead, use a more descriptive variable name.

## Example
```python
import pandas as pd

df = pd.read_csv("animals.csv")
```

Use instead:
```python
import pandas as pd

animals = pd.read_csv("animals.csv")
```

# unnecessary-list-cast (PERF101)

Derived from the **Perflint** linter.

Fix is always available.

## What it does
Checks for explicit casts to `list` on for-loop iterables.

## Why is this bad?
Using a `list()` call to eagerly iterate over an already-iterable type
(like a tuple, list, or set) is inefficient, as it forces Python to create
a new list unnecessarily.

Removing the `list()` call will not change the behavior of the code, but
may improve performance.

Note that, as with all `perflint` rules, this is only intended as a
micro-optimization, and will have a negligible impact on performance in
most cases.

## Example
```python
items = (1, 2, 3)
for i in list(items):
    print(i)
```

Use instead:
```python
items = (1, 2, 3)
for i in items:
    print(i)
```

## Fix safety
This rule's fix is marked as unsafe if there's comments in the
`list()` call, as comments may be removed.

For example, the fix would be marked as unsafe in the following case:
```python
items = (1, 2, 3)
for i in list(  # comment
    items
):
    print(i)
```

# incorrect-dict-iterator (PERF102)

Derived from the **Perflint** linter.

Fix is always available.

## What it does
Checks for uses of `dict.items()` that discard either the key or the value
when iterating over the dictionary.

## Why is this bad?
If you only need the keys or values of a dictionary, you should use
`dict.keys()` or `dict.values()` respectively, instead of `dict.items()`.
These specialized methods are more efficient than `dict.items()`, as they
avoid allocating tuples for every item in the dictionary. They also
communicate the intent of the code more clearly.

Note that, as with all `perflint` rules, this is only intended as a
micro-optimization, and will have a negligible impact on performance in
most cases.

## Example
```python
obj = {"a": 1, "b": 2}
for key, value in obj.items():
    print(value)
```

Use instead:
```python
obj = {"a": 1, "b": 2}
for value in obj.values():
    print(value)
```

## Fix safety
The fix does not perform any type analysis and, as such, may suggest an
incorrect fix if the object in question does not duck-type as a mapping
(e.g., if it is missing a `.keys()` or `.values()` method, or if those
methods behave differently than they do on standard mapping types).

# try-except-in-loop (PERF203)

Derived from the **Perflint** linter.

## What it does
Checks for uses of except handling via `try`-`except` within `for` and
`while` loops.

## Why is this bad?
Exception handling via `try`-`except` blocks incurs some performance
overhead, regardless of whether an exception is raised.

To optimize your code, two techniques are possible:
1. Refactor your code to put the entire loop into the `try`-`except` block,
   rather than wrapping each iteration in a separate `try`-`except` block.
2. Use "Look Before You Leap" idioms that attempt to avoid exceptions
   being raised in the first place, avoiding the need to use `try`-`except`
   blocks in the first place.

This rule is only enforced for Python versions prior to 3.11, which
introduced "zero-cost" exception handling. However, note that even on
Python 3.11 and newer, refactoring your code to avoid exception handling in
tight loops can provide a significant speedup in some cases, as zero-cost
exception handling is only zero-cost in the "happy path" where no exception
is raised in the `try`-`except` block.

As with all `perflint` rules, this is only intended as a
micro-optimization. In many cases, it will have a negligible impact on
performance.

## Example
```python
string_numbers: list[str] = ["1", "2", "three", "4", "5"]

# `try`/`except` that could be moved out of the loop:
int_numbers: list[int] = []
for num in string_numbers:
    try:
        int_numbers.append(int(num))
    except ValueError as e:
        print(f"Couldn't convert to integer: {e}")
        break

# `try`/`except` used when "look before you leap" idioms could be used:
number_names: dict[int, str] = {1: "one", 3: "three", 4: "four"}
for number in range(5):
    try:
        name = number_names[number]
    except KeyError:
        continue
    else:
        print(f"The name of {number} is {name}")
```

Use instead:
```python
string_numbers: list[str] = ["1", "2", "three", "4", "5"]

int_numbers: list[int] = []
try:
    for num in string_numbers:
        int_numbers.append(int(num))
except ValueError as e:
    print(f"Couldn't convert to integer: {e}")

number_names: dict[int, str] = {1: "one", 3: "three", 4: "four"}
for number in range(5):
    name = number_names.get(number)
    if name is not None:
        print(f"The name of {number} is {name}")
```

## Options
- `target-version`

# manual-list-comprehension (PERF401)

Derived from the **Perflint** linter.

Fix is sometimes available.

## What it does
Checks for `for` loops that can be replaced by a list comprehension.

## Why is this bad?
When creating a transformed list from an existing list using a for-loop,
prefer a list comprehension. List comprehensions are more readable and
more performant.

Using the below as an example, the list comprehension is ~10% faster on
Python 3.11, and ~25% faster on Python 3.10.

Note that, as with all `perflint` rules, this is only intended as a
micro-optimization, and will have a negligible impact on performance in
most cases.

## Example
```python
original = list(range(10000))
filtered = []
for i in original:
    if i % 2:
        filtered.append(i)
```

Use instead:
```python
original = list(range(10000))
filtered = [x for x in original if x % 2]
```

If you're appending to an existing list, use the `extend` method instead:
```python
original = list(range(10000))
filtered.extend(x for x in original if x % 2)
```

# manual-list-copy (PERF402)

Derived from the **Perflint** linter.

## What it does
Checks for `for` loops that can be replaced by a making a copy of a list.

## Why is this bad?
When creating a copy of an existing list using a for-loop, prefer
`list` or `list.copy` instead. Making a direct copy is more readable and
more performant.

Using the below as an example, the `list`-based copy is ~2x faster on
Python 3.11.

Note that, as with all `perflint` rules, this is only intended as a
micro-optimization, and will have a negligible impact on performance in
most cases.

## Example
```python
original = list(range(10000))
filtered = []
for i in original:
    filtered.append(i)
```

Use instead:
```python
original = list(range(10000))
filtered = list(original)
```

# manual-dict-comprehension (PERF403)

Derived from the **Perflint** linter.

Fix is sometimes available.

## What it does
Checks for `for` loops that can be replaced by a dictionary comprehension.

## Why is this bad?
When creating or extending a dictionary in a for-loop, prefer a dictionary
comprehension. Comprehensions are more readable and more performant.

For example, when comparing `{x: x for x in list(range(1000))}` to the `for`
loop version, the comprehension is ~10% faster on Python 3.11.

Note that, as with all `perflint` rules, this is only intended as a
micro-optimization, and will have a negligible impact on performance in
most cases.

## Example
```python
pairs = (("a", 1), ("b", 2))
result = {}
for x, y in pairs:
    if y % 2:
        result[x] = y
```

Use instead:
```python
pairs = (("a", 1), ("b", 2))
result = {x: y for x, y in pairs if y % 2}
```

If you're appending to an existing dictionary, use the `update` method instead:
```python
pairs = (("a", 1), ("b", 2))
result.update({x: y for x, y in pairs if y % 2})
```

# mixed-spaces-and-tabs (E101)

Derived from the **pycodestyle** linter.

## What it does
Checks for mixed tabs and spaces in indentation.

## Why is this bad?
Never mix tabs and spaces.

The most popular way of indenting Python is with spaces only. The
second-most popular way is with tabs only. Code indented with a
mixture of tabs and spaces should be converted to using spaces
exclusively.

## Example
```python
if a == 0:\n        a = 1\n\tb = 1
```

Use instead:
```python
if a == 0:\n    a = 1\n    b = 1
```

# indentation-with-invalid-multiple (E111)

Derived from the **pycodestyle** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for indentation with a non-multiple of 4 spaces.

## Why is this bad?
According to [PEP 8], 4 spaces per indentation level should be preferred.

## Example
```python
if True:
   a = 1
```

Use instead:
```python
if True:
    a = 1
```

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces consistent indentation, making the rule redundant.

The rule is also incompatible with the [formatter] when using
`indent-width` with a value other than `4`.

## Options
- `indent-width`

[PEP 8]: https://peps.python.org/pep-0008/#indentation
[formatter]:https://docs.astral.sh/ruff/formatter/

# no-indented-block (E112)

Derived from the **pycodestyle** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for indented blocks that are lacking indentation.

## Why is this bad?
All indented blocks should be indented; otherwise, they are not valid
Python syntax.

## Example
```python
for item in items:
pass
```

Use instead:
```python
for item in items:
    pass
```

[PEP 8]: https://peps.python.org/pep-0008/#indentation

# unexpected-indentation (E113)

Derived from the **pycodestyle** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for unexpected indentation.

## Why is this bad?
Indentation outside of a code block is not valid Python syntax.

## Example
```python
a = 1
    b = 2
```

Use instead:
```python
a = 1
b = 2
```

[PEP 8]: https://peps.python.org/pep-0008/#indentation

# indentation-with-invalid-multiple-comment (E114)

Derived from the **pycodestyle** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for indentation of comments with a non-multiple of 4 spaces.

## Why is this bad?
According to [PEP 8], 4 spaces per indentation level should be preferred.

## Example
```python
if True:
   # a = 1
    ...
```

Use instead:
```python
if True:
    # a = 1
    ...
```

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces consistent indentation, making the rule redundant.

The rule is also incompatible with the [formatter] when using
`indent-width` with a value other than `4`.

## Options
- `indent-width`

[PEP 8]: https://peps.python.org/pep-0008/#indentation
[formatter]:https://docs.astral.sh/ruff/formatter/

# no-indented-block-comment (E115)

Derived from the **pycodestyle** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for comments in a code blocks that are lacking indentation.

## Why is this bad?
Comments within an indented block should themselves be indented, to
indicate that they are part of the block.

## Example
```python
for item in items:
# Hi
    pass
```

Use instead:
```python
for item in items:
    # Hi
    pass
```

[PEP 8]: https://peps.python.org/pep-0008/#indentation

# unexpected-indentation-comment (E116)

Derived from the **pycodestyle** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for unexpected indentation of comment.

## Why is this bad?
Comments should match the indentation of the containing code block.

## Example
```python
a = 1
    # b = 2
```

Use instead:
```python
a = 1
# b = 2
```

[PEP 8]: https://peps.python.org/pep-0008/#indentation

# over-indented (E117)

Derived from the **pycodestyle** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for over-indented code.

## Why is this bad?
According to [PEP 8], 4 spaces per indentation level should be preferred. Increased
indentation can lead to inconsistent formatting, which can hurt
readability.

## Example
```python
for item in items:
      pass
```

Use instead:
```python
for item in items:
    pass
```

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces consistent indentation, making the rule redundant.

[PEP 8]: https://peps.python.org/pep-0008/#indentation
[formatter]:https://docs.astral.sh/ruff/formatter/

# whitespace-after-open-bracket (E201)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for the use of extraneous whitespace after "(", "[" or "{".

## Why is this bad?
[PEP 8] recommends the omission of whitespace in the following cases:
- "Immediately inside parentheses, brackets or braces."
- "Immediately before a comma, semicolon, or colon."

## Example
```python
spam( ham[1], {eggs: 2})
spam(ham[ 1], {eggs: 2})
spam(ham[1], { eggs: 2})
```

Use instead:
```python
spam(ham[1], {eggs: 2})
```

[PEP 8]: https://peps.python.org/pep-0008/#pet-peeves

# whitespace-before-close-bracket (E202)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for the use of extraneous whitespace before ")", "]" or "}".

## Why is this bad?
[PEP 8] recommends the omission of whitespace in the following cases:
- "Immediately inside parentheses, brackets or braces."
- "Immediately before a comma, semicolon, or colon."

## Example
```python
spam(ham[1], {eggs: 2} )
spam(ham[1 ], {eggs: 2})
spam(ham[1], {eggs: 2 })
```

Use instead:
```python
spam(ham[1], {eggs: 2})
```

[PEP 8]: https://peps.python.org/pep-0008/#pet-peeves

# whitespace-before-punctuation (E203)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for the use of extraneous whitespace before ",", ";" or ":".

## Why is this bad?
[PEP 8] recommends the omission of whitespace in the following cases:
- "Immediately inside parentheses, brackets or braces."
- "Immediately before a comma, semicolon, or colon."

## Example
```python
if x == 4: print(x, y); x, y = y , x
```

Use instead:
```python
if x == 4: print(x, y); x, y = y, x
```

[PEP 8]: https://peps.python.org/pep-0008/#pet-peeves

# whitespace-after-decorator (E204)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for trailing whitespace after a decorator's opening `@`.

## Why is this bad?
Including whitespace after the `@` symbol is not compliant with
[PEP 8].

## Example

```python
@ decorator
def func():
   pass
```

Use instead:
```python
@decorator
def func():
  pass
```

[PEP 8]: https://peps.python.org/pep-0008/#maximum-line-length

# whitespace-before-parameters (E211)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous whitespace immediately preceding an open parenthesis
or bracket.

## Why is this bad?
According to [PEP 8], open parentheses and brackets should not be preceded
by any trailing whitespace.

## Example
```python
spam (1)
```

Use instead:
```python
spam(1)
```

[PEP 8]: https://peps.python.org/pep-0008/#pet-peeves

# multiple-spaces-before-operator (E221)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous whitespace before an operator.

## Why is this bad?
According to [PEP 8], operators should be surrounded by at most a single space on either
side.

## Example
```python
a = 4  + 5
```

Use instead:
```python
a = 4 + 5
```

[PEP 8]: https://peps.python.org/pep-0008/#whitespace-in-expressions-and-statements

# multiple-spaces-after-operator (E222)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous whitespace after an operator.

## Why is this bad?
According to [PEP 8], operators should be surrounded by at most a single space on either
side.

## Example
```python
a = 4 +  5
```

Use instead:
```python
a = 4 + 5
```

[PEP 8]: https://peps.python.org/pep-0008/#whitespace-in-expressions-and-statements

# tab-before-operator (E223)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous tabs before an operator.

## Why is this bad?
According to [PEP 8], operators should be surrounded by at most a single space on either
side.

## Example
```python
a = 4\t+ 5
```

Use instead:
```python
a = 4 + 5
```

[PEP 8]: https://peps.python.org/pep-0008/#whitespace-in-expressions-and-statements

# tab-after-operator (E224)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous tabs after an operator.

## Why is this bad?
According to [PEP 8], operators should be surrounded by at most a single space on either
side.

## Example
```python
a = 4 +\t5
```

Use instead:
```python
a = 4 + 5
```

[PEP 8]: https://peps.python.org/pep-0008/#whitespace-in-expressions-and-statements

# missing-whitespace-around-operator (E225)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for missing whitespace around all operators.

## Why is this bad?
According to [PEP 8], there should be one space before and after all
assignment (`=`), augmented assignment (`+=`, `-=`, etc.), comparison,
and Booleans operators.

## Example
```python
if number==42:
    print('you have found the meaning of life')
```

Use instead:
```python
if number == 42:
    print('you have found the meaning of life')
```

[PEP 8]: https://peps.python.org/pep-0008/#pet-peeves

# missing-whitespace-around-arithmetic-operator (E226)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for missing whitespace arithmetic operators.

## Why is this bad?
[PEP 8] recommends never using more than one space, and always having the
same amount of whitespace on both sides of a binary operator.

For consistency, this rule enforces one space before and after an
arithmetic operator (`+`, `-`, `/`, and `*`).

(Note that [PEP 8] suggests only adding whitespace around the operator with
the lowest precedence, but that authors should "use [their] own judgment".)

## Example
```python
number = 40+2
```

Use instead:
```python
number = 40 + 2
```

[PEP 8]: https://peps.python.org/pep-0008/#other-recommendations

# missing-whitespace-around-bitwise-or-shift-operator (E227)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for missing whitespace around bitwise and shift operators.

## Why is this bad?
[PEP 8] recommends never using more than one space, and always having the
same amount of whitespace on both sides of a binary operator.

For consistency, this rule enforces one space before and after bitwise and
shift operators (`<<`, `>>`, `&`, `|`, `^`).

(Note that [PEP 8] suggests only adding whitespace around the operator with
the lowest precedence, but that authors should "use [their] own judgment".)

## Example
```python
x = 128<<1
```

Use instead:
```python
x = 128 << 1
```

[PEP 8]: https://peps.python.org/pep-0008/#other-recommendations

# missing-whitespace-around-modulo-operator (E228)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for missing whitespace around the modulo operator.

## Why is this bad?
[PEP 8] recommends never using more than one space, and always having the
same amount of whitespace on both sides of a binary operator.

For consistency, this rule enforces one space before and after a modulo
operator (`%`).

(Note that [PEP 8] suggests only adding whitespace around the operator with
the lowest precedence, but that authors should "use [their] own judgment".)

## Example
```python
remainder = 10%2
```

Use instead:
```python
remainder = 10 % 2
```

[PEP 8]: https://peps.python.org/pep-0008/#other-recommendations

# missing-whitespace (E231)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for missing whitespace after `,`, `;`, and `:`.

## Why is this bad?
Missing whitespace after `,`, `;`, and `:` makes the code harder to read.

## Example
```python
a = (1,2)
```

Use instead:
```python
a = (1, 2)
```

# multiple-spaces-after-comma (E241)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous whitespace after a comma.

## Why is this bad?
Consistency is good. This rule helps ensure you have a consistent
formatting style across your project.

## Example
```python
a = 4,    5
```

Use instead:
```python
a = 4, 5
```

# tab-after-comma (E242)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous tabs after a comma.

## Why is this bad?
Commas should be followed by one space, never tabs.

## Example
```python
a = 4,\t5
```

Use instead:
```python
a = 4, 5
```

# unexpected-spaces-around-keyword-parameter-equals (E251)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for missing whitespace around the equals sign in an unannotated
function keyword parameter.

## Why is this bad?
According to [PEP 8], there should be no spaces around the equals sign in a
keyword parameter, if it is unannotated:

> Dont use spaces around the = sign when used to indicate a keyword
> argument, or when used to indicate a default value for an unannotated
> function parameter.

## Example
```python
def add(a = 0) -> int:
    return a + 1
```

Use instead:
```python
def add(a=0) -> int:
    return a + 1
```

[PEP 8]: https://peps.python.org/pep-0008/#whitespace-in-expressions-and-statements

# missing-whitespace-around-parameter-equals (E252)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for missing whitespace around the equals sign in an annotated
function keyword parameter.

## Why is this bad?
According to [PEP 8], the spaces around the equals sign in a keyword
parameter should only be omitted when the parameter is unannotated:

> Dont use spaces around the = sign when used to indicate a keyword
> argument, or when used to indicate a default value for an unannotated
> function parameter.

## Example
```python
def add(a: int=0) -> int:
    return a + 1
```

Use instead:
```python
def add(a: int = 0) -> int:
    return a + 1
```

[PEP 8]: https://peps.python.org/pep-0008/#whitespace-in-expressions-and-statements

# too-few-spaces-before-inline-comment (E261)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks if inline comments are separated by at least two spaces.

## Why is this bad?
An inline comment is a comment on the same line as a statement.

Per [PEP 8], inline comments should be separated by at least two spaces from
the preceding statement.

## Example
```python
x = x + 1 # Increment x
```

Use instead:
```python
x = x + 1  # Increment x
x = x + 1    # Increment x
```

[PEP 8]: https://peps.python.org/pep-0008/#comments

# no-space-after-inline-comment (E262)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks if one space is used after inline comments.

## Why is this bad?
An inline comment is a comment on the same line as a statement.

Per [PEP 8], inline comments should start with a # and a single space.

## Example
```python
x = x + 1  #Increment x
x = x + 1  #  Increment x
x = x + 1  # \xa0Increment x
```

Use instead:
```python
x = x + 1  # Increment x
x = x + 1    # Increment x
```

[PEP 8]: https://peps.python.org/pep-0008/#comments

# no-space-after-block-comment (E265)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for block comments that lack a single space after the leading `#` character.

## Why is this bad?
Per [PEP 8], "Block comments generally consist of one or more paragraphs built
out of complete sentences, with each sentence ending in a period."

Block comments should start with a `#` followed by a single space.

Shebangs (lines starting with `#!`, at the top of a file) are exempt from this
rule.

## Example
```python
#Block comment
```

Use instead:
```python
# Block comment
```

[PEP 8]: https://peps.python.org/pep-0008/#comments

# multiple-leading-hashes-for-block-comment (E266)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for block comments that start with multiple leading `#` characters.

## Why is this bad?
Per [PEP 8], "Block comments generally consist of one or more paragraphs built
out of complete sentences, with each sentence ending in a period."

Each line of a block comment should start with a `#` followed by a single space.

Shebangs (lines starting with `#!`, at the top of a file) are exempt from this
rule.

## Example
```python
### Block comment
```

Use instead:
```python
# Block comment
```

Alternatively, this rule makes an exception for comments that consist
solely of `#` characters, as in:

```python
##############
# Block header
##############
```

[PEP 8]: https://peps.python.org/pep-0008/#comments

# multiple-spaces-after-keyword (E271)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous whitespace after keywords.

## Why is this bad?


## Example
```python
True and  False
```

Use instead:
```python
True and False
```

# multiple-spaces-before-keyword (E272)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous whitespace before keywords.

## Why is this bad?


## Example
```python
x  and y
```

Use instead:
```python
x and y
```

# tab-after-keyword (E273)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous tabs after keywords.

## Why is this bad?


## Example
```python
True and\tFalse
```

Use instead:
```python
True and False
```

# tab-before-keyword (E274)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous tabs before keywords.

## Why is this bad?


## Example
```python
True\tand False
```

Use instead:
```python
True and False
```

# missing-whitespace-after-keyword (E275)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for missing whitespace after keywords.

## Why is this bad?
Missing whitespace after keywords makes the code harder to read.

## Example
```python
if(True):
    pass
```

Use instead:
```python
if (True):
    pass
```

## References
- [Python documentation: Keywords](https://docs.python.org/3/reference/lexical_analysis.html#keywords)

# blank-line-between-methods (E301)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for missing blank lines between methods of a class.

## Why is this bad?
PEP 8 recommends exactly one blank line between methods of a class.

## Example
```python
class MyClass(object):
    def func1():
        pass
    def func2():
        pass
```

Use instead:
```python
class MyClass(object):
    def func1():
        pass

    def func2():
        pass
```

## Typing stub files (`.pyi`)
The typing style guide recommends to not use blank lines between methods except to group
them. That's why this rule is not enabled in typing stub files.

## References
- [PEP 8: Blank Lines](https://peps.python.org/pep-0008/#blank-lines)
- [Flake 8 rule](https://www.flake8rules.com/rules/E301.html)
- [Typing Style Guide](https://typing.python.org/en/latest/guides/writing_stubs.html#blank-lines)

# blank-lines-top-level (E302)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for missing blank lines between top level functions and classes.

## Why is this bad?
PEP 8 recommends exactly two blank lines between top level functions and classes.

The rule respects the [`lint.isort.lines-after-imports`] setting when
determining the required number of blank lines between top-level `import`
statements and function or class definitions for compatibility with isort.

## Example
```python
def func1():
    pass
def func2():
    pass
```

Use instead:
```python
def func1():
    pass


def func2():
    pass
```

## Typing stub files (`.pyi`)
The typing style guide recommends to not use blank lines between classes and functions except to group
them. That's why this rule is not enabled in typing stub files.

## Options
- `lint.isort.lines-after-imports`

## References
- [PEP 8: Blank Lines](https://peps.python.org/pep-0008/#blank-lines)
- [Flake 8 rule](https://www.flake8rules.com/rules/E302.html)
- [Typing Style Guide](https://typing.python.org/en/latest/guides/writing_stubs.html#blank-lines)

# too-many-blank-lines (E303)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous blank lines.

## Why is this bad?
PEP 8 recommends using blank lines as follows:
- No more than two blank lines between top-level statements.
- No more than one blank line between non-top-level statements.

## Example
```python
def func1():
    pass



def func2():
    pass
```

Use instead:
```python
def func1():
    pass


def func2():
    pass
```

## Typing stub files (`.pyi`)
The rule allows at most one blank line in typing stub files in accordance to the typing style guide recommendation.

Note: The rule respects the following `isort` settings when determining the maximum number of blank lines allowed between two statements:

* [`lint.isort.lines-after-imports`]: For top-level statements directly following an import statement.
* [`lint.isort.lines-between-types`]: For `import` statements directly following a `from ... import ...` statement or vice versa.

## Options
- `lint.isort.lines-after-imports`
- `lint.isort.lines-between-types`

## References
- [PEP 8: Blank Lines](https://peps.python.org/pep-0008/#blank-lines)
- [Flake 8 rule](https://www.flake8rules.com/rules/E303.html)
- [Typing Style Guide](https://typing.python.org/en/latest/guides/writing_stubs.html#blank-lines)

# blank-line-after-decorator (E304)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for extraneous blank line(s) after function decorators.

## Why is this bad?
There should be no blank lines between a decorator and the object it is decorating.

## Example
```python
class User(object):

    @property

    def name(self):
        pass
```

Use instead:
```python
class User(object):

    @property
    def name(self):
        pass
```

## References
- [PEP 8: Blank Lines](https://peps.python.org/pep-0008/#blank-lines)
- [Flake 8 rule](https://www.flake8rules.com/rules/E304.html)

# blank-lines-after-function-or-class (E305)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for missing blank lines after the end of function or class.

## Why is this bad?
PEP 8 recommends using blank lines as follows:
- Two blank lines are expected between functions and classes
- One blank line is expected between methods of a class.

## Example
```python
class User(object):
    pass
user = User()
```

Use instead:
```python
class User(object):
    pass


user = User()
```

## Typing stub files (`.pyi`)
The typing style guide recommends to not use blank lines between statements except to group
them. That's why this rule is not enabled in typing stub files.

## References
- [PEP 8: Blank Lines](https://peps.python.org/pep-0008/#blank-lines)
- [Flake 8 rule](https://www.flake8rules.com/rules/E305.html)
- [Typing Style Guide](https://typing.python.org/en/latest/guides/writing_stubs.html#blank-lines)

# blank-lines-before-nested-definition (E306)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for 1 blank line between nested function or class definitions.

## Why is this bad?
PEP 8 recommends using blank lines as follows:
- Two blank lines are expected between functions and classes
- One blank line is expected between methods of a class.

## Example
```python
def outer():
    def inner():
        pass
    def inner2():
        pass
```

Use instead:
```python
def outer():
    def inner():
        pass

    def inner2():
        pass
```

## Typing stub files (`.pyi`)
The typing style guide recommends to not use blank lines between classes and functions except to group
them. That's why this rule is not enabled in typing stub files.

## References
- [PEP 8: Blank Lines](https://peps.python.org/pep-0008/#blank-lines)
- [Flake 8 rule](https://www.flake8rules.com/rules/E306.html)
- [Typing Style Guide](https://typing.python.org/en/latest/guides/writing_stubs.html#blank-lines)

# multiple-imports-on-one-line (E401)

Derived from the **pycodestyle** linter.

Fix is sometimes available.

## What it does
Check for multiple imports on one line.

## Why is this bad?
According to [PEP 8], "imports should usually be on separate lines."

## Example
```python
import sys, os
```

Use instead:
```python
import os
import sys
```

[PEP 8]: https://peps.python.org/pep-0008/#imports

# module-import-not-at-top-of-file (E402)

Derived from the **pycodestyle** linter.

## What it does
Checks for imports that are not at the top of the file.

## Why is this bad?
According to [PEP 8], "imports are always put at the top of the file, just after any
module comments and docstrings, and before module globals and constants."

This rule makes an exception for both `sys.path` modifications (allowing for
`sys.path.insert`, `sys.path.append`, etc.) and `os.environ` modifications
between imports.

## Example
```python
"One string"
"Two string"
a = 1
import os
from sys import x
```

Use instead:
```python
import os
from sys import x

"One string"
"Two string"
a = 1
```

## Notebook behavior
For Jupyter notebooks, this rule checks for imports that are not at the top of a *cell*.

[PEP 8]: https://peps.python.org/pep-0008/#imports

# line-too-long (E501)

Derived from the **pycodestyle** linter.

## What it does
Checks for lines that exceed the specified maximum character length.

## Why is this bad?
Overlong lines can hurt readability. [PEP 8], for example, recommends
limiting lines to 79 characters. By default, this rule enforces a limit
of 88 characters for compatibility with Black and the Ruff formatter,
though that limit is configurable via the [`line-length`] setting.

In the interest of pragmatism, this rule makes a few exceptions when
determining whether a line is overlong. Namely, it:

1. Ignores lines that consist of a single "word" (i.e., without any
   whitespace between its characters).
2. Ignores lines that end with a URL, as long as the URL starts before
   the line-length threshold.
3. Ignores line that end with a pragma comment (e.g., `# type: ignore`
   or `# noqa`), as long as the pragma comment starts before the
   line-length threshold. That is, a line will not be flagged as
   overlong if a pragma comment _causes_ it to exceed the line length.
   (This behavior aligns with that of the Ruff formatter.)
4. Ignores SPDX license identifiers and copyright notices
   (e.g., `# SPDX-License-Identifier: MIT`), which are machine-readable
   and should _not_ wrap over multiple lines.

If [`lint.pycodestyle.ignore-overlong-task-comments`] is `true`, this rule will
also ignore comments that start with any of the specified [`lint.task-tags`]
(e.g., `# TODO:`).

## Example
```python
my_function(param1, param2, param3, param4, param5, param6, param7, param8, param9, param10)
```

Use instead:
```python
my_function(
    param1, param2, param3, param4, param5,
    param6, param7, param8, param9, param10
)
```

## Error suppression
Hint: when suppressing `E501` errors within multi-line strings (like
docstrings), the `noqa` directive should come at the end of the string
(after the closing triple quote), and will apply to the entire string, like
so:

```python
"""Lorem ipsum dolor sit amet.

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor.
"""  # noqa: E501
```

## Options
- `line-length`
- `lint.task-tags`
- `lint.pycodestyle.ignore-overlong-task-comments`
- `lint.pycodestyle.max-line-length`

[PEP 8]: https://peps.python.org/pep-0008/#maximum-line-length

# redundant-backslash (E502)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for redundant backslashes between brackets.

## Why is this bad?
Explicit line joins using a backslash are redundant between brackets.

## Example
```python
x = (2 + \
    2)
```

Use instead:
```python
x = (2 +
    2)
```

[PEP 8]: https://peps.python.org/pep-0008/#maximum-line-length

# multiple-statements-on-one-line-colon (E701)

Derived from the **pycodestyle** linter.

## What it does
Checks for compound statements (multiple statements on the same line).

## Why is this bad?
According to [PEP 8], "compound statements are generally discouraged".

## Example
```python
if foo == "blah": do_blah_thing()
```

Use instead:
```python
if foo == "blah":
    do_blah_thing()
```

[PEP 8]: https://peps.python.org/pep-0008/#other-recommendations

# multiple-statements-on-one-line-semicolon (E702)

Derived from the **pycodestyle** linter.

## What it does
Checks for multiline statements on one line.

## Why is this bad?
According to [PEP 8], including multi-clause statements on the same line is
discouraged.

## Example
```python
do_one(); do_two(); do_three()
```

Use instead:
```python
do_one()
do_two()
do_three()
```

[PEP 8]: https://peps.python.org/pep-0008/#other-recommendations

# useless-semicolon (E703)

Derived from the **pycodestyle** linter.

Fix is always available.

## What it does
Checks for statements that end with an unnecessary semicolon.

## Why is this bad?
A trailing semicolon is unnecessary and should be removed.

## Example
```python
do_four();  # useless semicolon
```

Use instead:
```python
do_four()
```

# none-comparison (E711)

Derived from the **pycodestyle** linter.

Fix is always available.

## What it does
Checks for comparisons to `None` which are not using the `is` operator.

## Why is this bad?
According to [PEP 8], "Comparisons to singletons like None should always be done with
`is` or `is not`, never the equality operators."

## Example
```python
if arg != None:
    pass
if None == arg:
    pass
```

Use instead:
```python
if arg is not None:
    pass
```

## Fix safety

This rule's fix is marked as unsafe, as it may alter runtime behavior when
used with libraries that override the `==`/`__eq__` or `!=`/`__ne__` operators.
In these cases, `is`/`is not` may not be equivalent to `==`/`!=`. For more
information, see [this issue].

[PEP 8]: https://peps.python.org/pep-0008/#programming-recommendations
[this issue]: https://github.com/astral-sh/ruff/issues/4560

# true-false-comparison (E712)

Derived from the **pycodestyle** linter.

Fix is always available.

## What it does
Checks for equality comparisons to boolean literals.

## Why is this bad?
[PEP 8] recommends against using the equality operators `==` and `!=` to
compare values to `True` or `False`.

Instead, use `if cond:` or `if not cond:` to check for truth values.

If you intend to check if a value is the boolean literal `True` or `False`,
consider using `is` or `is not` to check for identity instead.

## Example
```python
if foo == True:
    ...

if bar == False:
    ...
```

Use instead:
```python
if foo:
    ...

if not bar:
    ...
```

## Fix safety

This rule's fix is marked as unsafe, as it may alter runtime behavior when
used with libraries that override the `==`/`__eq__` or `!=`/`__ne__` operators.
In these cases, `is`/`is not` may not be equivalent to `==`/`!=`. For more
information, see [this issue].

[PEP 8]: https://peps.python.org/pep-0008/#programming-recommendations
[this issue]: https://github.com/astral-sh/ruff/issues/4560

# not-in-test (E713)

Derived from the **pycodestyle** linter.

Fix is always available.

## What it does
Checks for membership tests using `not {element} in {collection}`.

## Why is this bad?
Testing membership with `{element} not in {collection}` is more readable.

## Example
```python
Z = not X in Y
if not X.B in Y:
    pass
```

Use instead:
```python
Z = X not in Y
if X.B not in Y:
    pass
```

# not-is-test (E714)

Derived from the **pycodestyle** linter.

Fix is always available.

## What it does
Checks for identity comparisons using `not {foo} is {bar}`.

## Why is this bad?
According to [PEP8], testing for an object's identity with `is not` is more
readable.

## Example
```python
if not X is Y:
    pass
Z = not X.B is Y
```

Use instead:
```python
if X is not Y:
    pass
Z = X.B is not Y
```

[PEP8]: https://peps.python.org/pep-0008/#programming-recommendations

# type-comparison (E721)

Derived from the **pycodestyle** linter.

## What it does
Checks for object type comparisons using `==` and other comparison
operators.

## Why is this bad?
Unlike a direct type comparison, `isinstance` will also check if an object
is an instance of a class or a subclass thereof.

If you want to check for an exact type match, use `is` or `is not`.

## Known problems
When using libraries that override the `==` (`__eq__`) operator (such as NumPy,
Pandas, and SQLAlchemy), this rule may produce false positives, as converting
from `==` to `is` or `is not` will change the behavior of the code.

For example, the following operations are _not_ equivalent:
```python
import numpy as np

np.array([True, False]) == False
# array([False,  True])

np.array([True, False]) is False
# False
```

## Example
```python
if type(obj) == type(1):
    pass

if type(obj) == int:
    pass
```

Use instead:
```python
if isinstance(obj, int):
    pass
```

# bare-except (E722)

Derived from the **pycodestyle** linter.

## What it does
Checks for bare `except` catches in `try`-`except` statements.

## Why is this bad?
A bare `except` catches `BaseException` which includes
`KeyboardInterrupt`, `SystemExit`, `Exception`, and others. Catching
`BaseException` can make it hard to interrupt the program (e.g., with
Ctrl-C) and can disguise other problems.

## Example
```python
try:
    raise KeyboardInterrupt("You probably don't mean to break CTRL-C.")
except:
    print("But a bare `except` will ignore keyboard interrupts.")
```

Use instead:
```python
try:
    do_something_that_might_break()
except MoreSpecificException as e:
    handle_error(e)
```

If you actually need to catch an unknown error, use `Exception` which will
catch regular program errors but not important system exceptions.

```python
def run_a_function(some_other_fn):
    try:
        some_other_fn()
    except Exception as e:
        print(f"How exceptional! {e}")
```

## References
- [Python documentation: Exception hierarchy](https://docs.python.org/3/library/exceptions.html#exception-hierarchy)
- [Google Python Style Guide: "Exceptions"](https://google.github.io/styleguide/pyguide.html#24-exceptions)

# lambda-assignment (E731)

Derived from the **pycodestyle** linter.

Fix is sometimes available.

## What it does
Checks for lambda expressions which are assigned to a variable.

## Why is this bad?
Per PEP 8, you should "Always use a def statement instead of an assignment
statement that binds a lambda expression directly to an identifier."

Using a `def` statement leads to better tracebacks, and the assignment
itself negates the primary benefit of using a `lambda` expression (i.e.,
that it can be embedded inside another expression).

## Example
```python
f = lambda x: 2 * x
```

Use instead:
```python
def f(x):
    return 2 * x
```

[PEP 8]: https://peps.python.org/pep-0008/#programming-recommendations

# ambiguous-variable-name (E741)

Derived from the **pycodestyle** linter.

## What it does
Checks for the use of the characters 'l', 'O', or 'I' as variable names.

Note: This rule is automatically disabled for all stub files
(files with `.pyi` extensions). The rule has little relevance for authors
of stubs: a well-written stub should aim to faithfully represent the
interface of the equivalent .py file as it exists at runtime, including any
ambiguously named variables in the runtime module.

## Why is this bad?
In some fonts, these characters are indistinguishable from the
numerals one and zero. When tempted to use 'l', use 'L' instead.

## Example
```python
l = 0
O = 123
I = 42
```

Use instead:
```python
L = 0
o = 123
i = 42
```

# ambiguous-class-name (E742)

Derived from the **pycodestyle** linter.

## What it does
Checks for the use of the characters 'l', 'O', or 'I' as class names.

## Why is this bad?
In some fonts, these characters are indistinguishable from the
numerals one and zero. When tempted to use 'l', use 'L' instead.

## Example

```python
class I(object): ...
```

Use instead:

```python
class Integer(object): ...
```

# ambiguous-function-name (E743)

Derived from the **pycodestyle** linter.

## What it does
Checks for the use of the characters 'l', 'O', or 'I' as function names.

## Why is this bad?
In some fonts, these characters are indistinguishable from the
numerals one and zero. When tempted to use 'l', use 'L' instead.

## Example

```python
def l(x): ...
```

Use instead:

```python
def long_name(x): ...
```

# io-error (E902)

Derived from the **pycodestyle** linter.

## What it does
This is not a regular diagnostic; instead, it's raised when a file cannot be read
from disk.

## Why is this bad?
An `IOError` indicates an error in the development setup. For example, the user may
not have permissions to read a given file, or the filesystem may contain a broken
symlink.

## Example
On Linux or macOS:
```shell
$ echo 'print("hello world!")' > a.py
$ chmod 000 a.py
$ ruff a.py
a.py:1:1: E902 Permission denied (os error 13)
Found 1 error.
```

## References
- [UNIX Permissions introduction](https://mason.gmu.edu/~montecin/UNIXpermiss.htm)
- [Command Line Basics: Symbolic Links](https://www.digitalocean.com/community/tutorials/workflow-symbolic-links)

# syntax-error (E999)

Derived from the **pycodestyle** linter.

## Removed
This rule has been removed. Syntax errors will
always be shown regardless of whether this rule is selected or not.

## What it does
Checks for code that contains syntax errors.

## Why is this bad?
Code with syntax errors cannot be executed. Such errors are likely a
mistake.

## Example
```python
x =
```

Use instead:
```python
x = 1
```

## References
- [Python documentation: Syntax Errors](https://docs.python.org/3/tutorial/errors.html#syntax-errors)

# tab-indentation (W191)

Derived from the **pycodestyle** linter.

## What it does
Checks for indentation that uses tabs.

## Why is this bad?
According to [PEP 8], spaces are preferred over tabs (unless used to remain
consistent with code that is already indented with tabs).

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces consistent indentation, making the rule redundant.

The rule is also incompatible with the [formatter] when using
`format.indent-style="tab"`.

[PEP 8]: https://peps.python.org/pep-0008/#tabs-or-spaces
[formatter]: https://docs.astral.sh/ruff/formatter

# trailing-whitespace (W291)

Derived from the **pycodestyle** linter.

Fix is always available.

## What it does
Checks for superfluous trailing whitespace.

## Why is this bad?
According to [PEP 8], "avoid trailing whitespace anywhere. Because its usually
invisible, it can be confusing"

## Example
```python
spam(1) \n#
```

Use instead:
```python
spam(1)\n#
```

## Fix safety

This fix is marked unsafe if the whitespace is inside a multiline string,
as removing it changes the string's content.

[PEP 8]: https://peps.python.org/pep-0008/#other-recommendations

# missing-newline-at-end-of-file (W292)

Derived from the **pycodestyle** linter.

Fix is always available.

## What it does
Checks for files missing a new line at the end of the file.

## Why is this bad?
Trailing blank lines in a file are superfluous.

However, the last line of the file should end with a newline.

## Example
```python
spam(1)
```

Use instead:
```python
spam(1)\n
```

# blank-line-with-whitespace (W293)

Derived from the **pycodestyle** linter.

Fix is always available.

## What it does
Checks for superfluous whitespace in blank lines.

## Why is this bad?
According to [PEP 8], "avoid trailing whitespace anywhere. Because its usually
invisible, it can be confusing"

## Example
```python
class Foo(object):\n    \n    bang = 12
```

Use instead:
```python
class Foo(object):\n\n    bang = 12
```

## Fix safety

This fix is marked unsafe if the whitespace is inside a multiline string,
as removing it changes the string's content.

[PEP 8]: https://peps.python.org/pep-0008/#other-recommendations

# too-many-newlines-at-end-of-file (W391)

Derived from the **pycodestyle** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for files with multiple trailing blank lines.

In the case of notebooks, this check is applied to
each cell separately.

## Why is this bad?
Trailing blank lines in a file are superfluous.

However, the last line of the file should end with a newline.

## Example
```python
spam(1)\n\n\n
```

Use instead:
```python
spam(1)\n
```

# doc-line-too-long (W505)

Derived from the **pycodestyle** linter.

## What it does
Checks for doc lines that exceed the specified maximum character length.

## Why is this bad?
For flowing long blocks of text (docstrings or comments), overlong lines
can hurt readability. [PEP 8], for example, recommends that such lines be
limited to 72 characters, while this rule enforces the limit specified by
the [`lint.pycodestyle.max-doc-length`] setting. (If no value is provided, this
rule will be ignored, even if it's added to your `--select` list.)

In the context of this rule, a "doc line" is defined as a line consisting
of either a standalone comment or a standalone string, like a docstring.

In the interest of pragmatism, this rule makes a few exceptions when
determining whether a line is overlong. Namely, it:

1. Ignores lines that consist of a single "word" (i.e., without any
   whitespace between its characters).
2. Ignores lines that end with a URL, as long as the URL starts before
   the line-length threshold.
3. Ignores line that end with a pragma comment (e.g., `# type: ignore`
   or `# noqa`), as long as the pragma comment starts before the
   line-length threshold. That is, a line will not be flagged as
   overlong if a pragma comment _causes_ it to exceed the line length.
   (This behavior aligns with that of the Ruff formatter.)

If [`lint.pycodestyle.ignore-overlong-task-comments`] is `true`, this rule will
also ignore comments that start with any of the specified [`lint.task-tags`]
(e.g., `# TODO:`).

## Example
```python
def function(x):
    """Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis auctor purus ut ex fermentum, at maximus est hendrerit."""
```

Use instead:
```python
def function(x):
    """
    Lorem ipsum dolor sit amet, consectetur adipiscing elit.
    Duis auctor purus ut ex fermentum, at maximus est hendrerit.
    """
```

## Error suppression
Hint: when suppressing `W505` errors within multi-line strings (like
docstrings), the `noqa` directive should come at the end of the string
(after the closing triple quote), and will apply to the entire string, like
so:

```python
"""Lorem ipsum dolor sit amet.

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor.
"""  # noqa: W505
```

## Options
- `lint.task-tags`
- `lint.pycodestyle.max-doc-length`
- `lint.pycodestyle.ignore-overlong-task-comments`

[PEP 8]: https://peps.python.org/pep-0008/#maximum-line-length

# invalid-escape-sequence (W605)

Derived from the **pycodestyle** linter.

Fix is always available.

## What it does
Checks for invalid escape sequences.

## Why is this bad?
Invalid escape sequences are deprecated in Python 3.6.

## Example
```python
regex = "\.png$"
```

Use instead:
```python
regex = r"\.png$"
```

Or, if the string already contains a valid escape sequence:
```python
value = "new line\nand invalid escape \_ here"
```

Use instead:
```python
value = "new line\nand invalid escape \\_ here"
```

## References
- [Python documentation: String and Bytes literals](https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals)

# docstring-extraneous-parameter (DOC102)

Derived from the **pydoclint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for function docstrings that include parameters which are not
in the function signature.

## Why is this bad?
If a docstring documents a parameter which is not in the function signature,
it can be misleading to users and/or a sign of incomplete documentation or
refactors.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.
        acceleration: Rate of change of speed.

    Returns:
        Speed as distance divided by time.
    """
    return distance / time
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.
    """
    return distance / time
```

# docstring-missing-returns (DOC201)

Derived from the **pydoclint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for functions with `return` statements that do not have "Returns"
sections in their docstrings.

## Why is this bad?
A missing "Returns" section is a sign of incomplete documentation.

This rule is not enforced for abstract methods or functions that only return
`None`. It is also ignored for "stub functions": functions where the body only
consists of `pass`, `...`, `raise NotImplementedError`, or similar.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.
    """
    return distance / time
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.
    """
    return distance / time
```

# docstring-extraneous-returns (DOC202)

Derived from the **pydoclint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for function docstrings with unnecessary "Returns" sections.

## Why is this bad?
A function without an explicit `return` statement should not have a
"Returns" section in its docstring.

This rule is not enforced for abstract methods. It is also ignored for
"stub functions": functions where the body only consists of `pass`, `...`,
`raise NotImplementedError`, or similar.

## Example
```python
def say_hello(n: int) -> None:
    """Says hello to the user.

    Args:
        n: Number of times to say hello.

    Returns:
        Doesn't return anything.
    """
    for _ in range(n):
        print("Hello!")
```

Use instead:
```python
def say_hello(n: int) -> None:
    """Says hello to the user.

    Args:
        n: Number of times to say hello.
    """
    for _ in range(n):
        print("Hello!")
```

# docstring-missing-yields (DOC402)

Derived from the **pydoclint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for functions with `yield` statements that do not have "Yields" sections in
their docstrings.

## Why is this bad?
A missing "Yields" section is a sign of incomplete documentation.

This rule is not enforced for abstract methods or functions that only yield `None`.
It is also ignored for "stub functions": functions where the body only consists
of `pass`, `...`, `raise NotImplementedError`, or similar.

## Example
```python
def count_to_n(n: int) -> int:
    """Generate integers up to *n*.

    Args:
        n: The number at which to stop counting.
    """
    for i in range(1, n + 1):
        yield i
```

Use instead:
```python
def count_to_n(n: int) -> int:
    """Generate integers up to *n*.

    Args:
        n: The number at which to stop counting.

    Yields:
        int: The number we're at in the count.
    """
    for i in range(1, n + 1):
        yield i
```

# docstring-extraneous-yields (DOC403)

Derived from the **pydoclint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for function docstrings with unnecessary "Yields" sections.

## Why is this bad?
A function that doesn't yield anything should not have a "Yields" section
in its docstring.

This rule is not enforced for abstract methods. It is also ignored for
"stub functions": functions where the body only consists of `pass`, `...`,
`raise NotImplementedError`, or similar.

## Example
```python
def say_hello(n: int) -> None:
    """Says hello to the user.

    Args:
        n: Number of times to say hello.

    Yields:
        Doesn't yield anything.
    """
    for _ in range(n):
        print("Hello!")
```

Use instead:
```python
def say_hello(n: int) -> None:
    """Says hello to the user.

    Args:
        n: Number of times to say hello.
    """
    for _ in range(n):
        print("Hello!")
```

# docstring-missing-exception (DOC501)

Derived from the **pydoclint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for function docstrings that do not document all explicitly raised
exceptions.

## Why is this bad?
A function should document all exceptions that are directly raised in some
circumstances. Failing to document an exception that could be raised
can be misleading to users and/or a sign of incomplete documentation.

This rule is not enforced for abstract methods. It is also ignored for
"stub functions": functions where the body only consists of `pass`, `...`,
`raise NotImplementedError`, or similar.

## Example
```python
class FasterThanLightError(ArithmeticError): ...


def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
class FasterThanLightError(ArithmeticError): ...


def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.

    Raises:
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

# docstring-extraneous-exception (DOC502)

Derived from the **pydoclint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for function docstrings that state that exceptions could be raised
even though they are not directly raised in the function body.

## Why is this bad?
Some conventions prefer non-explicit exceptions be omitted from the
docstring.

This rule is not enforced for abstract methods. It is also ignored for
"stub functions": functions where the body only consists of `pass`, `...`,
`raise NotImplementedError`, or similar.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.

    Raises:
        ZeroDivisionError: Divided by zero.
    """
    return distance / time
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.
    """
    return distance / time
```

## Known issues
It may often be desirable to document *all* exceptions that a function
could possibly raise, even those which are not explicitly raised using
`raise` statements in the function body.

# undocumented-public-module (D100)

Derived from the **pydocstyle** linter.

## What it does
Checks for undocumented public module definitions.

## Why is this bad?
Public modules should be documented via docstrings to outline their purpose
and contents.

Generally, module docstrings should describe the purpose of the module and
list the classes, exceptions, functions, and other objects that are exported
by the module, alongside a one-line summary of each.

If the module is a script, the docstring should be usable as its "usage"
message.

If the codebase adheres to a standard format for module docstrings, follow
that format for consistency.

## Example

```python
class FasterThanLightError(ZeroDivisionError): ...


def calculate_speed(distance: float, time: float) -> float: ...
```

Use instead:

```python
"""Utility functions and classes for calculating speed.

This module provides:
- FasterThanLightError: exception when FTL speed is calculated;
- calculate_speed: calculate speed given distance and time.
"""


class FasterThanLightError(ZeroDivisionError): ...


def calculate_speed(distance: float, time: float) -> float: ...
```

## Notebook behavior
This rule is ignored for Jupyter Notebooks.

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# undocumented-public-class (D101)

Derived from the **pydocstyle** linter.

## What it does
Checks for undocumented public class definitions.

## Why is this bad?
Public classes should be documented via docstrings to outline their purpose
and behavior.

Generally, a class docstring should describe the class's purpose and list
its public attributes and methods.

If the codebase adheres to a standard format for class docstrings, follow
that format for consistency.

## Example
```python
class Player:
    def __init__(self, name: str, points: int = 0) -> None:
        self.name: str = name
        self.points: int = points

    def add_points(self, points: int) -> None:
        self.points += points
```

Use instead (in the NumPy docstring format):
```python
class Player:
    """A player in the game.

    Attributes
    ----------
    name : str
        The name of the player.
    points : int
        The number of points the player has.

    Methods
    -------
    add_points(points: int) -> None
        Add points to the player's score.
    """

    def __init__(self, name: str, points: int = 0) -> None:
        self.name: str = name
        self.points: int = points

    def add_points(self, points: int) -> None:
        self.points += points
```

Or (in the Google docstring format):
```python
class Player:
    """A player in the game.

    Attributes:
        name: The name of the player.
        points: The number of points the player has.
    """

    def __init__(self, name: str, points: int = 0) -> None:
        self.name: str = name
        self.points: int = points

    def add_points(self, points: int) -> None:
        self.points += points
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# undocumented-public-method (D102)

Derived from the **pydocstyle** linter.

## What it does
Checks for undocumented public method definitions.

## Why is this bad?
Public methods should be documented via docstrings to outline their purpose
and behavior.

Generally, a method docstring should describe the method's behavior,
arguments, side effects, exceptions, return values, and any other
information that may be relevant to the user.

If the codebase adheres to a standard format for method docstrings, follow
that format for consistency.

This rule exempts methods decorated with [`@typing.override`][override],
since it is a common practice to document a method on a superclass but not
on an overriding method in a subclass.

## Example

```python
class Cat(Animal):
    def greet(self, happy: bool = True):
        if happy:
            print("Meow!")
        else:
            raise ValueError("Tried to greet an unhappy cat.")
```

Use instead (in the NumPy docstring format):

```python
class Cat(Animal):
    def greet(self, happy: bool = True):
        """Print a greeting from the cat.

        Parameters
        ----------
        happy : bool, optional
            Whether the cat is happy, is True by default.

        Raises
        ------
        ValueError
            If the cat is not happy.
        """
        if happy:
            print("Meow!")
        else:
            raise ValueError("Tried to greet an unhappy cat.")
```

Or (in the Google docstring format):

```python
class Cat(Animal):
    def greet(self, happy: bool = True):
        """Print a greeting from the cat.

        Args:
            happy: Whether the cat is happy, is True by default.

        Raises:
            ValueError: If the cat is not happy.
        """
        if happy:
            print("Meow!")
        else:
            raise ValueError("Tried to greet an unhappy cat.")
```

## Options
- `lint.pydocstyle.ignore-decorators`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[override]: https://docs.python.org/3/library/typing.html#typing.override

# undocumented-public-function (D103)

Derived from the **pydocstyle** linter.

## What it does
Checks for undocumented public function definitions.

## Why is this bad?
Public functions should be documented via docstrings to outline their
purpose and behavior.

Generally, a function docstring should describe the function's behavior,
arguments, side effects, exceptions, return values, and any other
information that may be relevant to the user.

If the codebase adheres to a standard format for function docstrings, follow
that format for consistency.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead (using the NumPy docstring format):
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    -------
    float
        Speed as distance divided by time.

    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Or, using the Google docstring format:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.

    Raises:
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.ignore-decorators`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Style Python Docstrings](https://google.github.io/styleguide/pyguide.html#s3.8-comments-and-docstrings)

# undocumented-public-package (D104)

Derived from the **pydocstyle** linter.

## What it does
Checks for undocumented public package definitions.

## Why is this bad?
Public packages should be documented via docstrings to outline their
purpose and contents.

Generally, package docstrings should list the modules and subpackages that
are exported by the package.

If the codebase adheres to a standard format for package docstrings, follow
that format for consistency.

## Example
```python
__all__ = ["Player", "Game"]
```

Use instead:
```python
"""Game and player management package.

This package provides classes for managing players and games.
"""

__all__ = ["player", "game"]
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Style Python Docstrings](https://google.github.io/styleguide/pyguide.html#s3.8-comments-and-docstrings)

# undocumented-magic-method (D105)

Derived from the **pydocstyle** linter.

## What it does
Checks for undocumented magic method definitions.

## Why is this bad?
Magic methods (methods with names that start and end with double
underscores) are used to implement operator overloading and other special
behavior. Such methods should be documented via docstrings to
outline their behavior.

Generally, magic method docstrings should describe the method's behavior,
arguments, side effects, exceptions, return values, and any other
information that may be relevant to the user.

If the codebase adheres to a standard format for method docstrings, follow
that format for consistency.

## Example
```python
class Cat(Animal):
    def __str__(self) -> str:
        return f"Cat: {self.name}"


cat = Cat("Dusty")
print(cat)  # "Cat: Dusty"
```

Use instead:
```python
class Cat(Animal):
    def __str__(self) -> str:
        """Return a string representation of the cat."""
        return f"Cat: {self.name}"


cat = Cat("Dusty")
print(cat)  # "Cat: Dusty"
```

## Options
- `lint.pydocstyle.ignore-decorators`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Style Python Docstrings](https://google.github.io/styleguide/pyguide.html#s3.8-comments-and-docstrings)

# undocumented-public-nested-class (D106)

Derived from the **pydocstyle** linter.

## What it does
Checks for undocumented public class definitions, for nested classes.

## Why is this bad?
Public classes should be documented via docstrings to outline their
purpose and behavior.

Nested classes do not inherit the docstring of their enclosing class, so
they should have their own docstrings.

If the codebase adheres to a standard format for class docstrings, follow
that format for consistency.

## Example

```python
class Foo:
    """Class Foo."""

    class Bar: ...


bar = Foo.Bar()
bar.__doc__  # None
```

Use instead:

```python
class Foo:
    """Class Foo."""

    class Bar:
        """Class Bar."""


bar = Foo.Bar()
bar.__doc__  # "Class Bar."
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Style Python Docstrings](https://google.github.io/styleguide/pyguide.html#s3.8-comments-and-docstrings)

# undocumented-public-init (D107)

Derived from the **pydocstyle** linter.

## What it does
Checks for public `__init__` method definitions that are missing
docstrings.

## Why is this bad?
Public `__init__` methods are used to initialize objects. `__init__`
methods should be documented via docstrings to describe the method's
behavior, arguments, side effects, exceptions, and any other information
that may be relevant to the user.

If the codebase adheres to a standard format for `__init__` method docstrings,
follow that format for consistency.

## Example
```python
class City:
    def __init__(self, name: str, population: int) -> None:
        self.name: str = name
        self.population: int = population
```

Use instead:
```python
class City:
    def __init__(self, name: str, population: int) -> None:
        """Initialize a city with a name and population."""
        self.name: str = name
        self.population: int = population
```

## Options
- `lint.pydocstyle.ignore-decorators`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Style Python Docstrings](https://google.github.io/styleguide/pyguide.html#s3.8-comments-and-docstrings)

# unnecessary-multiline-docstring (D200)

Derived from the **pydocstyle** linter.

Fix is sometimes available.

## What it does
Checks for single-line docstrings that are broken across multiple lines.

## Why is this bad?
[PEP 257] recommends that docstrings that _can_ fit on one line should be
formatted on a single line, for consistency and readability.

## Example
```python
def average(values: list[float]) -> float:
    """
    Return the mean of the given values.
    """
```

Use instead:
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values."""
```

## Fix safety
The fix is marked as unsafe because it could affect tools that parse docstrings,
documentation generators, or custom introspection utilities that rely on
specific docstring formatting.

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)

[PEP 257]: https://peps.python.org/pep-0257/

# blank-line-before-function (D201)

Derived from the **pydocstyle** linter.

Fix is sometimes available.

## What it does
Checks for docstrings on functions that are separated by one or more blank
lines from the function definition.

## Why is this bad?
Remove any blank lines between the function definition and its docstring,
for consistency.

## Example
```python
def average(values: list[float]) -> float:

    """Return the mean of the given values."""
```

Use instead:
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values."""
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# blank-line-after-function (D202)

Derived from the **pydocstyle** linter.

Fix is sometimes available.

## What it does
Checks for docstrings on functions that are separated by one or more blank
lines from the function body.

## Why is this bad?
Remove any blank lines between the function body and the function
docstring, for consistency.

## Example
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values."""

    return sum(values) / len(values)
```

Use instead:
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values."""
    return sum(values) / len(values)
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# incorrect-blank-line-before-class (D203)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for docstrings on class definitions that are not preceded by a
blank line.

## Why is this bad?
Use a blank line to separate the docstring from the class definition, for
consistency.

This rule may not apply to all projects; its applicability is a matter of
convention. By default, this rule is disabled when using the `google`,
`numpy`, and `pep257` conventions.

For an alternative, see [D211].

## Example

```python
class PhotoMetadata:
    """Metadata about a photo."""
```

Use instead:

```python
class PhotoMetadata:

    """Metadata about a photo."""
```

## Options
- `lint.pydocstyle.convention`

[D211]: https://docs.astral.sh/ruff/rules/blank-line-before-class

# incorrect-blank-line-after-class (D204)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for class methods that are not separated from the class's docstring
by a blank line.

## Why is this bad?
[PEP 257] recommends the use of a blank line to separate a class's
docstring from its methods.

This rule may not apply to all projects; its applicability is a matter of
convention. By default, this rule is enabled when using the `numpy` and `pep257`
conventions, and disabled when using the `google` convention.

## Example
```python
class PhotoMetadata:
    """Metadata about a photo."""
    def __init__(self, file: Path):
        ...
```

Use instead:
```python
class PhotoMetadata:
    """Metadata about a photo."""

    def __init__(self, file: Path):
        ...
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[PEP 257]: https://peps.python.org/pep-0257/

# missing-blank-line-after-summary (D205)

Derived from the **pydocstyle** linter.

Fix is sometimes available.

## What it does
Checks for docstring summary lines that are not separated from the docstring
description by one blank line.

## Why is this bad?
[PEP 257] recommends that multi-line docstrings consist of "a summary line
just like a one-line docstring, followed by a blank line, followed by a
more elaborate description."

## Example
```python
def sort_list(l: list[int]) -> list[int]:
    """Return a sorted copy of the list.
    Sort the list in ascending order and return a copy of the
    result using the bubble sort algorithm.
    """
```

Use instead:
```python
def sort_list(l: list[int]) -> list[int]:
    """Return a sorted copy of the list.

    Sort the list in ascending order and return a copy of the
    result using the bubble sort algorithm.
    """
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[PEP 257]: https://peps.python.org/pep-0257/

# docstring-tab-indentation (D206)

Derived from the **pydocstyle** linter.

## What it does
Checks for docstrings that are indented with tabs.

## Why is this bad?
[PEP 8] recommends using spaces over tabs for indentation.

## Example
```python
def sort_list(l: list[int]) -> list[int]:
    """Return a sorted copy of the list.

	Sort the list in ascending order and return a copy of the result using the bubble
	sort algorithm.
    """
```

Use instead:
```python
def sort_list(l: list[int]) -> list[int]:
    """Return a sorted copy of the list.

    Sort the list in ascending order and return a copy of the result using the bubble
    sort algorithm.
    """
```

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces consistent indentation, making the rule redundant.

The rule is also incompatible with the [formatter] when using
`format.indent-style="tab"`.

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[PEP 8]: https://peps.python.org/pep-0008/#tabs-or-spaces
[formatter]: https://docs.astral.sh/ruff/formatter

# under-indentation (D207)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for under-indented docstrings.

## Why is this bad?
[PEP 257] recommends that docstrings be indented to the same level as their
opening quotes. Avoid under-indenting docstrings, for consistency.

## Example
```python
def sort_list(l: list[int]) -> list[int]:
    """Return a sorted copy of the list.

Sort the list in ascending order and return a copy of the result using the bubble sort
algorithm.
    """
```

Use instead:
```python
def sort_list(l: list[int]) -> list[int]:
    """Return a sorted copy of the list.

    Sort the list in ascending order and return a copy of the result using the bubble
    sort algorithm.
    """
```

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces consistent indentation, making the rule redundant.

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[PEP 257]: https://peps.python.org/pep-0257/
[formatter]: https://docs.astral.sh/ruff/formatter/

# over-indentation (D208)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for over-indented docstrings.

## Why is this bad?
[PEP 257] recommends that docstrings be indented to the same level as their
opening quotes. Avoid over-indenting docstrings, for consistency.

## Example
```python
def sort_list(l: list[int]) -> list[int]:
    """Return a sorted copy of the list.

        Sort the list in ascending order and return a copy of the result using the
        bubble sort algorithm.
    """
```

Use instead:
```python
def sort_list(l: list[int]) -> list[int]:
    """Return a sorted copy of the list.

    Sort the list in ascending order and return a copy of the result using the bubble
    sort algorithm.
    """
```

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces consistent indentation, making the rule redundant.

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[PEP 257]: https://peps.python.org/pep-0257/
[formatter]:https://docs.astral.sh/ruff/formatter/

# new-line-after-last-paragraph (D209)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for multi-line docstrings whose closing quotes are not on their
own line.

## Why is this bad?
[PEP 257] recommends that the closing quotes of a multi-line docstring be
on their own line, for consistency and compatibility with documentation
tools that may need to parse the docstring.

## Example
```python
def sort_list(l: List[int]) -> List[int]:
    """Return a sorted copy of the list.

    Sort the list in ascending order and return a copy of the result using the
    bubble sort algorithm."""
```

Use instead:
```python
def sort_list(l: List[int]) -> List[int]:
    """Return a sorted copy of the list.

    Sort the list in ascending order and return a copy of the result using the bubble
    sort algorithm.
    """
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[PEP 257]: https://peps.python.org/pep-0257/

# surrounding-whitespace (D210)

Derived from the **pydocstyle** linter.

Fix is sometimes available.

## What it does
Checks for surrounding whitespace in docstrings.

## Why is this bad?
Remove surrounding whitespace from the docstring, for consistency.

## Example
```python
def factorial(n: int) -> int:
    """ Return the factorial of n. """
```

Use instead:
```python
def factorial(n: int) -> int:
    """Return the factorial of n."""
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# blank-line-before-class (D211)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for docstrings on class definitions that are preceded by a blank
line.

## Why is this bad?
Avoid introducing any blank lines between a class definition and its
docstring, for consistency.

This rule may not apply to all projects; its applicability is a matter of
convention. By default, this rule is enabled when using the `google`,
`numpy`, and `pep257` conventions.

For an alternative, see [D203].

## Example

```python
class PhotoMetadata:

    """Metadata about a photo."""
```

Use instead:

```python
class PhotoMetadata:
    """Metadata about a photo."""
```

## Options
- `lint.pydocstyle.convention`

[D203]: https://docs.astral.sh/ruff/rules/incorrect-blank-line-before-class

# multi-line-summary-first-line (D212)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for docstring summary lines that are not positioned on the first
physical line of the docstring.

## Why is this bad?
[PEP 257] recommends that multi-line docstrings consist of "a summary line
just like a one-line docstring, followed by a blank line, followed by a
more elaborate description."

The summary line should be located on the first physical line of the
docstring, immediately after the opening quotes.

This rule may not apply to all projects; its applicability is a matter of
convention. By default, this rule is enabled when using the `google`
convention, and disabled when using the `numpy` and `pep257` conventions.

For an alternative, see [D213].

## Example
```python
def sort_list(l: list[int]) -> list[int]:
    """
    Return a sorted copy of the list.

    Sort the list in ascending order and return a copy of the result using the
    bubble sort algorithm.
    """
```

Use instead:
```python
def sort_list(l: list[int]) -> list[int]:
    """Return a sorted copy of the list.

    Sort the list in ascending order and return a copy of the result using the bubble
    sort algorithm.
    """
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[D213]: https://docs.astral.sh/ruff/rules/multi-line-summary-second-line
[PEP 257]: https://peps.python.org/pep-0257

# multi-line-summary-second-line (D213)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for docstring summary lines that are not positioned on the second
physical line of the docstring.

## Why is this bad?
[PEP 257] recommends that multi-line docstrings consist of "a summary line
just like a one-line docstring, followed by a blank line, followed by a
more elaborate description."

The summary line should be located on the second physical line of the
docstring, immediately after the opening quotes and the blank line.

This rule may not apply to all projects; its applicability is a matter of
convention. By default, this rule is disabled when using the `google`,
`numpy`, and `pep257` conventions.

For an alternative, see [D212].

## Example
```python
def sort_list(l: list[int]) -> list[int]:
    """Return a sorted copy of the list.

    Sort the list in ascending order and return a copy of the result using the
    bubble sort algorithm.
    """
```

Use instead:
```python
def sort_list(l: list[int]) -> list[int]:
    """
    Return a sorted copy of the list.

    Sort the list in ascending order and return a copy of the result using the bubble
    sort algorithm.
    """
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[D212]: https://docs.astral.sh/ruff/rules/multi-line-summary-first-line
[PEP 257]: https://peps.python.org/pep-0257

# overindented-section (D214)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for over-indented sections in docstrings.

## Why is this bad?
This rule enforces a consistent style for docstrings with multiple
sections.

Multiline docstrings are typically composed of a summary line, followed by
a blank line, followed by a series of sections, each with a section header
and a section body. The convention is that all sections should use
consistent indentation. In each section, the header should match the
indentation of the docstring's opening quotes, and the body should be
indented one level further.

This rule is enabled when using the `numpy` and `google` conventions, and
disabled when using the `pep257` convention.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

        Args:
            distance: Distance traveled.
            time: Time spent traveling.

    Returns:
        Speed as distance divided by time.

    Raises:
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.

    Raises:
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# overindented-section-underline (D215)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for over-indented section underlines in docstrings.

## Why is this bad?
This rule enforces a consistent style for multiline numpy-style docstrings,
and helps prevent incorrect syntax in docstrings using reStructuredText.

Multiline numpy-style docstrings are typically composed of a summary line,
followed by a blank line, followed by a series of sections. Each section
has a section header and a section body, and there should be a series of
underline characters in the line following the header. The underline should
have the same indentation as the header.

This rule enforces a consistent style for multiline numpy-style docstrings
with sections. If your docstring uses reStructuredText, the rule also
helps protect against incorrect reStructuredText syntax, which would cause
errors if you tried to use a tool such as Sphinx to generate documentation
from the docstring.

This rule is enabled when using the `numpy` convention, and disabled when
using the `google` or `pep257` conventions.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
        ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
          -------
    float
        Speed as distance divided by time.

    Raises
      ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    -------
    float
        Speed as distance divided by time.

    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)

# triple-single-quotes (D300)

Derived from the **pydocstyle** linter.

Fix is sometimes available.

## What it does
Checks for docstrings that use `'''triple single quotes'''` instead of
`"""triple double quotes"""`.

## Why is this bad?
[PEP 257](https://peps.python.org/pep-0257/#what-is-a-docstring) recommends
the use of `"""triple double quotes"""` for docstrings, to ensure
consistency.

## Example
```python
def kos_root():
    '''Return the pathname of the KOS root directory.'''
```

Use instead:
```python
def kos_root():
    """Return the pathname of the KOS root directory."""
```

## Formatter compatibility
We recommend against using this rule alongside the [formatter]. The
formatter enforces consistent quotes, making the rule redundant.

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[formatter]: https://docs.astral.sh/ruff/formatter/

# escape-sequence-in-docstring (D301)

Derived from the **pydocstyle** linter.

Fix is sometimes available.

## What it does
Checks for docstrings that include backslashes, but are not defined as
raw string literals.

## Why is this bad?
In Python, backslashes are typically used to escape characters in strings.
In raw strings (those prefixed with an `r`), however, backslashes are
treated as literal characters.

[PEP 257](https://peps.python.org/pep-0257/#what-is-a-docstring) recommends
the use of raw strings (i.e., `r"""raw triple double quotes"""`) for
docstrings that include backslashes. The use of a raw string ensures that
any backslashes are treated as literal characters, and not as escape
sequences, which avoids confusion.

## Example
```python
def foobar():
    """Docstring for foo\bar."""


foobar.__doc__  # "Docstring for foar."
```

Use instead:
```python
def foobar():
    r"""Docstring for foo\bar."""


foobar.__doc__  # "Docstring for foo\bar."
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [Python documentation: String and Bytes literals](https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals)

# missing-trailing-period (D400)

Derived from the **pydocstyle** linter.

Fix is sometimes available.

## What it does
Checks for docstrings in which the first line does not end in a period.

## Why is this bad?
[PEP 257] recommends that the first line of a docstring is written in the
form of a command, ending in a period.

This rule may not apply to all projects; its applicability is a matter of
convention. By default, this rule is enabled when using the `numpy` and
`pep257` conventions, and disabled when using the `google` convention.

## Example
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values"""
```

Use instead:
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values."""
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[PEP 257]: https://peps.python.org/pep-0257/

# non-imperative-mood (D401)

Derived from the **pydocstyle** linter.

## What it does
Checks for docstring first lines that are not in an imperative mood.

## Why is this bad?
[PEP 257] recommends that the first line of a docstring be written in the
imperative mood, for consistency.

Hint: to rewrite the docstring in the imperative, phrase the first line as
if it were a command.

This rule may not apply to all projects; its applicability is a matter of
convention. By default, this rule is enabled when using the `numpy` and
`pep257` conventions, and disabled when using the `google` conventions.

## Example
```python
def average(values: list[float]) -> float:
    """Returns the mean of the given values."""
```

Use instead:
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values."""
```

## Options
- `lint.pydocstyle.convention`
- `lint.pydocstyle.property-decorators`
- `lint.pydocstyle.ignore-decorators`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)

[PEP 257]: https://peps.python.org/pep-0257/

# signature-in-docstring (D402)

Derived from the **pydocstyle** linter.

## What it does
Checks for function docstrings that include the function's signature in
the summary line.

## Why is this bad?
[PEP 257] recommends against including a function's signature in its
docstring. Instead, consider using type annotations as a form of
documentation for the function's parameters and return value.

This rule may not apply to all projects; its applicability is a matter of
convention. By default, this rule is enabled when using the `google` and
`pep257` conventions, and disabled when using the `numpy` convention.

## Example
```python
def foo(a, b):
    """foo(a: int, b: int) -> list[int]"""
```

Use instead:
```python
def foo(a: int, b: int) -> list[int]:
    """Return a list of a and b."""
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

[PEP 257]: https://peps.python.org/pep-0257/

# first-word-uncapitalized (D403)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for docstrings that do not start with a capital letter.

## Why is this bad?
The first non-whitespace character in a docstring should be
capitalized for grammatical correctness and consistency.

## Example
```python
def average(values: list[float]) -> float:
    """return the mean of the given values."""
```

Use instead:
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values."""
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# docstring-starts-with-this (D404)

Derived from the **pydocstyle** linter.

## What it does
Checks for docstrings that start with `This`.

## Why is this bad?
[PEP 257] recommends that the first line of a docstring be written in the
imperative mood, for consistency.

Hint: to rewrite the docstring in the imperative, phrase the first line as
if it were a command.

This rule may not apply to all projects; its applicability is a matter of
convention. By default, this rule is enabled when using the `numpy`
convention,, and disabled when using the `google` and `pep257` conventions.

## Example
```python
def average(values: list[float]) -> float:
    """This function returns the mean of the given values."""
```

Use instead:
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values."""
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)

[PEP 257]: https://peps.python.org/pep-0257/

# non-capitalized-section-name (D405)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for section headers in docstrings that do not begin with capital
letters.

## Why is this bad?
For stylistic consistency, all section headers in a docstring should be
capitalized.

Multiline docstrings are typically composed of a summary line, followed by
a blank line, followed by a series of sections. Each section typically has
a header and a body.

This rule is enabled when using the `numpy` and `google` conventions, and
disabled when using the `pep257` convention.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    args:
        distance: Distance traveled.
        time: Time spent traveling.

    returns:
        Speed as distance divided by time.

    raises:
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.

    Raises:
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# missing-new-line-after-section-name (D406)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for section headers in docstrings that are followed by non-newline
characters.

## Why is this bad?
This rule enforces a consistent style for multiline numpy-style docstrings.

Multiline numpy-style docstrings are typically composed of a summary line,
followed by a blank line, followed by a series of sections. Each section
has a section header and a section body. The section header should be
followed by a newline, rather than by some other character (like a colon).

This rule is enabled when using the `numpy` convention, and disabled
when using the `google` or `pep257` conventions.

## Example
```python
# The `Parameters`, `Returns` and `Raises` section headers are all followed
# by a colon in this function's docstring:
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters:
    -----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns:
    --------
    float
        Speed as distance divided by time.

    Raises:
    -------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    -------
    float
        Speed as distance divided by time.

    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)

# missing-dashed-underline-after-section (D407)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for section headers in docstrings that are not followed by
underlines.

## Why is this bad?
This rule enforces a consistent style for multiline numpy-style docstrings,
and helps prevent incorrect syntax in docstrings using reStructuredText.

Multiline numpy-style docstrings are typically composed of a summary line,
followed by a blank line, followed by a series of sections. Each section
has a section header and a section body, and the header should be followed
by a series of underline characters in the following line.

This rule enforces a consistent style for multiline numpy-style docstrings
with sections. If your docstring uses reStructuredText, the rule also
helps protect against incorrect reStructuredText syntax, which would cause
errors if you tried to use a tool such as Sphinx to generate documentation
from the docstring.

This rule is enabled when using the `numpy` convention, and disabled
when using the `google` or `pep257` conventions.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters

    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns

    float
        Speed as distance divided by time.

    Raises

    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    -------
    float
        Speed as distance divided by time.

    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)

# missing-section-underline-after-name (D408)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for section underlines in docstrings that are not on the line
immediately following the section name.

## Why is this bad?
This rule enforces a consistent style for multiline numpy-style docstrings,
and helps prevent incorrect syntax in docstrings using reStructuredText.

Multiline numpy-style docstrings are typically composed of a summary line,
followed by a blank line, followed by a series of sections. Each section
has a header and a body. There should be a series of underline characters
in the line immediately below the header.

This rule enforces a consistent style for multiline numpy-style docstrings
with sections. If your docstring uses reStructuredText, the rule also
helps protect against incorrect reStructuredText syntax, which would cause
errors if you tried to use a tool such as Sphinx to generate documentation
from the docstring.

This rule is enabled when using the `numpy` convention, and disabled
when using the `google` or `pep257` conventions.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters

    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns

    -------
    float
        Speed as distance divided by time.

    Raises

    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    -------
    float
        Speed as distance divided by time.

    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)

# mismatched-section-underline-length (D409)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for section underlines in docstrings that do not match the length of
the corresponding section header.

## Why is this bad?
This rule enforces a consistent style for multiline numpy-style docstrings,
and helps prevent incorrect syntax in docstrings using reStructuredText.

Multiline numpy-style docstrings are typically composed of a summary line,
followed by a blank line, followed by a series of sections. Each section
has a section header and a section body, and there should be a series of
underline characters in the line following the header. The length of the
underline should exactly match the length of the section header.

This rule enforces a consistent style for multiline numpy-style docstrings
with sections. If your docstring uses reStructuredText, the rule also
helps protect against incorrect reStructuredText syntax, which would cause
errors if you tried to use a tool such as Sphinx to generate documentation
from the docstring.

This rule is enabled when using the `numpy` convention, and disabled
when using the `google` or `pep257` conventions.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ---
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    ---
    float
        Speed as distance divided by time.

    Raises
    ---
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    -------
    float
        Speed as distance divided by time.

    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)

# no-blank-line-after-section (D410)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for docstring sections that are not separated by a single blank
line.

## Why is this bad?
This rule enforces consistency in your docstrings, and helps ensure
compatibility with documentation tooling.

Multiline docstrings are typically composed of a summary line, followed by
a blank line, followed by a series of sections, each with a section header
and a section body. If a multiline numpy-style or Google-style docstring
consists of multiple sections, each section should be separated by a single
blank line.

This rule is enabled when using the `numpy` and `google` conventions, and
disabled when using the `pep257` convention.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.
    Returns
    -------
    float
        Speed as distance divided by time.
    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    -------
    float
        Speed as distance divided by time.

    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Style Guide](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# no-blank-line-before-section (D411)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for docstring sections that are not separated by a blank line.

## Why is this bad?
This rule enforces consistency in numpy-style and Google-style docstrings,
and helps ensure compatibility with documentation tooling.

Multiline docstrings are typically composed of a summary line, followed by
a blank line, followed by a series of sections, each with a section header
and a section body. Sections should be separated by a single blank line.

This rule is enabled when using the `numpy` and `google` conventions, and
disabled when using the `pep257` convention.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.
    Returns
    -------
    float
        Speed as distance divided by time.
    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    -------
    float
        Speed as distance divided by time.

    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)

# blank-lines-between-header-and-content (D412)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for docstring sections that contain blank lines between a section
header and a section body.

## Why is this bad?
This rule enforces a consistent style for multiline docstrings.

Multiline docstrings are typically composed of a summary line, followed by
a blank line, followed by a series of sections, each with a section header
and a section body. There should be no blank lines between a section header
and a section body.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:

        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.

    Raises:
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.

    Raises:
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# missing-blank-line-after-last-section (D413)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for missing blank lines after the last section of a multiline
docstring.

## Why is this bad?
This rule enforces a consistent style for multiline docstrings.

Multiline docstrings are typically composed of a summary line, followed by
a blank line, followed by a series of sections, each with a section header
and a section body.

This rule may not apply to all projects; its applicability is a matter of
convention. By default, the rule is disabled when using the `google`,
`numpy`, and `pep257` conventions.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.
    Returns
    -------
    float
        Speed as distance divided by time.
    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    -------
    float
        Speed as distance divided by time.

    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.

    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)

# empty-docstring-section (D414)

Derived from the **pydocstyle** linter.

## What it does
Checks for docstrings with empty sections.

## Why is this bad?
An empty section in a multiline docstring likely indicates an unfinished
or incomplete docstring.

Multiline docstrings are typically composed of a summary line, followed by
a blank line, followed by a series of sections, each with a section header
and a section body. Each section body should be non-empty; empty sections
should either have content added to them, or be removed entirely.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    -------
    float
        Speed as distance divided by time.

    Raises
    ------
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Parameters
    ----------
    distance : float
        Distance traveled.
    time : float
        Time spent traveling.

    Returns
    -------
    float
        Speed as distance divided by time.

    Raises
    ------
    FasterThanLightError
        If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Style Guide](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# missing-terminal-punctuation (D415)

Derived from the **pydocstyle** linter.

Fix is sometimes available.

## What it does
Checks for docstrings in which the first line does not end in a punctuation
mark, such as a period, question mark, or exclamation point.

## Why is this bad?
The first line of a docstring should end with a period, question mark, or
exclamation point, for grammatical correctness and consistency.

This rule may not apply to all projects; its applicability is a matter of
convention. By default, this rule is enabled when using the `google`
convention, and disabled when using the `numpy` and `pep257` conventions.

## Example
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values"""
```

Use instead:
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values."""
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# missing-section-name-colon (D416)

Derived from the **pydocstyle** linter.

Fix is always available.

## What it does
Checks for docstring section headers that do not end with a colon.

## Why is this bad?
This rule enforces a consistent style for multiline Google-style
docstrings. If a multiline Google-style docstring consists of multiple
sections, each section header should end with a colon.

Multiline docstrings are typically composed of a summary line, followed by
a blank line, followed by a series of sections, each with a section header
and a section body.

This rule is enabled when using the `google` convention, and disabled when
using the `pep257` and `numpy` conventions.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args
        distance: Distance traveled.
        time: Time spent traveling.

    Returns
        Speed as distance divided by time.

    Raises
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.

    Raises:
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [Google Style Guide](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# undocumented-param (D417)

Derived from the **pydocstyle** linter.

## What it does
Checks for function docstrings that do not include documentation for all
parameters in the function.

## Why is this bad?
This rule helps prevent you from leaving Google-style docstrings unfinished
or incomplete. Multiline Google-style docstrings should describe all
parameters for the function they are documenting.

Multiline docstrings are typically composed of a summary line, followed by
a blank line, followed by a series of sections, each with a section header
and a section body. Function docstrings often include a section for
function arguments; this rule is concerned with that section only.
Note that this rule only checks docstrings with an arguments (e.g. `Args`) section.

This rule is enabled when using the `google` convention, and disabled when
using the `pep257` and `numpy` conventions.

Parameters annotated with `typing.Unpack` are exempt from this rule.
This follows the Python typing specification for unpacking keyword arguments.

## Example
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.

    Returns:
        Speed as distance divided by time.

    Raises:
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

Use instead:
```python
def calculate_speed(distance: float, time: float) -> float:
    """Calculate speed as distance divided by time.

    Args:
        distance: Distance traveled.
        time: Time spent traveling.

    Returns:
        Speed as distance divided by time.

    Raises:
        FasterThanLightError: If speed is greater than the speed of light.
    """
    try:
        return distance / time
    except ZeroDivisionError as exc:
        raise FasterThanLightError from exc
```

## Options
- `lint.pydocstyle.convention`
- `lint.pydocstyle.ignore-var-parameters`

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [PEP 287  reStructuredText Docstring Format](https://peps.python.org/pep-0287/)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)
- [Python - Unpack for keyword arguments](https://typing.python.org/en/latest/spec/callables.html#unpack-kwargs)

# overload-with-docstring (D418)

Derived from the **pydocstyle** linter.

## What it does
Checks for `@overload` function definitions that contain a docstring.

## Why is this bad?
The `@overload` decorator is used to define multiple compatible signatures
for a given function, to support type-checking. A series of `@overload`
definitions should be followed by a single non-decorated definition that
contains the implementation of the function.

`@overload` function definitions should not contain a docstring; instead,
the docstring should be placed on the non-decorated definition that contains
the implementation.

## Example

```python
from typing import overload


@overload
def factorial(n: int) -> int:
    """Return the factorial of n."""


@overload
def factorial(n: float) -> float:
    """Return the factorial of n."""


def factorial(n):
    """Return the factorial of n."""


factorial.__doc__  # "Return the factorial of n."
```

Use instead:

```python
from typing import overload


@overload
def factorial(n: int) -> int: ...


@overload
def factorial(n: float) -> float: ...


def factorial(n):
    """Return the factorial of n."""


factorial.__doc__  # "Return the factorial of n."
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [Python documentation: `typing.overload`](https://docs.python.org/3/library/typing.html#typing.overload)

# empty-docstring (D419)

Derived from the **pydocstyle** linter.

## What it does
Checks for empty docstrings.

## Why is this bad?
An empty docstring is indicative of incomplete documentation. It should either
be removed or replaced with a meaningful docstring.

## Example
```python
def average(values: list[float]) -> float:
    """"""
```

Use instead:
```python
def average(values: list[float]) -> float:
    """Return the mean of the given values."""
```

## References
- [PEP 257  Docstring Conventions](https://peps.python.org/pep-0257/)
- [NumPy Style Guide](https://numpydoc.readthedocs.io/en/latest/format.html)
- [Google Python Style Guide - Docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)

# unused-import (F401)

Derived from the **Pyflakes** linter.

Fix is sometimes available.

## What it does
Checks for unused imports.

## Why is this bad?
Unused imports add a performance overhead at runtime, and risk creating
import cycles. They also increase the cognitive load of reading the code.

If an import statement is used to check for the availability or existence
of a module, consider using `importlib.util.find_spec` instead.

If an import statement is used to re-export a symbol as part of a module's
public interface, consider using a "redundant" import alias, which
instructs Ruff (and other tools) to respect the re-export, and avoid
marking it as unused, as in:

```python
from module import member as member
```

Alternatively, you can use `__all__` to declare a symbol as part of the module's
interface, as in:

```python
# __init__.py
import some_module

__all__ = ["some_module"]
```

## Preview
When [preview] is enabled (and certain simplifying assumptions
are met), we analyze all import statements for a given module
when determining whether an import is used, rather than simply
the last of these statements. This can result in both different and
more import statements being marked as unused.

For example, if a module consists of

```python
import a
import a.b
```

then both statements are marked as unused under [preview], whereas
only the second is marked as unused under stable behavior.

As another example, if a module consists of

```python
import a.b
import a

a.b.foo()
```

then a diagnostic will only be emitted for the first line under [preview],
whereas a diagnostic would only be emitted for the second line under
stable behavior.

Note that this behavior is somewhat subjective and is designed
to conform to the developer's intuition rather than Python's actual
execution. To wit, the statement `import a.b` automatically executes
`import a`, so in some sense `import a` is _always_ redundant
in the presence of `import a.b`.


## Fix safety

Fixes to remove unused imports are safe, except in `__init__.py` files.

Applying fixes to `__init__.py` files is currently in preview. The fix offered depends on the
type of the unused import. Ruff will suggest a safe fix to export first-party imports with
either a redundant alias or, if already present in the file, an `__all__` entry. If multiple
`__all__` declarations are present, Ruff will not offer a fix. Ruff will suggest an unsafe fix
to remove third-party and standard library imports -- the fix is unsafe because the module's
interface changes.

See [this FAQ section](https://docs.astral.sh/ruff/faq/#how-does-ruff-determine-which-of-my-imports-are-first-party-third-party-etc)
for more details on how Ruff
determines whether an import is first or third-party.

## Example

```python
import numpy as np  # unused import


def area(radius):
    return 3.14 * radius**2
```

Use instead:

```python
def area(radius):
    return 3.14 * radius**2
```

To check the availability of a module, use `importlib.util.find_spec`:

```python
from importlib.util import find_spec

if find_spec("numpy") is not None:
    print("numpy is installed")
else:
    print("numpy is not installed")
```

## Options
- `lint.ignore-init-module-imports`
- `lint.pyflakes.allowed-unused-imports`

## References
- [Python documentation: `import`](https://docs.python.org/3/reference/simple_stmts.html#the-import-statement)
- [Python documentation: `importlib.util.find_spec`](https://docs.python.org/3/library/importlib.html#importlib.util.find_spec)
- [Typing documentation: interface conventions](https://typing.python.org/en/latest/spec/distributing.html#library-interface-public-and-private-symbols)

[preview]: https://docs.astral.sh/ruff/preview/

# import-shadowed-by-loop-var (F402)

Derived from the **Pyflakes** linter.

## What it does
Checks for import bindings that are shadowed by loop variables.

## Why is this bad?
Shadowing an import with loop variables makes the code harder to read and
reason about, as the identify of the imported binding is no longer clear.
It's also often indicative of a mistake, as it's unlikely that the loop
variable is intended to be used as the imported binding.

Consider using a different name for the loop variable.

## Example
```python
from os import path

for path in files:
    print(path)
```

Use instead:
```python
from os import path


for filename in files:
    print(filename)
```

# undefined-local-with-import-star (F403)

Derived from the **Pyflakes** linter.

## What it does
Checks for the use of wildcard imports.

## Why is this bad?
Wildcard imports (e.g., `from module import *`) make it hard to determine
which symbols are available in the current namespace, and from which module
they were imported. They're also discouraged by [PEP 8].

## Example
```python
from math import *


def area(radius):
    return pi * radius**2
```

Use instead:
```python
from math import pi


def area(radius):
    return pi * radius**2
```

[PEP 8]: https://peps.python.org/pep-0008/#imports

# late-future-import (F404)

Derived from the **Pyflakes** linter.

## What it does
Checks for `__future__` imports that are not located at the beginning of a
file.

## Why is this bad?
Imports from `__future__` must be placed the beginning of the file, before any
other statements (apart from docstrings). The use of `__future__` imports
elsewhere is invalid and will result in a `SyntaxError`.

## Example
```python
from pathlib import Path

from __future__ import annotations
```

Use instead:
```python
from __future__ import annotations

from pathlib import Path
```

## References
- [Python documentation: Future statements](https://docs.python.org/3/reference/simple_stmts.html#future)

# undefined-local-with-import-star-usage (F405)

Derived from the **Pyflakes** linter.

## What it does
Checks for names that might be undefined, but may also be defined in a
wildcard import.

## Why is this bad?
Wildcard imports (e.g., `from module import *`) make it hard to determine
which symbols are available in the current namespace. If a module contains
a wildcard import, and a name in the current namespace has not been
explicitly defined or imported, then it's unclear whether the name is
undefined or was imported by the wildcard import.

If the name _is_ defined in via a wildcard import, that member should be
imported explicitly to avoid confusion.

If the name is _not_ defined in a wildcard import, it should be defined or
imported.

## Example
```python
from math import *


def area(radius):
    return pi * radius**2
```

Use instead:
```python
from math import pi


def area(radius):
    return pi * radius**2
```

# undefined-local-with-nested-import-star-usage (F406)

Derived from the **Pyflakes** linter.

## What it does
Check for the use of wildcard imports outside of the module namespace.

## Why is this bad?
The use of wildcard imports outside of the module namespace (e.g., within
functions) can lead to confusion, as the import can shadow local variables.

Though wildcard imports are discouraged by [PEP 8], when necessary, they
should be placed in the module namespace (i.e., at the top-level of a
module).

## Example

```python
def foo():
    from math import *
```

Use instead:

```python
from math import *


def foo(): ...
```

[PEP 8]: https://peps.python.org/pep-0008/#imports

# future-feature-not-defined (F407)

Derived from the **Pyflakes** linter.

## What it does
Checks for `__future__` imports that are not defined in the current Python
version.

## Why is this bad?
Importing undefined or unsupported members from the `__future__` module is
a `SyntaxError`.

## References
- [Python documentation: `__future__`](https://docs.python.org/3/library/__future__.html)

# percent-format-invalid-format (F501)

Derived from the **Pyflakes** linter.

## What it does
Checks for invalid `printf`-style format strings.

## Why is this bad?
Conversion specifiers are required for `printf`-style format strings. These
specifiers must contain a `%` character followed by a conversion type.

## Example
```python
"Hello, %" % "world"
```

Use instead:
```python
"Hello, %s" % "world"
```

## References
- [Python documentation: `printf`-style String Formatting](https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting)

# percent-format-expected-mapping (F502)

Derived from the **Pyflakes** linter.

## What it does
Checks for named placeholders in `printf`-style format strings without
mapping-type values.

## Why is this bad?
When using named placeholders in `printf`-style format strings, the values
must be a map type (such as a dictionary). Otherwise, the expression will
raise a `TypeError`.

## Example
```python
"%(greeting)s, %(name)s" % ("Hello", "World")
```

Use instead:
```python
"%(greeting)s, %(name)s" % {"greeting": "Hello", "name": "World"}
```

Or:
```python
"%s, %s" % ("Hello", "World")
```

## References
- [Python documentation: `printf`-style String Formatting](https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting)

# percent-format-expected-sequence (F503)

Derived from the **Pyflakes** linter.

## What it does
Checks for uses of mapping-type values in `printf`-style format strings
without named placeholders.

## Why is this bad?
When using mapping-type values (such as `dict`) in `printf`-style format
strings, the keys must be named. Otherwise, the expression will raise a
`TypeError`.

## Example
```python
"%s, %s" % {"greeting": "Hello", "name": "World"}
```

Use instead:
```python
"%(greeting)s, %(name)s" % {"greeting": "Hello", "name": "World"}
```

Or:
```python
"%s, %s" % ("Hello", "World")
```

## References
- [Python documentation: `printf`-style String Formatting](https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting)

# percent-format-extra-named-arguments (F504)

Derived from the **Pyflakes** linter.

Fix is always available.

## What it does
Checks for unused mapping keys in `printf`-style format strings.

## Why is this bad?
Unused named placeholders in `printf`-style format strings are unnecessary,
and likely indicative of a mistake. They should be removed.

## Example
```python
"Hello, %(name)s" % {"greeting": "Hello", "name": "World"}
```

Use instead:
```python
"Hello, %(name)s" % {"name": "World"}
```

## Fix safety
This rule's fix is marked as unsafe for mapping key
containing function calls with potential side effects,
because removing such arguments could change the behavior of the code.

For example, the fix would be marked as unsafe in the following case:
```python
"Hello, %(name)s" % {"greeting": print(1), "name": "World"}
```

## References
- [Python documentation: `printf`-style String Formatting](https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting)

# percent-format-missing-argument (F505)

Derived from the **Pyflakes** linter.

## What it does
Checks for named placeholders in `printf`-style format strings that are not
present in the provided mapping.

## Why is this bad?
Named placeholders that lack a corresponding value in the provided mapping
will raise a `KeyError`.

## Example
```python
"%(greeting)s, %(name)s" % {"name": "world"}
```

Use instead:
```python
"Hello, %(name)s" % {"name": "world"}
```

## References
- [Python documentation: `printf`-style String Formatting](https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting)

# percent-format-mixed-positional-and-named (F506)

Derived from the **Pyflakes** linter.

## What it does
Checks for `printf`-style format strings that have mixed positional and
named placeholders.

## Why is this bad?
Python does not support mixing positional and named placeholders in
`printf`-style format strings. The use of mixed placeholders will raise a
`TypeError` at runtime.

## Example
```python
"%s, %(name)s" % ("Hello", {"name": "World"})
```

Use instead:
```python
"%s, %s" % ("Hello", "World")
```

Or:
```python
"%(greeting)s, %(name)s" % {"greeting": "Hello", "name": "World"}
```

## References
- [Python documentation: `printf`-style String Formatting](https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting)

# percent-format-positional-count-mismatch (F507)

Derived from the **Pyflakes** linter.

## What it does
Checks for `printf`-style format strings that have a mismatch between the
number of positional placeholders and the number of substitution values.

## Why is this bad?
When a `printf`-style format string is provided with too many or too few
substitution values, it will raise a `TypeError` at runtime.

## Example
```python
"%s, %s" % ("Hello", "world", "!")
```

Use instead:
```python
"%s, %s" % ("Hello", "world")
```

## References
- [Python documentation: `printf`-style String Formatting](https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting)

# percent-format-star-requires-sequence (F508)

Derived from the **Pyflakes** linter.

## What it does
Checks for `printf`-style format strings that use the `*` specifier with
non-tuple values.

## Why is this bad?
The use of the `*` specifier with non-tuple values will raise a
`TypeError` at runtime.

## Example
```python
from math import pi

"%(n).*f" % {"n": (2, pi)}
```

Use instead:
```python
from math import pi

"%.*f" % (2, pi)  # 3.14
```

## References
- [Python documentation: `printf`-style String Formatting](https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting)

# percent-format-unsupported-format-character (F509)

Derived from the **Pyflakes** linter.

## What it does
Checks for `printf`-style format strings with invalid format characters.

## Why is this bad?
In `printf`-style format strings, the `%` character is used to indicate
placeholders. If a `%` character is not followed by a valid format
character, it will raise a `ValueError` at runtime.

## Example
```python
"Hello, %S" % "world"
```

Use instead:
```python
"Hello, %s" % "world"
```

## References
- [Python documentation: `printf`-style String Formatting](https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting)

# string-dot-format-invalid-format (F521)

Derived from the **Pyflakes** linter.

## What it does
Checks for `str.format` calls with invalid format strings.

## Why is this bad?
Invalid format strings will raise a `ValueError`.

## Example
```python
"{".format(foo)
```

Use instead:
```python
"{}".format(foo)
```

## References
- [Python documentation: `str.format`](https://docs.python.org/3/library/stdtypes.html#str.format)

# string-dot-format-extra-named-arguments (F522)

Derived from the **Pyflakes** linter.

Fix is sometimes available.

## What it does
Checks for `str.format` calls with unused keyword arguments.

## Why is this bad?
Unused keyword arguments are redundant, and often indicative of a mistake.
They should be removed.

## Example
```python
"Hello, {name}".format(greeting="Hello", name="World")
```

Use instead:
```python
"Hello, {name}".format(name="World")
```

## Fix safety
This rule's fix is marked as unsafe if the unused keyword argument
contains a function call with potential side effects,
because removing such arguments could change the behavior of the code.

For example, the fix would be marked as unsafe in the following case:
```python
"Hello, {name}".format(greeting=print(1), name="World")
```

## References
- [Python documentation: `str.format`](https://docs.python.org/3/library/stdtypes.html#str.format)

# string-dot-format-extra-positional-arguments (F523)

Derived from the **Pyflakes** linter.

Fix is sometimes available.

## What it does
Checks for `str.format` calls with unused positional arguments.

## Why is this bad?
Unused positional arguments are redundant, and often indicative of a mistake.
They should be removed.

## Example
```python
"Hello, {0}".format("world", "!")
```

Use instead:
```python
"Hello, {0}".format("world")
```

## Fix safety
This rule's fix is marked as unsafe if the unused positional argument
contains a function call with potential side effects,
because removing such arguments could change the behavior of the code.

For example, the fix would be marked as unsafe in the following case:
```python
"Hello, {0}".format("world", print(1))
```

## References
- [Python documentation: `str.format`](https://docs.python.org/3/library/stdtypes.html#str.format)

# string-dot-format-missing-arguments (F524)

Derived from the **Pyflakes** linter.

## What it does
Checks for `str.format` calls with placeholders that are missing arguments.

## Why is this bad?
In `str.format` calls, omitting arguments for placeholders will raise a
`KeyError` at runtime.

## Example
```python
"{greeting}, {name}".format(name="World")
```

Use instead:
```python
"{greeting}, {name}".format(greeting="Hello", name="World")
```

## References
- [Python documentation: `str.format`](https://docs.python.org/3/library/stdtypes.html#str.format)

# string-dot-format-mixing-automatic (F525)

Derived from the **Pyflakes** linter.

## What it does
Checks for `str.format` calls that mix automatic and manual numbering.

## Why is this bad?
In `str.format` calls, mixing automatic and manual numbering will raise a
`ValueError` at runtime.

## Example
```python
"{0}, {}".format("Hello", "World")
```

Use instead:
```python
"{0}, {1}".format("Hello", "World")
```

Or:
```python
"{}, {}".format("Hello", "World")
```

## References
- [Python documentation: `str.format`](https://docs.python.org/3/library/stdtypes.html#str.format)

# f-string-missing-placeholders (F541)

Derived from the **Pyflakes** linter.

Fix is always available.

## What it does
Checks for f-strings that do not contain any placeholder expressions.

## Why is this bad?
f-strings are a convenient way to format strings, but they are not
necessary if there are no placeholder expressions to format. In this
case, a regular string should be used instead, as an f-string without
placeholders can be confusing for readers, who may expect such a
placeholder to be present.

An f-string without any placeholders could also indicate that the
author forgot to add a placeholder expression.

## Example
```python
f"Hello, world!"
```

Use instead:
```python
"Hello, world!"
```

**Note:** to maintain compatibility with PyFlakes, this rule only flags
f-strings that are part of an implicit concatenation if _none_ of the
f-string segments contain placeholder expressions.

For example:

```python
# Will not be flagged.
(
    f"Hello,"
    f" {name}!"
)

# Will be flagged.
(
    f"Hello,"
    f" World!"
)
```

See [#10885](https://github.com/astral-sh/ruff/issues/10885) for more.

## References
- [PEP 498  Literal String Interpolation](https://peps.python.org/pep-0498/)

# multi-value-repeated-key-literal (F601)

Derived from the **Pyflakes** linter.

Fix is sometimes available.

## What it does
Checks for dictionary literals that associate multiple values with the
same key.

## Why is this bad?
Dictionary keys should be unique. If a key is associated with multiple values,
the earlier values will be overwritten. Including multiple values for the
same key in a dictionary literal is likely a mistake.

## Example
```python
foo = {
    "bar": 1,
    "baz": 2,
    "baz": 3,
}
foo["baz"]  # 3
```

Use instead:
```python
foo = {
    "bar": 1,
    "baz": 2,
}
foo["baz"]  # 2
```

## Fix safety

This rule's fix is marked as unsafe because removing a repeated dictionary key
may delete comments that are attached to the removed key-value pair. This can also change
the program's behavior if the value expressions have side effects.

## References
- [Python documentation: Dictionaries](https://docs.python.org/3/tutorial/datastructures.html#dictionaries)

# multi-value-repeated-key-variable (F602)

Derived from the **Pyflakes** linter.

Fix is sometimes available.

## What it does
Checks for dictionary keys that are repeated with different values.

## Why is this bad?
Dictionary keys should be unique. If a key is repeated with a different
value, the first values will be overwritten and the key will correspond to
the last value. This is likely a mistake.

## Example
```python
foo = {
    bar: 1,
    baz: 2,
    baz: 3,
}
foo[baz]  # 3
```

Use instead:
```python
foo = {
    bar: 1,
    baz: 2,
}
foo[baz]  # 2
```

## Fix safety

This rule's fix is marked as unsafe because removing a repeated dictionary key
may delete comments that are attached to the removed key-value pair. This can also change
the program's behavior if the value expressions have side effects.

## References
- [Python documentation: Dictionaries](https://docs.python.org/3/tutorial/datastructures.html#dictionaries)

# expressions-in-star-assignment (F621)

Derived from the **Pyflakes** linter.

## What it does
Checks for the use of too many expressions in starred assignment statements.

## Why is this bad?
In assignment statements, starred expressions can be used to unpack iterables.

In Python 3, no more than `1 << 8` assignments are allowed before a starred
expression, and no more than `1 << 24` expressions are allowed after a starred
expression.

## References
- [PEP 3132  Extended Iterable Unpacking](https://peps.python.org/pep-3132/)

# multiple-starred-expressions (F622)

Derived from the **Pyflakes** linter.

## What it does
Checks for the use of multiple starred expressions in assignment statements.

## Why is this bad?
In assignment statements, starred expressions can be used to unpack iterables.
Including more than one starred expression on the left-hand-side of an
assignment will cause a `SyntaxError`, as it is unclear which expression
should receive the remaining values.

## Example
```python
*foo, *bar, baz = (1, 2, 3)
```

## References
- [PEP 3132  Extended Iterable Unpacking](https://peps.python.org/pep-3132/)

# assert-tuple (F631)

Derived from the **Pyflakes** linter.

## What it does
Checks for `assert` statements that use non-empty tuples as test
conditions.

## Why is this bad?
Non-empty tuples are always `True`, so an `assert` statement with a
non-empty tuple as its test condition will always pass. This is likely a
mistake.

## Example
```python
assert (some_condition,)
```

Use instead:
```python
assert some_condition
```

## References
- [Python documentation: The `assert` statement](https://docs.python.org/3/reference/simple_stmts.html#the-assert-statement)

# is-literal (F632)

Derived from the **Pyflakes** linter.

Fix is always available.

## What it does
Checks for `is` and `is not` comparisons against literals, like integers,
strings, or lists.

## Why is this bad?
The `is` and `is not` comparators operate on identity, in that they check
whether two objects are the same object. If the objects are not the same
object, the comparison will always be `False`. Using `is` and `is not` with
constant literals often works "by accident", but are not guaranteed to produce
the expected result.

As of Python 3.8, using `is` and `is not` with constant literals will produce
a `SyntaxWarning`.

This rule will also flag `is` and `is not` comparisons against non-constant
literals, like lists, sets, and dictionaries. While such comparisons will
not raise a `SyntaxWarning`, they are still likely to be incorrect, as they
will compare the identities of the objects instead of their values, which
will always evaluate to `False`.

Instead, use `==` and `!=` to compare literals, which will compare the
values of the objects instead of their identities.

## Example
```python
x = 200
if x is 200:
    print("It's 200!")
```

Use instead:
```python
x = 200
if x == 200:
    print("It's 200!")
```

## References
- [Python documentation: Identity comparisons](https://docs.python.org/3/reference/expressions.html#is-not)
- [Python documentation: Value comparisons](https://docs.python.org/3/reference/expressions.html#value-comparisons)
- [_Why does Python log a SyntaxWarning for is with literals?_ by Adam Johnson](https://adamj.eu/tech/2020/01/21/why-does-python-3-8-syntaxwarning-for-is-literal/)

# invalid-print-syntax (F633)

Derived from the **Pyflakes** linter.

## What it does
Checks for `print` statements that use the `>>` syntax.

## Why is this bad?
In Python 2, the `print` statement can be used with the `>>` syntax to
print to a file-like object. This `print >> sys.stderr` syntax no
longer exists in Python 3, where `print` is only a function, not a
statement.

Instead, use the `file` keyword argument to the `print` function, the
`sys.stderr.write` function, or the `logging` module.

## Example
```python
from __future__ import print_function
import sys

print >> sys.stderr, "Hello, world!"
```

Use instead:
```python
print("Hello, world!", file=sys.stderr)
```

Or:
```python
import sys

sys.stderr.write("Hello, world!\n")
```

Or:
```python
import logging

logging.error("Hello, world!")
```

## References
- [Python documentation: `print`](https://docs.python.org/3/library/functions.html#print)

# if-tuple (F634)

Derived from the **Pyflakes** linter.

## What it does
Checks for `if` statements that use non-empty tuples as test conditions.

## Why is this bad?
Non-empty tuples are always `True`, so an `if` statement with a non-empty
tuple as its test condition will always pass. This is likely a mistake.

## Example
```python
if (False,):
    print("This will always run")
```

Use instead:
```python
if False:
    print("This will never run")
```

## References
- [Python documentation: The `if` statement](https://docs.python.org/3/reference/compound_stmts.html#the-if-statement)

# break-outside-loop (F701)

Derived from the **Pyflakes** linter.

## What it does
Checks for `break` statements outside of loops.

## Why is this bad?
The use of a `break` statement outside of a `for` or `while` loop will
raise a `SyntaxError`.

## Example
```python
def foo():
    break
```

## References
- [Python documentation: `break`](https://docs.python.org/3/reference/simple_stmts.html#the-break-statement)

# continue-outside-loop (F702)

Derived from the **Pyflakes** linter.

## What it does
Checks for `continue` statements outside of loops.

## Why is this bad?
The use of a `continue` statement outside of a `for` or `while` loop will
raise a `SyntaxError`.

## Example
```python
def foo():
    continue  # SyntaxError
```

## References
- [Python documentation: `continue`](https://docs.python.org/3/reference/simple_stmts.html#the-continue-statement)

# yield-outside-function (F704)

Derived from the **Pyflakes** linter.

## What it does
Checks for `yield`, `yield from`, and `await` usages outside of functions.

## Why is this bad?
The use of `yield`, `yield from`, or `await` outside of a function will
raise a `SyntaxError`.

## Example
```python
class Foo:
    yield 1
```

## Notebook behavior
As an exception, `await` is allowed at the top level of a Jupyter notebook
(see: [autoawait]).

## References
- [Python documentation: `yield`](https://docs.python.org/3/reference/simple_stmts.html#the-yield-statement)

[autoawait]: https://ipython.readthedocs.io/en/stable/interactive/autoawait.html

# return-outside-function (F706)

Derived from the **Pyflakes** linter.

## What it does
Checks for `return` statements outside of functions.

## Why is this bad?
The use of a `return` statement outside of a function will raise a
`SyntaxError`.

## Example
```python
class Foo:
    return 1
```

## References
- [Python documentation: `return`](https://docs.python.org/3/reference/simple_stmts.html#the-return-statement)

# default-except-not-last (F707)

Derived from the **Pyflakes** linter.

## What it does
Checks for `except` blocks that handle all exceptions, but are not the last
`except` block in a `try` statement.

## Why is this bad?
When an exception is raised within a `try` block, the `except` blocks are
evaluated in order, and the first matching block is executed. If an `except`
block handles all exceptions, but isn't the last block, Python will raise a
`SyntaxError`, as the following blocks would never be executed.

## Example
```python
def reciprocal(n):
    try:
        reciprocal = 1 / n
    except:
        print("An exception occurred.")
    except ZeroDivisionError:
        print("Cannot divide by zero.")
    else:
        return reciprocal
```

Use instead:
```python
def reciprocal(n):
    try:
        reciprocal = 1 / n
    except ZeroDivisionError:
        print("Cannot divide by zero.")
    except:
        print("An exception occurred.")
    else:
        return reciprocal
```

## References
- [Python documentation: `except` clause](https://docs.python.org/3/reference/compound_stmts.html#except-clause)

# forward-annotation-syntax-error (F722)

Derived from the **Pyflakes** linter.

## What it does
Checks for forward annotations that include invalid syntax.


## Why is this bad?
In Python, type annotations can be quoted as strings literals to enable
references to types that have not yet been defined, known as "forward
references".

However, these quoted annotations must be valid Python expressions. The use
of invalid syntax in a quoted annotation won't raise a `SyntaxError`, but
will instead raise an error when type checking is performed.

## Example

```python
def foo() -> "/": ...
```

## References
- [PEP 563  Postponed Evaluation of Annotations](https://peps.python.org/pep-0563/)

# redefined-while-unused (F811)

Derived from the **Pyflakes** linter.

Fix is sometimes available.

## What it does
Checks for variable definitions that redefine (or "shadow") unused
variables.

## Why is this bad?
Redefinitions of unused names are unnecessary and often indicative of a
mistake.

## Example
```python
import foo
import bar
import foo  # Redefinition of unused `foo` from line 1
```

Use instead:
```python
import foo
import bar
```

# undefined-name (F821)

Derived from the **Pyflakes** linter.

## What it does
Checks for uses of undefined names.

## Why is this bad?
An undefined name is likely to raise `NameError` at runtime.

## Example
```python
def double():
    return n * 2  # raises `NameError` if `n` is undefined when `double` is called
```

Use instead:
```python
def double(n):
    return n * 2
```

## Options
- [`target-version`]: Can be used to configure which symbols Ruff will understand
  as being available in the `builtins` namespace.

## References
- [Python documentation: Naming and binding](https://docs.python.org/3/reference/executionmodel.html#naming-and-binding)

# undefined-export (F822)

Derived from the **Pyflakes** linter.

## What it does
Checks for undefined names in `__all__`.

## Why is this bad?
In Python, the `__all__` variable is used to define the names that are
exported when a module is imported as a wildcard (e.g.,
`from foo import *`). The names in `__all__` must be defined in the module,
but are included as strings.

Including an undefined name in `__all__` is likely to raise `NameError` at
runtime, when the module is imported.

In [preview], this rule will flag undefined names in `__init__.py` file,
even if those names implicitly refer to other modules in the package. Users
that rely on implicit exports should disable this rule in `__init__.py`
files via [`lint.per-file-ignores`].

## Example
```python
from foo import bar


__all__ = ["bar", "baz"]  # undefined name `baz` in `__all__`
```

Use instead:
```python
from foo import bar, baz


__all__ = ["bar", "baz"]
```

## References
- [Python documentation: `__all__`](https://docs.python.org/3/tutorial/modules.html#importing-from-a-package)

[preview]: https://docs.astral.sh/ruff/preview/

# undefined-local (F823)

Derived from the **Pyflakes** linter.

## What it does
Checks for undefined local variables.

## Why is this bad?
Referencing a local variable before it has been assigned will raise
an `UnboundLocalError` at runtime.

## Example
```python
x = 1


def foo():
    x += 1
```

Use instead:
```python
x = 1


def foo():
    global x
    x += 1
```

# unused-variable (F841)

Derived from the **Pyflakes** linter.

Fix is sometimes available.

## What it does
Checks for the presence of unused variables in function scopes.

## Why is this bad?
A variable that is defined but not used is likely a mistake, and should
be removed to avoid confusion.

If a variable is intentionally defined-but-not-used, it should be
prefixed with an underscore, or some other value that adheres to the
[`lint.dummy-variable-rgx`] pattern.

## Example
```python
def foo():
    x = 1
    y = 2
    return x
```

Use instead:
```python
def foo():
    x = 1
    return x
```

## Fix safety

This rule's fix is marked as unsafe because removing an unused variable assignment may
delete comments that are attached to the assignment.

## See also

This rule does not apply to bindings in unpacked assignments (e.g. `x, y = 1, 2`). See
[`unused-unpacked-variable`][RUF059] for this case.

## Options
- `lint.dummy-variable-rgx`

[RUF059]: https://docs.astral.sh/ruff/rules/unused-unpacked-variable/

# unused-annotation (F842)

Derived from the **Pyflakes** linter.

## What it does
Checks for local variables that are annotated but never used.

## Why is this bad?
Annotations are used to provide type hints to static type checkers. If a
variable is annotated but never used, the annotation is unnecessary.

## Example
```python
def foo():
    bar: int
```

## References
- [PEP 484  Type Hints](https://peps.python.org/pep-0484/)

# raise-not-implemented (F901)

Derived from the **Pyflakes** linter.

Fix is sometimes available.

## What it does
Checks for `raise` statements that raise `NotImplemented`.

## Why is this bad?
`NotImplemented` is an exception used by binary special methods to indicate
that an operation is not implemented with respect to a particular type.

`NotImplemented` should not be raised directly. Instead, raise
`NotImplementedError`, which is used to indicate that the method is
abstract or not implemented in the derived class.

## Example
```python
class Foo:
    def bar(self):
        raise NotImplemented
```

Use instead:
```python
class Foo:
    def bar(self):
        raise NotImplementedError
```

## References
- [Python documentation: `NotImplemented`](https://docs.python.org/3/library/constants.html#NotImplemented)
- [Python documentation: `NotImplementedError`](https://docs.python.org/3/library/exceptions.html#NotImplementedError)

# eval (PGH001)

Derived from the **pygrep-hooks** linter.

## Removed
This rule is identical to [S307] which should be used instead.

## What it does
Checks for uses of the builtin `eval()` function.

## Why is this bad?
The `eval()` function is insecure as it enables arbitrary code execution.

## Example
```python
def foo():
    x = eval(input("Enter a number: "))
    ...
```

Use instead:
```python
def foo():
    x = input("Enter a number: ")
    ...
```

## References
- [Python documentation: `eval`](https://docs.python.org/3/library/functions.html#eval)
- [_Eval really is dangerous_ by Ned Batchelder](https://nedbatchelder.com/blog/201206/eval_really_is_dangerous.html)

[S307]: https://docs.astral.sh/ruff/rules/suspicious-eval-usage/

# deprecated-log-warn (PGH002)

Derived from the **pygrep-hooks** linter.

Fix is sometimes available.

## Removed
This rule is identical to [G010] which should be used instead.

## What it does
Check for usages of the deprecated `warn` method from the `logging` module.

## Why is this bad?
The `warn` method is deprecated. Use `warning` instead.

## Example
```python
import logging


def foo():
    logging.warn("Something happened")
```

Use instead:
```python
import logging


def foo():
    logging.warning("Something happened")
```

## References
- [Python documentation: `logger.Logger.warning`](https://docs.python.org/3/library/logging.html#logging.Logger.warning)

[G010]: https://docs.astral.sh/ruff/rules/logging-warn/

# blanket-type-ignore (PGH003)

Derived from the **pygrep-hooks** linter.

## What it does
Check for `type: ignore` annotations that suppress all type warnings, as
opposed to targeting specific type warnings.

## Why is this bad?
Suppressing all warnings can hide issues in the code.

Blanket `type: ignore` annotations are also more difficult to interpret and
maintain, as the annotation does not clarify which warnings are intended
to be suppressed.

## Example
```python
from foo import secrets  # type: ignore
```

Use instead:
```python
from foo import secrets  # type: ignore[attr-defined]
```

## References
Mypy supports a [built-in setting](https://mypy.readthedocs.io/en/stable/error_code_list2.html#check-that-type-ignore-include-an-error-code-ignore-without-code)
to enforce that all `type: ignore` annotations include an error code, akin
to enabling this rule:
```toml
[tool.mypy]
enable_error_code = ["ignore-without-code"]
```

# blanket-noqa (PGH004)

Derived from the **pygrep-hooks** linter.

Fix is sometimes available.

## What it does
Check for `noqa` annotations that suppress all diagnostics, as opposed to
targeting specific diagnostics.

## Why is this bad?
Suppressing all diagnostics can hide issues in the code.

Blanket `noqa` annotations are also more difficult to interpret and
maintain, as the annotation does not clarify which diagnostics are intended
to be suppressed.

## Example
```python
from .base import *  # noqa
```

Use instead:
```python
from .base import *  # noqa: F403
```

## Fix safety
This rule will attempt to fix blanket `noqa` annotations that appear to
be unintentional. For example, given `# noqa F401`, the rule will suggest
inserting a colon, as in `# noqa: F401`.

While modifying `noqa` comments is generally safe, doing so may introduce
additional diagnostics.

## References
- [Ruff documentation](https://docs.astral.sh/ruff/configuration/#error-suppression)

# invalid-mock-access (PGH005)

Derived from the **pygrep-hooks** linter.

## What it does
Checks for common mistakes when using mock objects.

## Why is this bad?
The `mock` module exposes an assertion API that can be used to verify that
mock objects undergo expected interactions. This rule checks for common
mistakes when using this API.

For example, it checks for mock attribute accesses that should be replaced
with mock method calls.

## Example
```python
my_mock.assert_called
```

Use instead:
```python
my_mock.assert_called()
```

# type-name-incorrect-variance (PLC0105)

Derived from the **Pylint** linter.

## What it does
Checks for type names that do not match the variance of their associated
type parameter.

## Why is this bad?
[PEP 484] recommends the use of the `_co` and `_contra` suffixes for
covariant and contravariant type parameters, respectively (while invariant
type parameters should not have any such suffix).

## Example
```python
from typing import TypeVar

T = TypeVar("T", covariant=True)
U = TypeVar("U", contravariant=True)
V_co = TypeVar("V_co")
```

Use instead:
```python
from typing import TypeVar

T_co = TypeVar("T_co", covariant=True)
U_contra = TypeVar("U_contra", contravariant=True)
V = TypeVar("V")
```

## References
- [Python documentation: `typing`  Support for type hints](https://docs.python.org/3/library/typing.html)
- [PEP 483  The Theory of Type Hints: Covariance and Contravariance](https://peps.python.org/pep-0483/#covariance-and-contravariance)
- [PEP 484  Type Hints: Covariance and contravariance](https://peps.python.org/pep-0484/#covariance-and-contravariance)

[PEP 484]: https://peps.python.org/pep-0484/

# type-bivariance (PLC0131)

Derived from the **Pylint** linter.

## What it does
Checks for `TypeVar` and `ParamSpec` definitions in which the type is
both covariant and contravariant.

## Why is this bad?
By default, Python's generic types are invariant, but can be marked as
either covariant or contravariant via the `covariant` and `contravariant`
keyword arguments. While the API does allow you to mark a type as both
covariant and contravariant, this is not supported by the type system,
and should be avoided.

Instead, change the variance of the type to be either covariant,
contravariant, or invariant. If you want to describe both covariance and
contravariance, consider using two separate type parameters.

For context: an "invariant" generic type only accepts values that exactly
match the type parameter; for example, `list[Dog]` accepts only `list[Dog]`,
not `list[Animal]` (superclass) or `list[Bulldog]` (subclass). This is
the default behavior for Python's generic types.

A "covariant" generic type accepts subclasses of the type parameter; for
example, `Sequence[Animal]` accepts `Sequence[Dog]`. A "contravariant"
generic type accepts superclasses of the type parameter; for example,
`Callable[Dog]` accepts `Callable[Animal]`.

## Example
```python
from typing import TypeVar

T = TypeVar("T", covariant=True, contravariant=True)
```

Use instead:
```python
from typing import TypeVar

T_co = TypeVar("T_co", covariant=True)
T_contra = TypeVar("T_contra", contravariant=True)
```

## References
- [Python documentation: `typing`  Support for type hints](https://docs.python.org/3/library/typing.html)
- [PEP 483  The Theory of Type Hints: Covariance and Contravariance](https://peps.python.org/pep-0483/#covariance-and-contravariance)
- [PEP 484  Type Hints: Covariance and contravariance](https://peps.python.org/pep-0484/#covariance-and-contravariance)

# type-param-name-mismatch (PLC0132)

Derived from the **Pylint** linter.

## What it does
Checks for `TypeVar`, `TypeVarTuple`, `ParamSpec`, and `NewType`
definitions in which the name of the type parameter does not match the name
of the variable to which it is assigned.

## Why is this bad?
When defining a `TypeVar` or a related type parameter, Python allows you to
provide a name for the type parameter. According to [PEP 484], the name
provided to the `TypeVar` constructor must be equal to the name of the
variable to which it is assigned.

## Example
```python
from typing import TypeVar

T = TypeVar("U")
```

Use instead:
```python
from typing import TypeVar

T = TypeVar("T")
```

## References
- [Python documentation: `typing`  Support for type hints](https://docs.python.org/3/library/typing.html)
- [PEP 484  Type Hints: Generics](https://peps.python.org/pep-0484/#generics)

[PEP 484]:https://peps.python.org/pep-0484/#generics

# single-string-slots (PLC0205)

Derived from the **Pylint** linter.

## What it does
Checks for single strings assigned to `__slots__`.

## Why is this bad?
In Python, the `__slots__` attribute allows you to explicitly define the
attributes (instance variables) that a class can have. By default, Python
uses a dictionary to store an object's attributes, which incurs some memory
overhead. However, when `__slots__` is defined, Python uses a more compact
internal structure to store the object's attributes, resulting in memory
savings.

Any string iterable may be assigned to `__slots__` (most commonly, a
`tuple` of strings). If a string is assigned to `__slots__`, it is
interpreted as a single attribute name, rather than an iterable of attribute
names. This can cause confusion, as users that iterate over the `__slots__`
value may expect to iterate over a sequence of attributes, but would instead
iterate over the characters of the string.

To use a single string attribute in `__slots__`, wrap the string in an
iterable container type, like a `tuple`.

## Example
```python
class Person:
    __slots__: str = "name"

    def __init__(self, name: str) -> None:
        self.name = name
```

Use instead:
```python
class Person:
    __slots__: tuple[str, ...] = ("name",)

    def __init__(self, name: str) -> None:
        self.name = name
```

## References
- [Python documentation: `__slots__`](https://docs.python.org/3/reference/datamodel.html#slots)

# dict-index-missing-items (PLC0206)

Derived from the **Pylint** linter.

## What it does
Checks for dictionary iterations that extract the dictionary value
via explicit indexing, instead of using `.items()`.

## Why is this bad?
Iterating over a dictionary with `.items()` is semantically clearer
and more efficient than extracting the value with the key.

## Example
```python
ORCHESTRA = {
    "violin": "strings",
    "oboe": "woodwind",
    "tuba": "brass",
    "gong": "percussion",
}

for instrument in ORCHESTRA:
    print(f"{instrument}: {ORCHESTRA[instrument]}")
```

Use instead:
```python
ORCHESTRA = {
    "violin": "strings",
    "oboe": "woodwind",
    "tuba": "brass",
    "gong": "percussion",
}

for instrument, section in ORCHESTRA.items():
    print(f"{instrument}: {section}")
```

# missing-maxsplit-arg (PLC0207)

Derived from the **Pylint** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for access to the first or last element of `str.split()` or `str.rsplit()` without
`maxsplit=1`

## Why is this bad?
Calling `str.split()` or `str.rsplit()` without passing `maxsplit=1` splits on every delimiter in the
string. When accessing only the first or last element of the result, it
would be more efficient to only split once.

## Example
```python
url = "www.example.com"
prefix = url.split(".")[0]
```

Use instead:
```python
url = "www.example.com"
prefix = url.split(".", maxsplit=1)[0]
```

To access the last element, use `str.rsplit()` instead of `str.split()`:
```python
url = "www.example.com"
suffix = url.rsplit(".", maxsplit=1)[-1]
```

## Fix Safety
This rule's fix is marked as unsafe for `split()`/`rsplit()` calls that contain `*args` or `**kwargs` arguments, as
adding a `maxsplit` argument to such a call may lead to duplicated arguments.

# iteration-over-set (PLC0208)

Derived from the **Pylint** linter.

Fix is always available.

## What it does
Checks for iteration over a `set` literal where each element in the set is
itself a literal value.

## Why is this bad?
Iterating over a `set` is less efficient than iterating over a sequence
type, like `list` or `tuple`.

## Example
```python
for number in {1, 2, 3}:
    ...
```

Use instead:
```python
for number in (1, 2, 3):
    ...
```

## References
- [Python documentation: `set`](https://docs.python.org/3/library/stdtypes.html#set)

# useless-import-alias (PLC0414)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for import aliases that do not rename the original package.
This rule does not apply in `__init__.py` files.

## Why is this bad?
The import alias is redundant and should be removed to avoid confusion.

## Fix safety
This fix is marked as always unsafe because the user may be intentionally
re-exporting the import. While statements like `import numpy as numpy`
appear redundant, they can have semantic meaning in certain contexts.

## Example
```python
import numpy as numpy
```

Use instead:
```python
import numpy as np
```

or

```python
import numpy
```

# import-outside-top-level (PLC0415)

Derived from the **Pylint** linter.

## What it does
Checks for `import` statements outside of a module's top-level scope, such
as within a function or class definition.

## Why is this bad?
[PEP 8] recommends placing imports not only at the top-level of a module,
but at the very top of the file, "just after any module comments and
docstrings, and before module globals and constants."

`import` statements have effects that are global in scope; defining them at
the top level has a number of benefits. For example, it makes it easier to
identify the dependencies of a module, and ensures that any invalid imports
are caught regardless of whether a specific function is called or class is
instantiated.

An import statement would typically be placed within a function only to
avoid a circular dependency, to defer a costly module load, or to avoid
loading a dependency altogether in a certain runtime environment.

## Example
```python
def print_python_version():
    import platform

    print(platform.python_version())
```

Use instead:
```python
import platform


def print_python_version():
    print(platform.python_version())
```

## See also
This rule will ignore import statements configured in
[`lint.flake8-tidy-imports.banned-module-level-imports`][banned-module-level-imports]
if the rule [`banned-module-level-imports`][TID253] is enabled.

[banned-module-level-imports]: https://docs.astral.sh/ruff/settings/#lint_flake8-tidy-imports_banned-module-level-imports
[TID253]: https://docs.astral.sh/ruff/rules/banned-module-level-imports/
[PEP 8]: https://peps.python.org/pep-0008/#imports

# len-test (PLC1802)

Derived from the **Pylint** linter.

Fix is always available.

## What it does
Checks for `len` calls on sequences in a boolean test context.

## Why is this bad?
Empty sequences are considered false in a boolean context.
You can either remove the call to `len`
or compare the length against a scalar.

## Example
```python
fruits = ["orange", "apple"]
vegetables = []

if len(fruits):
    print(fruits)

if not len(vegetables):
    print(vegetables)
```

Use instead:
```python
fruits = ["orange", "apple"]
vegetables = []

if fruits:
    print(fruits)

if not vegetables:
    print(vegetables)
```

## Fix safety
This rule's fix is marked as unsafe when the `len` call includes a comment,
as the comment would be removed.

For example, the fix would be marked as unsafe in the following case:
```python
fruits = []
if len(
    fruits  # comment
):
    ...
```

## References
[PEP 8: Programming Recommendations](https://peps.python.org/pep-0008/#programming-recommendations)

# compare-to-empty-string (PLC1901)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for comparisons to empty strings.

## Why is this bad?
An empty string is falsy, so it is unnecessary to compare it to `""`. If
the value can be something else Python considers falsy, such as `None`,
`0`, or another empty container, then the code is not equivalent.

## Known problems
High false positive rate, as the check is context-insensitive and does not
consider the type of the variable being compared ([#4282]).

## Example
```python
x: str = ...

if x == "":
    print("x is empty")
```

Use instead:
```python
x: str = ...

if not x:
    print("x is empty")
```

## References
- [Python documentation: Truth Value Testing](https://docs.python.org/3/library/stdtypes.html#truth-value-testing)

[#4282]: https://github.com/astral-sh/ruff/issues/4282

# non-ascii-name (PLC2401)

Derived from the **Pylint** linter.

## What it does
Checks for the use of non-ASCII characters in variable names.

## Why is this bad?
The use of non-ASCII characters in variable names can cause confusion
and compatibility issues (see: [PEP 672]).

## Example
```python
pple_count: int
```

Use instead:
```python
apple_count: int
```

[PEP 672]: https://peps.python.org/pep-0672/

# non-ascii-import-name (PLC2403)

Derived from the **Pylint** linter.

## What it does
Checks for the use of non-ASCII characters in import statements.

## Why is this bad?
The use of non-ASCII characters in import statements can cause confusion
and compatibility issues (see: [PEP 672]).

## Example
```python
import br
```

Use instead:
```python
import bar
```

If the module is third-party, use an ASCII-only alias:
```python
import br as bar
```

[PEP 672]: https://peps.python.org/pep-0672/

# import-private-name (PLC2701)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for import statements that import a private name (a name starting
with an underscore `_`) from another module.

## Why is this bad?
[PEP 8] states that names starting with an underscore are private. Thus,
they are not intended to be used outside of the module in which they are
defined.

Further, as private imports are not considered part of the public API, they
are prone to unexpected changes, especially outside of semantic versioning.

Instead, consider using the public API of the module.

This rule ignores private name imports that are exclusively used in type
annotations. Ideally, types would be public; however, this is not always
possible when using third-party libraries.

## Known problems
Does not ignore private name imports from within the module that defines
the private name if the module is defined with [PEP 420] namespace packages
(i.e., directories that omit the `__init__.py` file). Namespace packages
must be configured via the [`namespace-packages`] setting.

## Example
```python
from foo import _bar
```

## Options
- `namespace-packages`

## References
- [PEP 8: Naming Conventions](https://peps.python.org/pep-0008/#naming-conventions)
- [Semantic Versioning](https://semver.org/)

[PEP 8]: https://peps.python.org/pep-0008/
[PEP 420]: https://peps.python.org/pep-0420/

# unnecessary-dunder-call (PLC2801)

Derived from the **Pylint** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for explicit use of dunder methods, like `__str__` and `__add__`.

## Why is this bad?
Dunder names are not meant to be called explicitly and, in most cases, can
be replaced with builtins or operators.

## Fix safety
This fix is always unsafe. When replacing dunder method calls with operators
or builtins, the behavior can change in the following ways:

1. Types may implement only a subset of related dunder methods. Calling a
   missing dunder method directly returns `NotImplemented`, but using the
   equivalent operator raises a `TypeError`.
   ```python
   class C: pass
   c = C()
   c.__gt__(1)  # before fix: NotImplemented
   c > 1        # after fix: raises TypeError
   ```
2. Instance-assigned dunder methods are ignored by operators and builtins.
   ```python
   class C: pass
   c = C()
   c.__bool__ = lambda: False
   c.__bool__() # before fix: False
   bool(c)      # after fix: True
   ```

3. Even with built-in types, behavior can differ.
   ```python
   (1).__gt__(1.0)  # before fix: NotImplemented
   1 > 1.0          # after fix: False
   ```

## Example
```python
three = (3.0).__str__()
twelve = "1".__add__("2")


def is_greater_than_two(x: int) -> bool:
    return x.__gt__(2)
```

Use instead:
```python
three = str(3.0)
twelve = "1" + "2"


def is_greater_than_two(x: int) -> bool:
    return x > 2
```

# unnecessary-direct-lambda-call (PLC3002)

Derived from the **Pylint** linter.

## What it does
Checks for unnecessary direct calls to lambda expressions.

## Why is this bad?
Calling a lambda expression directly is unnecessary. The expression can be
executed inline instead to improve readability.

## Example
```python
area = (lambda r: 3.14 * r**2)(radius)
```

Use instead:
```python
area = 3.14 * radius**2
```

## References
- [Python documentation: Lambdas](https://docs.python.org/3/reference/expressions.html#lambda)

# yield-in-init (PLE0100)

Derived from the **Pylint** linter.

## What it does
Checks for `__init__` methods that are turned into generators by the
inclusion of `yield` or `yield from` expressions.

## Why is this bad?
The `__init__` method is the constructor for a given Python class,
responsible for initializing, rather than creating, new objects.

The `__init__` method has to return `None`. By including a `yield` or
`yield from` expression in an `__init__`, the method will return a
generator object when called at runtime, resulting in a runtime error.

## Example
```python
class InitIsGenerator:
    def __init__(self, i):
        yield i
```

## References
- [CodeQL: `py-init-method-is-generator`](https://codeql.github.com/codeql-query-help/python/py-init-method-is-generator/)

# return-in-init (PLE0101)

Derived from the **Pylint** linter.

## What it does
Checks for `__init__` methods that return values.

## Why is this bad?
The `__init__` method is the constructor for a given Python class,
responsible for initializing, rather than creating, new objects.

The `__init__` method has to return `None`. Returning any value from
an `__init__` method will result in a runtime error.

## Example
```python
class Example:
    def __init__(self):
        return []
```

Use instead:
```python
class Example:
    def __init__(self):
        self.value = []
```

## References
- [CodeQL: `py-explicit-return-in-init`](https://codeql.github.com/codeql-query-help/python/py-explicit-return-in-init/)

# nonlocal-and-global (PLE0115)

Derived from the **Pylint** linter.

## What it does
Checks for variables which are both declared as both `nonlocal` and
`global`.

## Why is this bad?
A `nonlocal` variable is a variable that is defined in the nearest
enclosing scope, but not in the global scope, while a `global` variable is
a variable that is defined in the global scope.

Declaring a variable as both `nonlocal` and `global` is contradictory and
will raise a `SyntaxError`.

## Example
```python
counter = 0


def increment():
    global counter
    nonlocal counter
    counter += 1
```

Use instead:
```python
counter = 0


def increment():
    global counter
    counter += 1
```

## References
- [Python documentation: The `global` statement](https://docs.python.org/3/reference/simple_stmts.html#the-global-statement)
- [Python documentation: The `nonlocal` statement](https://docs.python.org/3/reference/simple_stmts.html#nonlocal)

# continue-in-finally (PLE0116)

Derived from the **Pylint** linter.

## What it does
Checks for `continue` statements inside `finally`

## Why is this bad?
`continue` statements were not allowed within `finally` clauses prior to
Python 3.8. Using a `continue` statement within a `finally` clause can
cause a `SyntaxError`.

## Example
```python
while True:
    try:
        pass
    finally:
        continue
```

Use instead:
```python
while True:
    try:
        pass
    except Exception:
        pass
    else:
        continue
```

## Options
- `target-version`

# nonlocal-without-binding (PLE0117)

Derived from the **Pylint** linter.

## What it does
Checks for `nonlocal` names without bindings.

## Why is this bad?
`nonlocal` names must be bound to a name in an outer scope.
Violating this rule leads to a `SyntaxError` at runtime.

## Example
```python
def foo():
    def get_bar(self):
        nonlocal bar
        ...
```

Use instead:
```python
def foo():
    bar = 1

    def get_bar(self):
        nonlocal bar
        ...
```

## References
- [Python documentation: The `nonlocal` statement](https://docs.python.org/3/reference/simple_stmts.html#nonlocal)
- [PEP 3104  Access to Names in Outer Scopes](https://peps.python.org/pep-3104/)

# load-before-global-declaration (PLE0118)

Derived from the **Pylint** linter.

## What it does
Checks for uses of names that are declared as `global` prior to the
relevant `global` declaration.

## Why is this bad?
The `global` declaration applies to the entire scope. Using a name that's
declared as `global` in a given scope prior to the relevant `global`
declaration is a `SyntaxError`.

## Example
```python
counter = 1


def increment():
    print(f"Adding 1 to {counter}")
    global counter
    counter += 1
```

Use instead:
```python
counter = 1


def increment():
    global counter
    print(f"Adding 1 to {counter}")
    counter += 1
```

## References
- [Python documentation: The `global` statement](https://docs.python.org/3/reference/simple_stmts.html#the-global-statement)

# non-slot-assignment (PLE0237)

Derived from the **Pylint** linter.

## What it does
Checks for assignments to attributes that are not defined in `__slots__`.

## Why is this bad?
When using `__slots__`, only the specified attributes are allowed.
Attempting to assign to an attribute that is not defined in `__slots__`
will result in an `AttributeError` at runtime.

## Known problems
This rule can't detect `__slots__` implementations in superclasses, and
so limits its analysis to classes that inherit from (at most) `object`.

## Example
```python
class Student:
    __slots__ = ("name",)

    def __init__(self, name, surname):
        self.name = name
        self.surname = surname  # [assigning-non-slot]
        self.setup()

    def setup(self):
        pass
```

Use instead:
```python
class Student:
    __slots__ = ("name", "surname")

    def __init__(self, name, surname):
        self.name = name
        self.surname = surname
        self.setup()

    def setup(self):
        pass
```

# duplicate-bases (PLE0241)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for duplicate base classes in class definitions.

## Why is this bad?
Including duplicate base classes will raise a `TypeError` at runtime.

## Example
```python
class Foo:
    pass


class Bar(Foo, Foo):
    pass
```

Use instead:
```python
class Foo:
    pass


class Bar(Foo):
    pass
```

## Fix safety
This rule's fix is marked as unsafe if there's comments in the
base classes, as comments may be removed.

For example, the fix would be marked as unsafe in the following case:
```python
class Foo:
    pass


class Bar(
    Foo,  # comment
    Foo,
):
    pass
```

## References
- [Python documentation: Class definitions](https://docs.python.org/3/reference/compound_stmts.html#class-definitions)

# unexpected-special-method-signature (PLE0302)

Derived from the **Pylint** linter.

## What it does
Checks for "special" methods that have an unexpected method signature.

## Why is this bad?
"Special" methods, like `__len__`, are expected to adhere to a specific,
standard function signature. Implementing a "special" method using a
non-standard function signature can lead to unexpected and surprising
behavior for users of a given class.

## Example
```python
class Bookshelf:
    def __init__(self):
        self._books = ["Foo", "Bar", "Baz"]

    def __len__(self, index):  # __len__ does not except an index parameter
        return len(self._books)

    def __getitem__(self, index):
        return self._books[index]
```

Use instead:
```python
class Bookshelf:
    def __init__(self):
        self._books = ["Foo", "Bar", "Baz"]

    def __len__(self):
        return len(self._books)

    def __getitem__(self, index):
        return self._books[index]
```

## References
- [Python documentation: Data model](https://docs.python.org/3/reference/datamodel.html)

# invalid-length-return-type (PLE0303)

Derived from the **Pylint** linter.

## What it does
Checks for `__len__` implementations that return values that are not non-negative
integers.

## Why is this bad?
The `__len__` method should return a non-negative integer. Returning a different
value may cause unexpected behavior.

Note: `bool` is a subclass of `int`, so it's technically valid for `__len__` to
return `True` or `False`. However, for consistency with other rules, Ruff will
still emit a diagnostic when `__len__` returns a `bool`.

## Example
```python
class Foo:
    def __len__(self):
        return "2"
```

Use instead:
```python
class Foo:
    def __len__(self):
        return 2
```

## References
- [Python documentation: The `__len__` method](https://docs.python.org/3/reference/datamodel.html#object.__len__)

# invalid-bool-return-type (PLE0304)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for `__bool__` implementations that return a type other than `bool`.

## Why is this bad?
The `__bool__` method should return a `bool` object. Returning a different
type may cause unexpected behavior.

## Example
```python
class Foo:
    def __bool__(self):
        return 2
```

Use instead:
```python
class Foo:
    def __bool__(self):
        return True
```

## References
- [Python documentation: The `__bool__` method](https://docs.python.org/3/reference/datamodel.html#object.__bool__)

# invalid-index-return-type (PLE0305)

Derived from the **Pylint** linter.

## What it does
Checks for `__index__` implementations that return non-integer values.

## Why is this bad?
The `__index__` method should return an integer. Returning a different
type may cause unexpected behavior.

Note: `bool` is a subclass of `int`, so it's technically valid for `__index__` to
return `True` or `False`. However, a `DeprecationWarning` (`DeprecationWarning:
__index__ returned non-int (type bool)`) for such cases was already introduced,
thus this is a conscious difference between the original pylint rule and the
current ruff implementation.

## Example
```python
class Foo:
    def __index__(self):
        return "2"
```

Use instead:
```python
class Foo:
    def __index__(self):
        return 2
```

## References
- [Python documentation: The `__index__` method](https://docs.python.org/3/reference/datamodel.html#object.__index__)

# invalid-str-return-type (PLE0307)

Derived from the **Pylint** linter.

## What it does
Checks for `__str__` implementations that return a type other than `str`.

## Why is this bad?
The `__str__` method should return a `str` object. Returning a different
type may cause unexpected behavior.

## Example
```python
class Foo:
    def __str__(self):
        return True
```

Use instead:
```python
class Foo:
    def __str__(self):
        return "Foo"
```

## References
- [Python documentation: The `__str__` method](https://docs.python.org/3/reference/datamodel.html#object.__str__)

# invalid-bytes-return-type (PLE0308)

Derived from the **Pylint** linter.

## What it does
Checks for `__bytes__` implementations that return types other than `bytes`.

## Why is this bad?
The `__bytes__` method should return a `bytes` object. Returning a different
type may cause unexpected behavior.

## Example
```python
class Foo:
    def __bytes__(self):
        return 2
```

Use instead:
```python
class Foo:
    def __bytes__(self):
        return b"2"
```

## References
- [Python documentation: The `__bytes__` method](https://docs.python.org/3/reference/datamodel.html#object.__bytes__)

# invalid-hash-return-type (PLE0309)

Derived from the **Pylint** linter.

## What it does
Checks for `__hash__` implementations that return non-integer values.

## Why is this bad?
The `__hash__` method should return an integer. Returning a different
type may cause unexpected behavior.

Note: `bool` is a subclass of `int`, so it's technically valid for `__hash__` to
return `True` or `False`. However, for consistency with other rules, Ruff will
still emit a diagnostic when `__hash__` returns a `bool`.

## Example
```python
class Foo:
    def __hash__(self):
        return "2"
```

Use instead:
```python
class Foo:
    def __hash__(self):
        return 2
```

## References
- [Python documentation: The `__hash__` method](https://docs.python.org/3/reference/datamodel.html#object.__hash__)

# invalid-all-object (PLE0604)

Derived from the **Pylint** linter.

## What it does
Checks for the inclusion of invalid objects in `__all__`.

## Why is this bad?
In Python, `__all__` should contain a sequence of strings that represent
the names of all "public" symbols exported by a module.

Assigning anything other than a `tuple` or `list` of strings to `__all__`
is invalid.

## Example
```python
__all__ = [Foo, 1, None]
```

Use instead:
```python
__all__ = ["Foo", "Bar", "Baz"]
```

## References
- [Python documentation: The `import` statement](https://docs.python.org/3/reference/simple_stmts.html#the-import-statement)

# invalid-all-format (PLE0605)

Derived from the **Pylint** linter.

## What it does
Checks for invalid assignments to `__all__`.

## Why is this bad?
In Python, `__all__` should contain a sequence of strings that represent
the names of all "public" symbols exported by a module.

Assigning anything other than a `tuple` or `list` of strings to `__all__`
is invalid.

## Example
```python
__all__ = "Foo"
```

Use instead:
```python
__all__ = ("Foo",)
```

## References
- [Python documentation: The `import` statement](https://docs.python.org/3/reference/simple_stmts.html#the-import-statement)

# potential-index-error (PLE0643)

Derived from the **Pylint** linter.

## What it does
Checks for hard-coded sequence accesses that are known to be out of bounds.

## Why is this bad?
Attempting to access a sequence with an out-of-bounds index will cause an
`IndexError` to be raised at runtime. When the sequence and index are
defined statically (e.g., subscripts on `list` and `tuple` literals, with
integer indexes), such errors can be detected ahead of time.

## Example
```python
print([0, 1, 2][3])
```

# misplaced-bare-raise (PLE0704)

Derived from the **Pylint** linter.

## What it does
Checks for bare `raise` statements outside of exception handlers.

## Why is this bad?
A bare `raise` statement without an exception object will re-raise the last
exception that was active in the current scope, and is typically used
within an exception handler to re-raise the caught exception.

If a bare `raise` is used outside of an exception handler, it will generate
an error due to the lack of an active exception.

Note that a bare `raise` within a  `finally` block will work in some cases
(namely, when the exception is raised within the `try` block), but should
be avoided as it can lead to confusing behavior.

## Example
```python
from typing import Any


def is_some(obj: Any) -> bool:
    if obj is None:
        raise
```

Use instead:
```python
from typing import Any


def is_some(obj: Any) -> bool:
    if obj is None:
        raise ValueError("`obj` cannot be `None`")
```

# repeated-keyword-argument (PLE1132)

Derived from the **Pylint** linter.

## What it does
Checks for repeated keyword arguments in function calls.

## Why is this bad?
Python does not allow repeated keyword arguments in function calls. If a
function is called with the same keyword argument multiple times, the
interpreter will raise an exception.

## Example
```python
func(1, 2, c=3, **{"c": 4})
```

## References
- [Python documentation: Argument](https://docs.python.org/3/glossary.html#term-argument)

# dict-iter-missing-items (PLE1141)

Derived from the **Pylint** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for dictionary unpacking in a for loop without calling `.items()`.

## Why is this bad?
When iterating over a dictionary in a for loop, if a dictionary is unpacked
without calling `.items()`, it could lead to a runtime error if the keys are not
a tuple of two elements.

It is likely that you're looking for an iteration over (key, value) pairs which
can only be achieved when calling `.items()`.

## Example
```python
data = {"Paris": 2_165_423, "New York City": 8_804_190, "Tokyo": 13_988_129}

for city, population in data:
    print(f"{city} has population {population}.")
```

Use instead:
```python
data = {"Paris": 2_165_423, "New York City": 8_804_190, "Tokyo": 13_988_129}

for city, population in data.items():
    print(f"{city} has population {population}.")
```

## Known problems
If the dictionary key is a tuple, e.g.:

```python
d = {(1, 2): 3, (3, 4): 5}
for x, y in d:
    print(x, y)
```

The tuple key is unpacked into `x` and `y` instead of the key and values. This means that
the suggested fix of using `d.items()` would result in different runtime behavior. Ruff
cannot consistently infer the type of a dictionary's keys.

## Fix safety
Due to the known problem with tuple keys, this fix is unsafe.

# await-outside-async (PLE1142)

Derived from the **Pylint** linter.

## What it does
Checks for uses of `await` outside `async` functions.

## Why is this bad?
Using `await` outside an `async` function is a syntax error.

## Example
```python
import asyncio


def foo():
    await asyncio.sleep(1)
```

Use instead:
```python
import asyncio


async def foo():
    await asyncio.sleep(1)
```

## Notebook behavior
As an exception, `await` is allowed at the top level of a Jupyter notebook
(see: [autoawait]).

## References
- [Python documentation: Await expression](https://docs.python.org/3/reference/expressions.html#await)
- [PEP 492: Await Expression](https://peps.python.org/pep-0492/#await-expression)

[autoawait]: https://ipython.readthedocs.io/en/stable/interactive/autoawait.html

# logging-too-many-args (PLE1205)

Derived from the **Pylint** linter.

## What it does
Checks for too many positional arguments for a `logging` format string.

## Why is this bad?
A `TypeError` will be raised if the statement is run.

## Example
```python
import logging

try:
    function()
except Exception as e:
    logging.error("Error occurred: %s", type(e), e)
    raise
```

Use instead:
```python
import logging

try:
    function()
except Exception as e:
    logging.error("%s error occurred: %s", type(e), e)
    raise
```

# logging-too-few-args (PLE1206)

Derived from the **Pylint** linter.

## What it does
Checks for too few positional arguments for a `logging` format string.

## Why is this bad?
A `TypeError` will be raised if the statement is run.

## Example
```python
import logging

try:
    function()
except Exception as e:
    logging.error("%s error occurred: %s", e)
    raise
```

Use instead:
```python
import logging

try:
    function()
except Exception as e:
    logging.error("%s error occurred: %s", type(e), e)
    raise
```

# bad-string-format-character (PLE1300)

Derived from the **Pylint** linter.

## What it does
Checks for unsupported format types in format strings.

## Why is this bad?
An invalid format string character will result in an error at runtime.

## Example
```python
# `z` is not a valid format type.
print("%z" % "1")

print("{:z}".format("1"))
```

# bad-string-format-type (PLE1307)

Derived from the **Pylint** linter.

## What it does
Checks for mismatched argument types in "old-style" format strings.

## Why is this bad?
The format string is not checked at compile time, so it is easy to
introduce bugs by mistyping the format string.

## Example
```python
print("%d" % "1")
```

Use instead:
```python
print("%d" % 1)
```

# bad-str-strip-call (PLE1310)

Derived from the **Pylint** linter.

## What it does
Checks duplicate characters in `str.strip` calls.

## Why is this bad?
All characters in `str.strip` calls are removed from both the leading and
trailing ends of the string. Including duplicate characters in the call
is redundant and often indicative of a mistake.

In Python 3.9 and later, you can use `str.removeprefix` and
`str.removesuffix` to remove an exact prefix or suffix from a string,
respectively, which should be preferred when possible.

## Example
```python
# Evaluates to "foo".
"bar foo baz".strip("bar baz ")
```

Use instead:
```python
# Evaluates to "foo".
"bar foo baz".strip("abrz ")  # "foo"
```

Or:
```python
# Evaluates to "foo".
"bar foo baz".removeprefix("bar ").removesuffix(" baz")
```

## Options
- `target-version`

## References
- [Python documentation: `str.strip`](https://docs.python.org/3/library/stdtypes.html?highlight=strip#str.strip)

# invalid-envvar-value (PLE1507)

Derived from the **Pylint** linter.

## What it does
Checks for `os.getenv` calls with an invalid `key` argument.

## Why is this bad?
`os.getenv` only supports strings as the first argument (`key`).

If the provided argument is not a string, `os.getenv` will throw a
`TypeError` at runtime.

## Example
```python
import os

os.getenv(1)
```

Use instead:
```python
import os

os.getenv("1")
```

# singledispatch-method (PLE1519)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for methods decorated with `@singledispatch`.

## Why is this bad?
The `@singledispatch` decorator is intended for use with functions, not methods.

Instead, use the `@singledispatchmethod` decorator, or migrate the method to a
standalone function.

## Example

```python
from functools import singledispatch


class Class:
    @singledispatch
    def method(self, arg): ...
```

Use instead:

```python
from functools import singledispatchmethod


class Class:
    @singledispatchmethod
    def method(self, arg): ...
```

## Fix safety
This rule's fix is marked as unsafe, as migrating from `@singledispatch` to
`@singledispatchmethod` may change the behavior of the code.

# singledispatchmethod-function (PLE1520)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for non-method functions decorated with `@singledispatchmethod`.

## Why is this bad?
The `@singledispatchmethod` decorator is intended for use with methods, not
functions.

Instead, use the `@singledispatch` decorator.

## Example

```python
from functools import singledispatchmethod


@singledispatchmethod
def func(arg): ...
```

Use instead:

```python
from functools import singledispatch


@singledispatch
def func(arg): ...
```

## Fix safety
This rule's fix is marked as unsafe, as migrating from `@singledispatchmethod` to
`@singledispatch` may change the behavior of the code.

# yield-from-in-async-function (PLE1700)

Derived from the **Pylint** linter.

## What it does
Checks for uses of `yield from` in async functions.

## Why is this bad?
Python doesn't support the use of `yield from` in async functions, and will
raise a `SyntaxError` in such cases.

Instead, considering refactoring the code to use an `async for` loop instead.

## Example
```python
async def numbers():
    yield from [1, 2, 3, 4, 5]
```

Use instead:
```python
async def numbers():
    async for number in [1, 2, 3, 4, 5]:
        yield number
```

# bidirectional-unicode (PLE2502)

Derived from the **Pylint** linter.

## What it does
Checks for bidirectional formatting characters.

## Why is this bad?
The interaction between bidirectional formatting characters and the
surrounding code can be surprising to those that are unfamiliar
with right-to-left writing systems.

In some cases, bidirectional formatting characters can also be used to
obfuscate code and introduce or mask security vulnerabilities.

## Example
```python
example = "x" * 100  #    "x" is assigned
```

The example uses two `RIGHT-TO-LEFT MARK`s to make the `100 * ` appear inside the comment.
Without the `RIGHT-TO-LEFT MARK`s, the code looks like this:

```py
example = "x" * 100  #    "x" is assigned
```

## References
- [PEP 672: Bidirectional Marks, Embeddings, Overrides and Isolates](https://peps.python.org/pep-0672/#bidirectional-marks-embeddings-overrides-and-isolates)

# invalid-character-backspace (PLE2510)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for strings that contain the control character `BS`.

## Why is this bad?
Control characters are displayed differently by different text editors and
terminals.

By using the `\b` sequence in lieu of the `BS` control character, the
string will contain the same value, but will render visibly in all editors.

## Example
```python
x = ""
```

Use instead:
```python
x = "\b"
```

# invalid-character-sub (PLE2512)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for strings that contain the raw control character `SUB`.

## Why is this bad?
Control characters are displayed differently by different text editors and
terminals.

By using the `\x1a` sequence in lieu of the `SUB` control character, the
string will contain the same value, but will render visibly in all editors.

## Example
```python
x = ""
```

Use instead:
```python
x = "\x1a"
```

# invalid-character-esc (PLE2513)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for strings that contain the raw control character `ESC`.

## Why is this bad?
Control characters are displayed differently by different text editors and
terminals.

By using the `\x1b` sequence in lieu of the `ESC` control character, the
string will contain the same value, but will render visibly in all editors.

## Example
```python
x = ""
```

Use instead:
```python
x = "\x1b"
```

# invalid-character-nul (PLE2514)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for strings that contain the raw control character `NUL` (0 byte).

## Why is this bad?
Control characters are displayed differently by different text editors and
terminals.

By using the `\0` sequence in lieu of the `NUL` control character, the
string will contain the same value, but will render visibly in all editors.

## Example
```python
x = ""
```

Use instead:
```python
x = "\0"
```

# invalid-character-zero-width-space (PLE2515)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for strings that contain the zero width space character.

## Why is this bad?
This character is rendered invisibly in some text editors and terminals.

By using the `\u200B` sequence, the string will contain the same value,
but will render visibly in all editors.

## Example
```python
x = "Dear Sir/Madam"
```

Use instead:
```python
x = "Dear Sir\u200b/\u200bMadam"  # zero width space
```

# modified-iterating-set (PLE4703)

Derived from the **Pylint** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for loops in which a `set` is modified during iteration.

## Why is this bad?
If a `set` is modified during iteration, it will cause a `RuntimeError`.

If you need to modify a `set` within a loop, consider iterating over a copy
of the `set` instead.

## Known problems
This rule favors false negatives over false positives. Specifically, it
will only detect variables that can be inferred to be a `set` type based on
local type inference, and will only detect modifications that are made
directly on the variable itself (e.g., `set.add()`), as opposed to
modifications within other function calls (e.g., `some_function(set)`).

## Example
```python
nums = {1, 2, 3}
for num in nums:
    nums.add(num + 5)
```

Use instead:
```python
nums = {1, 2, 3}
for num in nums.copy():
    nums.add(num + 5)
```

## Fix safety
This fix is always unsafe because it changes the programs behavior. Replacing the
original set with a copy during iteration allows code that would previously raise a
`RuntimeError` to run without error.

## References
- [Python documentation: `set`](https://docs.python.org/3/library/stdtypes.html#set)

# comparison-with-itself (PLR0124)

Derived from the **Pylint** linter.

## What it does
Checks for operations that compare a name to itself.

## Why is this bad?
Comparing a name to itself always results in the same value, and is likely
a mistake.

## Example
```python
foo == foo
```

In some cases, self-comparisons are used to determine whether a float is
NaN. Instead, prefer `math.isnan`:
```python
import math

math.isnan(foo)
```

## References
- [Python documentation: Comparisons](https://docs.python.org/3/reference/expressions.html#comparisons)

# comparison-of-constant (PLR0133)

Derived from the **Pylint** linter.

## What it does
Checks for comparisons between constants.

## Why is this bad?
Comparing two constants will always resolve to the same value, so the
comparison is redundant. Instead, the expression should be replaced
with the result of the comparison.

## Example
```python
foo = 1 == 1
```

Use instead:
```python
foo = True
```

## References
- [Python documentation: Comparisons](https://docs.python.org/3/reference/expressions.html#comparisons)

# no-classmethod-decorator (PLR0202)

Derived from the **Pylint** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for the use of a classmethod being made without the decorator.

## Why is this bad?
When it comes to consistency and readability, it's preferred to use the decorator.

## Example

```python
class Foo:
    def bar(cls): ...

    bar = classmethod(bar)
```

Use instead:

```python
class Foo:
    @classmethod
    def bar(cls): ...
```

# no-staticmethod-decorator (PLR0203)

Derived from the **Pylint** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for the use of a staticmethod being made without the decorator.

## Why is this bad?
When it comes to consistency and readability, it's preferred to use the decorator.

## Example

```python
class Foo:
    def bar(arg1, arg2): ...

    bar = staticmethod(bar)
```

Use instead:

```python
class Foo:
    @staticmethod
    def bar(arg1, arg2): ...
```

# property-with-parameters (PLR0206)

Derived from the **Pylint** linter.

## What it does
Checks for property definitions that accept function parameters.

## Why is this bad?
Properties cannot be called with parameters.

If you need to pass parameters to a property, create a method with the
desired parameters and call that method instead.

## Example

```python
class Cat:
    @property
    def purr(self, volume): ...
```

Use instead:

```python
class Cat:
    @property
    def purr(self): ...

    def purr_volume(self, volume): ...
```

## References
- [Python documentation: `property`](https://docs.python.org/3/library/functions.html#property)

# manual-from-import (PLR0402)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for submodule imports that are aliased to the submodule name.

## Why is this bad?
Using the `from` keyword to import the submodule is more concise and
readable.

## Example
```python
import concurrent.futures as futures
```

Use instead:
```python
from concurrent import futures
```

## References
- [Python documentation: Submodules](https://docs.python.org/3/reference/import.html#submodules)

# too-many-public-methods (PLR0904)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for classes with too many public methods

By default, this rule allows up to 20 public methods, as configured by
the [`lint.pylint.max-public-methods`] option.

## Why is this bad?
Classes with many public methods are harder to understand
and maintain.

Instead, consider refactoring the class into separate classes.

## Example
Assuming that `lint.pylint.max-public-methods` is set to 5:
```python
class Linter:
    def __init__(self):
        pass

    def pylint(self):
        pass

    def pylint_settings(self):
        pass

    def flake8(self):
        pass

    def flake8_settings(self):
        pass

    def pydocstyle(self):
        pass

    def pydocstyle_settings(self):
        pass
```

Use instead:
```python
class Linter:
    def __init__(self):
        self.pylint = Pylint()
        self.flake8 = Flake8()
        self.pydocstyle = Pydocstyle()

    def lint(self):
        pass


class Pylint:
    def lint(self):
        pass

    def settings(self):
        pass


class Flake8:
    def lint(self):
        pass

    def settings(self):
        pass


class Pydocstyle:
    def lint(self):
        pass

    def settings(self):
        pass
```

## Options
- `lint.pylint.max-public-methods`

# too-many-return-statements (PLR0911)

Derived from the **Pylint** linter.

## What it does
Checks for functions or methods with too many return statements.

By default, this rule allows up to six return statements, as configured by
the [`lint.pylint.max-returns`] option.

## Why is this bad?
Functions or methods with many return statements are harder to understand
and maintain, and often indicative of complex logic.

## Example
```python
def capital(country: str) -> str | None:
    if country == "England":
        return "London"
    elif country == "France":
        return "Paris"
    elif country == "Poland":
        return "Warsaw"
    elif country == "Romania":
        return "Bucharest"
    elif country == "Spain":
        return "Madrid"
    elif country == "Thailand":
        return "Bangkok"
    else:
        return None
```

Use instead:
```python
def capital(country: str) -> str | None:
    capitals = {
        "England": "London",
        "France": "Paris",
        "Poland": "Warsaw",
        "Romania": "Bucharest",
        "Spain": "Madrid",
        "Thailand": "Bangkok",
    }
    return capitals.get(country)
```

## Options
- `lint.pylint.max-returns`

# too-many-branches (PLR0912)

Derived from the **Pylint** linter.

## What it does
Checks for functions or methods with too many branches, including (nested)
`if`, `elif`, and `else` branches, `for` loops, `try`-`except` clauses, and
`match` and `case` statements.

By default, this rule allows up to 12 branches. This can be configured
using the [`lint.pylint.max-branches`] option.

## Why is this bad?
Functions or methods with many branches are harder to understand
and maintain than functions or methods with fewer branches.

## Example
Given:
```python
def capital(country):
    if country == "Australia":
        return "Canberra"
    elif country == "Brazil":
        return "Brasilia"
    elif country == "Canada":
        return "Ottawa"
    elif country == "England":
        return "London"
    elif country == "France":
        return "Paris"
    elif country == "Germany":
        return "Berlin"
    elif country == "Poland":
        return "Warsaw"
    elif country == "Romania":
        return "Bucharest"
    elif country == "Spain":
        return "Madrid"
    elif country == "Thailand":
        return "Bangkok"
    elif country == "Turkey":
        return "Ankara"
    elif country == "United States":
        return "Washington"
    else:
        return "Unknown"  # 13th branch
```

Use instead:
```python
def capital(country):
    capitals = {
        "Australia": "Canberra",
        "Brazil": "Brasilia",
        "Canada": "Ottawa",
        "England": "London",
        "France": "Paris",
        "Germany": "Berlin",
        "Poland": "Warsaw",
        "Romania": "Bucharest",
        "Spain": "Madrid",
        "Thailand": "Bangkok",
        "Turkey": "Ankara",
        "United States": "Washington",
    }
    city = capitals.get(country, "Unknown")
    return city
```

Given:
```python
def grades_to_average_number(grades):
    numbers = []
    for grade in grades:  # 1st branch
        if len(grade) not in {1, 2}:
            raise ValueError(f"Invalid grade: {grade}")

        if len(grade) == 2 and grade[1] not in {"+", "-"}:
            raise ValueError(f"Invalid grade: {grade}")

        letter = grade[0]

        if letter in {"F", "E"}:
            number = 0.0
        elif letter == "D":
            number = 1.0
        elif letter == "C":
            number = 2.0
        elif letter == "B":
            number = 3.0
        elif letter == "A":
            number = 4.0
        else:
            raise ValueError(f"Invalid grade: {grade}")

        modifier = 0.0
        if letter != "F" and grade[-1] == "+":
            modifier = 0.3
        elif letter != "F" and grade[-1] == "-":
            modifier = -0.3

        numbers.append(max(0.0, min(number + modifier, 4.0)))

    try:
        return sum(numbers) / len(numbers)
    except ZeroDivisionError:  # 13th branch
        return 0
```

Use instead:
```python
def grades_to_average_number(grades):
    grade_values = {"F": 0.0, "E": 0.0, "D": 1.0, "C": 2.0, "B": 3.0, "A": 4.0}
    modifier_values = {"+": 0.3, "-": -0.3}

    numbers = []
    for grade in grades:
        if len(grade) not in {1, 2}:
            raise ValueError(f"Invalid grade: {grade}")

        letter = grade[0]
        if letter not in grade_values:
            raise ValueError(f"Invalid grade: {grade}")
        number = grade_values[letter]

        if len(grade) == 2 and grade[1] not in modifier_values:
            raise ValueError(f"Invalid grade: {grade}")
        modifier = modifier_values.get(grade[-1], 0.0)

        if letter == "F":
            numbers.append(0.0)
        else:
            numbers.append(max(0.0, min(number + modifier, 4.0)))

    try:
        return sum(numbers) / len(numbers)
    except ZeroDivisionError:
        return 0
```

## Options
- `lint.pylint.max-branches`

# too-many-arguments (PLR0913)

Derived from the **Pylint** linter.

## What it does
Checks for function definitions that include too many arguments.

By default, this rule allows up to five arguments, as configured by the
[`lint.pylint.max-args`] option.

This rule exempts methods decorated with [`@typing.override`][override].
Changing the signature of a subclass method may cause type checkers to
complain about a violation of the Liskov Substitution Principle if it
means that the method now incompatibly overrides a method defined on a
superclass. Explicitly decorating an overriding method with `@override`
signals to Ruff that the method is intended to override a superclass
method and that a type checker will enforce that it does so; Ruff
therefore knows that it should not enforce rules about methods having
too many arguments.

## Why is this bad?
Functions with many arguments are harder to understand, maintain, and call.
Consider refactoring functions with many arguments into smaller functions
with fewer arguments, or using objects to group related arguments.

## Example
```python
def calculate_position(x_pos, y_pos, z_pos, x_vel, y_vel, z_vel, time):
    new_x = x_pos + x_vel * time
    new_y = y_pos + y_vel * time
    new_z = z_pos + z_vel * time
    return new_x, new_y, new_z
```

Use instead:
```python
from typing import NamedTuple


class Vector(NamedTuple):
    x: float
    y: float
    z: float


def calculate_position(pos: Vector, vel: Vector, time: float) -> Vector:
    return Vector(*(p + v * time for p, v in zip(pos, vel)))
```

## Options
- `lint.pylint.max-args`

[override]: https://docs.python.org/3/library/typing.html#typing.override

# too-many-locals (PLR0914)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for functions that include too many local variables.

By default, this rule allows up to fifteen locals, as configured by the
[`lint.pylint.max-locals`] option.

## Why is this bad?
Functions with many local variables are harder to understand and maintain.

Consider refactoring functions with many local variables into smaller
functions with fewer assignments.

## Options
- `lint.pylint.max-locals`

# too-many-statements (PLR0915)

Derived from the **Pylint** linter.

## What it does
Checks for functions or methods with too many statements.

By default, this rule allows up to 50 statements, as configured by the
[`lint.pylint.max-statements`] option.

## Why is this bad?
Functions or methods with many statements are harder to understand
and maintain.

Instead, consider refactoring the function or method into smaller
functions or methods, or identifying generalizable patterns and
replacing them with generic logic or abstractions.

## Example
```python
def is_even(number: int) -> bool:
    if number == 0:
        return True
    elif number == 1:
        return False
    elif number == 2:
        return True
    elif number == 3:
        return False
    elif number == 4:
        return True
    elif number == 5:
        return False
    else:
        ...
```

Use instead:
```python
def is_even(number: int) -> bool:
    return number % 2 == 0
```

## Options
- `lint.pylint.max-statements`

# too-many-boolean-expressions (PLR0916)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for too many Boolean expressions in an `if` statement.

By default, this rule allows up to 5 expressions. This can be configured
using the [`lint.pylint.max-bool-expr`] option.

## Why is this bad?
`if` statements with many Boolean expressions are harder to understand
and maintain. Consider assigning the result of the Boolean expression,
or any of its sub-expressions, to a variable.

## Example
```python
if a and b and c and d and e and f and g and h:
    ...
```

## Options
- `lint.pylint.max-bool-expr`

# too-many-positional-arguments (PLR0917)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for function definitions that include too many positional arguments.

By default, this rule allows up to five arguments, as configured by the
[`lint.pylint.max-positional-args`] option.

## Why is this bad?
Functions with many arguments are harder to understand, maintain, and call.
This is especially true for functions with many positional arguments, as
providing arguments positionally is more error-prone and less clear to
readers than providing arguments by name.

Consider refactoring functions with many arguments into smaller functions
with fewer arguments, using objects to group related arguments, or migrating to
[keyword-only arguments](https://docs.python.org/3/tutorial/controlflow.html#special-parameters).

This rule exempts methods decorated with [`@typing.override`][override].
Changing the signature of a subclass method may cause type checkers to
complain about a violation of the Liskov Substitution Principle if it
means that the method now incompatibly overrides a method defined on a
superclass. Explicitly decorating an overriding method with `@override`
signals to Ruff that the method is intended to override a superclass
method and that a type checker will enforce that it does so; Ruff
therefore knows that it should not enforce rules about methods having
too many arguments.

## Example

```python
def plot(x, y, z, color, mark, add_trendline): ...


plot(1, 2, 3, "r", "*", True)
```

Use instead:

```python
def plot(x, y, z, *, color, mark, add_trendline): ...


plot(1, 2, 3, color="r", mark="*", add_trendline=True)
```

## Options
- `lint.pylint.max-positional-args`

[override]: https://docs.python.org/3/library/typing.html#typing.override

# repeated-isinstance-calls (PLR1701)

Derived from the **Pylint** linter.

Fix is always available.

## Removed
This rule is identical to [SIM101] which should be used instead.

## What it does
Checks for repeated `isinstance` calls on the same object.

## Why is this bad?
Repeated `isinstance` calls on the same object can be merged into a
single call.

## Fix safety
This rule's fix is marked as unsafe on Python 3.10 and later, as combining
multiple `isinstance` calls with a binary operator (`|`) will fail at
runtime if any of the operands are themselves tuples.

For example, given `TYPES = (dict, list)`, then
`isinstance(None, TYPES | set | float)` will raise a `TypeError` at runtime,
while `isinstance(None, set | float)` will not.

## Example
```python
def is_number(x):
    return isinstance(x, int) or isinstance(x, float) or isinstance(x, complex)
```

Use instead:
```python
def is_number(x):
    return isinstance(x, (int, float, complex))
```

Or, for Python 3.10 and later:

```python
def is_number(x):
    return isinstance(x, int | float | complex)
```

## Options
- `target-version`

## References
- [Python documentation: `isinstance`](https://docs.python.org/3/library/functions.html#isinstance)

[SIM101]: https://docs.astral.sh/ruff/rules/duplicate-isinstance-call/

# too-many-nested-blocks (PLR1702)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for functions or methods with too many nested blocks.

By default, this rule allows up to five nested blocks.
This can be configured using the [`lint.pylint.max-nested-blocks`] option.

## Why is this bad?
Functions or methods with too many nested blocks are harder to understand
and maintain.

## Options
- `lint.pylint.max-nested-blocks`

# redefined-argument-from-local (PLR1704)

Derived from the **Pylint** linter.

## What it does
Checks for variables defined in `for`, `try`, `with` statements
that redefine function parameters.

## Why is this bad?
Redefined variables can cause unexpected behavior because of overridden function parameters.
If nested functions are declared, an inner function's body can override an outer function's parameters.

## Example
```python
def show(host_id=10.11):
    for host_id, host in [[12.13, "Venus"], [14.15, "Mars"]]:
        print(host_id, host)
```

Use instead:
```python
def show(host_id=10.11):
    for inner_host_id, host in [[12.13, "Venus"], [14.15, "Mars"]]:
        print(host_id, inner_host_id, host)
```

## Options
- `lint.dummy-variable-rgx`

## References
- [Pylint documentation](https://pylint.readthedocs.io/en/latest/user_guide/messages/refactor/redefined-argument-from-local.html)

# and-or-ternary (PLR1706)

Derived from the **Pylint** linter.

## Removal
This rule was removed from Ruff because it was common for it to introduce behavioral changes.
See [#9007](https://github.com/astral-sh/ruff/issues/9007) for more information.

## What it does
Checks for uses of the known pre-Python 2.5 ternary syntax.

## Why is this bad?
Prior to the introduction of the if-expression (ternary) operator in Python
2.5, the only way to express a conditional expression was to use the `and`
and `or` operators.

The if-expression construct is clearer and more explicit, and should be
preferred over the use of `and` and `or` for ternary expressions.

## Example
```python
x, y = 1, 2
maximum = x >= y and x or y
```

Use instead:
```python
x, y = 1, 2
maximum = x if x >= y else y
```

# stop-iteration-return (PLR1708)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for explicit `raise StopIteration` in generator functions.

## Why is this bad?
Raising `StopIteration` in a generator function causes a `RuntimeError`
when the generator is iterated over.

Instead of `raise StopIteration`, use `return` in generator functions.

## Example
```python
def my_generator():
    yield 1
    yield 2
    raise StopIteration  # This causes RuntimeError at runtime
```

Use instead:
```python
def my_generator():
    yield 1
    yield 2
    return  # Use return instead
```

## References
- [PEP 479](https://peps.python.org/pep-0479/)
- [Python documentation](https://docs.python.org/3/library/exceptions.html#StopIteration)

# useless-return (PLR1711)

Derived from the **Pylint** linter.

Fix is always available.

## What it does
Checks for functions that end with an unnecessary `return` or
`return None`, and contain no other `return` statements.

## Why is this bad?
Python implicitly assumes a `None` return at the end of a function, making
it unnecessary to explicitly write `return None`.

## Example
```python
def f():
    print(5)
    return None
```

Use instead:
```python
def f():
    print(5)
```

# repeated-equality-comparison (PLR1714)

Derived from the **Pylint** linter.

Fix is always available.

## What it does
Checks for repeated equality comparisons that can be rewritten as a membership
test.

This rule will try to determine if the values are hashable
and the fix will use a `set` if they are. If unable to determine, the fix
will use a `tuple` and suggest the use of a `set`.

## Why is this bad?
To check if a variable is equal to one of many values, it is common to
write a series of equality comparisons (e.g.,
`foo == "bar" or foo == "baz"`).

Instead, prefer to combine the values into a collection and use the `in`
operator to check for membership, which is more performant and succinct.
If the items are hashable, use a `set` for efficiency; otherwise, use a
`tuple`.

## Fix safety
This rule is always unsafe since literal sets and tuples
evaluate their members eagerly whereas `or` comparisons
are short-circuited. It is therefore possible that a fix
will change behavior in the presence of side-effects.

## Example
```python
foo == "bar" or foo == "baz" or foo == "qux"
```

Use instead:
```python
foo in {"bar", "baz", "qux"}
```

## References
- [Python documentation: Comparisons](https://docs.python.org/3/reference/expressions.html#comparisons)
- [Python documentation: Membership test operations](https://docs.python.org/3/reference/expressions.html#membership-test-operations)
- [Python documentation: `set`](https://docs.python.org/3/library/stdtypes.html#set)

# boolean-chained-comparison (PLR1716)

Derived from the **Pylint** linter.

Fix is always available.

## What it does
Check for chained boolean operations that can be simplified.

## Why is this bad?
Refactoring the code will improve readability for these cases.

## Example

```python
a = int(input())
b = int(input())
c = int(input())
if a < b and b < c:
    pass
```

Use instead:

```python
a = int(input())
b = int(input())
c = int(input())
if a < b < c:
    pass
```

# sys-exit-alias (PLR1722)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for uses of the `exit()` and `quit()`.

## Why is this bad?
`exit` and `quit` come from the `site` module, which is typically imported
automatically during startup. However, it is not _guaranteed_ to be
imported, and so using these functions may result in a `NameError` at
runtime. Generally, these constants are intended to be used in an interactive
interpreter, and not in programs.

Prefer `sys.exit()`, as the `sys` module is guaranteed to exist in all
contexts.

## Fix safety
This fix is always unsafe. When replacing `exit` or `quit` with `sys.exit`,
the behavior can change in the following ways:

1. If the code runs in an environment where the `site` module is not imported
   (e.g., with `python -S`), the original code would raise a `NameError`, while
   the fixed code would execute normally.

2. `site.exit` and `sys.exit` handle tuple arguments differently. `site.exit`
   treats tuples as regular objects and always returns exit code 1, while `sys.exit`
   interprets tuple contents to determine the exit code: an empty tuple () results in
   exit code 0, and a single-element tuple like (2,) uses that element's value (2) as
   the exit code.

## Example
```python
if __name__ == "__main__":
    exit()
```

Use instead:
```python
import sys

if __name__ == "__main__":
    sys.exit()
```

## References
- [Python documentation: Constants added by the `site` module](https://docs.python.org/3/library/constants.html#constants-added-by-the-site-module)

# if-stmt-min-max (PLR1730)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for `if` statements that can be replaced with `min()` or `max()`
calls.

## Why is this bad?
An `if` statement that selects the lesser or greater of two sub-expressions
can be replaced with a `min()` or `max()` call respectively. Where possible,
prefer `min()` and `max()`, as they're more concise and readable than the
equivalent `if` statements.

## Example
```python
if score > highest_score:
    highest_score = score
```

Use instead:
```python
highest_score = max(highest_score, score)
```

## Fix safety
This fix is marked unsafe if it would delete any comments within the replacement range.

An example to illustrate where comments are preserved and where they are not:

```py
a, b = 0, 10

if a >= b: # deleted comment
    # deleted comment
    a = b # preserved comment
```

## References
- [Python documentation: `max`](https://docs.python.org/3/library/functions.html#max)
- [Python documentation: `min`](https://docs.python.org/3/library/functions.html#min)

# unnecessary-dict-index-lookup (PLR1733)

Derived from the **Pylint** linter.

Fix is always available.

## What it does
Checks for key-based dict accesses during `.items()` iterations.

## Why is this bad?
When iterating over a dict via `.items()`, the current value is already
available alongside its key. Using the key to look up the value is
unnecessary.

## Example
```python
FRUITS = {"apple": 1, "orange": 10, "berry": 22}

for fruit_name, fruit_count in FRUITS.items():
    print(FRUITS[fruit_name])
```

Use instead:
```python
FRUITS = {"apple": 1, "orange": 10, "berry": 22}

for fruit_name, fruit_count in FRUITS.items():
    print(fruit_count)
```

# unnecessary-list-index-lookup (PLR1736)

Derived from the **Pylint** linter.

Fix is always available.

## What it does
Checks for index-based list accesses during `enumerate` iterations.

## Why is this bad?
When iterating over a list with `enumerate`, the current item is already
available alongside its index. Using the index to look up the item is
unnecessary.

## Example
```python
letters = ["a", "b", "c"]

for index, letter in enumerate(letters):
    print(letters[index])
```

Use instead:
```python
letters = ["a", "b", "c"]

for index, letter in enumerate(letters):
    print(letter)
```

# magic-value-comparison (PLR2004)

Derived from the **Pylint** linter.

## What it does
Checks for the use of unnamed numerical constants ("magic") values in
comparisons.

## Why is this bad?
The use of "magic" values can make code harder to read and maintain, as
readers will have to infer the meaning of the value from the context.
Such values are discouraged by [PEP 8].

For convenience, this rule excludes a variety of common values from the
"magic" value definition, such as `0`, `1`, `""`, and `"__main__"`.

## Example
```python
def apply_discount(price: float) -> float:
    if price <= 100:
        return price / 2
    else:
        return price
```

Use instead:
```python
MAX_DISCOUNT = 100


def apply_discount(price: float) -> float:
    if price <= MAX_DISCOUNT:
        return price / 2
    else:
        return price
```

## Options
- `lint.pylint.allow-magic-value-types`

[PEP 8]: https://peps.python.org/pep-0008/#constants

# empty-comment (PLR2044)

Derived from the **Pylint** linter.

Fix is always available.

## What it does
Checks for a # symbol appearing on a line not followed by an actual comment.

## Why is this bad?
Empty comments don't provide any clarity to the code, and just add clutter.
Either add a comment or delete the empty comment.

## Example
```python
class Foo:  #
    pass
```

Use instead:
```python
class Foo:
    pass
```

## References
- [Pylint documentation](https://pylint.pycqa.org/en/latest/user_guide/messages/refactor/empty-comment.html)

# collapsible-else-if (PLR5501)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for `else` blocks that consist of a single `if` statement.

## Why is this bad?
If an `else` block contains a single `if` statement, it can be collapsed
into an `elif`, thus reducing the indentation level.

## Example
```python
def check_sign(value: int) -> None:
    if value > 0:
        print("Number is positive.")
    else:
        if value < 0:
            print("Number is negative.")
        else:
            print("Number is zero.")
```

Use instead:
```python
def check_sign(value: int) -> None:
    if value > 0:
        print("Number is positive.")
    elif value < 0:
        print("Number is negative.")
    else:
        print("Number is zero.")
```

## References
- [Python documentation: `if` Statements](https://docs.python.org/3/tutorial/controlflow.html#if-statements)

# non-augmented-assignment (PLR6104)

Derived from the **Pylint** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for assignments that can be replaced with augmented assignment
statements.

## Why is this bad?
If the right-hand side of an assignment statement consists of a binary
operation in which one operand is the same as the assignment target,
it can be rewritten as an augmented assignment. For example, `x = x + 1`
can be rewritten as `x += 1`.

When performing such an operation, an augmented assignment is more concise
and idiomatic.

## Known problems
In some cases, this rule will not detect assignments in which the target
is on the right-hand side of a binary operation (e.g., `x = y + x`, as
opposed to `x = x + y`), as such operations are not commutative for
certain data types, like strings.

For example, `x = "prefix-" + x` is not equivalent to `x += "prefix-"`,
while `x = 1 + x` is equivalent to `x += 1`.

If the type of the left-hand side cannot be trivially inferred, the rule
will ignore the assignment.

## Example
```python
x = x + 1
```

Use instead:
```python
x += 1
```

## Fix safety
This rule's fix is marked as unsafe, as augmented assignments have
different semantics when the target is a mutable data type, like a list or
dictionary.

For example, consider the following:

```python
foo = [1]
bar = foo
foo = foo + [2]
assert (foo, bar) == ([1, 2], [1])
```

If the assignment is replaced with an augmented assignment, the update
operation will apply to both `foo` and `bar`, as they refer to the same
object:

```python
foo = [1]
bar = foo
foo += [2]
assert (foo, bar) == ([1, 2], [1, 2])
```

# literal-membership (PLR6201)

Derived from the **Pylint** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for membership tests on `list` and `tuple` literals.

## Why is this bad?
When testing for membership in a static sequence, prefer a `set` literal
over a `list` or `tuple`, as Python optimizes `set` membership tests.

## Example
```python
1 in [1, 2, 3]
```

Use instead:
```python
1 in {1, 2, 3}
```

## Fix safety
This rule's fix is marked as unsafe, as the use of a `set` literal will
error at runtime if either the element being tested for membership (the
left-hand side) or any element of the sequence (the right-hand side)
is unhashable (like lists or dictionaries). While Ruff will attempt to
infer the hashability of both sides and skip the fix when it can determine
that either side is unhashable, it may not always be able to do so.

## References
- [Whats New In Python 3.2](https://docs.python.org/3/whatsnew/3.2.html#optimizations)

# no-self-use (PLR6301)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for the presence of unused `self` parameter in methods definitions.

## Why is this bad?
Unused `self` parameters are usually a sign of a method that could be
replaced by a function, class method, or static method.

This rule exempts methods decorated with [`@typing.override`][override].
Converting an instance method into a static method or class method may
cause type checkers to complain about a violation of the Liskov
Substitution Principle if it means that the method now incompatibly
overrides a method defined on a superclass. Explicitly decorating an
overriding method with `@override` signals to Ruff that the method is
intended to override a superclass method and that a type checker will
enforce that it does so; Ruff therefore knows that it should not enforce
rules about unused `self` parameters on such methods.

## Example
```python
class Person:
    def greeting(self):
        print("Greetings friend!")
```

Use instead:
```python
def greeting():
    print("Greetings friend!")
```

or

```python
class Person:
    @staticmethod
    def greeting():
        print("Greetings friend!")
```

[override]: https://docs.python.org/3/library/typing.html#typing.override

# unnecessary-lambda (PLW0108)

Derived from the **Pylint** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for `lambda` definitions that consist of a single function call
with the same arguments as the `lambda` itself.

## Why is this bad?
When a `lambda` is used to wrap a function call, and merely propagates
the `lambda` arguments to that function, it can typically be replaced with
the function itself, removing a level of indirection.

## Example
```python
df.apply(lambda x: str(x))
```

Use instead:
```python
df.apply(str)
```

## Fix safety
This rule's fix is marked as unsafe for two primary reasons.

First, the lambda body itself could contain an effect.

For example, replacing `lambda x, y: (func()(x, y))` with `func()` would
lead to a change in behavior, as `func()` would be evaluated eagerly when
defining the lambda, rather than when the lambda is called.

However, even when the lambda body itself is pure, the lambda may
change the argument names, which can lead to a change in behavior when
callers pass arguments by name.

For example, replacing `foo = lambda x, y: func(x, y)` with `foo = func`,
where `func` is defined as `def func(a, b): return a + b`, would be a
breaking change for callers that execute the lambda by passing arguments by
name, as in: `foo(x=1, y=2)`. Since `func` does not define the arguments
`x` and `y`, unlike the lambda, the call would raise a `TypeError`.

# useless-else-on-loop (PLW0120)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for `else` clauses on loops without a `break` statement.

## Why is this bad?
When a loop includes an `else` statement, the code inside the `else` clause
will be executed if the loop terminates "normally" (i.e., without a
`break`).

If a loop _always_ terminates "normally" (i.e., does _not_ contain a
`break`), then the `else` clause is redundant, as the code inside the
`else` clause will always be executed.

In such cases, the code inside the `else` clause can be moved outside the
loop entirely, and the `else` clause can be removed.

## Example
```python
for item in items:
    print(item)
else:
    print("All items printed")
```

Use instead:
```python
for item in items:
    print(item)
print("All items printed")
```

## References
- [Python documentation: `break` and `continue` Statements, and `else` Clauses on Loops](https://docs.python.org/3/tutorial/controlflow.html#break-and-continue-statements-and-else-clauses-on-loops)

# self-assigning-variable (PLW0127)

Derived from the **Pylint** linter.

## What it does
Checks for self-assignment of variables.

## Why is this bad?
Self-assignment of variables is redundant and likely a mistake.

## Example
```python
country = "Poland"
country = country
```

Use instead:
```python
country = "Poland"
```

# redeclared-assigned-name (PLW0128)

Derived from the **Pylint** linter.

## What it does
Checks for declared assignments to the same variable multiple times
in the same assignment.

## Why is this bad?
Assigning a variable multiple times in the same assignment is redundant,
as the final assignment to the variable is what the value will be.

## Example
```python
a, b, a = (1, 2, 3)
print(a)  # 3
```

Use instead:
```python
# this is assuming you want to assign 3 to `a`
_, b, a = (1, 2, 3)
print(a)  # 3
```

# assert-on-string-literal (PLW0129)

Derived from the **Pylint** linter.

## What it does
Checks for `assert` statements that use a string literal as the first
argument.

## Why is this bad?
An `assert` on a non-empty string literal will always pass, while an
`assert` on an empty string literal will always fail.

## Example
```python
assert "always true"
```

# named-expr-without-context (PLW0131)

Derived from the **Pylint** linter.

## What it does
Checks for uses of named expressions (e.g., `a := 42`) that can be
replaced by regular assignment statements (e.g., `a = 42`).

## Why is this bad?
While a top-level named expression is syntactically and semantically valid,
it's less clear than a regular assignment statement. Named expressions are
intended to be used in comprehensions and generator expressions, where
assignment statements are not allowed.

## Example
```python
(a := 42)
```

Use instead:
```python
a = 42
```

# useless-exception-statement (PLW0133)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for an exception that is not raised.

## Why is this bad?
It's unnecessary to create an exception without raising it. For example,
`ValueError("...")` on its own will have no effect (unlike
`raise ValueError("...")`) and is likely a mistake.

## Known problems
This rule only detects built-in exceptions, like `ValueError`, and does
not catch user-defined exceptions.

In [preview], this rule will also detect user-defined exceptions, but only
the ones defined in the file being checked.

## Example
```python
ValueError("...")
```

Use instead:
```python
raise ValueError("...")
```

## Fix safety
This rule's fix is marked as unsafe, as converting a useless exception

[preview]: https://docs.astral.sh/ruff/preview/

# nan-comparison (PLW0177)

Derived from the **Pylint** linter.

## What it does
Checks for comparisons against NaN values.

## Why is this bad?
Comparing against a NaN value can lead to unexpected results. For example,
`float("NaN") == float("NaN")` will return `False` and, in general,
`x == float("NaN")` will always return `False`, even if `x` is `NaN`.

To determine whether a value is `NaN`, use `math.isnan` or `np.isnan`
instead of comparing against `NaN` directly.

## Example
```python
if x == float("NaN"):
    pass
```

Use instead:
```python
import math

if math.isnan(x):
    pass
```

# bad-staticmethod-argument (PLW0211)

Derived from the **Pylint** linter.

## What it does
Checks for static methods that use `self` or `cls` as their first argument.
This rule also applies to `__new__` methods, which are implicitly static.

## Why is this bad?
[PEP 8] recommends the use of `self` and `cls` as the first arguments for
instance methods and class methods, respectively. Naming the first argument
of a static method as `self` or `cls` can be misleading, as static methods
do not receive an instance or class reference as their first argument.

## Example
```python
class Wolf:
    @staticmethod
    def eat(self):
        pass
```

Use instead:
```python
class Wolf:
    @staticmethod
    def eat(sheep):
        pass
```

[PEP 8]: https://peps.python.org/pep-0008/#function-and-method-arguments

# redefined-slots-in-subclass (PLW0244)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for a re-defined slot in a subclass.

## Why is this bad?
If a class defines a slot also defined in a base class, the
instance variable defined by the base class slot is inaccessible
(except by retrieving its descriptor directly from the base class).

## Example
```python
class Base:
    __slots__ = ("a", "b")


class Subclass(Base):
    __slots__ = ("a", "d")  # slot "a" redefined
```

Use instead:
```python
class Base:
    __slots__ = ("a", "b")


class Subclass(Base):
    __slots__ = "d"
```

# super-without-brackets (PLW0245)

Derived from the **Pylint** linter.

Fix is always available.

## What it does
Detects attempts to use `super` without parentheses.

## Why is this bad?
The [`super()` callable](https://docs.python.org/3/library/functions.html#super)
can be used inside method definitions to create a proxy object that
delegates attribute access to a superclass of the current class. Attempting
to access attributes on `super` itself, however, instead of the object
returned by a call to `super()`, will raise `AttributeError`.

## Example
```python
class Animal:
    @staticmethod
    def speak():
        return "This animal says something."


class Dog(Animal):
    @staticmethod
    def speak():
        original_speak = super.speak()  # ERROR: `super.speak()`
        return f"{original_speak} But as a dog, it barks!"
```

Use instead:
```python
class Animal:
    @staticmethod
    def speak():
        return "This animal says something."


class Dog(Animal):
    @staticmethod
    def speak():
        original_speak = super().speak()  # Correct: `super().speak()`
        return f"{original_speak} But as a dog, it barks!"
```

# import-self (PLW0406)

Derived from the **Pylint** linter.

## What it does
Checks for import statements that import the current module.

## Why is this bad?
Importing a module from itself is a circular dependency and results
in an `ImportError` exception.

## Example

```python
# file: this_file.py
from this_file import foo


def foo(): ...
```

# global-variable-not-assigned (PLW0602)

Derived from the **Pylint** linter.

## What it does
Checks for `global` variables that are not assigned a value in the current
scope.

## Why is this bad?
The `global` keyword allows an inner scope to modify a variable declared
in the outer scope. If the variable is not modified within the inner scope,
there is no need to use `global`.

## Example
```python
DEBUG = True


def foo():
    global DEBUG
    if DEBUG:
        print("foo() called")
    ...
```

Use instead:
```python
DEBUG = True


def foo():
    if DEBUG:
        print("foo() called")
    ...
```

## References
- [Python documentation: The `global` statement](https://docs.python.org/3/reference/simple_stmts.html#the-global-statement)

# global-statement (PLW0603)

Derived from the **Pylint** linter.

## What it does
Checks for the use of `global` statements to update identifiers.

## Why is this bad?
Pylint discourages the use of `global` variables as global mutable
state is a common source of bugs and confusing behavior.

## Example
```python
var = 1


def foo():
    global var  # [global-statement]
    var = 10
    print(var)


foo()
print(var)
```

Use instead:
```python
var = 1


def foo():
    var = 10
    print(var)
    return var


var = foo()
print(var)
```

# global-at-module-level (PLW0604)

Derived from the **Pylint** linter.

## What it does
Checks for uses of the `global` keyword at the module level.

## Why is this bad?
The `global` keyword is used within functions to indicate that a name
refers to a global variable, rather than a local variable.

At the module level, all names are global by default, so the `global`
keyword is redundant.

# self-or-cls-assignment (PLW0642)

Derived from the **Pylint** linter.

## What it does
Checks for assignment of `self` and `cls` in instance and class methods respectively.

This check also applies to `__new__` even though this is technically
a static method.

## Why is this bad?
The identifiers `self` and `cls` are conventional in Python for the first parameter of instance
methods and class methods, respectively. Assigning new values to these variables can be
confusing for others reading your code; using a different variable name can lead to clearer
code.

## Example

```python
class Version:
    def add(self, other):
        self = self + other
        return self

    @classmethod
    def superclass(cls):
        cls = cls.__mro__[-1]
        return cls
```

Use instead:
```python
class Version:
    def add(self, other):
        new_version = self + other
        return new_version

    @classmethod
    def superclass(cls):
        supercls = cls.__mro__[-1]
        return supercls
```

# binary-op-exception (PLW0711)

Derived from the **Pylint** linter.

## What it does
Checks for `except` clauses that attempt to catch multiple
exceptions with a binary operation (`and` or `or`).

## Why is this bad?
A binary operation will not catch multiple exceptions. Instead, the binary
operation will be evaluated first, and the result of _that_ operation will
be caught (for an `or` operation, this is typically the first exception in
the list). This is almost never the desired behavior.

## Example
```python
try:
    pass
except A or B:
    pass
```

Use instead:
```python
try:
    pass
except (A, B):
    pass
```

# bad-open-mode (PLW1501)

Derived from the **Pylint** linter.

## What it does
Check for an invalid `mode` argument in `open` calls.

## Why is this bad?
The `open` function accepts a `mode` argument that specifies how the file
should be opened (e.g., read-only, write-only, append-only, etc.).

Python supports a variety of open modes: `r`, `w`, `a`, and `x`, to control
reading, writing, appending, and creating, respectively, along with
`b` (binary mode), `+` (read and write), and `U` (universal newlines),
the latter of which is only valid alongside `r`. This rule detects both
invalid combinations of modes and invalid characters in the mode string
itself.

## Example
```python
with open("file", "rwx") as f:
    content = f.read()
```

Use instead:

```python
with open("file", "r") as f:
    content = f.read()
```

## References
- [Python documentation: `open`](https://docs.python.org/3/library/functions.html#open)

# shallow-copy-environ (PLW1507)

Derived from the **Pylint** linter.

Fix is always available.

## What it does
Check for shallow `os.environ` copies.

## Why is this bad?
`os.environ` is not a `dict` object, but rather, a proxy object. As such, mutating a shallow
copy of `os.environ` will also mutate the original object.

See [BPO 15373] for more information.

## Example
```python
import copy
import os

env = copy.copy(os.environ)
```

Use instead:
```python
import os

env = os.environ.copy()
```

## Fix safety

This rule's fix is marked as unsafe because replacing a shallow copy with a deep copy can lead
to unintended side effects. If the program modifies the shallow copy at some point, changing it
to a deep copy may prevent those modifications from affecting the original data, potentially
altering the program's behavior.

## References
- [Python documentation: `copy`  Shallow and deep copy operations](https://docs.python.org/3/library/copy.html)
- [Python documentation: `os.environ`](https://docs.python.org/3/library/os.html#os.environ)

[BPO 15373]: https://bugs.python.org/issue15373

# invalid-envvar-default (PLW1508)

Derived from the **Pylint** linter.

## What it does
Checks for `os.getenv` calls with invalid default values.

## Why is this bad?
If an environment variable is set, `os.getenv` will return its value as
a string. If the environment variable is _not_ set, `os.getenv` will
return `None`, or the default value if one is provided.

If the default value is not a string or `None`, then it will be
inconsistent with the return type of `os.getenv`, which can lead to
confusing behavior.

## Example
```python
import os

int(os.getenv("FOO", 1))
```

Use instead:
```python
import os

int(os.getenv("FOO", "1"))
```

# subprocess-popen-preexec-fn (PLW1509)

Derived from the **Pylint** linter.

## What it does
Checks for uses of `subprocess.Popen` with a `preexec_fn` argument.

## Why is this bad?
The `preexec_fn` argument is unsafe within threads as it can lead to
deadlocks. Furthermore, `preexec_fn` is [targeted for deprecation].

Instead, consider using task-specific arguments such as `env`,
`start_new_session`, and `process_group`. These are not prone to deadlocks
and are more explicit.

## Example
```python
import os, subprocess

subprocess.Popen(foo, preexec_fn=os.setsid)
subprocess.Popen(bar, preexec_fn=os.setpgid(0, 0))
```

Use instead:
```python
import subprocess

subprocess.Popen(foo, start_new_session=True)
subprocess.Popen(bar, process_group=0)  # Introduced in Python 3.11
```

## References
- [Python documentation: `subprocess.Popen`](https://docs.python.org/3/library/subprocess.html#popen-constructor)
- [Why `preexec_fn` in `subprocess.Popen` may lead to deadlock?](https://discuss.python.org/t/why-preexec-fn-in-subprocess-popen-may-lead-to-deadlock/16908/2)

[targeted for deprecation]: https://github.com/python/cpython/issues/82616

# subprocess-run-without-check (PLW1510)

Derived from the **Pylint** linter.

Fix is always available.

## What it does
Checks for uses of `subprocess.run` without an explicit `check` argument.

## Why is this bad?
By default, `subprocess.run` does not check the return code of the process
it runs. This can lead to silent failures.

Instead, consider using `check=True` to raise an exception if the process
fails, or set `check=False` explicitly to mark the behavior as intentional.

## Example
```python
import subprocess

subprocess.run(["ls", "nonexistent"])  # No exception raised.
```

Use instead:
```python
import subprocess

subprocess.run(["ls", "nonexistent"], check=True)  # Raises exception.
```

Or:
```python
import subprocess

subprocess.run(["ls", "nonexistent"], check=False)  # Explicitly no check.
```

## Fix safety
This rule's fix is marked as unsafe for function calls that contain
`**kwargs`, as adding a `check` keyword argument to such a call may lead
to a duplicate keyword argument error.

## References
- [Python documentation: `subprocess.run`](https://docs.python.org/3/library/subprocess.html#subprocess.run)

# unspecified-encoding (PLW1514)

Derived from the **Pylint** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for uses of `open` and related calls without an explicit `encoding`
argument.

## Why is this bad?
Using `open` in text mode without an explicit encoding can lead to
non-portable code, with differing behavior across platforms. While readers
may assume that UTF-8 is the default encoding, in reality, the default
is locale-specific.

Instead, consider using the `encoding` parameter to enforce a specific
encoding. [PEP 597] recommends the use of `encoding="utf-8"` as a default,
and suggests that it may become the default in future versions of Python.

If a locale-specific encoding is intended, use `encoding="locale"`  on
Python 3.10 and later, or `locale.getpreferredencoding()` on earlier versions,
to make the encoding explicit.

## Fix safety
This fix is always unsafe and may change the program's behavior. It forces
`encoding="utf-8"` as the default, regardless of the platforms actual default
encoding, which may cause `UnicodeDecodeError` on non-UTF-8 systems.
```python
with open("test.txt") as f:
    print(f.read()) # before fix (on UTF-8 systems): 
with open("test.txt", encoding="utf-8") as f:
    print(f.read()) # after fix (on Windows): UnicodeDecodeError
```

## Example
```python
open("file.txt")
```

Use instead:
```python
open("file.txt", encoding="utf-8")
```

## References
- [Python documentation: `open`](https://docs.python.org/3/library/functions.html#open)

[PEP 597]: https://peps.python.org/pep-0597/

# eq-without-hash (PLW1641)

Derived from the **Pylint** linter.

## What it does
Checks for classes that implement `__eq__` but not `__hash__`.

## Why is this bad?
A class that implements `__eq__` but not `__hash__` will have its hash
method implicitly set to `None`, regardless of if a superclass defines
`__hash__`. This will cause the class to be unhashable, which will in turn
cause issues when using instances of the class as keys in a dictionary or
members of a set.

## Example

```python
class Person:
    def __init__(self):
        self.name = "monty"

    def __eq__(self, other):
        return isinstance(other, Person) and other.name == self.name
```

Use instead:

```python
class Person:
    def __init__(self):
        self.name = "monty"

    def __eq__(self, other):
        return isinstance(other, Person) and other.name == self.name

    def __hash__(self):
        return hash(self.name)
```

In general, it is unsound to inherit a `__hash__` implementation from a parent class while
overriding the `__eq__` implementation because the two must be kept in sync. However, an easy
way to resolve this error in cases where it _is_ sound is to explicitly set `__hash__` to the
parent class's implementation:

```python
class Developer(Person):
    def __init__(self): ...

    def __eq__(self, other): ...

    __hash__ = Person.__hash__
```

## References
- [Python documentation: `object.__hash__`](https://docs.python.org/3/reference/datamodel.html#object.__hash__)
- [Python glossary: hashable](https://docs.python.org/3/glossary.html#term-hashable)

# useless-with-lock (PLW2101)

Derived from the **Pylint** linter.

## What it does
Checks for lock objects that are created and immediately discarded in
`with` statements.

## Why is this bad?
Creating a lock (via `threading.Lock` or similar) in a `with` statement
has no effect, as locks are only relevant when shared between threads.

Instead, assign the lock to a variable outside the `with` statement,
and share that variable between threads.

## Example
```python
import threading

counter = 0


def increment():
    global counter

    with threading.Lock():
        counter += 1
```

Use instead:
```python
import threading

counter = 0
lock = threading.Lock()


def increment():
    global counter

    with lock:
        counter += 1
```

## References
- [Python documentation: `Lock Objects`](https://docs.python.org/3/library/threading.html#lock-objects)

# redefined-loop-name (PLW2901)

Derived from the **Pylint** linter.

## What it does
Checks for variables defined in `for` loops and `with` statements that
get overwritten within the body, for example by another `for` loop or
`with` statement or by direct assignment.

## Why is this bad?
Redefinition of a loop variable inside the loop's body causes its value
to differ from the original loop iteration for the remainder of the
block, in a way that will likely cause bugs.

In Python, unlike many other languages, `for` loops and `with`
statements don't define their own scopes. Therefore, a nested loop that
uses the same target variable name as an outer loop will reuse the same
actual variable, and the value from the last iteration will "leak out"
into the remainder of the enclosing loop.

While this mistake is easy to spot in small examples, it can be hidden
in larger blocks of code, where the definition and redefinition of the
variable may not be visible at the same time.

## Example
```python
for i in range(10):
    i = 9
    print(i)  # prints 9 every iteration

for i in range(10):
    for i in range(10):  # original value overwritten
        pass
    print(i)  # also prints 9 every iteration

with path1.open() as f:
    with path2.open() as f:
        f = path2.open()
    print(f.readline())  # prints a line from path2
```

# bad-dunder-method-name (PLW3201)

Derived from the **Pylint** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for dunder methods that have no special meaning in Python 3.

## Why is this bad?
Misspelled or no longer supported dunder name methods may cause your code to not function
as expected.

Since dunder methods are associated with customizing the behavior
of a class in Python, introducing a dunder method such as `__foo__`
that diverges from standard Python dunder methods could potentially
confuse someone reading the code.

This rule will detect all methods starting and ending with at least
one underscore (e.g., `_str_`), but ignores known dunder methods (like
`__init__`), as well as methods that are marked with [`@override`][override].

Additional dunder methods names can be allowed via the
[`lint.pylint.allow-dunder-method-names`] setting.

## Example

```python
class Foo:
    def __init_(self): ...
```

Use instead:

```python
class Foo:
    def __init__(self): ...
```

## Options
- `lint.pylint.allow-dunder-method-names`

[override]: https://docs.python.org/3/library/typing.html#typing.override

# nested-min-max (PLW3301)

Derived from the **Pylint** linter.

Fix is sometimes available.

## What it does
Checks for nested `min` and `max` calls.

## Why is this bad?
Nested `min` and `max` calls can be flattened into a single call to improve
readability.

## Example

```python
minimum = min(1, 2, min(3, 4, 5))
maximum = max(1, 2, max(3, 4, 5))
diff = maximum - minimum
```

Use instead:

```python
minimum = min(1, 2, 3, 4, 5)
maximum = max(1, 2, 3, 4, 5)
diff = maximum - minimum
```

## Known issues

The resulting code may be slower and use more memory, especially for nested iterables. For
example, this code:

```python
iterable = range(3)
min(1, min(iterable))
```

will be fixed to:

```python
iterable = range(3)
min(1, *iterable)
```

At least on current versions of CPython, this allocates a collection for the whole iterable
before calling `min` and could cause performance regressions, at least for large iterables.

## Fix safety

This fix is always unsafe and may change the program's behavior for types without full
equivalence relations, such as float comparisons involving `NaN`.

```python
print(min(2.0, min(float("nan"), 1.0)))  # before fix: 2.0
print(min(2.0, float("nan"), 1.0))  # after fix: 1.0

print(max(1.0, max(float("nan"), 2.0)))  # before fix: 1.0
print(max(1.0, float("nan"), 2.0))  # after fix: 2.0
```

The fix will also remove any comments within the outer call.

## References
- [Python documentation: `min`](https://docs.python.org/3/library/functions.html#min)
- [Python documentation: `max`](https://docs.python.org/3/library/functions.html#max)

# useless-metaclass-type (UP001)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for the use of `__metaclass__ = type` in class definitions.

## Why is this bad?
Since Python 3, `__metaclass__ = type` is implied and can thus be omitted.

## Example

```python
class Foo:
    __metaclass__ = type
```

Use instead:

```python
class Foo: ...
```

## References
- [PEP 3115  Metaclasses in Python 3000](https://peps.python.org/pep-3115/)

# type-of-primitive (UP003)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for uses of `type` that take a primitive as an argument.

## Why is this bad?
`type()` returns the type of a given object. A type of a primitive can
always be known in advance and accessed directly, which is more concise
and explicit than using `type()`.

## Example
```python
type(1)
```

Use instead:
```python
int
```

## References
- [Python documentation: `type()`](https://docs.python.org/3/library/functions.html#type)
- [Python documentation: Built-in types](https://docs.python.org/3/library/stdtypes.html)

# useless-object-inheritance (UP004)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for classes that inherit from `object`.

## Why is this bad?
Since Python 3, all classes inherit from `object` by default, so `object` can
be omitted from the list of base classes.

## Example

```python
class Foo(object): ...
```

Use instead:

```python
class Foo: ...
```

## Fix safety
This fix is unsafe if it would cause comments to be deleted.

## References
- [PEP 3115  Metaclasses in Python 3000](https://peps.python.org/pep-3115/)

# deprecated-unittest-alias (UP005)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for uses of deprecated methods from the `unittest` module.

## Why is this bad?
The `unittest` module has deprecated aliases for some of its methods.
The deprecated aliases were removed in Python 3.12. Instead of aliases,
use their non-deprecated counterparts.

## Example
```python
from unittest import TestCase


class SomeTest(TestCase):
    def test_something(self):
        self.assertEquals(1, 1)
```

Use instead:
```python
from unittest import TestCase


class SomeTest(TestCase):
    def test_something(self):
        self.assertEqual(1, 1)
```

## References
- [Python 3.11 documentation: Deprecated aliases](https://docs.python.org/3.11/library/unittest.html#deprecated-aliases)

# non-pep585-annotation (UP006)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for the use of generics that can be replaced with standard library
variants based on [PEP 585].

## Why is this bad?
[PEP 585] enabled collections in the Python standard library (like `list`)
to be used as generics directly, instead of importing analogous members
from the `typing` module (like `typing.List`).

When available, the [PEP 585] syntax should be used instead of importing
members from the `typing` module, as it's more concise and readable.
Importing those members from `typing` is considered deprecated as of [PEP
585].

This rule is enabled when targeting Python 3.9 or later (see:
[`target-version`]). By default, it's _also_ enabled for earlier Python
versions if `from __future__ import annotations` is present, as
`__future__` annotations are not evaluated at runtime. If your code relies
on runtime type annotations (either directly or via a library like
Pydantic), you can disable this behavior for Python versions prior to 3.9
by setting [`lint.pyupgrade.keep-runtime-typing`] to `true`.

## Example
```python
from typing import List

foo: List[int] = [1, 2, 3]
```

Use instead:
```python
foo: list[int] = [1, 2, 3]
```

## Fix safety
This rule's fix is marked as unsafe, as it may lead to runtime errors when
alongside libraries that rely on runtime type annotations, like Pydantic,
on Python versions prior to Python 3.9.

## Options
- `target-version`
- `lint.pyupgrade.keep-runtime-typing`

[PEP 585]: https://peps.python.org/pep-0585/

# non-pep604-annotation-union (UP007)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Check for type annotations that can be rewritten based on [PEP 604] syntax.

## Why is this bad?
[PEP 604] introduced a new syntax for union type annotations based on the
`|` operator. This syntax is more concise and readable than the previous
`typing.Union` and `typing.Optional` syntaxes.

This rule is enabled when targeting Python 3.10 or later (see:
[`target-version`]). By default, it's _also_ enabled for earlier Python
versions if `from __future__ import annotations` is present, as
`__future__` annotations are not evaluated at runtime. If your code relies
on runtime type annotations (either directly or via a library like
Pydantic), you can disable this behavior for Python versions prior to 3.10
by setting [`lint.pyupgrade.keep-runtime-typing`] to `true`.

## Example
```python
from typing import Union

foo: Union[int, str] = 1
```

Use instead:
```python
foo: int | str = 1
```

Note that this rule only checks for usages of `typing.Union`,
while `UP045` checks for `typing.Optional`.

## Fix safety
This rule's fix is marked as unsafe, as it may lead to runtime errors when
alongside libraries that rely on runtime type annotations, like Pydantic,
on Python versions prior to Python 3.10. It may also lead to runtime errors
in unusual and likely incorrect type annotations where the type does not
support the `|` operator.

## Options
- `target-version`
- `lint.pyupgrade.keep-runtime-typing`

[PEP 604]: https://peps.python.org/pep-0604/

# super-call-with-parameters (UP008)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for `super` calls that pass redundant arguments.

## Why is this bad?
In Python 3, `super` can be invoked without any arguments when: (1) the
first argument is `__class__`, and (2) the second argument is equivalent to
the first argument of the enclosing method.

When possible, omit the arguments to `super` to make the code more concise
and maintainable.

## Example
```python
class A:
    def foo(self):
        pass


class B(A):
    def bar(self):
        super(B, self).foo()
```

Use instead:
```python
class A:
    def foo(self):
        pass


class B(A):
    def bar(self):
        super().foo()
```

## Fix safety

This rule's fix is marked as unsafe because removing the arguments from a call
may delete comments that are attached to the arguments.

In [preview], the fix is marked safe if no comments are present.

[preview]: https://docs.astral.sh/ruff/preview/

## References
- [Python documentation: `super`](https://docs.python.org/3/library/functions.html#super)
- [super/MRO, Python's most misunderstood feature.](https://www.youtube.com/watch?v=X1PQ7zzltz4)

# utf8-encoding-declaration (UP009)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for unnecessary UTF-8 encoding declarations.

## Why is this bad?
[PEP 3120] makes UTF-8 the default encoding, so a UTF-8 encoding
declaration is unnecessary.

## Example
```python
# -*- coding: utf-8 -*-
print("Hello, world!")
```

Use instead:
```python
print("Hello, world!")
```

[PEP 3120]: https://peps.python.org/pep-3120/

# unnecessary-future-import (UP010)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for unnecessary `__future__` imports.

## Why is this bad?
The `__future__` module is used to enable features that are not yet
available in the current Python version. If a feature is already
available in the minimum supported Python version, importing it
from `__future__` is unnecessary and should be removed to avoid
confusion.

## Example
```python
from __future__ import print_function

print("Hello, world!")
```

Use instead:
```python
print("Hello, world!")
```

## Fix safety
This fix is marked unsafe if applying it would delete a comment.

## Options
- `target-version`

## References
- [Python documentation: `__future__`  Future statement definitions](https://docs.python.org/3/library/__future__.html)

# lru-cache-without-parameters (UP011)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for unnecessary parentheses on `functools.lru_cache` decorators.

## Why is this bad?
Since Python 3.8, `functools.lru_cache` can be used as a decorator without
trailing parentheses, as long as no arguments are passed to it.

## Example

```python
import functools


@functools.lru_cache()
def foo(): ...
```

Use instead:

```python
import functools


@functools.lru_cache
def foo(): ...
```

## Options
- `target-version`

## References
- [Python documentation: `@functools.lru_cache`](https://docs.python.org/3/library/functools.html#functools.lru_cache)
- [Let lru_cache be used as a decorator with no arguments](https://github.com/python/cpython/issues/80953)

# unnecessary-encode-utf8 (UP012)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for unnecessary calls to `encode` as UTF-8.

## Why is this bad?
UTF-8 is the default encoding in Python, so there is no need to call
`encode` when UTF-8 is the desired encoding. Instead, use a bytes literal.

## Example
```python
"foo".encode("utf-8")
```

Use instead:
```python
b"foo"
```

## References
- [Python documentation: `str.encode`](https://docs.python.org/3/library/stdtypes.html#str.encode)

# convert-typed-dict-functional-to-class (UP013)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for `TypedDict` declarations that use functional syntax.

## Why is this bad?
`TypedDict` types can be defined either through a functional syntax
(`Foo = TypedDict(...)`) or a class syntax (`class Foo(TypedDict): ...`).

The class syntax is more readable and generally preferred over the
functional syntax.

Nonetheless, there are some situations in which it is impossible to use
the class-based syntax. This rule will not apply to those cases. Namely,
it is impossible to use the class-based syntax if any `TypedDict` fields are:
- Not valid [python identifiers] (for example, `@x`)
- [Python keywords] such as `in`
- [Private names] such as `__id` that would undergo [name mangling] at runtime
  if the class-based syntax was used
- [Dunder names] such as `__int__` that can confuse type checkers if they're used
  with the class-based syntax.

## Example
```python
from typing import TypedDict

Foo = TypedDict("Foo", {"a": int, "b": str})
```

Use instead:
```python
from typing import TypedDict


class Foo(TypedDict):
    a: int
    b: str
```

## Fix safety
This rule's fix is marked as unsafe if there are any comments within the
range of the `TypedDict` definition, as these will be dropped by the
autofix.

## References
- [Python documentation: `typing.TypedDict`](https://docs.python.org/3/library/typing.html#typing.TypedDict)

[Private names]: https://docs.python.org/3/tutorial/classes.html#private-variables
[name mangling]: https://docs.python.org/3/reference/expressions.html#private-name-mangling
[python identifiers]: https://docs.python.org/3/reference/lexical_analysis.html#identifiers
[Python keywords]: https://docs.python.org/3/reference/lexical_analysis.html#keywords
[Dunder names]: https://docs.python.org/3/reference/lexical_analysis.html#reserved-classes-of-identifiers

# convert-named-tuple-functional-to-class (UP014)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for `NamedTuple` declarations that use functional syntax.

## Why is this bad?
`NamedTuple` subclasses can be defined either through a functional syntax
(`Foo = NamedTuple(...)`) or a class syntax (`class Foo(NamedTuple): ...`).

The class syntax is more readable and generally preferred over the
functional syntax, which exists primarily for backwards compatibility
with `collections.namedtuple`.

## Example
```python
from typing import NamedTuple

Foo = NamedTuple("Foo", [("a", int), ("b", str)])
```

Use instead:
```python
from typing import NamedTuple


class Foo(NamedTuple):
    a: int
    b: str
```

## Fix safety
This rule's fix is marked as unsafe if there are any comments within the
range of the `NamedTuple` definition, as these will be dropped by the
autofix.

## References
- [Python documentation: `typing.NamedTuple`](https://docs.python.org/3/library/typing.html#typing.NamedTuple)

# redundant-open-modes (UP015)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for redundant `open` mode arguments.

## Why is this bad?
Redundant `open` mode arguments are unnecessary and should be removed to
avoid confusion.

## Example
```python
with open("foo.txt", "r") as f:
    ...
```

Use instead:
```python
with open("foo.txt") as f:
    ...
```

## References
- [Python documentation: `open`](https://docs.python.org/3/library/functions.html#open)

# datetime-timezone-utc (UP017)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for uses of `datetime.timezone.utc`.

## Why is this bad?
As of Python 3.11, `datetime.UTC` is an alias for `datetime.timezone.utc`.
The alias is more readable and generally preferred over the full path.

## Example
```python
import datetime

datetime.timezone.utc
```

Use instead:
```python
import datetime

datetime.UTC
```

## Options
- `target-version`

## References
- [Python documentation: `datetime.UTC`](https://docs.python.org/3/library/datetime.html#datetime.UTC)

# native-literals (UP018)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for unnecessary calls to `str`, `bytes`, `int`, `float`, and `bool`.

## Why is this bad?
The mentioned constructors can be replaced with their respective literal
forms, which are more readable and idiomatic.

## Example
```python
str("foo")
```

Use instead:
```python
"foo"
```

## Fix safety
The fix is marked as unsafe if it might remove comments.

## References
- [Python documentation: `str`](https://docs.python.org/3/library/stdtypes.html#str)
- [Python documentation: `bytes`](https://docs.python.org/3/library/stdtypes.html#bytes)
- [Python documentation: `int`](https://docs.python.org/3/library/functions.html#int)
- [Python documentation: `float`](https://docs.python.org/3/library/functions.html#float)
- [Python documentation: `bool`](https://docs.python.org/3/library/functions.html#bool)

# typing-text-str-alias (UP019)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for uses of `typing.Text`.

In preview mode, also checks for `typing_extensions.Text`.

## Why is this bad?
`typing.Text` is an alias for `str`, and only exists for Python 2
compatibility. As of Python 3.11, `typing.Text` is deprecated. Use `str`
instead.

## Example
```python
from typing import Text

foo: Text = "bar"
```

Use instead:
```python
foo: str = "bar"
```

## References
- [Python documentation: `typing.Text`](https://docs.python.org/3/library/typing.html#typing.Text)

# open-alias (UP020)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for uses of `io.open`.

## Why is this bad?
In Python 3, `io.open` is an alias for `open`. Prefer using `open` directly,
as it is more idiomatic.

## Example
```python
import io

with io.open("file.txt") as f:
    ...
```

Use instead:
```python
with open("file.txt") as f:
    ...
```

## References
- [Python documentation: `io.open`](https://docs.python.org/3/library/io.html#io.open)

# replace-universal-newlines (UP021)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for uses of `subprocess.run` that set the `universal_newlines`
keyword argument.

## Why is this bad?
As of Python 3.7, the `universal_newlines` keyword argument has been
renamed to `text`, and now exists for backwards compatibility. The
`universal_newlines` keyword argument may be removed in a future version of
Python. Prefer `text`, which is more explicit and readable.

## Example
```python
import subprocess

subprocess.run(["foo"], universal_newlines=True)
```

Use instead:
```python
import subprocess

subprocess.run(["foo"], text=True)
```

## References
- [Python 3.7 release notes](https://docs.python.org/3/whatsnew/3.7.html#subprocess)
- [Python documentation: `subprocess.run`](https://docs.python.org/3/library/subprocess.html#subprocess.run)

# replace-stdout-stderr (UP022)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for uses of `subprocess.run` that send `stdout` and `stderr` to a
pipe.

## Why is this bad?
As of Python 3.7, `subprocess.run` has a `capture_output` keyword argument
that can be set to `True` to capture `stdout` and `stderr` outputs. This is
equivalent to setting `stdout` and `stderr` to `subprocess.PIPE`, but is
more explicit and readable.

## Example
```python
import subprocess

subprocess.run(["foo"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
```

Use instead:
```python
import subprocess

subprocess.run(["foo"], capture_output=True)
```

## Fix safety

This rule's fix is marked as unsafe because replacing `stdout=subprocess.PIPE` and
`stderr=subprocess.PIPE` with `capture_output=True` may delete comments attached
to the original arguments.

## References
- [Python 3.7 release notes](https://docs.python.org/3/whatsnew/3.7.html#subprocess)
- [Python documentation: `subprocess.run`](https://docs.python.org/3/library/subprocess.html#subprocess.run)

# deprecated-c-element-tree (UP023)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for uses of the `xml.etree.cElementTree` module.

## Why is this bad?
In Python 3.3, `xml.etree.cElementTree` was deprecated in favor of
`xml.etree.ElementTree`.

## Example
```python
from xml.etree import cElementTree as ET
```

Use instead:
```python
from xml.etree import ElementTree as ET
```

## References
- [Python documentation: `xml.etree.ElementTree`](https://docs.python.org/3/library/xml.etree.elementtree.html)

# os-error-alias (UP024)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for uses of exceptions that alias `OSError`.

## Why is this bad?
`OSError` is the builtin error type used for exceptions that relate to the
operating system.

In Python 3.3, a variety of other exceptions, like `WindowsError` were
aliased to `OSError`. These aliases remain in place for compatibility with
older versions of Python, but may be removed in future versions.

Prefer using `OSError` directly, as it is more idiomatic and future-proof.

## Example
```python
raise IOError
```

Use instead:
```python
raise OSError
```

## References
- [Python documentation: `OSError`](https://docs.python.org/3/library/exceptions.html#OSError)

# unicode-kind-prefix (UP025)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for uses of the Unicode kind prefix (`u`) in strings.

## Why is this bad?
In Python 3, all strings are Unicode by default. The Unicode kind prefix is
unnecessary and should be removed to avoid confusion.

## Example
```python
u"foo"
```

Use instead:
```python
"foo"
```

## References
- [Python documentation: Unicode HOWTO](https://docs.python.org/3/howto/unicode.html)

# deprecated-mock-import (UP026)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for imports of the `mock` module that should be replaced with
`unittest.mock`.

## Why is this bad?
Since Python 3.3, `mock` has been a part of the standard library as
`unittest.mock`. The `mock` package is deprecated; use `unittest.mock`
instead.

## Example
```python
import mock
```

Use instead:
```python
from unittest import mock
```

## References
- [Python documentation: `unittest.mock`](https://docs.python.org/3/library/unittest.mock.html)
- [PyPI: `mock`](https://pypi.org/project/mock/)

# unpacked-list-comprehension (UP027)

Derived from the **pyupgrade** linter.

## Removed
There's no [evidence](https://github.com/astral-sh/ruff/issues/12754) that generators are
meaningfully faster than list comprehensions when combined with unpacking.

## What it does
Checks for list comprehensions that are immediately unpacked.

## Why is this bad?
There is no reason to use a list comprehension if the result is immediately
unpacked. Instead, use a generator expression, which avoids allocating
an intermediary list.

## Example
```python
a, b, c = [foo(x) for x in items]
```

Use instead:
```python
a, b, c = (foo(x) for x in items)
```

## References
- [Python documentation: Generator expressions](https://docs.python.org/3/reference/expressions.html#generator-expressions)
- [Python documentation: List comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)

# yield-in-for-loop (UP028)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for `for` loops that can be replaced with `yield from` expressions.

## Why is this bad?
If a `for` loop only contains a `yield` statement, it can be replaced with a
`yield from` expression, which is more concise and idiomatic.

## Example
```python
def bar():
    for x in foo:
        yield x

    global y
    for y in foo:
        yield y
```

Use instead:
```python
def bar():
    yield from foo

    for _element in foo:
        y = _element
        yield y
```

## Fix safety
This rule's fix is marked as unsafe, as converting a `for` loop to a `yield
from` expression can change the behavior of the program in rare cases.
For example, if a generator is being sent values via `send`, then rewriting
to a `yield from` could lead to an attribute error if the underlying
generator does not implement the `send` method.

Additionally, if at least one target is `global` or `nonlocal`,
no fix will be offered.

In most cases, however, the fix is safe, and such a modification should have
no effect on the behavior of the program.

## References
- [Python documentation: The `yield` statement](https://docs.python.org/3/reference/simple_stmts.html#the-yield-statement)
- [PEP 380  Syntax for Delegating to a Subgenerator](https://peps.python.org/pep-0380/)

# unnecessary-builtin-import (UP029)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for unnecessary imports of builtins.

## Why is this bad?
Builtins are always available. Importing them is unnecessary and should be
removed to avoid confusion.

## Example
```python
from builtins import str

str(1)
```

Use instead:
```python
str(1)
```

## Fix safety
This fix is marked as unsafe because removing the import
may change program behavior. For example, in the following
situation:

```python
def str(x):
    return x


from builtins import str

str(1)  # `"1"` with the import, `1` without
```

## References
- [Python documentation: The Python Standard Library](https://docs.python.org/3/library/index.html)

# format-literals (UP030)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for unnecessary positional indices in format strings.

## Why is this bad?
In Python 3.1 and later, format strings can use implicit positional
references. For example, `"{0}, {1}".format("Hello", "World")` can be
rewritten as `"{}, {}".format("Hello", "World")`.

If the positional indices appear exactly in-order, they can be omitted
in favor of automatic indices to improve readability.

## Example
```python
"{0}, {1}".format("Hello", "World")  # "Hello, World"
```

Use instead:
```python
"{}, {}".format("Hello", "World")  # "Hello, World"
```

This fix is marked as unsafe because:
- Comments attached to arguments are not moved, which can cause comments to mismatch the actual arguments.
- If arguments have side effects (e.g., print), reordering may change program behavior.

## References
- [Python documentation: Format String Syntax](https://docs.python.org/3/library/string.html#format-string-syntax)
- [Python documentation: `str.format`](https://docs.python.org/3/library/stdtypes.html#str.format)

# printf-string-formatting (UP031)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for `printf`-style string formatting, and offers to replace it with
`str.format` calls.

## Why is this bad?
`printf`-style string formatting has a number of quirks, and leads to less
readable code than using `str.format` calls or f-strings. In general, prefer
the newer `str.format` and f-strings constructs over `printf`-style string
formatting.

## Example

```python
"%s, %s" % ("Hello", "World")  # "Hello, World"
```

Use instead:

```python
"{}, {}".format("Hello", "World")  # "Hello, World"
```

```python
f"{'Hello'}, {'World'}"  # "Hello, World"
```

## Fix safety

In cases where the format string contains a single generic format specifier
(e.g. `%s`), and the right-hand side is an ambiguous expression,
we cannot offer a safe fix.

For example, given:

```python
"%s" % val
```

`val` could be a single-element tuple, _or_ a single value (not
contained in a tuple). Both of these would resolve to the same
formatted string when using `printf`-style formatting, but
resolve differently when using f-strings:

```python
val = 1
print("%s" % val)  # "1"
print("{}".format(val))  # "1"

val = (1,)
print("%s" % val)  # "1"
print("{}".format(val))  # "(1,)"
```

## References
- [Python documentation: `printf`-style String Formatting](https://docs.python.org/3/library/stdtypes.html#old-string-formatting)
- [Python documentation: `str.format`](https://docs.python.org/3/library/stdtypes.html#str.format)

# f-string (UP032)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for `str.format` calls that can be replaced with f-strings.

## Why is this bad?
f-strings are more readable and generally preferred over `str.format`
calls.

## Example
```python
"{}".format(foo)
```

Use instead:
```python
f"{foo}"
```

## References
- [Python documentation: f-strings](https://docs.python.org/3/reference/lexical_analysis.html#f-strings)

# lru-cache-with-maxsize-none (UP033)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for uses of `functools.lru_cache` that set `maxsize=None`.

## Why is this bad?
Since Python 3.9, `functools.cache` can be used as a drop-in replacement
for `functools.lru_cache(maxsize=None)`. When possible, prefer
`functools.cache` as it is more readable and idiomatic.

## Example

```python
import functools


@functools.lru_cache(maxsize=None)
def foo(): ...
```

Use instead:

```python
import functools


@functools.cache
def foo(): ...
```

## Options
- `target-version`

## References
- [Python documentation: `@functools.cache`](https://docs.python.org/3/library/functools.html#functools.cache)

# extraneous-parentheses (UP034)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for extraneous parentheses.

## Why is this bad?
Extraneous parentheses are redundant, and can be removed to improve
readability while retaining identical semantics.

## Example
```python
print(("Hello, world"))
```

Use instead:
```python
print("Hello, world")
```

# deprecated-import (UP035)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for uses of deprecated imports based on the minimum supported
Python version.

## Why is this bad?
Deprecated imports may be removed in future versions of Python, and
should be replaced with their new equivalents.

Note that, in some cases, it may be preferable to continue importing
members from `typing_extensions` even after they're added to the Python
standard library, as `typing_extensions` can backport bugfixes and
optimizations from later Python versions. This rule thus avoids flagging
imports from `typing_extensions` in such cases.

## Example
```python
from collections import Sequence
```

Use instead:
```python
from collections.abc import Sequence
```

# outdated-version-block (UP036)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for conditional blocks gated on `sys.version_info` comparisons
that are outdated for the minimum supported Python version.

## Why is this bad?
In Python, code can be conditionally executed based on the active
Python version by comparing against the `sys.version_info` tuple.

If a code block is only executed for Python versions older than the
minimum supported version, it should be removed.

## Example
```python
import sys

if sys.version_info < (3, 0):
    print("py2")
else:
    print("py3")
```

Use instead:
```python
print("py3")
```

## Options
- `target-version`

## Fix safety
This rule's fix is marked as unsafe because it will remove all code,
comments, and annotations within unreachable version blocks.

## References
- [Python documentation: `sys.version_info`](https://docs.python.org/3/library/sys.html#sys.version_info)

# quoted-annotation (UP037)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for the presence of unnecessary quotes in type annotations.

## Why is this bad?
In Python, type annotations can be quoted to avoid forward references.

However, if `from __future__ import annotations` is present, Python
will always evaluate type annotations in a deferred manner, making
the quotes unnecessary.

Similarly, if the annotation is located in a typing-only context and
won't be evaluated by Python at runtime, the quotes will also be
considered unnecessary. For example, Python does not evaluate type
annotations on assignments in function bodies.

## Example

Given:

```python
from __future__ import annotations


def foo(bar: "Bar") -> "Bar": ...
```

Use instead:

```python
from __future__ import annotations


def foo(bar: Bar) -> Bar: ...
```

Given:

```python
def foo() -> None:
    bar: "Bar"
```

Use instead:

```python
def foo() -> None:
    bar: Bar
```

## Preview

When [preview] is enabled, if [`lint.future-annotations`] is set to `true`,
`from __future__ import annotations` will be added if doing so would allow an annotation to be
unquoted.

## Fix safety

The rule's fix is marked as safe, unless [preview] and
[`lint.future-annotations`] are enabled and a `from __future__ import
annotations` import is added. Such an import may change the behavior of all annotations in the
file.

## Options
- `lint.future-annotations`

## See also
- [`quoted-annotation-in-stub`][PYI020]: A rule that
  removes all quoted annotations from stub files
- [`quoted-type-alias`][TC008]: A rule that removes unnecessary quotes
  from type aliases.

## References
- [PEP 563  Postponed Evaluation of Annotations](https://peps.python.org/pep-0563/)
- [Python documentation: `__future__`](https://docs.python.org/3/library/__future__.html#module-__future__)

[PYI020]: https://docs.astral.sh/ruff/rules/quoted-annotation-in-stub/
[TC008]: https://docs.astral.sh/ruff/rules/quoted-type-alias/
[preview]: https://docs.astral.sh/ruff/preview/

# non-pep604-isinstance (UP038)

Derived from the **pyupgrade** linter.

Fix is always available.

## Removed
This rule was removed as using [PEP 604] syntax in `isinstance` and `issubclass` calls
isn't recommended practice, and it incorrectly suggests that other typing syntaxes like [PEP 695]
would be supported by `isinstance` and `issubclass`. Using the [PEP 604] syntax
is also slightly slower.

## What it does
Checks for uses of `isinstance` and `issubclass` that take a tuple
of types for comparison.

## Why is this bad?
Since Python 3.10, `isinstance` and `issubclass` can be passed a
`|`-separated union of types, which is consistent
with the union operator introduced in [PEP 604].

Note that this results in slower code. Ignore this rule if the
performance of an `isinstance` or `issubclass` check is a
concern, e.g., in a hot loop.

## Example
```python
isinstance(x, (int, float))
```

Use instead:
```python
isinstance(x, int | float)
```

## Options
- `target-version`

## References
- [Python documentation: `isinstance`](https://docs.python.org/3/library/functions.html#isinstance)
- [Python documentation: `issubclass`](https://docs.python.org/3/library/functions.html#issubclass)

[PEP 604]: https://peps.python.org/pep-0604/
[PEP 695]: https://peps.python.org/pep-0695/

# unnecessary-class-parentheses (UP039)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for class definitions that include unnecessary parentheses after
the class name.

## Why is this bad?
If a class definition doesn't have any bases, the parentheses are
unnecessary.

## Example
```python
class Foo():
    ...
```

Use instead:
```python
class Foo:
    ...
```

# non-pep695-type-alias (UP040)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for use of `TypeAlias` annotations and `TypeAliasType` assignments
for declaring type aliases.

## Why is this bad?
The `type` keyword was introduced in Python 3.12 by [PEP 695] for defining
type aliases. The `type` keyword is easier to read and provides cleaner
support for generics.

## Known problems
[PEP 695] uses inferred variance for type parameters, instead of the
`covariant` and `contravariant` keywords used by `TypeVar` variables. As
such, rewriting a type alias using a PEP-695 `type` statement may change
the variance of the alias's type parameters.

Unlike type aliases that use simple assignments, definitions created using
[PEP 695] `type` statements cannot be used as drop-in replacements at
runtime for the value on the right-hand side of the statement. This means
that while for some simple old-style type aliases you can use them as the
second argument to an `isinstance()` call (for example), doing the same
with a [PEP 695] `type` statement will always raise `TypeError` at
runtime.

## Example
```python
from typing import Annotated, TypeAlias, TypeAliasType
from annotated_types import Gt

ListOfInt: TypeAlias = list[int]
PositiveInt = TypeAliasType("PositiveInt", Annotated[int, Gt(0)])
```

Use instead:
```python
from typing import Annotated
from annotated_types import Gt

type ListOfInt = list[int]
type PositiveInt = Annotated[int, Gt(0)]
```

## Fix safety

This fix is marked unsafe for `TypeAlias` assignments outside of stub files because of the
runtime behavior around `isinstance()` calls noted above. The fix is also unsafe for
`TypeAliasType` assignments if there are any comments in the replacement range that would be
deleted.

## See also

This rule only applies to `TypeAlias`es and `TypeAliasType`s. See
[`non-pep695-generic-class`][UP046] and [`non-pep695-generic-function`][UP047] for similar
transformations for generic classes and functions.

This rule replaces standalone type variables in aliases but doesn't remove the corresponding
type variables even if they are unused after the fix. See [`unused-private-type-var`][PYI018]
for a rule to clean up unused private type variables.

This rule will not rename private type variables to remove leading underscores, even though the
new type parameters are restricted in scope to their associated aliases. See
[`private-type-parameter`][UP049] for a rule to update these names.

[PEP 695]: https://peps.python.org/pep-0695/
[PYI018]: https://docs.astral.sh/ruff/rules/unused-private-type-var/
[UP046]: https://docs.astral.sh/ruff/rules/non-pep695-generic-class/
[UP047]: https://docs.astral.sh/ruff/rules/non-pep695-generic-function/
[UP049]: https://docs.astral.sh/ruff/rules/private-type-parameter/

# timeout-error-alias (UP041)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for uses of exceptions that alias `TimeoutError`.

## Why is this bad?
`TimeoutError` is the builtin error type used for exceptions when a system
function timed out at the system level.

In Python 3.10, `socket.timeout` was aliased to `TimeoutError`. In Python
3.11, `asyncio.TimeoutError` was aliased to `TimeoutError`.

These aliases remain in place for compatibility with older versions of
Python, but may be removed in future versions.

Prefer using `TimeoutError` directly, as it is more idiomatic and future-proof.

## Example
```python
import asyncio

raise asyncio.TimeoutError
```

Use instead:
```python
raise TimeoutError
```

## References
- [Python documentation: `TimeoutError`](https://docs.python.org/3/library/exceptions.html#TimeoutError)

# replace-str-enum (UP042)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for classes that inherit from both `str` and `enum.Enum`.

## Why is this bad?
Python 3.11 introduced `enum.StrEnum`, which is preferred over inheriting
from both `str` and `enum.Enum`.

## Example

```python
import enum


class Foo(str, enum.Enum): ...
```

Use instead:

```python
import enum


class Foo(enum.StrEnum): ...
```

## Fix safety

Python 3.11 introduced a [breaking change] for enums that inherit from both
`str` and `enum.Enum`. Consider the following enum:

```python
from enum import Enum


class Foo(str, Enum):
    BAR = "bar"
```

In Python 3.11, the formatted representation of `Foo.BAR` changed as
follows:

```python
# Python 3.10
f"{Foo.BAR}"  # > bar
# Python 3.11
f"{Foo.BAR}"  # > Foo.BAR
```

Migrating from `str` and `enum.Enum` to `enum.StrEnum` will restore the
previous behavior, such that:

```python
from enum import StrEnum


class Foo(StrEnum):
    BAR = "bar"


f"{Foo.BAR}"  # > bar
```

As such, migrating to `enum.StrEnum` will introduce a behavior change for
code that relies on the Python 3.11 behavior.

## References
- [enum.StrEnum](https://docs.python.org/3/library/enum.html#enum.StrEnum)

[breaking change]: https://blog.pecar.me/python-enum

# unnecessary-default-type-args (UP043)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for unnecessary default type arguments for `Generator` and
`AsyncGenerator` on Python 3.13+.
In [preview], this rule will also apply to stub files.

## Why is this bad?
Python 3.13 introduced the ability for type parameters to specify default
values. Following this change, several standard-library classes were
updated to add default values for some of their type parameters. For
example, `Generator[int]` is now equivalent to
`Generator[int, None, None]`, as the second and third type parameters of
`Generator` now default to `None`.

Omitting type arguments that match the default values can make the code
more concise and easier to read.

## Example

```python
from collections.abc import Generator, AsyncGenerator


def sync_gen() -> Generator[int, None, None]:
    yield 42


async def async_gen() -> AsyncGenerator[int, None]:
    yield 42
```

Use instead:

```python
from collections.abc import Generator, AsyncGenerator


def sync_gen() -> Generator[int]:
    yield 42


async def async_gen() -> AsyncGenerator[int]:
    yield 42
```

## Fix safety
This rule's fix is marked as safe, unless the type annotation contains comments.

## Options
- `target-version`

## References
- [PEP 696  Type Defaults for Type Parameters](https://peps.python.org/pep-0696/)
- [Annotating generators and coroutines](https://docs.python.org/3/library/typing.html#annotating-generators-and-coroutines)
- [Python documentation: `typing.Generator`](https://docs.python.org/3/library/typing.html#typing.Generator)
- [Python documentation: `typing.AsyncGenerator`](https://docs.python.org/3/library/typing.html#typing.AsyncGenerator)

[preview]: https://docs.astral.sh/ruff/preview/

# non-pep646-unpack (UP044)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does
Checks for uses of `Unpack[]` on Python 3.11 and above, and suggests
using `*` instead.

## Why is this bad?
[PEP 646] introduced a new syntax for unpacking sequences based on the `*`
operator. This syntax is more concise and readable than the previous
`Unpack[]` syntax.

## Example
```python
from typing import Unpack


def foo(*args: Unpack[tuple[int, ...]]) -> None:
    pass
```

Use instead:
```python
def foo(*args: *tuple[int, ...]) -> None:
    pass
```

## Fix safety
This rule's fix is marked as unsafe, as `Unpack[T]` and `*T` are considered
different values when introspecting types at runtime. However, in most cases,
the fix should be safe to apply.

[PEP 646]: https://peps.python.org/pep-0646/

# non-pep604-annotation-optional (UP045)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Check for `typing.Optional` annotations that can be rewritten based on [PEP 604] syntax.

## Why is this bad?
[PEP 604] introduced a new syntax for union type annotations based on the
`|` operator. This syntax is more concise and readable than the previous
`typing.Optional` syntax.

This rule is enabled when targeting Python 3.10 or later (see:
[`target-version`]). By default, it's _also_ enabled for earlier Python
versions if `from __future__ import annotations` is present, as
`__future__` annotations are not evaluated at runtime. If your code relies
on runtime type annotations (either directly or via a library like
Pydantic), you can disable this behavior for Python versions prior to 3.10
by setting [`lint.pyupgrade.keep-runtime-typing`] to `true`.

## Example
```python
from typing import Optional

foo: Optional[int] = None
```

Use instead:
```python
foo: int | None = None
```

## Fix safety
This rule's fix is marked as unsafe, as it may lead to runtime errors
using libraries that rely on runtime type annotations, like Pydantic,
on Python versions prior to Python 3.10. It may also lead to runtime errors
in unusual and likely incorrect type annotations where the type does not
support the `|` operator.

## Options
- `target-version`
- `lint.pyupgrade.keep-runtime-typing`

[PEP 604]: https://peps.python.org/pep-0604/

# non-pep695-generic-class (UP046)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does

Checks for use of standalone type variables and parameter specifications in generic classes.

## Why is this bad?

Special type parameter syntax was introduced in Python 3.12 by [PEP 695] for defining generic
classes. This syntax is easier to read and provides cleaner support for generics.

## Known problems

The rule currently skips generic classes nested inside of other functions or classes. It also
skips type parameters with the `default` argument introduced in [PEP 696] and implemented in
Python 3.13.

This rule can only offer a fix if all of the generic types in the class definition are defined
in the current module. For external type parameters, a diagnostic is emitted without a suggested
fix.

Not all type checkers fully support PEP 695 yet, so even valid fixes suggested by this rule may
cause type checking to [fail].

## Fix safety

This fix is marked as unsafe, as [PEP 695] uses inferred variance for type parameters, instead
of the `covariant` and `contravariant` keywords used by `TypeVar` variables. As such, replacing
a `TypeVar` variable with an inline type parameter may change its variance.

## Example

```python
from typing import Generic, TypeVar

T = TypeVar("T")


class GenericClass(Generic[T]):
    var: T
```

Use instead:

```python
class GenericClass[T]:
    var: T
```

## See also

This rule replaces standalone type variables in classes but doesn't remove
the corresponding type variables even if they are unused after the fix. See
[`unused-private-type-var`][PYI018] for a rule to clean up unused
private type variables.

This rule will not rename private type variables to remove leading underscores, even though the
new type parameters are restricted in scope to their associated class. See
[`private-type-parameter`][UP049] for a rule to update these names.

This rule will correctly handle classes with multiple base classes, as long as the single
`Generic` base class is at the end of the argument list, as checked by
[`generic-not-last-base-class`][PYI059]. If a `Generic` base class is
found outside of the last position, a diagnostic is emitted without a suggested fix.

This rule only applies to generic classes and does not include generic functions. See
[`non-pep695-generic-function`][UP047] for the function version.

[PEP 695]: https://peps.python.org/pep-0695/
[PEP 696]: https://peps.python.org/pep-0696/
[PYI018]: https://docs.astral.sh/ruff/rules/unused-private-type-var/
[PYI059]: https://docs.astral.sh/ruff/rules/generic-not-last-base-class/
[UP047]: https://docs.astral.sh/ruff/rules/non-pep695-generic-function/
[UP049]: https://docs.astral.sh/ruff/rules/private-type-parameter/
[fail]: https://github.com/python/mypy/issues/18507

# non-pep695-generic-function (UP047)

Derived from the **pyupgrade** linter.

Fix is always available.

## What it does

Checks for use of standalone type variables and parameter specifications in generic functions.

## Why is this bad?

Special type parameter syntax was introduced in Python 3.12 by [PEP 695] for defining generic
functions. This syntax is easier to read and provides cleaner support for generics.

## Known problems

The rule currently skips generic functions nested inside of other functions or classes and those
with type parameters containing the `default` argument introduced in [PEP 696] and implemented
in Python 3.13.

Not all type checkers fully support PEP 695 yet, so even valid fixes suggested by this rule may
cause type checking to [fail].

## Fix safety

This fix is marked unsafe, as [PEP 695] uses inferred variance for type parameters, instead of
the `covariant` and `contravariant` keywords used by `TypeVar` variables. As such, replacing a
`TypeVar` variable with an inline type parameter may change its variance.

Additionally, if the rule cannot determine whether a parameter annotation corresponds to a type
variable (e.g. for a type imported from another module), it will not add the type to the generic
type parameter list. This causes the function to have a mix of old-style type variables and
new-style generic type parameters, which will be rejected by type checkers.

## Example

```python
from typing import TypeVar

T = TypeVar("T")


def generic_function(var: T) -> T:
    return var
```

Use instead:

```python
def generic_function[T](var: T) -> T:
    return var
```

## See also

This rule replaces standalone type variables in function signatures but doesn't remove
the corresponding type variables even if they are unused after the fix. See
[`unused-private-type-var`][PYI018] for a rule to clean up unused
private type variables.

This rule will not rename private type variables to remove leading underscores, even though the
new type parameters are restricted in scope to their associated function. See
[`private-type-parameter`][UP049] for a rule to update these names.

This rule only applies to generic functions and does not include generic classes. See
[`non-pep695-generic-class`][UP046] for the class version.

[PEP 695]: https://peps.python.org/pep-0695/
[PEP 696]: https://peps.python.org/pep-0696/
[PYI018]: https://docs.astral.sh/ruff/rules/unused-private-type-var/
[UP046]: https://docs.astral.sh/ruff/rules/non-pep695-generic-class/
[UP049]: https://docs.astral.sh/ruff/rules/private-type-parameter/
[fail]: https://github.com/python/mypy/issues/18507

# private-type-parameter (UP049)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does

Checks for use of [PEP 695] type parameters with leading underscores in generic classes and
functions.

## Why is this bad?

[PEP 695] type parameters are already restricted in scope to the class or function in which they
appear, so leading underscores just hurt readability without the usual privacy benefits.

However, neither a diagnostic nor a fix will be emitted for "sunder" (`_T_`) or "dunder"
(`__T__`) type parameter names as these are not considered private.

## Example

```python
class GenericClass[_T]:
    var: _T


def generic_function[_T](var: _T) -> list[_T]:
    return var[0]
```

Use instead:

```python
class GenericClass[T]:
    var: T


def generic_function[T](var: T) -> list[T]:
    return var[0]
```

## Fix availability

If the name without an underscore would shadow a builtin or another variable, would be a
keyword, or would otherwise be an invalid identifier, a fix will not be available. In these
situations, you can consider using a trailing underscore or a different name entirely to satisfy
the lint rule.

## See also

This rule renames private [PEP 695] type parameters but doesn't convert pre-[PEP 695] generics
to the new format. See [`non-pep695-generic-function`][UP047] and
[`non-pep695-generic-class`][UP046] for rules that will make this transformation.
Those rules do not remove unused type variables after their changes,
so you may also want to consider enabling [`unused-private-type-var`][PYI018] to complete
the transition to [PEP 695] generics.

[PEP 695]: https://peps.python.org/pep-0695/
[UP047]: https://docs.astral.sh/ruff/rules/non-pep695-generic-function
[UP046]: https://docs.astral.sh/ruff/rules/non-pep695-generic-class
[PYI018]: https://docs.astral.sh/ruff/rules/unused-private-type-var

# useless-class-metaclass-type (UP050)

Derived from the **pyupgrade** linter.

Fix is sometimes available.

## What it does
Checks for `metaclass=type` in class definitions.

## Why is this bad?
Since Python 3, the default metaclass is `type`, so specifying it explicitly is redundant.

Even though `__prepare__` is not required, the default metaclass (`type`) implements it,
for the convenience of subclasses calling it via `super()`.
## Example

```python
class Foo(metaclass=type): ...
```

Use instead:

```python
class Foo: ...
```

## References
- [PEP 3115  Metaclasses in Python 3000](https://peps.python.org/pep-3115/)

# read-whole-file (FURB101)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for uses of `open` and `read` that can be replaced by `pathlib`
methods, like `Path.read_text` and `Path.read_bytes`.

## Why is this bad?
When reading the entire contents of a file into a variable, it's simpler
and more concise to use `pathlib` methods like `Path.read_text` and
`Path.read_bytes` instead of `open` and `read` calls via `with` statements.

## Example
```python
with open(filename) as f:
    contents = f.read()
```

Use instead:
```python
from pathlib import Path

contents = Path(filename).read_text()
```
## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.read_bytes`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.read_bytes)
- [Python documentation: `Path.read_text`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.read_text)

# write-whole-file (FURB103)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for uses of `open` and `write` that can be replaced by `pathlib`
methods, like `Path.write_text` and `Path.write_bytes`.

## Why is this bad?
When writing a single string to a file, it's simpler and more concise
to use `pathlib` methods like `Path.write_text` and `Path.write_bytes`
instead of `open` and `write` calls via `with` statements.

## Example
```python
with open(filename, "w") as f:
    f.write(contents)
```

Use instead:
```python
from pathlib import Path

Path(filename).write_text(contents)
```

## Fix Safety
This rule's fix is marked as unsafe if the replacement would remove comments attached to the original expression.

## References
- [Python documentation: `Path.write_bytes`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.write_bytes)
- [Python documentation: `Path.write_text`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.write_text)

# print-empty-string (FURB105)

Derived from the **refurb** linter.

Fix is sometimes available.

## What it does
Checks for `print` calls with unnecessary empty strings as positional
arguments and unnecessary `sep` keyword arguments.

## Why is this bad?
Prefer calling `print` without any positional arguments, which is
equivalent and more concise.

Similarly, when printing one or fewer items, the `sep` keyword argument,
(used to define the string that separates the `print` arguments) can be
omitted, as it's redundant when there are no items to separate.

## Example
```python
print("")
```

Use instead:
```python
print()
```

## Fix safety
This fix is marked as unsafe if it removes an unused `sep` keyword argument
that may have side effects. Removing such arguments may change the program's
behavior by skipping the execution of those side effects.

## References
- [Python documentation: `print`](https://docs.python.org/3/library/functions.html#print)

# if-exp-instead-of-or-operator (FURB110)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for ternary `if` expressions that can be replaced with the `or`
operator.

## Why is this bad?
Ternary `if` expressions are more verbose than `or` expressions while
providing the same functionality.

## Example
```python
z = x if x else y
```

Use instead:
```python
z = x or y
```

## Fix safety
This rule's fix is marked as unsafe in the event that the body of the
`if` expression contains side effects.

For example, `foo` will be called twice in `foo() if foo() else bar()`
(assuming `foo()` returns a truthy value), but only once in
`foo() or bar()`.

# repeated-append (FURB113)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for consecutive calls to `append`.

## Why is this bad?
Consecutive calls to `append` can be less efficient than batching them into
a single `extend`. Each `append` resizes the list individually, whereas an
`extend` can resize the list once for all elements.

## Known problems
This rule is prone to false negatives due to type inference limitations,
as it will only detect lists that are instantiated as literals or annotated
with a type annotation.

## Example
```python
nums = [1, 2, 3]

nums.append(4)
nums.append(5)
nums.append(6)
```

Use instead:
```python
nums = [1, 2, 3]

nums.extend((4, 5, 6))
```

## References
- [Python documentation: More on Lists](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists)

# f-string-number-format (FURB116)

Derived from the **refurb** linter.

Fix is sometimes available.

## What it does
Checks for uses of `bin(...)[2:]` (or `hex`, or `oct`) to convert
an integer into a string.

## Why is this bad?
When converting an integer to a baseless binary, hexadecimal, or octal
string, using f-strings is more concise and readable than using the
`bin`, `hex`, or `oct` functions followed by a slice.

## Example
```python
print(bin(1337)[2:])
```

Use instead:
```python
print(f"{1337:b}")
```

## Fix safety
The fix is only marked as safe for integer literals, all other cases
are display-only, as they may change the runtime behaviour of the program
or introduce syntax errors.

# reimplemented-operator (FURB118)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for lambda expressions and function definitions that can be replaced with a function from
the `operator` module.

## Why is this bad?
The `operator` module provides functions that implement the same functionality as the
corresponding operators. For example, `operator.add` is often equivalent to `lambda x, y: x + y`.
Using the functions from the `operator` module is more concise and communicates the intent of
the code more clearly.

## Example
```python
import functools

nums = [1, 2, 3]
total = functools.reduce(lambda x, y: x + y, nums)
```

Use instead:
```python
import functools
import operator

nums = [1, 2, 3]
total = functools.reduce(operator.add, nums)
```

## Fix safety
The fix offered by this rule is always marked as unsafe. While the changes the fix would make
would rarely break your code, there are two ways in which functions from the `operator` module
differ from user-defined functions. It would be non-trivial for Ruff to detect whether or not
these differences would matter in a specific situation where Ruff is emitting a diagnostic for
this rule.

The first difference is that `operator` functions cannot be called with keyword arguments, but
most user-defined functions can. If an `add` function is defined as `add = lambda x, y: x + y`,
replacing this function with `operator.add` will cause the later call to raise `TypeError` if
the function is later called with keyword arguments, e.g. `add(x=1, y=2)`.

The second difference is that user-defined functions are [descriptors], but this is not true of
the functions defined in the `operator` module. Practically speaking, this means that defining
a function in a class body (either by using a `def` statement or assigning a `lambda` function
to a variable) is a valid way of defining an instance method on that class; monkeypatching a
user-defined function onto a class after the class has been created also has the same effect.
The same is not true of an `operator` function: assigning an `operator` function to a variable
in a class body or monkeypatching one onto a class will not create a valid instance method.
Ruff will refrain from emitting diagnostics for this rule on function definitions in class
bodies; however, it does not currently have sophisticated enough type inference to avoid
emitting this diagnostic if a user-defined function is being monkeypatched onto a class after
the class has been constructed.

[descriptors]: https://docs.python.org/3/howto/descriptor.html

# for-loop-writes (FURB122)

Derived from the **refurb** linter.

Fix is always available.

## What it does
Checks for the use of `IOBase.write` in a for loop.

## Why is this bad?
When writing a batch of elements, it's more idiomatic to use a single method call to
`IOBase.writelines`, rather than write elements one by one.

## Example
```python
from pathlib import Path

with Path("file").open("w") as f:
    for line in lines:
        f.write(line)

with Path("file").open("wb") as f_b:
    for line_b in lines_b:
        f_b.write(line_b.encode())
```

Use instead:
```python
from pathlib import Path

with Path("file").open("w") as f:
    f.writelines(lines)

with Path("file").open("wb") as f_b:
    f_b.writelines(line_b.encode() for line_b in lines_b)
```

## Fix safety
This fix is marked as unsafe if it would cause comments to be deleted.

## References
- [Python documentation: `io.IOBase.writelines`](https://docs.python.org/3/library/io.html#io.IOBase.writelines)

# readlines-in-for (FURB129)

Derived from the **refurb** linter.

Fix is always available.

## What it does
Checks for uses of `readlines()` when iterating over a file line-by-line.

## Why is this bad?
Rather than iterating over all lines in a file by calling `readlines()`,
it's more convenient and performant to iterate over the file object
directly.

## Example
```python
with open("file.txt") as fp:
    for line in fp.readlines():
        ...
```

Use instead:
```python
with open("file.txt") as fp:
    for line in fp:
        ...
```

## Fix safety
This rule's fix is marked as unsafe if there's comments in the
`readlines()` call, as comments may be removed.

For example, the fix would be marked as unsafe in the following case:
```python
with open("file.txt") as fp:
    for line in (  # comment
        fp.readlines()  # comment
    ):
        ...
```

## References
- [Python documentation: `io.IOBase.readlines`](https://docs.python.org/3/library/io.html#io.IOBase.readlines)

# delete-full-slice (FURB131)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for `del` statements that delete the entire slice of a list or
dictionary.

## Why is this bad?
It is faster and more succinct to remove all items via the `clear()`
method.

## Known problems
This rule is prone to false negatives due to type inference limitations,
as it will only detect lists and dictionaries that are instantiated as
literals or annotated with a type annotation.

## Example
```python
names = {"key": "value"}
nums = [1, 2, 3]

del names[:]
del nums[:]
```

Use instead:
```python
names = {"key": "value"}
nums = [1, 2, 3]

names.clear()
nums.clear()
```

## References
- [Python documentation: Mutable Sequence Types](https://docs.python.org/3/library/stdtypes.html?highlight=list#mutable-sequence-types)
- [Python documentation: `dict.clear()`](https://docs.python.org/3/library/stdtypes.html?highlight=list#dict.clear)

# check-and-remove-from-set (FURB132)

Derived from the **refurb** linter.

Fix is always available.

## What it does
Checks for uses of `set.remove` that can be replaced with `set.discard`.

## Why is this bad?
If an element should be removed from a set if it is present, it is more
succinct and idiomatic to use `discard`.

## Known problems
This rule is prone to false negatives due to type inference limitations,
as it will only detect sets that are instantiated as literals or annotated
with a type annotation.

## Example
```python
nums = {123, 456}

if 123 in nums:
    nums.remove(123)
```

Use instead:
```python
nums = {123, 456}

nums.discard(123)
```

## References
- [Python documentation: `set.discard()`](https://docs.python.org/3/library/stdtypes.html?highlight=list#frozenset.discard)

# if-expr-min-max (FURB136)

Derived from the **refurb** linter.

Fix is sometimes available.

## What it does
Checks for `if` expressions that can be replaced with `min()` or `max()`
calls.

## Why is this bad?
An `if` expression that selects the lesser or greater of two
sub-expressions can be replaced with a `min()` or `max()` call
respectively. When possible, prefer `min()` and `max()`, as they're more
concise and readable than the equivalent `if` expression.

## Example
```python
highest_score = score1 if score1 > score2 else score2
```

Use instead:
```python
highest_score = max(score2, score1)
```

## References
- [Python documentation: `min`](https://docs.python.org/3.11/library/functions.html#min)
- [Python documentation: `max`](https://docs.python.org/3.11/library/functions.html#max)

# reimplemented-starmap (FURB140)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for generator expressions, list and set comprehensions that can
be replaced with `itertools.starmap`.

## Why is this bad?
When unpacking values from iterators to pass them directly to
a function, prefer `itertools.starmap`.

Using `itertools.starmap` is more concise and readable. Furthermore, it is
more efficient than generator expressions, and in some versions of Python,
it is more efficient than comprehensions.

## Known problems
Since Python 3.12, `itertools.starmap` is less efficient than
comprehensions ([#7771]). This is due to [PEP 709], which made
comprehensions faster.

## Example
```python
all(predicate(a, b) for a, b in some_iterable)
```

Use instead:
```python
from itertools import starmap


all(starmap(predicate, some_iterable))
```

## References
- [Python documentation: `itertools.starmap`](https://docs.python.org/3/library/itertools.html#itertools.starmap)

[PEP 709]: https://peps.python.org/pep-0709/
[#7771]: https://github.com/astral-sh/ruff/issues/7771

# for-loop-set-mutations (FURB142)

Derived from the **refurb** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for code that updates a set with the contents of an iterable by
using a `for` loop to call `.add()` or `.discard()` on each element
separately.

## Why is this bad?
When adding or removing a batch of elements to or from a set, it's more
idiomatic to use a single method call rather than adding or removing
elements one by one.

## Example
```python
s = set()

for x in (1, 2, 3):
    s.add(x)

for x in (1, 2, 3):
    s.discard(x)
```

Use instead:
```python
s = set()

s.update((1, 2, 3))
s.difference_update((1, 2, 3))
```

## Fix safety
The fix will be marked as unsafe if applying the fix would delete any comments.
Otherwise, it is marked as safe.

## References
- [Python documentation: `set`](https://docs.python.org/3/library/stdtypes.html#set)

# slice-copy (FURB145)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for unbounded slice expressions to copy a list.

## Why is this bad?
The `list.copy` method is more readable and consistent with copying other
types.

## Known problems
This rule is prone to false negatives due to type inference limitations,
as it will only detect lists that are instantiated as literals or annotated
with a type annotation.

## Example
```python
a = [1, 2, 3]
b = a[:]
```

Use instead:
```python
a = [1, 2, 3]
b = a.copy()
```

## References
- [Python documentation: Mutable Sequence Types](https://docs.python.org/3/library/stdtypes.html#mutable-sequence-types)

# unnecessary-enumerate (FURB148)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for uses of `enumerate` that discard either the index or the value
when iterating over a sequence.

## Why is this bad?
The built-in `enumerate` function is useful when you need both the index and
value of a sequence.

If you only need the index or values of a sequence, you should iterate over
`range(len(...))` or the sequence itself, respectively, instead. This is
more efficient and communicates the intent of the code more clearly.

## Known problems
This rule is prone to false negatives due to type inference limitations;
namely, it will only suggest a fix using the `len` builtin function if the
sequence passed to `enumerate` is an instantiated as a list, set, dict, or
tuple literal, or annotated as such with a type annotation.

The `len` builtin function is not defined for all object types (such as
generators), and so refactoring to use `len` over `enumerate` is not always
safe.

## Example
```python
for index, _ in enumerate(sequence):
    print(index)

for _, value in enumerate(sequence):
    print(value)
```

Use instead:
```python
for index in range(len(sequence)):
    print(index)

for value in sequence:
    print(value)
```

## References
- [Python documentation: `enumerate`](https://docs.python.org/3/library/functions.html#enumerate)
- [Python documentation: `range`](https://docs.python.org/3/library/stdtypes.html#range)
- [Python documentation: `len`](https://docs.python.org/3/library/functions.html#len)

# math-constant (FURB152)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for literals that are similar to constants in `math` module.

## Why is this bad?
Hard-coding mathematical constants like  increases code duplication,
reduces readability, and may lead to a lack of precision.

## Example
```python
A = 3.141592 * r**2
```

Use instead:
```python
A = math.pi * r**2
```

## References
- [Python documentation: `math` constants](https://docs.python.org/3/library/math.html#constants)

# repeated-global (FURB154)

Derived from the **refurb** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for consecutive `global` (or `nonlocal`) statements.

## Why is this bad?
The `global` and `nonlocal` keywords accepts multiple comma-separated names.
Instead of using multiple `global` (or `nonlocal`) statements for separate
variables, you can use a single statement to declare multiple variables at
once.

## Example
```python
def func():
    global x
    global y

    print(x, y)
```

Use instead:
```python
def func():
    global x, y

    print(x, y)
```

## References
- [Python documentation: the `global` statement](https://docs.python.org/3/reference/simple_stmts.html#the-global-statement)
- [Python documentation: the `nonlocal` statement](https://docs.python.org/3/reference/simple_stmts.html#the-nonlocal-statement)

# hardcoded-string-charset (FURB156)

Derived from the **refurb** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for uses of hardcoded charsets, which are defined in Python string module.

## Why is this bad?
Usage of named charsets from the standard library is more readable and less error-prone.

## Example
```python
x = "0123456789"
y in "abcdefghijklmnopqrstuvwxyz"
```

Use instead
```python
import string

x = string.digits
y in string.ascii_lowercase
```

## References
- [Python documentation: String constants](https://docs.python.org/3/library/string.html#string-constants)

# verbose-decimal-constructor (FURB157)

Derived from the **refurb** linter.

Fix is always available.

## What it does
Checks for unnecessary string literal or float casts in `Decimal`
constructors.

## Why is this bad?
The `Decimal` constructor accepts a variety of arguments, including
integers, floats, and strings. However, it's not necessary to cast
integer literals to strings when passing them to the `Decimal`.

Similarly, `Decimal` accepts `inf`, `-inf`, and `nan` as string literals,
so there's no need to wrap those values in a `float` call when passing
them to the `Decimal` constructor.

Prefer the more concise form of argument passing for `Decimal`
constructors, as it's more readable and idiomatic.

Note that this rule does not flag quoted float literals such as `Decimal("0.1")`, which will
produce a more precise `Decimal` value than the unquoted `Decimal(0.1)`.

## Example
```python
from decimal import Decimal

Decimal("0")
Decimal(float("Infinity"))
```

Use instead:
```python
from decimal import Decimal

Decimal(0)
Decimal("Infinity")
```

## References
- [Python documentation: `decimal`](https://docs.python.org/3/library/decimal.html)

# bit-count (FURB161)

Derived from the **refurb** linter.

Fix is always available.

## What it does
Checks for uses of `bin(...).count("1")` to perform a population count.

## Why is this bad?
In Python 3.10, a `bit_count()` method was added to the `int` class,
which is more concise and efficient than converting to a binary
representation via `bin(...)`.

## Example
```python
x = bin(123).count("1")
y = bin(0b1111011).count("1")
```

Use instead:
```python
x = (123).bit_count()
y = 0b1111011.bit_count()
```

## Fix safety
This rule's fix is marked as unsafe unless the argument to `bin` can be inferred as
an instance of a type that implements the `__index__` and `bit_count` methods because this can
change the exception raised at runtime for an invalid argument.

## Options
- `target-version`

## References
- [Python documentation:`int.bit_count`](https://docs.python.org/3/library/stdtypes.html#int.bit_count)

# fromisoformat-replace-z (FURB162)

Derived from the **refurb** linter.

Fix is always available.

## What it does
Checks for `datetime.fromisoformat()` calls
where the only argument is an inline replacement
of `Z` with a zero offset timezone.

## Why is this bad?
On Python 3.11 and later, `datetime.fromisoformat()` can handle most [ISO 8601][iso-8601]
formats including ones affixed with `Z`, so such an operation is unnecessary.

More information on unsupported formats
can be found in [the official documentation][fromisoformat].

## Example

```python
from datetime import datetime


date = "2025-01-01T00:00:00Z"

datetime.fromisoformat(date.replace("Z", "+00:00"))
datetime.fromisoformat(date[:-1] + "-00")
datetime.fromisoformat(date.strip("Z", "-0000"))
datetime.fromisoformat(date.rstrip("Z", "-00:00"))
```

Use instead:

```python
from datetime import datetime


date = "2025-01-01T00:00:00Z"

datetime.fromisoformat(date)
```

## Fix safety
The fix is always marked as unsafe,
as it might change the program's behaviour.

For example, working code might become non-working:

```python
d = "Z2025-01-01T00:00:00Z"  # Note the leading `Z`

datetime.fromisoformat(d.strip("Z") + "+00:00")  # Fine
datetime.fromisoformat(d)  # Runtime error
```

## References
* [Whats New In Python 3.11 &sect; `datetime`](https://docs.python.org/3/whatsnew/3.11.html#datetime)
* [`fromisoformat`](https://docs.python.org/3/library/datetime.html#datetime.date.fromisoformat)

[iso-8601]: https://www.iso.org/obp/ui/#iso:std:iso:8601
[fromisoformat]: https://docs.python.org/3/library/datetime.html#datetime.date.fromisoformat

# redundant-log-base (FURB163)

Derived from the **refurb** linter.

Fix is sometimes available.

## What it does
Checks for `math.log` calls with a redundant base.

## Why is this bad?
The default base of `math.log` is `e`, so specifying it explicitly is
redundant.

Instead of passing 2 or 10 as the base, use `math.log2` or `math.log10`
respectively, as these dedicated variants are typically more accurate
than `math.log`.

## Example
```python
import math

math.log(4, math.e)
math.log(4, 2)
math.log(4, 10)
```

Use instead:
```python
import math

math.log(4)
math.log2(4)
math.log10(4)
```

## Fix safety
This fix is marked unsafe when the argument is a starred expression, as this changes
the call semantics and may raise runtime errors. It is also unsafe if comments are
present within the call, as they will be removed. Additionally, `math.log(x, base)`
and `math.log2(x)` / `math.log10(x)` may differ due to floating-point rounding, so
the fix is also unsafe when making this transformation.

## References
- [Python documentation: `math.log`](https://docs.python.org/3/library/math.html#math.log)
- [Python documentation: `math.log2`](https://docs.python.org/3/library/math.html#math.log2)
- [Python documentation: `math.log10`](https://docs.python.org/3/library/math.html#math.log10)
- [Python documentation: `math.e`](https://docs.python.org/3/library/math.html#math.e)

# unnecessary-from-float (FURB164)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for unnecessary `from_float` and `from_decimal` usages to construct
`Decimal` and `Fraction` instances.

## Why is this bad?
Since Python 3.2, the `Fraction` and `Decimal` classes can be constructed
by passing float or decimal instances to the constructor directly. As such,
the use of `from_float` and `from_decimal` methods is unnecessary, and
should be avoided in favor of the more concise constructor syntax.

However, there are important behavioral differences between the `from_*` methods
and the constructors:
- The `from_*` methods validate their argument types and raise `TypeError` for invalid types
- The constructors accept broader argument types without validation
- The `from_*` methods have different parameter names than the constructors

## Example
```python
from decimal import Decimal
from fractions import Fraction

Decimal.from_float(4.2)
Decimal.from_float(float("inf"))
Fraction.from_float(4.2)
Fraction.from_decimal(Decimal("4.2"))
```

Use instead:
```python
from decimal import Decimal
from fractions import Fraction

Decimal(4.2)
Decimal("inf")
Fraction(4.2)
Fraction(Decimal("4.2"))
```

## Fix safety
This rule's fix is marked as unsafe by default because:
- The `from_*` methods provide type validation that the constructors don't
- Removing type validation can change program behavior
- The parameter names are different between methods and constructors

The fix is marked as safe only when:
- The argument type is known to be valid for the target constructor
- No keyword arguments are used, or they match the constructor's parameters

## References
- [Python documentation: `decimal`](https://docs.python.org/3/library/decimal.html)
- [Python documentation: `fractions`](https://docs.python.org/3/library/fractions.html)

# int-on-sliced-str (FURB166)

Derived from the **refurb** linter.

Fix is always available.

## What it does
Checks for uses of `int` with an explicit base in which a string expression
is stripped of its leading prefix (i.e., `0b`, `0o`, or `0x`).

## Why is this bad?
Given an integer string with a prefix (e.g., `0xABC`), Python can automatically
determine the base of the integer by the prefix without needing to specify
it explicitly.

Instead of `int(num[2:], 16)`, use `int(num, 0)`, which will automatically
deduce the base based on the prefix.

## Example
```python
num = "0xABC"

if num.startswith("0b"):
    i = int(num[2:], 2)
elif num.startswith("0o"):
    i = int(num[2:], 8)
elif num.startswith("0x"):
    i = int(num[2:], 16)

print(i)
```

Use instead:
```python
num = "0xABC"

i = int(num, 0)

print(i)
```

## Fix safety
The rule's fix is marked as unsafe, as Ruff cannot guarantee that the
argument to `int` will remain valid when its base is included in the
function call.

## References
- [Python documentation: `int`](https://docs.python.org/3/library/functions.html#int)

# regex-flag-alias (FURB167)

Derived from the **refurb** linter.

Fix is always available.

## What it does
Checks for the use of shorthand aliases for regular expression flags
(e.g., `re.I` instead of `re.IGNORECASE`).

## Why is this bad?
The regular expression module provides descriptive names for each flag,
along with single-letter aliases. Prefer the descriptive names, as they
are more readable and self-documenting.

## Example
```python
import re

if re.match("^hello", "hello world", re.I):
    ...
```

Use instead:
```python
import re

if re.match("^hello", "hello world", re.IGNORECASE):
    ...
```

# isinstance-type-none (FURB168)

Derived from the **refurb** linter.

Fix is sometimes available.

## What it does
Checks for uses of `isinstance` that check if an object is of type `None`.

## Why is this bad?
There is only ever one instance of `None`, so it is more efficient and
readable to use the `is` operator to check if an object is `None`.

## Example
```python
isinstance(obj, type(None))
```

Use instead:
```python
obj is None
```

## Fix safety
The fix will be marked as unsafe if there are any comments within the call.

## References
- [Python documentation: `isinstance`](https://docs.python.org/3/library/functions.html#isinstance)
- [Python documentation: `None`](https://docs.python.org/3/library/constants.html#None)
- [Python documentation: `type`](https://docs.python.org/3/library/functions.html#type)
- [Python documentation: Identity comparisons](https://docs.python.org/3/reference/expressions.html#is-not)

# type-none-comparison (FURB169)

Derived from the **refurb** linter.

Fix is always available.

## What it does
Checks for uses of `type` that compare the type of an object to the type of `None`.

## Why is this bad?
There is only ever one instance of `None`, so it is more efficient and
readable to use the `is` operator to check if an object is `None`.

## Example
```python
type(obj) is type(None)
```

Use instead:
```python
obj is None
```

## Fix safety
If the fix might remove comments, it will be marked as unsafe.

## References
- [Python documentation: `isinstance`](https://docs.python.org/3/library/functions.html#isinstance)
- [Python documentation: `None`](https://docs.python.org/3/library/constants.html#None)
- [Python documentation: `type`](https://docs.python.org/3/library/functions.html#type)
- [Python documentation: Identity comparisons](https://docs.python.org/3/reference/expressions.html#is-not)

# single-item-membership-test (FURB171)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for membership tests against single-item containers.

## Why is this bad?
Performing a membership test against a container (like a `list` or `set`)
with a single item is less readable and less efficient than comparing
against the item directly.

## Example
```python
1 in [1]
```

Use instead:
```python
1 == 1
```

## Fix safety
The fix is always marked as unsafe.

When the right-hand side is a string, this fix can change the behavior of your program.
This is because `c in "a"` is true both when `c` is `"a"` and when `c` is the empty string.

Additionally, converting `in`/`not in` against a single-item container to `==`/`!=` can
change runtime behavior: `in` may consider identity (e.g., `NaN`) and always
yields a `bool`.

Comments within the replacement range will also be removed.

## References
- [Python documentation: Comparisons](https://docs.python.org/3/reference/expressions.html#comparisons)
- [Python documentation: Membership test operations](https://docs.python.org/3/reference/expressions.html#membership-test-operations)

# implicit-cwd (FURB177)

Derived from the **refurb** linter.

Fix is sometimes available.

## What it does
Checks for current-directory lookups using `Path().resolve()`.

## Why is this bad?
When looking up the current directory, prefer `Path.cwd()` over
`Path().resolve()`, as `Path.cwd()` is more explicit in its intent.

## Example
```python
from pathlib import Path

cwd = Path().resolve()
```

Use instead:
```python
from pathlib import Path

cwd = Path.cwd()
```

## References
- [Python documentation: `Path.cwd`](https://docs.python.org/3/library/pathlib.html#pathlib.Path.cwd)

# meta-class-abc-meta (FURB180)

Derived from the **refurb** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for uses of `metaclass=abc.ABCMeta` to define abstract base classes
(ABCs).

## Why is this bad?

Instead of `class C(metaclass=abc.ABCMeta): ...`, use `class C(ABC): ...`
to define an abstract base class. Inheriting from the `ABC` wrapper class
is semantically identical to setting `metaclass=abc.ABCMeta`, but more
succinct.

## Example
```python
import abc


class C(metaclass=abc.ABCMeta):
    pass
```

Use instead:
```python
import abc


class C(abc.ABC):
    pass
```

## Fix safety
The rule's fix is unsafe if the class has base classes. This is because the base classes might
be validating the class's other base classes (e.g., `typing.Protocol` does this) or otherwise
alter runtime behavior if more base classes are added.

## References
- [Python documentation: `abc.ABC`](https://docs.python.org/3/library/abc.html#abc.ABC)
- [Python documentation: `abc.ABCMeta`](https://docs.python.org/3/library/abc.html#abc.ABCMeta)

# hashlib-digest-hex (FURB181)

Derived from the **refurb** linter.

Fix is sometimes available.

## What it does
Checks for the use of `.digest().hex()` on a hashlib hash, like `sha512`.

## Why is this bad?
When generating a hex digest from a hash, it's preferable to use the
`.hexdigest()` method, rather than calling `.digest()` and then `.hex()`,
as the former is more concise and readable.

## Example
```python
from hashlib import sha512

hashed = sha512(b"some data").digest().hex()
```

Use instead:
```python
from hashlib import sha512

hashed = sha512(b"some data").hexdigest()
```

## References
- [Python documentation: `hashlib`](https://docs.python.org/3/library/hashlib.html)

# list-reverse-copy (FURB187)

Derived from the **refurb** linter.

Fix is always available.

## What it does
Checks for list reversals that can be performed in-place in lieu of
creating a new list.

## Why is this bad?
When reversing a list, it's more efficient to use the in-place method
`.reverse()` instead of creating a new list, if the original list is
no longer needed.

## Example
```python
l = [1, 2, 3]
l = reversed(l)

l = [1, 2, 3]
l = list(reversed(l))

l = [1, 2, 3]
l = l[::-1]
```

Use instead:
```python
l = [1, 2, 3]
l.reverse()
```

## Fix safety
This rule's fix is marked as unsafe, as calling `.reverse()` on a list
will mutate the list in-place, unlike `reversed`, which creates a new list
and leaves the original list unchanged.

If the list is referenced elsewhere, this could lead to unexpected
behavior.

## References
- [Python documentation: More on Lists](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists)

# slice-to-remove-prefix-or-suffix (FURB188)

Derived from the **refurb** linter.

Fix is always available.

## What it does
Checks for code that could be written more idiomatically using
[`str.removeprefix()`](https://docs.python.org/3/library/stdtypes.html#str.removeprefix)
or [`str.removesuffix()`](https://docs.python.org/3/library/stdtypes.html#str.removesuffix).

Specifically, the rule flags code that conditionally removes a prefix or suffix
using a slice operation following an `if` test that uses `str.startswith()` or `str.endswith()`.

The rule is only applied if your project targets Python 3.9 or later.

## Why is this bad?
The methods [`str.removeprefix()`](https://docs.python.org/3/library/stdtypes.html#str.removeprefix)
and [`str.removesuffix()`](https://docs.python.org/3/library/stdtypes.html#str.removesuffix),
introduced in Python 3.9, have the same behavior while being more readable and efficient.

## Example
```python
def example(filename: str, text: str):
    filename = filename[:-4] if filename.endswith(".txt") else filename

    if text.startswith("pre"):
        text = text[3:]
```

Use instead:
```python
def example(filename: str, text: str):
    filename = filename.removesuffix(".txt")
    text = text.removeprefix("pre")
```

# subclass-builtin (FURB189)

Derived from the **refurb** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for subclasses of `dict`, `list` or `str`.

## Why is this bad?
Built-in types don't consistently use their own dunder methods. For example,
`dict.__init__` and `dict.update()` bypass `__setitem__`, making inheritance unreliable.

Use the `UserDict`, `UserList`, and `UserString` objects from the `collections` module
instead.

## Example

```python
class UppercaseDict(dict):
    def __setitem__(self, key, value):
        super().__setitem__(key.upper(), value)


d = UppercaseDict({"a": 1, "b": 2})  # Bypasses __setitem__
print(d)  # {'a': 1, 'b': 2}
```

Use instead:

```python
from collections import UserDict


class UppercaseDict(UserDict):
    def __setitem__(self, key, value):
        super().__setitem__(key.upper(), value)


d = UppercaseDict({"a": 1, "b": 2})  # Uses __setitem__
print(d)  # {'A': 1, 'B': 2}
```

## Fix safety
This fix is marked as unsafe because `isinstance()` checks for `dict`,
`list`, and `str` types will fail when using the corresponding User class.
If you need to pass custom `dict` or `list` objects to code you don't
control, ignore this check. If you do control the code, consider using
the following type checks instead:

* `dict` -> `collections.abc.MutableMapping`
* `list` -> `collections.abc.MutableSequence`
* `str` -> No such conversion exists

## References

- [Python documentation: `collections`](https://docs.python.org/3/library/collections.html)

# sorted-min-max (FURB192)

Derived from the **refurb** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for uses of `sorted()` to retrieve the minimum or maximum value in
a sequence.

## Why is this bad?
Using `sorted()` to compute the minimum or maximum value in a sequence is
inefficient and less readable than using `min()` or `max()` directly.

## Example
```python
nums = [3, 1, 4, 1, 5]
lowest = sorted(nums)[0]
highest = sorted(nums)[-1]
highest = sorted(nums, reverse=True)[0]
```

Use instead:
```python
nums = [3, 1, 4, 1, 5]
lowest = min(nums)
highest = max(nums)
```

## Fix safety
In some cases, migrating to `min` or `max` can lead to a change in behavior,
notably when breaking ties.

As an example, `sorted(data, key=itemgetter(0), reverse=True)[0]` will return
the _last_ "minimum" element in the list, if there are multiple elements with
the same key. However, `min(data, key=itemgetter(0))` will return the _first_
"minimum" element in the list in the same scenario.

As such, this rule's fix is marked as unsafe when the `reverse` keyword is used.

## References
- [Python documentation: `min`](https://docs.python.org/3/library/functions.html#min)
- [Python documentation: `max`](https://docs.python.org/3/library/functions.html#max)

# ambiguous-unicode-character-string (RUF001)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for ambiguous Unicode characters in strings.

## Why is this bad?
Some Unicode characters are visually similar to ASCII characters, but have
different code points. For example, `GREEK CAPITAL LETTER ALPHA` (`U+0391`)
is visually similar, but not identical, to the ASCII character `A`.

The use of ambiguous Unicode characters can confuse readers, cause subtle
bugs, and even make malicious code look harmless.

In [preview], this rule will also flag Unicode characters that are
confusable with other, non-preferred Unicode characters. For example, the
spec recommends `GREEK CAPITAL LETTER OMEGA` over `OHM SIGN`.

You can omit characters from being flagged as ambiguous via the
[`lint.allowed-confusables`] setting.

## Example
```python
print("ello, world!")  # "" is the Greek eta (`U+0397`).
```

Use instead:
```python
print("Hello, world!")  # "H" is the Latin capital H (`U+0048`).
```

## Options
- `lint.allowed-confusables`

[preview]: https://docs.astral.sh/ruff/preview/

# ambiguous-unicode-character-docstring (RUF002)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for ambiguous Unicode characters in docstrings.

## Why is this bad?
Some Unicode characters are visually similar to ASCII characters, but have
different code points. For example, `GREEK CAPITAL LETTER ALPHA` (`U+0391`)
is visually similar, but not identical, to the ASCII character `A`.

The use of ambiguous Unicode characters can confuse readers, cause subtle
bugs, and even make malicious code look harmless.

In [preview], this rule will also flag Unicode characters that are
confusable with other, non-preferred Unicode characters. For example, the
spec recommends `GREEK CAPITAL LETTER OMEGA` over `OHM SIGN`.

You can omit characters from being flagged as ambiguous via the
[`lint.allowed-confusables`] setting.

## Example
```python
"""A lovely docstring (with a `U+FF09` parenthesis."""
```

Use instead:
```python
"""A lovely docstring (with no strange parentheses)."""
```

## Options
- `lint.allowed-confusables`

[preview]: https://docs.astral.sh/ruff/preview/

# ambiguous-unicode-character-comment (RUF003)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for ambiguous Unicode characters in comments.

## Why is this bad?
Some Unicode characters are visually similar to ASCII characters, but have
different code points. For example, `GREEK CAPITAL LETTER ALPHA` (`U+0391`)
is visually similar, but not identical, to the ASCII character `A`.

The use of ambiguous Unicode characters can confuse readers, cause subtle
bugs, and even make malicious code look harmless.

In [preview], this rule will also flag Unicode characters that are
confusable with other, non-preferred Unicode characters. For example, the
spec recommends `GREEK CAPITAL LETTER OMEGA` over `OHM SIGN`.

You can omit characters from being flagged as ambiguous via the
[`lint.allowed-confusables`] setting.

## Example
```python
foo()  # nqa  # "" is Cyrillic (`U+043E`)
```

Use instead:
```python
foo()  # noqa  # "o" is Latin (`U+006F`)
```

## Options
- `lint.allowed-confusables`

[preview]: https://docs.astral.sh/ruff/preview/

# collection-literal-concatenation (RUF005)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for uses of the `+` operator to concatenate collections.

## Why is this bad?
In Python, the `+` operator can be used to concatenate collections (e.g.,
`x + y` to concatenate the lists `x` and `y`).

However, collections can be concatenated more efficiently using the
unpacking operator (e.g., `[*x, *y]` to concatenate `x` and `y`).

Prefer the unpacking operator to concatenate collections, as it is more
readable and flexible. The `*` operator can unpack any iterable, whereas
 `+` operates only on particular sequences which, in many cases, must be of
the same type.

## Example
```python
foo = [2, 3, 4]
bar = [1] + foo + [5, 6]
```

Use instead:
```python
foo = [2, 3, 4]
bar = [1, *foo, 5, 6]
```

## Fix safety

The fix is always marked as unsafe because the `+` operator uses the `__add__` magic method and
`*`-unpacking uses the `__iter__` magic method. Both of these could have custom
implementations, causing the fix to change program behaviour.

## References
- [PEP 448  Additional Unpacking Generalizations](https://peps.python.org/pep-0448/)
- [Python documentation: Sequence Types  `list`, `tuple`, `range`](https://docs.python.org/3/library/stdtypes.html#sequence-types-list-tuple-range)

# asyncio-dangling-task (RUF006)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for `asyncio.create_task` and `asyncio.ensure_future` calls
that do not store a reference to the returned result.

## Why is this bad?
Per the `asyncio` documentation, the event loop only retains a weak
reference to tasks. If the task returned by `asyncio.create_task` and
`asyncio.ensure_future` is not stored in a variable, or a collection,
or otherwise referenced, it may be garbage collected at any time. This
can lead to unexpected and inconsistent behavior, as your tasks may or
may not run to completion.

## Example
```python
import asyncio

for i in range(10):
    # This creates a weak reference to the task, which may be garbage
    # collected at any time.
    asyncio.create_task(some_coro(param=i))
```

Use instead:
```python
import asyncio

background_tasks = set()

for i in range(10):
    task = asyncio.create_task(some_coro(param=i))

    # Add task to the set. This creates a strong reference.
    background_tasks.add(task)

    # To prevent keeping references to finished tasks forever,
    # make each task remove its own reference from the set after
    # completion:
    task.add_done_callback(background_tasks.discard)
```

## References
- [_The Heisenbug lurking in your async code_](https://textual.textualize.io/blog/2023/02/11/the-heisenbug-lurking-in-your-async-code/)
- [The Python Standard Library](https://docs.python.org/3/library/asyncio-task.html#asyncio.create_task)

# zip-instead-of-pairwise (RUF007)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for use of `zip()` to iterate over successive pairs of elements.

## Why is this bad?
When iterating over successive pairs of elements, prefer
`itertools.pairwise()` over `zip()`.

`itertools.pairwise()` is more readable and conveys the intent of the code
more clearly.

## Example
```python
letters = "ABCD"
zip(letters, letters[1:])  # ("A", "B"), ("B", "C"), ("C", "D")
```

Use instead:
```python
from itertools import pairwise

letters = "ABCD"
pairwise(letters)  # ("A", "B"), ("B", "C"), ("C", "D")
```

## Fix safety

The fix is always marked unsafe because it assumes that slicing an object
(e.g., `obj[1:]`) produces a value with the same type and iteration behavior
as the original object, which is not guaranteed for user-defined types that
override `__getitem__` without properly handling slices. Moreover, the fix
could delete comments.

## References
- [Python documentation: `itertools.pairwise`](https://docs.python.org/3/library/itertools.html#itertools.pairwise)

# mutable-dataclass-default (RUF008)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for mutable default values in dataclass attributes.

## Why is this bad?
Mutable default values share state across all instances of the dataclass.
This can lead to bugs when the attributes are changed in one instance, as
those changes will unexpectedly affect all other instances.

Instead of sharing mutable defaults, use the `field(default_factory=...)`
pattern.

If the default value is intended to be mutable, it must be annotated with
`typing.ClassVar`; otherwise, a `ValueError` will be raised.

## Example
```python
from dataclasses import dataclass


@dataclass
class A:
    # A list without a `default_factory` or `ClassVar` annotation
    # will raise a `ValueError`.
    mutable_default: list[int] = []
```

Use instead:
```python
from dataclasses import dataclass, field


@dataclass
class A:
    mutable_default: list[int] = field(default_factory=list)
```

Or:
```python
from dataclasses import dataclass
from typing import ClassVar


@dataclass
class A:
    mutable_default: ClassVar[list[int]] = []
```

# function-call-in-dataclass-default-argument (RUF009)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for function calls in dataclass attribute defaults.

## Why is this bad?
Function calls are only performed once, at definition time. The returned
value is then reused by all instances of the dataclass. This can lead to
unexpected behavior when the function call returns a mutable object, as
changes to the object will be shared across all instances.

If a field needs to be initialized with a mutable object, use the
`field(default_factory=...)` pattern.

Attributes whose default arguments are `NewType` calls
where the original type is immutable are ignored.

## Example
```python
from dataclasses import dataclass


def simple_list() -> list[int]:
    return [1, 2, 3, 4]


@dataclass
class A:
    mutable_default: list[int] = simple_list()
```

Use instead:
```python
from dataclasses import dataclass, field


def creating_list() -> list[int]:
    return [1, 2, 3, 4]


@dataclass
class A:
    mutable_default: list[int] = field(default_factory=creating_list)
```

## Options
- `lint.flake8-bugbear.extend-immutable-calls`

# explicit-f-string-type-conversion (RUF010)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for uses of `str()`, `repr()`, and `ascii()` as explicit type
conversions within f-strings.

## Why is this bad?
f-strings support dedicated conversion flags for these types, which are
more succinct and idiomatic.

Note that, in many cases, calling `str()` within an f-string is
unnecessary and can be removed entirely, as the value will be converted
to a string automatically, the notable exception being for classes that
implement a custom `__format__` method.

## Example
```python
a = "some string"
f"{repr(a)}"
```

Use instead:
```python
a = "some string"
f"{a!r}"
```

# ruff-static-key-dict-comprehension (RUF011)

Derived from the **Ruff-specific rules** linter.

## Removed
This rule was implemented in `flake8-bugbear` and has been remapped to [B035]

## What it does
Checks for dictionary comprehensions that use a static key, like a string
literal or a variable defined outside the comprehension.

## Why is this bad?
Using a static key (like a string literal) in a dictionary comprehension
is usually a mistake, as it will result in a dictionary with only one key,
despite the comprehension iterating over multiple values.

## Example
```python
data = ["some", "Data"]
{"key": value.upper() for value in data}
```

Use instead:
```python
data = ["some", "Data"]
{value: value.upper() for value in data}
```

[B035]: https://docs.astral.sh/ruff/rules/static-key-dict-comprehension/

# mutable-class-default (RUF012)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for mutable default values in class attributes.

## Why is this bad?
Mutable default values share state across all instances of the class,
while not being obvious. This can lead to bugs when the attributes are
changed in one instance, as those changes will unexpectedly affect all
other instances.

Generally speaking, you probably want to avoid having mutable default
values in the class body at all; instead, these variables should usually
be initialized in `__init__`. However, other possible fixes for the issue
can include:
- Explicitly annotating the variable with [`typing.ClassVar`][ClassVar] to
  indicate that it is intended to be shared across all instances.
- Using an immutable data type (e.g. a tuple instead of a list)
  for the default value.

## Example

```python
class A:
    variable_1: list[int] = []
    variable_2: set[int] = set()
    variable_3: dict[str, int] = {}
```

Use instead:

```python
class A:
    def __init__(self) -> None:
        self.variable_1: list[int] = []
        self.variable_2: set[int] = set()
        self.variable_3: dict[str, int] = {}
```

Or:

```python
from typing import ClassVar


class A:
    variable_1: ClassVar[list[int]] = []
    variable_2: ClassVar[set[int]] = set()
    variable_3: ClassVar[dict[str, int]] = {}
```

Or:

```python
class A:
    variable_1: list[int] | None = None
    variable_2: set[int] | None = None
    variable_3: dict[str, int] | None = None
```

Or:

```python
from collections.abc import Sequence, Mapping, Set as AbstractSet
from types import MappingProxyType


class A:
    variable_1: Sequence[int] = ()
    variable_2: AbstractSet[int] = frozenset()
    variable_3: Mapping[str, int] = MappingProxyType({})
```

[ClassVar]: https://docs.python.org/3/library/typing.html#typing.ClassVar

# implicit-optional (RUF013)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for the use of implicit `Optional` in type annotations when the
default parameter value is `None`.

If [`lint.future-annotations`] is set to `true`, `from __future__ import
annotations` will be added if doing so would allow using the `|` operator on
a Python version before 3.10.

## Why is this bad?
Implicit `Optional` is prohibited by [PEP 484]. It is confusing and
inconsistent with the rest of the type system.

It's recommended to use `Optional[T]` instead. For Python 3.10 and later,
you can also use `T | None`.

## Example
```python
def foo(arg: int = None):
    pass
```

Use instead:
```python
from typing import Optional


def foo(arg: Optional[int] = None):
    pass
```

Or, for Python 3.10 and later:
```python
def foo(arg: int | None = None):
    pass
```

If you want to use the `|` operator in Python 3.9 and earlier, you can
use future imports:
```python
from __future__ import annotations


def foo(arg: int | None = None):
    pass
```

## Limitations

Type aliases are not supported and could result in false negatives.
For example, the following code will not be flagged:
```python
Text = str | bytes


def foo(arg: Text = None):
    pass
```

## Options
- `target-version`
- `lint.future-annotations`

## Fix safety

This fix is always marked as unsafe because it can change the behavior of code that relies on
type hints, and it assumes the default value is always appropriatewhich might not be the case.

[PEP 484]: https://peps.python.org/pep-0484/#union-types

# unnecessary-iterable-allocation-for-first-element (RUF015)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks the following constructs, all of which can be replaced by
`next(iter(...))`:

- `list(...)[0]`
- `tuple(...)[0]`
- `list(i for i in ...)[0]`
- `[i for i in ...][0]`
- `list(...).pop(0)`

## Why is this bad?
Calling e.g. `list(...)` will create a new list of the entire collection,
which can be very expensive for large collections. If you only need the
first element of the collection, you can use `next(...)` or
`next(iter(...)` to lazily fetch the first element. The same is true for
the other constructs.

## Example
```python
head = list(x)[0]
head = [x * x for x in range(10)][0]
```

Use instead:
```python
head = next(iter(x))
head = next(x * x for x in range(10))
```

## Fix safety
This rule's fix is marked as unsafe, as migrating from (e.g.) `list(...)[0]`
to `next(iter(...))` can change the behavior of your program in two ways:

1. First, all above-mentioned constructs will eagerly evaluate the entire
   collection, while `next(iter(...))` will only evaluate the first
   element. As such, any side effects that occur during iteration will be
   delayed.
2. Second, accessing members of a collection via square bracket notation
   `[0]` or the `pop()` function will raise `IndexError` if the collection
   is empty, while `next(iter(...))` will raise `StopIteration`.

## References
- [Iterators and Iterables in Python: Run Efficient Iterations](https://realpython.com/python-iterators-iterables/#when-to-use-an-iterator-in-python)

# invalid-index-type (RUF016)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for indexed access to lists, strings, tuples, bytes, and comprehensions
using a type other than an integer or slice.

## Why is this bad?
Only integers or slices can be used as indices to these types. Using
other types will result in a `TypeError` at runtime and a `SyntaxWarning` at
import time.

## Example
```python
var = [1, 2, 3]["x"]
```

Use instead:
```python
var = [1, 2, 3][0]
```

# quadratic-list-summation (RUF017)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks for the use of `sum()` to flatten lists of lists, which has
quadratic complexity.

## Why is this bad?
The use of `sum()` to flatten lists of lists is quadratic in the number of
lists, as `sum()` creates a new list for each element in the summation.

Instead, consider using another method of flattening lists to avoid
quadratic complexity. The following methods are all linear in the number of
lists:

- `functools.reduce(operator.iadd, lists, [])`
- `list(itertools.chain.from_iterable(lists))`
- `[item for sublist in lists for item in sublist]`

When fixing relevant violations, Ruff defaults to the `functools.reduce`
form, which outperforms the other methods in [microbenchmarks].

## Example
```python
lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
joined = sum(lists, [])
```

Use instead:
```python
import functools
import operator


lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
functools.reduce(operator.iadd, lists, [])
```

## Fix safety

This fix is always marked as unsafe because `sum` uses the `__add__` magic method while
`operator.iadd` uses the `__iadd__` magic method, and these behave differently on lists.
The former requires the right summand to be a list, whereas the latter allows for any iterable.
Therefore, the fix could inadvertently cause code that previously raised an error to silently
succeed. Moreover, the fix could remove comments from the original code.

## References
- [_How Not to Flatten a List of Lists in Python_](https://mathieularose.com/how-not-to-flatten-a-list-of-lists-in-python)
- [_How do I make a flat list out of a list of lists?_](https://stackoverflow.com/questions/952914/how-do-i-make-a-flat-list-out-of-a-list-of-lists/953097#953097)

[microbenchmarks]: https://github.com/astral-sh/ruff/issues/5073#issuecomment-1591836349

# assignment-in-assert (RUF018)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for named assignment expressions (e.g., `x := 0`) in `assert`
statements.

## Why is this bad?
Named assignment expressions (also known as "walrus operators") are used to
assign a value to a variable as part of a larger expression.

Named assignments are syntactically valid in `assert` statements. However,
when the Python interpreter is run under the `-O` flag, `assert` statements
are not executed. In this case, the named assignment will also be ignored,
which may result in unexpected behavior (e.g., undefined variable
accesses).

## Example
```python
assert (x := 0) == 0
print(x)
```

Use instead:
```python
x = 0
assert x == 0
print(x)
```

The rule avoids flagging named expressions that define variables which are
only referenced from inside `assert` statements; the following will not
trigger the rule:
```python
assert (x := y**2) > 42, f"Expected >42 but got {x}"
```

Nor will this:
```python
assert (x := y**2) > 42
assert x < 1_000_000
```

## References
- [Python documentation: `-O`](https://docs.python.org/3/using/cmdline.html#cmdoption-O)

# unnecessary-key-check (RUF019)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks for unnecessary key checks prior to accessing a dictionary.

## Why is this bad?
When working with dictionaries, the `get` can be used to access a value
without having to check if the dictionary contains the relevant key,
returning `None` if the key is not present.

## Example
```python
if "key" in dct and dct["key"]:
    ...
```

Use instead:
```python
if dct.get("key"):
    ...
```

# never-union (RUF020)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for uses of `typing.NoReturn` and `typing.Never` in union types.

## Why is this bad?
`typing.NoReturn` and `typing.Never` are special types, used to indicate
that a function never returns, or that a type has no values.

Including `typing.NoReturn` or `typing.Never` in a union type is redundant,
as, e.g., `typing.Never | T` is equivalent to `T`.

## Example

```python
from typing import Never


def func() -> Never | int: ...
```

Use instead:

```python
def func() -> int: ...
```

## References
- [Python documentation: `typing.Never`](https://docs.python.org/3/library/typing.html#typing.Never)
- [Python documentation: `typing.NoReturn`](https://docs.python.org/3/library/typing.html#typing.NoReturn)

# parenthesize-chained-operators (RUF021)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks for chained operators where adding parentheses could improve the
clarity of the code.

## Why is this bad?
`and` always binds more tightly than `or` when chaining the two together,
but this can be hard to remember (and sometimes surprising).
Adding parentheses in these situations can greatly improve code readability,
with no change to semantics or performance.

For example:
```python
a, b, c = 1, 0, 2
x = a or b and c

d, e, f = 0, 1, 2
y = d and e or f
```

Use instead:
```python
a, b, c = 1, 0, 2
x = a or (b and c)

d, e, f = 0, 1, 2
y = (d and e) or f
```

# unsorted-dunder-all (RUF022)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for `__all__` definitions that are not ordered
according to an "isort-style" sort.

An isort-style sort orders items first according to their casing:
SCREAMING_SNAKE_CASE names (conventionally used for global constants)
come first, followed by CamelCase names (conventionally used for
classes), followed by anything else. Within each category,
a [natural sort](https://en.wikipedia.org/wiki/Natural_sort_order)
is used to order the elements.

## Why is this bad?
Consistency is good. Use a common convention for `__all__` to make your
code more readable and idiomatic.

## Example
```python
import sys

__all__ = [
    "b",
    "c",
    "a",
]

if sys.platform == "win32":
    __all__ += ["z", "y"]
```

Use instead:
```python
import sys

__all__ = [
    "a",
    "b",
    "c",
]

if sys.platform == "win32":
    __all__ += ["y", "z"]
```

## Fix safety
This rule's fix is marked as unsafe if there are any comments that take up
a whole line by themselves inside the `__all__` definition, for example:
```py
__all__ = [
    # eggy things
    "duck_eggs",
    "chicken_eggs",
    # hammy things
    "country_ham",
    "parma_ham",
]
```

This is a common pattern used to delimit categories within a module's API,
but it would be out of the scope of this rule to attempt to maintain these
categories when alphabetically sorting the items of `__all__`.

The fix is also marked as unsafe if there are more than two `__all__` items
on a single line and that line also has a trailing comment, since here it
is impossible to accurately gauge which item the comment should be moved
with when sorting `__all__`:
```py
__all__ = [
    "a", "c", "e",  # a comment
    "b", "d", "f",  # a second  comment
]
```

Other than this, the rule's fix is marked as always being safe, in that
it should very rarely alter the semantics of any Python code.
However, note that (although it's rare) the value of `__all__`
could be read by code elsewhere that depends on the exact
iteration order of the items in `__all__`, in which case this
rule's fix could theoretically cause breakage.

# unsorted-dunder-slots (RUF023)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for `__slots__` definitions that are not ordered according to a
[natural sort](https://en.wikipedia.org/wiki/Natural_sort_order).

## Why is this bad?
Consistency is good. Use a common convention for this special variable
to make your code more readable and idiomatic.

## Example
```python
class Dog:
    __slots__ = "name", "breed"
```

Use instead:
```python
class Dog:
    __slots__ = "breed", "name"
```

## Fix safety
This rule's fix is marked as unsafe in three situations.

Firstly, the fix is unsafe if there are any comments that take up
a whole line by themselves inside the `__slots__` definition, for example:
```py
class Foo:
    __slots__ = [
        # eggy things
        "duck_eggs",
        "chicken_eggs",
        # hammy things
        "country_ham",
        "parma_ham",
    ]
```

This is a common pattern used to delimit categories within a class's slots,
but it would be out of the scope of this rule to attempt to maintain these
categories when applying a natural sort to the items of `__slots__`.

Secondly, the fix is also marked as unsafe if there are more than two
`__slots__` items on a single line and that line also has a trailing
comment, since here it is impossible to accurately gauge which item the
comment should be moved with when sorting `__slots__`:
```py
class Bar:
    __slots__ = [
        "a", "c", "e",  # a comment
        "b", "d", "f",  # a second  comment
    ]
```

Lastly, this rule's fix is marked as unsafe whenever Ruff can detect that
code elsewhere in the same file reads the `__slots__` variable in some way
and the `__slots__` variable is not assigned to a set. This is because the
order of the items in `__slots__` may have semantic significance if the
`__slots__` of a class is being iterated over, or being assigned to another
value.

In the vast majority of other cases, this rule's fix is unlikely to
cause breakage; as such, Ruff will otherwise mark this rule's fix as
safe. However, note that (although it's rare) the value of `__slots__`
could still be read by code outside of the module in which the
`__slots__` definition occurs, in which case this rule's fix could
theoretically cause breakage.

# mutable-fromkeys-value (RUF024)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for mutable objects passed as a value argument to `dict.fromkeys`.

## Why is this bad?
All values in the dictionary created by the `dict.fromkeys` method
refer to the same instance of the provided object. If that object is
modified, all values are modified, which can lead to unexpected behavior.
For example, if the empty list (`[]`) is provided as the default value,
all values in the dictionary will use the same list; as such, appending to
any one entry will append to all entries.

Instead, use a comprehension to generate a dictionary with distinct
instances of the default value.

## Example
```python
cities = dict.fromkeys(["UK", "Poland"], [])
cities["UK"].append("London")
cities["Poland"].append("Poznan")
print(cities)  # {'UK': ['London', 'Poznan'], 'Poland': ['London', 'Poznan']}
```

Use instead:
```python
cities = {country: [] for country in ["UK", "Poland"]}
cities["UK"].append("London")
cities["Poland"].append("Poznan")
print(cities)  # {'UK': ['London'], 'Poland': ['Poznan']}
```

## Fix safety
This rule's fix is marked as unsafe, as the edit will change the behavior of
the program by using a distinct object for every value in the dictionary,
rather than a shared mutable instance. In some cases, programs may rely on
the previous behavior.

## References
- [Python documentation: `dict.fromkeys`](https://docs.python.org/3/library/stdtypes.html#dict.fromkeys)

# default-factory-kwarg (RUF026)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for incorrect usages of `default_factory` as a keyword argument when
initializing a `defaultdict`.

## Why is this bad?
The `defaultdict` constructor accepts a callable as its first argument.
For example, it's common to initialize a `defaultdict` with `int` or `list`
via `defaultdict(int)` or `defaultdict(list)`, to create a dictionary that
returns `0` or `[]` respectively when a key is missing.

The default factory _must_ be provided as a positional argument, as all
keyword arguments to `defaultdict` are interpreted as initial entries in
the dictionary. For example, `defaultdict(foo=1, bar=2)` will create a
dictionary with `{"foo": 1, "bar": 2}` as its initial entries.

As such, `defaultdict(default_factory=list)` will create a dictionary with
`{"default_factory": list}` as its initial entry, instead of a dictionary
that returns `[]` when a key is missing. Specifying a `default_factory`
keyword argument is almost always a mistake, and one that type checkers
can't reliably detect.

## Fix safety
This rule's fix is marked as unsafe, as converting `default_factory` from a
keyword to a positional argument will change the behavior of the code, even
if the keyword argument was used erroneously.

## Example
```python
defaultdict(default_factory=int)
defaultdict(default_factory=list)
```

Use instead:
```python
defaultdict(int)
defaultdict(list)
```

# missing-f-string-syntax (RUF027)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Searches for strings that look like they were meant to be f-strings, but are missing an `f` prefix.

## Why is this bad?
Expressions inside curly braces are only evaluated if the string has an `f` prefix.

## Details

There are many possible string literals which are not meant to be f-strings
despite containing f-string-like syntax. As such, this lint ignores all strings
where one of the following conditions applies:

1. The string is a standalone expression. For example, the rule ignores all docstrings.
2. The string is part of a function call with argument names that match at least one variable
   (for example: `format("Message: {value}", value="Hello World")`)
3. The string (or a parent expression of the string) has a direct method call on it
   (for example: `"{value}".format(...)`)
4. The string has no `{...}` expression sections, or uses invalid f-string syntax.
5. The string references variables that are not in scope, or it doesn't capture variables at all.
6. Any format specifiers in the potential f-string are invalid.
7. The string is part of a function call that is known to expect a template string rather than an
   evaluated f-string: for example, a [`logging`][logging] call, a [`gettext`][gettext] call,
   or a [FastAPI path].

## Example

```python
name = "Sarah"
day_of_week = "Tuesday"
print("Hello {name}! It is {day_of_week} today!")
```

Use instead:
```python
name = "Sarah"
day_of_week = "Tuesday"
print(f"Hello {name}! It is {day_of_week} today!")
```

## Fix safety

This fix will always change the behavior of the program and, despite the precautions detailed
above, this may be undesired. As such the fix is always marked as unsafe.

[logging]: https://docs.python.org/3/howto/logging-cookbook.html#using-particular-formatting-styles-throughout-your-application
[gettext]: https://docs.python.org/3/library/gettext.html
[FastAPI path]: https://fastapi.tiangolo.com/tutorial/path-params/

# invalid-formatter-suppression-comment (RUF028)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks for formatter suppression comments that are ineffective or incompatible
with Ruff's formatter.

## Why is this bad?
Suppression comments that do not actually prevent formatting could cause unintended changes
when the formatter is run.

## Example
In the following example, all suppression comments would cause
a rule violation.

```python
def decorator():
    pass


@decorator
# fmt: off
def example():
    if True:
        # fmt: skip
        expression = [
            # fmt: off
            1,
            2,
        ]
        # yapf: disable
    # fmt: on
    # yapf: enable
```

## Fix safety

This fix is always marked as unsafe because it deletes the invalid suppression comment,
rather than trying to move it to a valid position, which the user more likely intended.

# unused-async (RUF029)

Derived from the **Ruff-specific rules** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for functions declared `async` that do not await or otherwise use features requiring the
function to be declared `async`.

## Why is this bad?
Declaring a function `async` when it's not is usually a mistake, and will artificially limit the
contexts where that function may be called. In some cases, labeling a function `async` is
semantically meaningful (e.g. with the trio library).

## Example
```python
async def foo():
    bar()
```

Use instead:
```python
def foo():
    bar()
```

# assert-with-print-message (RUF030)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks for uses of `assert expression, print(message)`.

## Why is this bad?
If an `assert x, y` assertion fails, the Python interpreter raises an
`AssertionError`, and the evaluated value of `y` is used as the contents of
that assertion error. The `print` function always returns `None`, however,
so the evaluated value of a call to `print` will always be `None`.

Using a `print` call in this context will therefore output the message to
`stdout`, before raising an empty `AssertionError(None)`. Instead, remove
the `print` and pass the message directly as the second expression,
allowing `stderr` to capture the message in a well-formatted context.

## Example
```python
assert False, print("This is a message")
```

Use instead:
```python
assert False, "This is a message"
```

## Fix safety
This rule's fix is marked as unsafe, as changing the second expression
will result in a different `AssertionError` message being raised, as well as
a change in `stdout` output.

## References
- [Python documentation: `assert`](https://docs.python.org/3/reference/simple_stmts.html#the-assert-statement)

# incorrectly-parenthesized-tuple-in-subscript (RUF031)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for consistent style regarding whether nonempty tuples in subscripts
are parenthesized.

The exact nature of this violation depends on the setting
[`lint.ruff.parenthesize-tuple-in-subscript`]. By default, the use of
parentheses is considered a violation.

This rule is not applied inside "typing contexts" (type annotations,
type aliases and subscripted class bases), as these have their own specific
conventions around them.

## Why is this bad?
It is good to be consistent and, depending on the codebase, one or the other
convention may be preferred.

## Example

```python
directions = {(0, 1): "North", (1, 0): "East", (0, -1): "South", (-1, 0): "West"}
directions[(0, 1)]
```

Use instead (with default setting):

```python
directions = {(0, 1): "North", (1, 0): "East", (0, -1): "South", (-1, 0): "West"}
directions[0, 1]
```

## Options
- `lint.ruff.parenthesize-tuple-in-subscript`

# decimal-from-float-literal (RUF032)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks for `Decimal` calls passing a float literal.

## Why is this bad?
Float literals have limited precision that can lead to unexpected results.
The `Decimal` class is designed to handle numbers with fixed-point precision,
so a string literal should be used instead.

## Example

```python
num = Decimal(1.2345)
```

Use instead:
```python
num = Decimal("1.2345")
```

## Fix safety
This rule's fix is marked as unsafe because it changes the underlying value
of the `Decimal` instance that is constructed. This can lead to unexpected
behavior if your program relies on the previous value (whether deliberately or not).

# post-init-default (RUF033)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for `__post_init__` dataclass methods with parameter defaults.

## Why is this bad?
Adding a default value to a parameter in a `__post_init__` method has no
impact on whether the parameter will have a default value in the dataclass's
generated `__init__` method. To create an init-only dataclass parameter with
a default value, you should use an `InitVar` field in the dataclass's class
body and give that `InitVar` field a default value.

As the [documentation] states:

> Init-only fields are added as parameters to the generated `__init__()`
> method, and are passed to the optional `__post_init__()` method. They are
> not otherwise used by dataclasses.

## Example
```python
from dataclasses import InitVar, dataclass


@dataclass
class Foo:
    bar: InitVar[int] = 0

    def __post_init__(self, bar: int = 1, baz: int = 2) -> None:
        print(bar, baz)


foo = Foo()  # Prints '0 2'.
```

Use instead:
```python
from dataclasses import InitVar, dataclass


@dataclass
class Foo:
    bar: InitVar[int] = 1
    baz: InitVar[int] = 2

    def __post_init__(self, bar: int, baz: int) -> None:
        print(bar, baz)


foo = Foo()  # Prints '1 2'.
```

## Fix safety

This fix is always marked as unsafe because, although switching to `InitVar` is usually correct,
it is incorrect when the parameter is not intended to be part of the public API or when the value
is meant to be shared across all instances.

## References
- [Python documentation: Post-init processing](https://docs.python.org/3/library/dataclasses.html#post-init-processing)
- [Python documentation: Init-only variables](https://docs.python.org/3/library/dataclasses.html#init-only-variables)

[documentation]: https://docs.python.org/3/library/dataclasses.html#init-only-variables

# useless-if-else (RUF034)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for useless `if`-`else` conditions with identical arms.

## Why is this bad?
Useless `if`-`else` conditions add unnecessary complexity to the code without
providing any logical benefit. Assigning the value directly is clearer.

## Example
```python
foo = x if y else x
```

Use instead:
```python
foo = x
```

# ruff-unsafe-markup-use (RUF035)

Derived from the **Ruff-specific rules** linter.

## Removed
This rule was implemented in `bandit` and has been remapped to
[S704](unsafe-markup-use.md)

## What it does
Checks for non-literal strings being passed to [`markupsafe.Markup`][markupsafe-markup].

## Why is this bad?
[`markupsafe.Markup`][markupsafe-markup] does not perform any escaping,
so passing dynamic content, like f-strings, variables or interpolated strings
will potentially lead to XSS vulnerabilities.

Instead you should interpolate the `Markup` object.

Using [`lint.flake8-bandit.extend-markup-names`] additional objects can be
treated like `Markup`.

This rule was originally inspired by [flake8-markupsafe] but doesn't carve
out any exceptions for i18n related calls by default.

You can use [`lint.flake8-bandit.allowed-markup-calls`] to specify exceptions.

## Example
Given:
```python
from markupsafe import Markup

content = "<script>alert('Hello, world!')</script>"
html = Markup(f"<b>{content}</b>")  # XSS
```

Use instead:
```python
from markupsafe import Markup

content = "<script>alert('Hello, world!')</script>"
html = Markup("<b>{}</b>").format(content)  # Safe
```

Given:
```python
from markupsafe import Markup

lines = [
    Markup("<b>heading</b>"),
    "<script>alert('XSS attempt')</script>",
]
html = Markup("<br>".join(lines))  # XSS
```

Use instead:
```python
from markupsafe import Markup

lines = [
    Markup("<b>heading</b>"),
    "<script>alert('XSS attempt')</script>",
]
html = Markup("<br>").join(lines)  # Safe
```
## Options
- `lint.flake8-bandit.extend-markup-names`
- `lint.flake8-bandit.allowed-markup-calls`

## References
- [MarkupSafe on PyPI](https://pypi.org/project/MarkupSafe/)
- [`markupsafe.Markup` API documentation](https://markupsafe.palletsprojects.com/en/stable/escaping/#markupsafe.Markup)

[markupsafe-markup]: https://markupsafe.palletsprojects.com/en/stable/escaping/#markupsafe.Markup
[flake8-markupsafe]: https://github.com/vmagamedov/flake8-markupsafe

# none-not-at-end-of-union (RUF036)

Derived from the **Ruff-specific rules** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for type annotations where `None` is not at the end of an union.

## Why is this bad?
Type annotation unions are commutative, meaning that the order of the elements
does not matter. The `None` literal represents the absence of a value. For
readability, it's preferred to write the more informative type expressions first.

## Example
```python
def func(arg: None | int): ...
```

Use instead:
```python
def func(arg: int | None): ...
```

## References
- [Python documentation: Union type](https://docs.python.org/3/library/stdtypes.html#types-union)
- [Python documentation: `typing.Optional`](https://docs.python.org/3/library/typing.html#typing.Optional)
- [Python documentation: `None`](https://docs.python.org/3/library/constants.html#None)

# unnecessary-empty-iterable-within-deque-call (RUF037)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for usages of `collections.deque` that have an empty iterable as the first argument.

## Why is this bad?
It's unnecessary to use an empty literal as a deque's iterable, since this is already the default behavior.

## Example

```python
from collections import deque

queue = deque(set())
queue = deque([], 10)
```

Use instead:

```python
from collections import deque

queue = deque()
queue = deque(maxlen=10)
```

## Fix safety

The fix is marked as unsafe whenever it would delete comments present in the `deque` call or if
there are unrecognized arguments other than `iterable` and `maxlen`.

## Fix availability

This rule's fix is unavailable if any starred arguments are present after the initial iterable.

## References
- [Python documentation: `collections.deque`](https://docs.python.org/3/library/collections.html#collections.deque)

# redundant-bool-literal (RUF038)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for `Literal[True, False]` type annotations.

## Why is this bad?
`Literal[True, False]` can be replaced with `bool` in type annotations,
which has the same semantic meaning but is more concise and readable.

`bool` type has exactly two constant instances: `True` and `False`. Static
type checkers such as [mypy] treat `Literal[True, False]` as equivalent to
`bool` in a type annotation.

## Example
```python
from typing import Literal

x: Literal[True, False]
y: Literal[True, False, "hello", "world"]
```

Use instead:
```python
from typing import Literal

x: bool
y: Literal["hello", "world"] | bool
```

## Fix safety
The fix for this rule is marked as unsafe, as it may change the semantics of the code.
Specifically:

- Type checkers may not treat `bool` as equivalent when overloading boolean arguments
  with `Literal[True]` and `Literal[False]` (see, e.g., [#14764] and [#5421]).
- `bool` is not strictly equivalent to `Literal[True, False]`, as `bool` is
  a subclass of `int`, and this rule may not apply if the type annotations are used
  in a numeric context.

Further, the `Literal` slice may contain trailing-line comments which the fix would remove.

## References
- [Typing documentation: Legal parameters for `Literal` at type check time](https://typing.python.org/en/latest/spec/literal.html#legal-parameters-for-literal-at-type-check-time)
- [Python documentation: Boolean type - `bool`](https://docs.python.org/3/library/stdtypes.html#boolean-type-bool)

[mypy]: https://github.com/python/mypy/blob/master/mypy/typeops.py#L985
[#14764]: https://github.com/python/mypy/issues/14764
[#5421]: https://github.com/microsoft/pyright/issues/5421

# unraw-re-pattern (RUF039)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Reports the following `re` and `regex` calls when
their first arguments are not raw strings:

- For `regex` and `re`: `compile`, `findall`, `finditer`,
  `fullmatch`, `match`, `search`, `split`, `sub`, `subn`.
- `regex`-specific: `splititer`, `subf`, `subfn`, `template`.

## Why is this bad?
Regular expressions should be written
using raw strings to avoid double escaping.

## Fix safety
The fix is unsafe if the string/bytes literal contains an escape sequence because the fix alters
the runtime value of the literal while retaining the regex semantics.

For example
```python
# Literal is `1\n2`.
re.compile("1\n2")

# Literal is `1\\n2`, but the regex library will interpret `\\n` and will still match a newline
# character as before.
re.compile(r"1\n2")
```

## Fix availability
 A fix is not available if either
 * the argument is a string with a (no-op) `u` prefix (e.g., `u"foo"`) as the prefix is
   incompatible with the raw prefix `r`
 * the argument is a string or bytes literal with an escape sequence that has a different
   meaning in the context of a regular expression such as `\b`, which is word boundary or
   backspace in a regex, depending on the context, but always a backspace in string and bytes
   literals.

## Example

```python
re.compile("foo\\bar")
```

Use instead:

```python
re.compile(r"foo\bar")
```

# invalid-assert-message-literal-argument (RUF040)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for invalid use of literals in assert message arguments.

## Why is this bad?
An assert message which is a non-string literal was likely intended
to be used in a comparison assertion, rather than as a message.

## Example
```python
fruits = ["apples", "plums", "pears"]
fruits.filter(lambda fruit: fruit.startwith("p"))
assert len(fruits), 2  # True unless the list is empty
```

Use instead:
```python
fruits = ["apples", "plums", "pears"]
fruits.filter(lambda fruit: fruit.startwith("p"))
assert len(fruits) == 2
```

# unnecessary-nested-literal (RUF041)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for unnecessary nested `Literal`.

## Why is this bad?
Prefer using a single `Literal`, which is equivalent and more concise.

Parameterization of literals by other literals is supported as an ergonomic
feature as proposed in [PEP 586], to enable patterns such as:
```python
ReadOnlyMode         = Literal["r", "r+"]
WriteAndTruncateMode = Literal["w", "w+", "wt", "w+t"]
WriteNoTruncateMode  = Literal["r+", "r+t"]
AppendMode           = Literal["a", "a+", "at", "a+t"]

AllModes = Literal[ReadOnlyMode, WriteAndTruncateMode,
                  WriteNoTruncateMode, AppendMode]
```

As a consequence, type checkers also support nesting of literals
which is less readable than a flat `Literal`:
```python
AllModes = Literal[Literal["r", "r+"], Literal["w", "w+", "wt", "w+t"],
                  Literal["r+", "r+t"], Literal["a", "a+", "at", "a+t"]]
```

## Example
```python
AllModes = Literal[
    Literal["r", "r+"],
    Literal["w", "w+", "wt", "w+t"],
    Literal["r+", "r+t"],
    Literal["a", "a+", "at", "a+t"],
]
```

Use instead:
```python
AllModes = Literal[
    "r", "r+", "w", "w+", "wt", "w+t", "r+", "r+t", "a", "a+", "at", "a+t"
]
```

or assign the literal to a variable as in the first example.

## Fix safety
The fix for this rule is marked as unsafe when the `Literal` slice is split
across multiple lines and some of the lines have trailing comments.

## References
- [Typing documentation: Legal parameters for `Literal` at type check time](https://typing.python.org/en/latest/spec/literal.html#legal-parameters-for-literal-at-type-check-time)

[PEP 586](https://peps.python.org/pep-0586/)

# pytest-raises-ambiguous-pattern (RUF043)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for non-raw literal string arguments passed to the `match` parameter
of `pytest.raises()` where the string contains at least one unescaped
regex metacharacter.

## Why is this bad?
The `match` argument is implicitly converted to a regex under the hood.
It should be made explicit whether the string is meant to be a regex or a "plain" pattern
by prefixing the string with the `r` suffix, escaping the metacharacter(s)
in the string using backslashes, or wrapping the entire string in a call to
`re.escape()`.

## Example

```python
import pytest


with pytest.raises(Exception, match="A full sentence."):
    do_thing_that_raises()
```

If the pattern is intended to be a regular expression, use a raw string to signal this
intention:

```python
import pytest


with pytest.raises(Exception, match=r"A full sentence."):
    do_thing_that_raises()
```

Alternatively, escape any regex metacharacters with `re.escape`:

```python
import pytest
import re


with pytest.raises(Exception, match=re.escape("A full sentence.")):
    do_thing_that_raises()
```

or directly with backslashes:

```python
import pytest
import re


with pytest.raises(Exception, "A full sentence\\."):
    do_thing_that_raises()
```

## References
- [Python documentation: `re.escape`](https://docs.python.org/3/library/re.html#re.escape)
- [`pytest` documentation: `pytest.raises`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-raises)

# implicit-class-var-in-dataclass (RUF045)

Derived from the **Ruff-specific rules** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for implicit class variables in dataclasses.

Variables matching the [`lint.dummy-variable-rgx`] are excluded
from this rule.

## Why is this bad?
Class variables are shared between all instances of that class.
In dataclasses, fields with no annotations at all
are implicitly considered class variables, and a `TypeError` is
raised if a user attempts to initialize an instance of the class
with this field.


```python
@dataclass
class C:
    a = 1
    b: str = ""

C(a = 42)  # TypeError: C.__init__() got an unexpected keyword argument 'a'
```

## Example

```python
@dataclass
class C:
    a = 1
```

Use instead:

```python
from typing import ClassVar


@dataclass
class C:
    a: ClassVar[int] = 1
```

## Options
- [`lint.dummy-variable-rgx`]

# unnecessary-cast-to-int (RUF046)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks for `int` conversions of values that are already integers.

## Why is this bad?
Such a conversion is unnecessary.

## Known problems
This rule may produce false positives for `round`, `math.ceil`, `math.floor`,
and `math.trunc` calls when values override the `__round__`, `__ceil__`, `__floor__`,
or `__trunc__` operators such that they don't return an integer.

## Example

```python
int(len([]))
int(round(foo, None))
```

Use instead:

```python
len([])
round(foo)
```

## Fix safety
The fix for `round`, `math.ceil`, `math.floor`, and `math.truncate` is unsafe
because removing the `int` conversion can change the semantics for values
overriding the `__round__`, `__ceil__`, `__floor__`, or `__trunc__` dunder methods
such that they don't return an integer.

# needless-else (RUF047)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for `else` clauses that only contains `pass` and `...` statements.

## Why is this bad?
Such an else clause does nothing and can be removed.

## Example
```python
if foo:
    bar()
else:
    pass
```

Use instead:
```python
if foo:
    bar()
```

# map-int-version-parsing (RUF048)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for calls of the form `map(int, __version__.split("."))`.

## Why is this bad?
`__version__` does not always contain integral-like elements.

```python
import matplotlib  # `__version__ == "3.9.1.post-1"` in our environment

# ValueError: invalid literal for int() with base 10: 'post1'
tuple(map(int, matplotlib.__version__.split(".")))
```

See also [*Version specifiers* | Packaging spec][version-specifier].

## Example
```python
tuple(map(int, matplotlib.__version__.split(".")))
```

Use instead:
```python
import packaging.version as version

version.parse(matplotlib.__version__)
```

[version-specifier]: https://packaging.python.org/en/latest/specifications/version-specifiers/#version-specifiers

# dataclass-enum (RUF049)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for enum classes which are also decorated with `@dataclass`.

## Why is this bad?
Decorating an enum with `@dataclass()` does not cause any errors at runtime,
but may cause erroneous results:

```python
@dataclass
class E(Enum):
    A = 1
    B = 2

print(E.A == E.B)  # True
```

## Example

```python
from dataclasses import dataclass
from enum import Enum


@dataclass
class E(Enum): ...
```

Use instead:

```python
from enum import Enum


class E(Enum): ...
```

## References
- [Python documentation: Enum HOWTO &sect; Dataclass support](https://docs.python.org/3/howto/enum.html#dataclass-support)

# if-key-in-dict-del (RUF051)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks for `if key in dictionary: del dictionary[key]`.

## Why is this bad?
To remove a key-value pair from a dictionary, it's more concise to use `.pop(..., None)`.

## Example

```python
if key in dictionary:
    del dictionary[key]
```

Use instead:

```python
dictionary.pop(key, None)
```

## Fix safety
This rule's fix is marked as safe, unless the if statement contains comments.

# used-dummy-variable (RUF052)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for "dummy variables" (variables that are named as if to indicate they are unused)
that are in fact used.

By default, "dummy variables" are any variables with names that start with leading
underscores. However, this is customisable using the [`lint.dummy-variable-rgx`] setting).

## Why is this bad?
Marking a variable with a leading underscore conveys that it is intentionally unused within the function or method.
When these variables are later referenced in the code, it causes confusion and potential misunderstandings about
the code's intention. If a variable marked as "unused" is subsequently used, it suggests that either the variable
could be given a clearer name, or that the code is accidentally making use of the wrong variable.

Sometimes leading underscores are used to avoid variables shadowing other variables, Python builtins, or Python
keywords. However, [PEP 8] recommends to use trailing underscores for this rather than leading underscores.

Dunder variables are ignored by this rule, as are variables named `_`.
Only local variables in function scopes are flagged by the rule.

## Example
```python
def function():
    _variable = 3
    # important: avoid shadowing the builtin `id()` function!
    _id = 4
    return _variable + _id
```

Use instead:
```python
def function():
    variable = 3
    # important: avoid shadowing the builtin `id()` function!
    id_ = 4
    return variable + id_
```

## Fix availability
The rule's fix is only available for variables that start with leading underscores.
It will also only be available if the "obvious" new name for the variable
would not shadow any other known variables already accessible from the scope
in which the variable is defined.

## Fix safety
This rule's fix is marked as unsafe.

For this rule's fix, Ruff renames the variable and fixes up all known references to
it so they point to the renamed variable. However, some renamings also require other
changes such as different arguments to constructor calls or alterations to comments.
Ruff is aware of some of these cases: `_T = TypeVar("_T")` will be fixed to
`T = TypeVar("T")` if the `_T` binding is flagged by this rule. However, in general,
cases like these are hard to detect and hard to automatically fix.

## Options
- [`lint.dummy-variable-rgx`]

[PEP 8]: https://peps.python.org/pep-0008/

# class-with-mixed-type-vars (RUF053)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for classes that have [PEP 695] [type parameter lists]
while also inheriting from `typing.Generic` or `typing_extensions.Generic`.

## Why is this bad?
Such classes cause errors at runtime:

```python
from typing import Generic, TypeVar

U = TypeVar("U")

# TypeError: Cannot inherit from Generic[...] multiple times.
class C[T](Generic[U]): ...
```

## Example

```python
from typing import Generic, ParamSpec, TypeVar, TypeVarTuple

U = TypeVar("U")
P = ParamSpec("P")
Ts = TypeVarTuple("Ts")


class C[T](Generic[U, P, *Ts]): ...
```

Use instead:

```python
class C[T, U, **P, *Ts]: ...
```

## Fix safety
As the fix changes runtime behaviour, it is always marked as unsafe.
Additionally, comments within the fix range will not be preserved.

## References
- [Python documentation: User-defined generic types](https://docs.python.org/3/library/typing.html#user-defined-generic-types)
- [Python documentation: type parameter lists](https://docs.python.org/3/reference/compound_stmts.html#type-params)
- [PEP 695 - Type Parameter Syntax](https://peps.python.org/pep-0695/)

[PEP 695]: https://peps.python.org/pep-0695/
[type parameter lists]: https://docs.python.org/3/reference/compound_stmts.html#type-params

# indented-form-feed (RUF054)

Derived from the **Ruff-specific rules** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for form feed characters preceded by either a space or a tab.

## Why is this bad?
[The language reference][lexical-analysis-indentation] states:

> A formfeed character may be present at the start of the line;
> it will be ignored for the indentation calculations above.
> Formfeed characters occurring elsewhere in the leading whitespace
> have an undefined effect (for instance, they may reset the space count to zero).

## Example

```python
if foo():\n    \fbar()
```

Use instead:

```python
if foo():\n    bar()
```

[lexical-analysis-indentation]: https://docs.python.org/3/reference/lexical_analysis.html#indentation

# unnecessary-regular-expression (RUF055)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does

Checks for uses of the `re` module that can be replaced with builtin `str` methods.

## Why is this bad?

Performing checks on strings directly can make the code simpler, may require
less escaping, and will often be faster.

## Example

```python
re.sub("abc", "", s)
```

Use instead:

```python
s.replace("abc", "")
```

## Details

The rule reports the following calls when the first argument to the call is
a plain string literal, and no additional flags are passed:

- `re.sub`
- `re.match`
- `re.search`
- `re.fullmatch`
- `re.split`

For `re.sub`, the `repl` (replacement) argument must also be a string literal,
not a function. For `re.match`, `re.search`, and `re.fullmatch`, the return
value must also be used only for its truth value.

## Fix safety

This rule's fix is marked as unsafe if the affected expression contains comments. Otherwise,
the fix can be applied safely.

## References
- [Python Regular Expression HOWTO: Common Problems - Use String Methods](https://docs.python.org/3/howto/regex.html#use-string-methods)

# falsy-dict-get-fallback (RUF056)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for `dict.get(key, falsy_value)` calls in boolean test positions.

## Why is this bad?
The default fallback `None` is already falsy.

## Example

```python
if dict.get(key, False):
    ...
```

Use instead:

```python
if dict.get(key):
    ...
```

## Fix safety

This rule's fix is marked as safe, unless the `dict.get()` call contains comments between
arguments that will be deleted.

## Fix availability

This rule's fix is unavailable in cases where invalid arguments are provided to `dict.get`. As
shown in the [documentation], `dict.get` takes two positional-only arguments, so invalid cases
are identified by the presence of more than two arguments or any keyword arguments.

[documentation]: https://docs.python.org/3.13/library/stdtypes.html#dict.get

# unnecessary-round (RUF057)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks for `round()` calls that have no effect on the input.

## Why is this bad?
Rounding a value that's already an integer is unnecessary.
It's clearer to use the value directly.

## Example

```python
a = round(1, 0)
```

Use instead:

```python
a = 1
```

## Fix safety

The fix is marked unsafe if it is not possible to guarantee that the first argument of
`round()` is of type `int`, or if the fix deletes comments.

# starmap-zip (RUF058)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for `itertools.starmap` calls where the second argument is a `zip` call.

## Why is this bad?
`zip`-ping iterables only to unpack them later from within `starmap` is unnecessary.
For such cases, `map()` should be used instead.

## Example

```python
from itertools import starmap


starmap(func, zip(a, b))
starmap(func, zip(a, b, strict=True))
```

Use instead:

```python
map(func, a, b)
map(func, a, b, strict=True)  # 3.14+
```

## Fix safety

This rule's fix is marked as unsafe if the `starmap` or `zip` expressions contain comments that
would be deleted by applying the fix. Otherwise, the fix can be applied safely.

## Fix availability

This rule will emit a diagnostic but not suggest a fix if `map` has been shadowed from its
builtin binding.

# unused-unpacked-variable (RUF059)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

## What it does
Checks for the presence of unused variables in unpacked assignments.

## Why is this bad?
A variable that is defined but never used can confuse readers.

If a variable is intentionally defined-but-not-used, it should be
prefixed with an underscore, or some other value that adheres to the
[`lint.dummy-variable-rgx`] pattern.

## Example

```python
def get_pair():
    return 1, 2


def foo():
    x, y = get_pair()
    return x
```

Use instead:

```python
def foo():
    x, _ = get_pair()
    return x
```

## See also

This rule applies only to unpacked assignments. For regular assignments, see
[`unused-variable`][F841].

## Options
- `lint.dummy-variable-rgx`

[F841]: https://docs.astral.sh/ruff/rules/unused-variable/

# in-empty-collection (RUF060)

Derived from the **Ruff-specific rules** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for membership tests on empty collections (such as `list`, `tuple`, `set` or `dict`).

## Why is this bad?
If the collection is always empty, the check is unnecessary, and can be removed.

## Example

```python
if 1 not in set():
    print("got it!")
```

Use instead:

```python
print("got it!")
```

# legacy-form-pytest-raises (RUF061)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for non-contextmanager use of `pytest.raises`, `pytest.warns`, and `pytest.deprecated_call`.

## Why is this bad?
The context-manager form is more readable, easier to extend, and supports additional kwargs.

## Example
```python
import pytest


excinfo = pytest.raises(ValueError, int, "hello")
pytest.warns(UserWarning, my_function, arg)
pytest.deprecated_call(my_deprecated_function, arg1, arg2)
```

Use instead:
```python
import pytest


with pytest.raises(ValueError) as excinfo:
    int("hello")
with pytest.warns(UserWarning):
    my_function(arg)
with pytest.deprecated_call():
    my_deprecated_function(arg1, arg2)
```

## References
- [`pytest` documentation: `pytest.raises`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-raises)
- [`pytest` documentation: `pytest.warns`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-warns)
- [`pytest` documentation: `pytest.deprecated_call`](https://docs.pytest.org/en/latest/reference/reference.html#pytest-deprecated-call)

# access-annotations-from-class-dict (RUF063)

Derived from the **Ruff-specific rules** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for uses of `foo.__dict__.get("__annotations__")` or
`foo.__dict__["__annotations__"]` on Python 3.10+ and Python < 3.10 when
[typing-extensions](https://docs.astral.sh/ruff/settings/#lint_typing-extensions)
is enabled.

## Why is this bad?
Starting with Python 3.14, directly accessing `__annotations__` via
`foo.__dict__.get("__annotations__")` or `foo.__dict__["__annotations__"]`
will only return annotations if the class is defined under
`from __future__ import annotations`.

Therefore, it is better to use dedicated library functions like
`annotationlib.get_annotations` (Python 3.14+), `inspect.get_annotations`
(Python 3.10+), or `typing_extensions.get_annotations` (for Python < 3.10 if
[typing-extensions](https://pypi.org/project/typing-extensions/) is
available).

The benefits of using these functions include:
1.  **Avoiding Undocumented Internals:** They provide a stable, public API,
    unlike direct `__dict__` access which relies on implementation details.
2.  **Forward-Compatibility:** They are designed to handle changes in
    Python's annotation system across versions, ensuring your code remains
    robust (e.g., correctly handling the Python 3.14 behavior mentioned
    above).

See [Python Annotations Best Practices](https://docs.python.org/3.14/howto/annotations.html)
for alternatives.

## Example

```python
foo.__dict__.get("__annotations__", {})
# or
foo.__dict__["__annotations__"]
```

On Python 3.14+, use instead:
```python
import annotationlib

annotationlib.get_annotations(foo)
```

On Python 3.10+, use instead:
```python
import inspect

inspect.get_annotations(foo)
```

On Python < 3.10 with [typing-extensions](https://pypi.org/project/typing-extensions/)
installed, use instead:
```python
import typing_extensions

typing_extensions.get_annotations(foo)
```

## Fix safety

No autofix is currently provided for this rule.

## Fix availability

No autofix is currently provided for this rule.

## References
- [Python Annotations Best Practices](https://docs.python.org/3.14/howto/annotations.html)

# non-octal-permissions (RUF064)

Derived from the **Ruff-specific rules** linter.

Fix is sometimes available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for standard library functions which take a numeric `mode` argument
where a non-octal integer literal is passed.

## Why is this bad?

Numeric modes are made up of one to four octal digits. Converting a non-octal
integer to octal may not be the mode the author intended.

## Example

```python
os.chmod("foo", 644)
```

Use instead:

```python
os.chmod("foo", 0o644)
```

## Fix safety

There are two categories of fix, the first of which is where it looks like
the author intended to use an octal literal but the `0o` prefix is missing:

```python
os.chmod("foo", 400)
os.chmod("foo", 644)
```

This class of fix changes runtime behaviour. In the first case, `400`
corresponds to `0o620` (`u=rw,g=w,o=`). As this mode is not deemed likely,
it is changed to `0o400` (`u=r,go=`). Similarly, `644` corresponds to
`0o1204` (`u=ws,g=,o=r`) and is changed to `0o644` (`u=rw,go=r`).

The second category is decimal literals which are recognised as likely valid
but in decimal form:

```python
os.chmod("foo", 256)
os.chmod("foo", 493)
```

`256` corresponds to `0o400` (`u=r,go=`) and `493` corresponds to `0o755`
(`u=rwx,go=rx`). Both of these fixes keep runtime behavior unchanged. If the
original code really intended to use `0o256` (`u=w,g=rx,o=rw`) instead of
`256`, this fix should not be accepted.

As a special case, zero is allowed to omit the `0o` prefix unless it has
multiple digits:

```python
os.chmod("foo", 0)  # Ok
os.chmod("foo", 0o000)  # Ok
os.chmod("foo", 000)  # Lint emitted and fix suggested
```

Ruff will suggest a safe fix for multi-digit zeros to add the `0o` prefix.

## Fix availability

A fix is only available if the integer literal matches a set of common modes.

# logging-eager-conversion (RUF065)

Derived from the **Ruff-specific rules** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for eager string conversion of arguments to `logging` calls.

## Why is this bad?
Arguments to `logging` calls will be formatted as strings automatically, so it
is unnecessary and less efficient to eagerly format the arguments before passing
them in.

## Known problems

This rule detects uses of the `logging` module via a heuristic.
Specifically, it matches against:

- Uses of the `logging` module itself (e.g., `import logging; logging.info(...)`).
- Uses of `flask.current_app.logger` (e.g., `from flask import current_app; current_app.logger.info(...)`).
- Objects whose name starts with `log` or ends with `logger` or `logging`,
  when used in the same file in which they are defined (e.g., `logger = logging.getLogger(); logger.info(...)`).
- Imported objects marked as loggers via the [`lint.logger-objects`] setting, which can be
  used to enforce these rules against shared logger objects (e.g., `from module import logger; logger.info(...)`,
  when [`lint.logger-objects`] is set to `["module.logger"]`).

## Example
```python
import logging

logging.basicConfig(format="%(message)s", level=logging.INFO)

user = "Maria"

logging.info("%s - Something happened", str(user))
```

Use instead:
```python
import logging

logging.basicConfig(format="%(message)s", level=logging.INFO)

user = "Maria"

logging.info("%s - Something happened", user)
```

## Options
- `lint.logger-objects`

## References
- [Python documentation: `logging`](https://docs.python.org/3/library/logging.html)
- [Python documentation: Optimization](https://docs.python.org/3/howto/logging.html#optimization)

# property-without-return (RUF066)

Derived from the **Ruff-specific rules** linter.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Detects class `@property` methods that does not have a `return` statement.

## Why is this bad?
Property methods are expected to return a computed value, a missing return in a property usually indicates an implementation mistake.

## Example
```python
class User:
    @property
    def full_name(self):
        f"{self.first_name} {self.last_name}"
```

Use instead:
```python
class User:
    @property
    def full_name(self):
        return f"{self.first_name} {self.last_name}"
```

## References
- [Python documentation: The property class](https://docs.python.org/3/library/functions.html#property)

# unused-noqa (RUF100)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks for `noqa` directives that are no longer applicable.

## Why is this bad?
A `noqa` directive that no longer matches any diagnostic violations is
likely included by mistake, and should be removed to avoid confusion.

## Example
```python
import foo  # noqa: F401


def bar():
    foo.bar()
```

Use instead:
```python
import foo


def bar():
    foo.bar()
```

## Options
- `lint.external`

## References
- [Ruff error suppression](https://docs.astral.sh/ruff/linter/#error-suppression)

# redirected-noqa (RUF101)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

## What it does
Checks for `noqa` directives that use redirected rule codes.

## Why is this bad?
When one of Ruff's rule codes has been redirected, the implication is that the rule has
been deprecated in favor of another rule or code. To keep your codebase
consistent and up-to-date, prefer the canonical rule code over the deprecated
code.

## Example
```python
x = eval(command)  # noqa: PGH001
```

Use instead:
```python
x = eval(command)  # noqa: S307
```

# invalid-rule-code (RUF102)

Derived from the **Ruff-specific rules** linter.

Fix is always available.

This rule is in preview and is not stable. The `--preview` flag is required for use.

## What it does
Checks for `noqa` codes that are invalid.

## Why is this bad?
Invalid rule codes serve no purpose and may indicate outdated code suppressions.

## Example
```python
import os  # noqa: XYZ999
```

Use instead:
```python
import os
```

Or if there are still valid codes needed:
```python
import os  # noqa: E402
```

## Options
- `lint.external`

# invalid-pyproject-toml (RUF200)

Derived from the **Ruff-specific rules** linter.

## What it does
Checks for any pyproject.toml that does not conform to the schema from the relevant PEPs.

## Why is this bad?
Your project may contain invalid metadata or configuration without you noticing

## Example
```toml
[project]
name = "crab"
version = "1.0.0"
authors = ["Ferris the Crab <ferris@example.org>"]
```

Use instead:
```toml
[project]
name = "crab"
version = "1.0.0"
authors = [
  { name = "Ferris the Crab", email = "ferris@example.org" }
]
```

## References
- [Specification of `[project]` in pyproject.toml](https://packaging.python.org/en/latest/specifications/declaring-project-metadata/)
- [Specification of `[build-system]` in pyproject.toml](https://peps.python.org/pep-0518/)
- [Draft but implemented license declaration extensions](https://peps.python.org/pep-0639)

# raise-vanilla-class (TRY002)

Derived from the **tryceratops** linter.

## What it does
Checks for code that raises `Exception` or `BaseException` directly.

## Why is this bad?
Handling such exceptions requires the use of `except Exception` or
`except BaseException`. These will capture almost _any_ raised exception,
including failed assertions, division by zero, and more.

Prefer to raise your own exception, or a more specific built-in
exception, so that you can avoid over-capturing exceptions that you
don't intend to handle.

## Example
```python
def main_function():
    if not cond:
        raise Exception()


def consumer_func():
    try:
        do_step()
        prepare()
        main_function()
    except Exception:
        logger.error("Oops")
```

Use instead:
```python
def main_function():
    if not cond:
        raise CustomException()


def consumer_func():
    try:
        do_step()
        prepare()
        main_function()
    except CustomException:
        logger.error("Main function failed")
    except Exception:
        logger.error("Oops")
```

# raise-vanilla-args (TRY003)

Derived from the **tryceratops** linter.

## What it does
Checks for long exception messages that are not defined in the exception
class itself.

## Why is this bad?
By formatting an exception message at the `raise` site, the exception class
becomes less reusable, and may now raise inconsistent messages depending on
where it is raised.

If the exception message is instead defined within the exception class, it
will be consistent across all `raise` invocations.

This rule is not enforced for some built-in exceptions that are commonly
raised with a message and would be unusual to subclass, such as
`NotImplementedError`.

## Example
```python
class CantBeNegative(Exception):
    pass


def foo(x):
    if x < 0:
        raise CantBeNegative(f"{x} is negative")
```

Use instead:
```python
class CantBeNegative(Exception):
    def __init__(self, number):
        super().__init__(f"{number} is negative")


def foo(x):
    if x < 0:
        raise CantBeNegative(x)
```

# type-check-without-type-error (TRY004)

Derived from the **tryceratops** linter.

## What it does
Checks for type checks that do not raise `TypeError`.

## Why is this bad?
The Python documentation states that `TypeError` should be raised upon
encountering an inappropriate type.

## Example
```python
def foo(n: int):
    if isinstance(n, int):
        pass
    else:
        raise ValueError("n must be an integer")
```

Use instead:
```python
def foo(n: int):
    if isinstance(n, int):
        pass
    else:
        raise TypeError("n must be an integer")
```

## References
- [Python documentation: `TypeError`](https://docs.python.org/3/library/exceptions.html#TypeError)

# reraise-no-cause (TRY200)

Derived from the **tryceratops** linter.

## Removed
This rule is identical to [B904] which should be used instead.

## What it does
Checks for exceptions that are re-raised without specifying the cause via
the `from` keyword.

## Why is this bad?
The `from` keyword sets the `__cause__` attribute of the exception, which
stores the "cause" of the exception. The availability of an exception
"cause" is useful for debugging.

## Example
```python
def reciprocal(n):
    try:
        return 1 / n
    except ZeroDivisionError:
        raise ValueError()
```

Use instead:
```python
def reciprocal(n):
    try:
        return 1 / n
    except ZeroDivisionError as exc:
        raise ValueError() from exc
```

## References
- [Python documentation: Exception context](https://docs.python.org/3/library/exceptions.html#exception-context)

[B904]: https://docs.astral.sh/ruff/rules/raise-without-from-inside-except/

# verbose-raise (TRY201)

Derived from the **tryceratops** linter.

Fix is always available.

## What it does
Checks for needless exception names in `raise` statements.

## Why is this bad?
It's redundant to specify the exception name in a `raise` statement if the
exception is being re-raised.

## Example
```python
def foo():
    try:
        ...
    except ValueError as exc:
        raise exc
```

Use instead:
```python
def foo():
    try:
        ...
    except ValueError:
        raise
```

## Fix safety
This rule's fix is marked as unsafe, as it doesn't properly handle bound
exceptions that are shadowed between the `except` and `raise` statements.

# useless-try-except (TRY203)

Derived from the **tryceratops** linter.

## What it does
Checks for immediate uses of `raise` within exception handlers.

## Why is this bad?
Capturing an exception, only to immediately reraise it, has no effect.
Instead, remove the error-handling code and let the exception propagate
upwards without the unnecessary `try`-`except` block.

## Example
```python
def foo():
    try:
        bar()
    except NotImplementedError:
        raise
```

Use instead:
```python
def foo():
    bar()
```

# try-consider-else (TRY300)

Derived from the **tryceratops** linter.

## What it does
Checks for `return` statements in `try` blocks.

## Why is this bad?
The `try`-`except` statement has an `else` clause for code that should
run _only_ if no exceptions were raised. Returns in `try` blocks may
exhibit confusing or unwanted behavior, such as being overridden by
control flow in `except` and `finally` blocks, or unintentionally
suppressing an exception.

## Example
```python
import logging


def reciprocal(n):
    try:
        rec = 1 / n
        print(f"reciprocal of {n} is {rec}")
        return rec
    except ZeroDivisionError:
        logging.exception("Exception occurred")
        raise
```

Use instead:
```python
import logging


def reciprocal(n):
    try:
        rec = 1 / n
    except ZeroDivisionError:
        logging.exception("Exception occurred")
        raise
    else:
        print(f"reciprocal of {n} is {rec}")
        return rec
```

## References
- [Python documentation: Errors and Exceptions](https://docs.python.org/3/tutorial/errors.html)

# raise-within-try (TRY301)

Derived from the **tryceratops** linter.

## What it does
Checks for `raise` statements within `try` blocks. The only `raise`s
caught are those that throw exceptions caught by the `try` statement itself.

## Why is this bad?
Raising and catching exceptions within the same `try` block is redundant,
as the code can be refactored to avoid the `try` block entirely.

Alternatively, the `raise` can be moved within an inner function, making
the exception reusable across multiple call sites.

## Example
```python
def bar():
    pass


def foo():
    try:
        a = bar()
        if not a:
            raise ValueError
    except ValueError:
        raise
```

Use instead:
```python
def bar():
    raise ValueError


def foo():
    try:
        a = bar()  # refactored `bar` to raise `ValueError`
    except ValueError:
        raise
```

# error-instead-of-exception (TRY400)

Derived from the **tryceratops** linter.

Fix is sometimes available.

## What it does
Checks for uses of `logging.error` instead of `logging.exception` when
logging an exception.

## Why is this bad?
`logging.exception` logs the exception and the traceback, while
`logging.error` only logs the exception. The former is more appropriate
when logging an exception, as the traceback is often useful for debugging.

## Example
```python
import logging


def func():
    try:
        raise NotImplementedError
    except NotImplementedError:
        logging.error("Exception occurred")
```

Use instead:
```python
import logging


def func():
    try:
        raise NotImplementedError
    except NotImplementedError:
        logging.exception("Exception occurred")
```

## Fix safety
This rule's fix is marked as safe when run against `logging.error` calls,
but unsafe when marked against other logger-like calls (e.g.,
`logger.error`), since the rule is prone to false positives when detecting
logger-like calls outside of the `logging` module.

## References
- [Python documentation: `logging.exception`](https://docs.python.org/3/library/logging.html#logging.exception)

# verbose-log-message (TRY401)

Derived from the **tryceratops** linter.

## What it does
Checks for excessive logging of exception objects.

## Why is this bad?
When logging exceptions via `logging.exception`, the exception object
is logged automatically. Including the exception object in the log
message is redundant and can lead to excessive logging.

## Example
```python
try:
    ...
except ValueError as e:
    logger.exception(f"Found an error: {e}")
```

Use instead:
```python
try:
    ...
except ValueError:
    logger.exception("Found an error")
```

